[{"title":"【web】Sinopia 构建Windows 本地NPM 仓库","url":"/2019/07/05/【web】sinopia-nssm-yarn构建Windows本地npm仓库/","content":"\n## Sinopia 构建Windows 本地NPM 仓库\n\n### 安装Node 环境\n\n[Downloads](https://nodejs.org/en/download/)\n\n![1.png](1.png)\n\n\n\n### 下载NSSM\n\n[Download](https://www.nssm.cc/download/)\n\n![2.png](2.png)\n\n\n\n### 如何使用NSSM\n\n服务安装命令： `nssm install <servicename>`\n\n参考：\n\n[使用NSSM将exe封装为服务](https://www.cnblogs.com/TianFang/p/7912648.html)\n\n![3.png](3.png)\n\n\n\n### Installing As a Windows Service\n\nPetrik van der Velde edited this page Oct 31, 2017 · [10 revisions](https://github.com/rlidwka/sinopia/wiki/Installing-As-a-Windows-Service/_history)\n\nLoosely based upon the instructions found [here](http://asysadmin.tumblr.com/post/32941224574/running-nginx-on-windows-as-a-service). I crafted the following and it provided me with a fully working sinopia service installation:\n\n1. Create a directory for sinopia\n\n   - `mkdir c:\\sinopia`\n   - `cd c:\\sinopia`\n\n2. Install sinopia locally (I ran into npm issues with global installs)\n\n   - `npm install sinopia`\n\n3. Create your config.yaml file in this location (`c:\\sinopia\\config.yaml`)\n\n4. Windows Service Setup\n\n   #### Using NSSM:\n\n   - Download [NSSM](https://www.nssm.cc/download/) and extract\n\n   - Open an administrative command\n\n   - Browse to the nssm extract location\n\n   - Run `nssm install sinopia` At a minimum you must fill in the *Application* tab Path, Startup directory and Arguments fields. Assuming an install with node in the system path and a location of c:\\sinopia the below values will work:\n\n     - Path: `node`\n     - Startup directory: `c:\\sinopia`\n     - Arguments: `c:\\sinopia\\node_modules\\sinopia\\lib\\cli.js -c c:\\sinopia\\config.yaml`\n\n     You can adjust other service settings under other tabs as desired. When you are done, click *Install service* button\n\n   - Start the service `sc start sinopia`\n\n   #### Using WinSW\n\n   - Download [WinSW](http://repo.jenkins-ci.org/releases/com/sun/winsw/winsw/)\n     - Place the executable (e.g. `winsw-1.19-bin.exe`) into this folder (`c:\\sinopia`) and rename it to `sinopia-winsw.exe`\n   - Create a configuration file in `c:\\sinopia`, named `sinopia-winsw.xml` with the following configuration\n\n```\n<service>\n  <id>sinopia</id>\n  <name>sinopia</name>\n  <description>sinopia</description>\n  <executable>node</executable>\n  <arguments>c:\\sinopia\\node_modules\\sinopia\\lib\\cli.js -c c:\\sinopia\\config.yaml</arguments>\n  <logmode>roll</logmode>\n  <workingdirectory>c:\\sinopia\\</workingdirectory>\n</service>\n```\n\n* Install your service\n    * `cd c:\\sinopia`\n    * `sinopia-winsw.exe install`\n* Start your service\n    * `sinopia-winsw.exe start`\n\nSome of the above config is more verbose than I had expected, it appears as though 'workingdirectory' is ignored, but other than that, this works for me and allows my sinopia instance to persist between restarts of the server, and also restart itself should there be any crashes of the sinopia process.\n\n\n\n### Sinopia 目录结构\n\n![4.png](4.png)\n\n\n\n### Sinopia 配置文件（config.yaml）\n\n```\n#\n# This is the default config file. It allows all users to do anything,\n# so don't use it on production systems.\n#\n# Look here for more config file examples:\n# https://github.com/rlidwka/sinopia/tree/master/conf\n#\n\n# path to a directory with all packages\nstorage: ./storage\n\nauth:\n  htpasswd:\n    file: ./htpasswd\n    # Maximum amount of users allowed to register, defaults to \"+inf\".\n    # You can set this to -1 to disable registration.\n    max_users: 3\n\n# a list of other known repositories we can talk to\nuplinks:\n  npmjs:\n    url: http://registry.npm.taobao.org/\n\npackages:\n  '@*/*':\n    # scoped packages\n    access: $all\n    publish: $authenticated\n\n  '*':\n    # allow all users (including non-authenticated users) to read and\n    # publish all packages\n    #\n    # you can specify usernames/groupnames (depending on your auth plugin)\n    # and three keywords: \"$all\", \"$anonymous\", \"$authenticated\"\n    access: $all\n\n    # allow all known users to publish packages\n    # (anyone can register by default, remember?)\n    publish: $authenticated\n\n    # if package is not available locally, proxy requests to 'npmjs' registry\n    proxy: npmjs\n\n# log settings\nlogs:\n  - {type: stdout, format: pretty, level: http}\n  #- {type: file, path: sinopia.log, level: info}\n\nlisten: 0.0.0.0:4873\n```\n\n","tags":["web","sinopia","nssm"]},{"title":"【随笔】201907","url":"/2019/07/04/【随笔】201907/","content":"\n## 2019-7-4\n\n```\n尽管操作可能会很复杂，但命令的语法始终是：\nawk '{pattern + action}' 或者 awk 'pattern {action}'\n\n注意命令行中的程序是用单引号包围着的。这会防止shell解释程序中 $ 这样的字符，也允许程序的长度超过一行。\n\nsinopia + nssm + yarn 部署Windows 上的Node 仓库\n\n通过python 的socket 模块检测tcp 端口，判断与之对应的服务是否正常\n```\n\n\n\n## 2019-7-2\n\n```\nOOM Killer 的全称叫 Out Of Memory Killer，它是 linux 内核的内存保护机制。当应用程序大量请求内存导致内存不足的时候，通常会触发 OOM Killer，OOM Killer 会根据相对简单粗暴的算法杀掉某个进程以解燃眉之急。如果杀掉一个进程还不足以解决问题，Killer 会按照它对进程的评分，逐次干掉，分数越高，被干掉的几率越大，直到内存可以正常使用。\n```\n\n","tags":["随笔","201907"]},{"title":"【python】通过检测tcp端口来判断服务是否正常","url":"/2019/07/04/【python】通过检测tcp端口来判断服务是否正常/","content":"\n### 通过检测tcp端口来判断服务是否正常\n\n1. 使用socket模块来连接尝试来确定端口是否开放\n2. 如果输入域名，先获取并返回与之对应的IP\n3. 定义常用的端口与服务，以便于一次性检测\n4. 实现本机常用端口的统一检测\n5. 实现远程主机的常用端口统一检测\n6. 开放自定义主机与端口的检测方法\n\n```python\n#!/usr/bin/env python\n\nimport socket\nimport sys\n\nred='\\033[31m'\ngreen='\\033[32m'\nend='\\033[0m'\n\nPorts = [22, 8080, 8443, 8088, 3306, 6379, 61613, 61616, 22122, 23000]\nServices = ['SSH', 'HTTP', 'HTTPS', 'Office', 'MySQL', 'Redis', 'ActiveMQ', 'ActiveMQ', 'Tracker', 'Storage']\n\ndef get_host_by_name(domain):\n    try:\n        return socket.gethostbyname(domain)\n    except socket.error, e:\n        print red + 'error: ' + end + '%s - %s' %(domain, e)\n        return 0 \n\ndef tcp_port_check(ip, port, timeout=1.0):\n    s = socket.socket()\n    s.settimeout(timeout)\n    s.connect((ip, port))\n    s.close()\n\ndef ifs_tcp_port_check(domain):\n    ip = get_host_by_name(domain)\n    if ip:\n        print('*** Host: ' + ip + ' ***')\n        for port,service in zip(Ports,Services):\n            try:\n                tcp_port_check(ip, port)\n                print(green + '[pass] ' + end + service + '(' + str(port) + ')' + ' is up')\n            except:\n                print(red + '[failed] ' + end  + service + '(' + str(port) + ')' + ' is down')\n\ndef sg_tcp_port_check(domain,port):\n    ip = get_host_by_name(domain)\n    if ip:\n        print('*** Host: ' + ip + ' ***')\n        try:\n            tcp_port_check(ip, int(port))\n            print(green + '[pass] ' + end + 'Port ' + port + ' is open')\n        except:\n            print(red + '[failed] ' + end  + 'Port ' + port + ' is down')\n\ndef useage():\n    print(' -l     Check all local services')\n    print(' -r     Check all remote services')\n    print(' -s     Check if the port is open')\n\ndef main():\n    if len(sys.argv) == 2 and sys.argv[1] == '-l':\n        ifs_tcp_port_check('127.0.0.1')\n    elif len(sys.argv) == 3 and sys.argv[1] == '-r':\n        ifs_tcp_port_check(sys.argv[2])\n    elif len(sys.argv) == 4 and sys.argv[1] == '-s':\n        sg_tcp_port_check(sys.argv[2], sys.argv[3])\n    else:\n        useage()\n\nif __name__=='__main__':\n    main()\n\n```\n\n","tags":["python"]},{"title":"【awk】命令回顾 - AWK","url":"/2019/07/04/【awk】命令回顾-AWK/","content":"\n### AWK 语法\n\nawk是一个报告生成器，它拥有强大的文本格式化的能力。\n\nawk [ -F re][parameter...] ['prog'][-f progfile]\n参数说明：\n\n-F re：允许awk更改其字段分隔符。\n\nparameter : 该参数帮助为不同的变量赋值。\n\n'prog' : awk的程序语句段。这个语句段必须用单括号：'和'括起，以防被shell解释。这个程序语句段的标准形式为：\n\n`'pattern {action}'`\n\n其中pattern参数可以是egrep正则表达式中的任何一个，它可以使用语法/re/再加上一些样式匹配技巧构成。与sed类似，你也可以使用\",\" 分开两样式以选择某个范围。关于匹配的细节，你可以参考附录，如果仍不懂的话，找本UNIX书学学grep和sed（本人是在学习sed时掌握匹配技术的）。action参数总是被大括号包围，它由一系列awk语句组成，各语句之间用\";\"分隔。awk解释它们，并在pattern给定的样式匹配的记录上执行其操作。与shell类似，你也可以使用“#”作为注释符，它使“#”到行尾的内容成为注释，在解释执行时，它们将被忽略。你可以省略pattern和 action之一，但不能两者同时省略，当省略pattern时没有样式匹配，表示对所有行（记录）均执行操作，省略action时执行缺省的操作——在标准输出上显示。\n\n-f progfile：允许awk调用并执行progfile指定有程序文件。progfile是一个文本文件，他必须符合awk的语法。\n\nin_file : awk的输入文件，awk允许对多个输入文件进行处理。值得注意的是awk不修改输入文件。如果未指定输入文件，awk将接受标准输入，并将结果显示在标准输出上。awk支持输入输出重定向。\n\n\n\n尽管操作可能会很复杂，但命令的语法始终是：\n\nawk '{pattern + action}' 或者 awk 'pattern {action}'\n\n**注意命令行中的程序是用单引号包围着的。这会防止shell解释程序中 $ 这样的字符，也允许程序的长度超过一行。**\n\n\n\ngrep 、sed、awk 被称为linux 中的 \"三剑客\"。\n\n- grep 更适合单纯的查找或匹配文本\n- sed  更适合编辑匹配到的文本\n- awk  更适合格式化文本，对文本进行较复杂格式处理\n\n\n\n### 内置变量\n\n| **属性**    | **说明**                            |\n| ----------- | ----------------------------------- |\n| $0          | 当前记录（作为单个变量）            |\n| $1~$n       | 当前记录的第n个字段，字段间由FS分隔 |\n| FS          | 输入字段分隔符 默认是空格           |\n| NF          | 当前记录中的字段个数，就是有多少列  |\n| NR          | 已经读出的记录数，就是行号，从1开始 |\n| RS          | 输入的记录他隔符默 认为换行符       |\n| OFS         | 输出字段分隔符 默认也是空格         |\n| ORS         | 输出的记录分隔符，默认为换行符      |\n| ARGC        | 命令行参数个数                      |\n| ARGV        | 命令行参数数组                      |\n| FILENAME    | 当前输入文件的名字                  |\n| IGNORECASE  | 如果为真，则进行忽略大小写的匹配    |\n| ARGIND      | 当前被处理文件的ARGV标志符          |\n| CONVFMT     | 数字转换格式 %.6g                   |\n| ENVIRON     | UNIX环境变量                        |\n| ERRNO       | UNIX系统错误消息                    |\n| FIELDWIDTHS | 输入字段宽度的空白分隔字符串        |\n| FNR         | 当前记录数                          |\n| OFMT        | 数字的输出格式 %.6g                 |\n| RSTART      | 被匹配函数匹配的字符串首            |\n| RLENGTH     | 被匹配函数匹配的字符串长度          |\n| SUBSEP      | \\034                                |\n\n\n\n### 内置字符串函数\n\n| **函数**                            | **说明**                                                     |\n| ----------------------------------- | ------------------------------------------------------------ |\n| gsub( Ere, Repl, [ In ] )           | 除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行，。 |\n| sub( Ere, Repl, [ In ] )            | 用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。 |\n| index( String1, String2 )           | 在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。 |\n| length [(String)]                   | 返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 |\n| blength [(String)]                  | 返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 |\n| substr( String, M, [ N ] )          | 返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。 |\n| match( String, Ere )                | 在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。 |\n| split( String, A, [Ere] )           | 将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。 |\n| tolower( String )                   | 返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 |\n| toupper( String )                   | 返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 |\n| sprintf(Format, Expr, Expr, . . . ) | 根据 Format 参数指定的 [printf](http://www.cnblogs.com/chengmo/admin/zh_CN/libs/basetrf1/printf.htm#a8zed0gaco) 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。 |\n\n\n\n### 字符串格式化\n\n| **格式符** | **说明**                      |\n| ---------- | ----------------------------- |\n| %d         | 十进制有符号整数              |\n| %u         | 十进制无符号整数              |\n| %f         | 浮点数                        |\n| %s         | 字符串                        |\n| %c         | 单个字符                      |\n| %p         | 指针的值                      |\n| %e         | 指数形式的浮点数              |\n| %x         | %X 无符号以十六进制表示的整数 |\n| %o         | 无符号以八进制表示的整数      |\n| %g         | 自动选择合适的表示法          |\n\n\n\n### 实例\n\n操作数据：\n\n```\n[root@host-172-16-2-221 ~]# cat emp.data \nBeth\t4.00\t0\nDan\t3.75\t0\nkathy\t4.00\t10\nMark\t5.00\t20\nMary\t5.50\t22\nSusie\t4.25\t18\n\n```\n\n简单操作：\n\n```\n[root@host-172-16-2-221 ~]# cat pattern \nBEGIN { print \"Name    RATE    HOURS\"; print \"\"}\t# 字符处理开始时执行，可以定义分隔符（FS），定义初始变量等，多条语句用；隔开\n      { print NR \" line\" }\t\t# 行号\n      { print NF \" parts\" }\t\t# 这一行被分为几块\n      { print $NF \" last\" }\t\t# 最后一块内容\n      { print \"length: \" length($1) }\t\t# 第一项长度\n      { print $0 }\t\t# 整行\n      { print \"\" }\t\t# 空行\n      { printf(\"%s-%s-%s\", $1, $2, $3) }\t# 格式化输出1,2,3项\n      { pay += $2 * $3}\t\t# 循环计算\n      { pay = pay + $2 * $3}\t# 同上\n      { names = names $1 \" \"}\t# 字符串连接\nEND   { print \"\"; print \"over~\" \n        print NR, \"employees\"\n        print \"total: \" pay\t\t# 循环结束后的结果\n        print \"average: \" pay/NR\n        print \"Names: \" names\n      }\n\n```\n\n\n\n","tags":["awk"]},{"title":"【onda】Onda obook10 安装CentOS7 系统","url":"/2019/07/01/【onda】Onda-obook10-安装CentOS7-系统/","content":"\n### 问题：U盘安装长时间停留在 starting dracut initqueue hook\n\n1. 安装引导界面按 “e” 进行编辑，修改完成执行 “Ctrl + X”\n\n    ![2.png](2.png)\n\n```\n默认信息：\nsetparams 'Install CentOS Linux 7'\nlinuxefi /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet\ninitrdefi /images/pxeboot/initrd.img\n\n修改为：\nsetparams 'Install CentOS linux 7'\nlinuxefi /images/pxeboot/vmlinuz linux dd nomodeset quiet\ninitrdefi /images/pxeboot/initrd.img\n```\n\n2. 在显示信息中找到优盘设备，比如：sdb4，记住此设备路径\n\n    ![3.png](3.png)\n\n3. 重启，再次按 “e” 进入引导界面，执行编辑，并在修改完成后执行 “Ctrl + X”\n\n```\nsetparams 'Install CentOS Linux 7'\nlinuxefi /images/pxeboot/vmlinuz inst.stage2=hd:/dev/sdb4 nomodeset quiet\ninitrdefi /images/pxeboot/initrd.img\n```\n\n4. 按需求开始正常安装\n\n\n\n ","tags":["onda"]},{"title":"【随笔】201906","url":"/2019/06/30/【随笔】201906/","content":"\n## 2019-6-26\n\n| 查看内核           | uname -a                                                     |\n| ------------------ | ------------------------------------------------------------ |\n| 查看Ubuntu版本     | cat /etc/issue或者lsb_release -a                             |\n| 查看内核加载的模块 | lsmod                                                        |\n| 查看PCI设备        | lspci                                                        |\n| 查看USB设备        | lsusb                                                        |\n| 查看网卡状态       | sudo ethtool eth0                                            |\n| 查看CPU信息        | cat /proc/cpuinfo                                            |\n| 显示当前硬件信息   | sudo lshw                                                    |\n| 查看硬盘的分区     | sudo fdisk -l                                                |\n| 查看IDE硬盘信息    | sudo hdparm -i /dev/had                                      |\n| 查看STAT硬盘信息   | sudo hdparm -I /dev/sda  sudo apt-get install blktool sudo blktool /dev/sda id |\n| 查看硬盘剩馀空间   | df -h df -H                                                  |\n| 查看目录占用空间   | du -hs 目录名                                                |\n| 优盘没法卸载       | sync fuser -km /media/usbdisk                                |\n\n```\npython-hwinfo、psutil\n\nls、lsattr、lsblk、lscpu、lshw、lsinitrd、lsipc、lslocks、lslogins、lsmod、lsns、lsof、lspci、lsscsi\n\ndmidecode\nmultipath\nstrace\nraid\nlvm \nsg3_utils\niostat \nhdparm \n\ncat /proc/scsi/scsi\n/sys/class/scsi_device/<h:c:t:l>/device/model\n/sys/class/scsi_device/<h:c:t:l>/device/rev\n/sys/class/scsi_device/<h:c:t:l>/device/vendor\n\nsplit(\"\\\\s+\") 按空格,制表符，等进行拆分\n\npsutil是一个跨平台库，轻松获取系统运行的进程和系统利用率能实现ps、top、lso、nice、netstat、ifconfig、who、df、kill、free、ionice、iostat、iotop、uptime、pidof、tty、taskset、pmap 这些命令的功能\n\nlsscsi展示信息解释：\n第一列：SCSI设备id：host, channel,id,lun。\n第二列：设备类型。\n第3，4，5列：设备厂商，型号，版本信息。\n最后一列：设备主节点名。\nlsscsi \n-s 显示容量大小。\n-c 用全称显示默认的信息。\n-d 显示设备主，次设备号。\n-g 显示对应的sg设备名。\n-H 显示主机控制器列表，-Hl,-Hlv。\n-l 显示相关属性，-ll,-lll=-L。\n-v 显示设备属性所在目录。\n-x 以16进制显示lun号。\n-p 输出DIF,DIX 保护类型。\n-P 输出有效的保护模式信息。\n-i 显示udev相关的属性\n-w 显示WWN\n-t 显示相应传输信息(ATA,FC,SBP,ISCSI,SPI,SAS,SATA,USB)，-Ht,-tl.（包括sas地址）\n\nLUN的全称是Logical Unit Number，也就是逻辑单元号。我们知道SCSI总线上可挂接的设备数量是有限的，一般为8个或者16个，我们可以用Target ID(也有称为SCSI ID的)来描述这些设备，设备只要一加入系统，就有一个代号，我们在区别设备的时候,只要说几号几号就可以了。\n\nlinux下命令行json工具: jq\n\nMegaCLI下载：\nhttps://docs.broadcom.com/docs-and-downloads/raid-controllers/raid-controllers-common-files/8-07-06_MegaCLI.zip\n命令使用：\n#/opt/MegaRAID/MegaCli/MegaCli64 -LDInfo -Lall -aALL 查raid级别\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aALL 查raid卡信息\n#/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aALL 查看硬盘信息\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -aAll 查看电池信息\n#/opt/MegaRAID/MegaCli/MegaCli64 -FwTermLog -Dsply -aALL 查看raid卡日志\n#/opt/MegaRAID/MegaCli/MegaCli64 -adpCount 【显示适配器个数】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpGetTime –aALL 【显示适配器时间】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aAll 【显示所有适配器信息】\n#/opt/MegaRAID/MegaCli/MegaCli64 -LDInfo -LALL -aAll 【显示所有逻辑磁盘组信息】\n#/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll 【显示所有的物理信息】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL |grep ‘Charger Status’ 【查看充电状态】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL【显示BBU状态信息】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuCapacityInfo -aALL【显示BBU容量信息】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuDesignInfo -aALL 【显示BBU设计参数】\n#/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuProperties -aALL 【显示当前BBU属性】\n#/opt/MegaRAID/MegaCli/MegaCli64 -cfgdsply -aALL 【显示Raid卡型号，Raid设置，Disk相关信息】\n```\n\n## 2019-6-24\n\n```\nglibc是GNU发布的libc库，即c运行库。glibc是linux系统中最底层的api，几乎其它任何运行库都会依赖于glibc。glibc除了封装linux操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。由于 glibc 囊括了几乎所有的UNIX通行的标准，可以想见其内容包罗万象。而就像其他的 UNIX 系统一样，其内含的档案群分散于系统的树状目录结构中，像一个支架一般撑起整个操作系统。在 GNU/Linux 系统中，其C函式库发展史点出了GNU/Linux 演进的几个重要里程碑，用 glibc 作为系统的C函式库，是GNU/Linux演进的一个重要里程碑。\nAppImageKit\n,通过构建一个内核加载文件系统,打包app的,这样的好处就是linux内核通用型好,因为打包文件系统,在嵌入式linux中是一个非常常用手段,弄一个文件系统(通常是只读的),放到磁盘上,然后读取,后加载到内核执行,如果要写入的话,就写入到另一个存储区域,这样就可以保证系统的安全性.\n```\n\n## 2019-6-21\n\n```\nUPX非常好的可执行文件压缩软件，支持的格式包括 atari/tos，djgpp2/coff，dos/com，dos/exe，dos/sys，rtm32/pe，tmt/adam，watcom/le，win32/pe，Linux/i386 等等，压缩比率也非常的高。 \n```\n\n## 2019-6-20\n\n```\n问题：lvs+keepalived集群环境配置完成后通过vip无法访问web\n1. 网卡上不存在vip\n检查keepalived配置文件是否正确，keepalived服务是否正常启动。\n2. 网卡上存在vip，但是无法访问\n检查防火墙是否开启vip映射到RealServer的所有端口；检查所有RealServer的回环网卡及ARP配置是否正确。\n3. 两边网卡都存在vip\n两台主机不能正常通信，都把自己当成Master，检查防火墙是否配置vrrp规则\n\n\n```\n\n## 2019-6-19\n\n```\nHTTP 属于超文本传输协议，用来在 Internet 上传送超文本，而 HTTPS 为安全超文本传输协议，在 HTTPS 基础上拥有更强的安全性，简单来说 HTTPS 是 HTTP 的安全版，是使用 TLS/SSL 加密的 HTTP 协议。\nHTTPS和HTTP的区别主要如下：\n1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。\n2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。\n3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。\n4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。\n\nOSI七层模型：\n应用层 文件传输，电子邮件，文件服务，虚拟终端 TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet\n表示层 数据格式化，代码转换，数据加密 没有协议\n会话层 解除或建立与别的接点的联系 没有协议\n传输层 提供端对端的接口 TCP，UDP\n网络层 为数据包选择路由 IP，ICMP，RIP，OSPF，BGP，IGMP\n数据链路层 传输有地址的帧以及错误检测功能 SLIP，CSLIP，PPP，ARP，RARP，MTU\n物理层 以二进制数据形式在物理媒体上传输数据 ISO2110，IEEE802，IEEE802.2\n\nkeepalived原理：\nLayer3,4&7工作在IP/TCP协议栈的IP层，TCP层，及应用层,原理分别如下：\n\nLayer3：Keepalived使用Layer3的方式工作式时，Keepalived会定期向服务器群中的服务器发送一个ICMP的数据包（既我们平时用的Ping程序）,如果发现某台服务的IP地址没有激活，Keepalived便报告这台服务器失效，并将它从服务器群中剔除，这种情况的典型例子是某台服务器被 非法关机。Layer3的方式是以服务器的IP地址是否有效作为服务器工作正常与否的标准。\n\nLayer4:如果您理解了Layer3的方式，Layer4就容易了。Layer4主要以TCP端口的状态来决定服务器工作正常与否。如web server的服务端口一般是80，如果Keepalived检测到80端口没有启动，则Keepalived将把这台服务器从服务器群中剔除。\n\nLayer7：Layer7就是工作在具体的应用层了，比Layer3,Layer4要复杂一点，在网络上占用的带宽也要大一些。Keepalived将根据用户的设定检查服务器程序的运行是否正常，如果与用户的设定不相符，则Keepalived将把服务器从服务器群中剔除。\n```\n\n## 2019-6-18\n\n```\n网卡状态查看\nnmcli conn show\nethtool ens160\n```\n\n## 2019-6-14\n\n```\nfunction parseURL(url) {\n    var a =  document.createElement('a');\n    a.href = url;\n    return {\n        source: url,\n        protocol: a.protocol.replace(':',''),\n        host: a.hostname,\n        port: a.port,\n        query: a.search,\n        params: (function(){\n            var ret = {},\n                seg = a.search.replace(/^\\?/,'').split('&'),\n                len = seg.length, i = 0, s;\n            for (;i<len;i++) {\n                if (!seg[i]) { continue; }\n                s = seg[i].split('=');\n                ret[s[0]] = s[1];\n            }\n            return ret;\n        })(),\n        file: (a.pathname.match(/\\/([^\\/?#]+)$/i) || [,''])[1],\n        hash: a.hash.replace('#',''),\n        path: a.pathname.replace(/^([^\\/])/,'/$1'),\n        relative: (a.href.match(/tps?:\\/\\/[^\\/]+(.+)/) || [,''])[1],\n        segments: a.pathname.replace(/^\\//,'').split('/')\n    };}\n```\n\n## 2019-6-13\n\n```\ndocker kill $(docker ps -q) ; docker rm $(docker ps -a -q) ; docker rmi $(docker images -q -a)\n\necho `pwd`\necho $(pwd)\necho $(eval pwd)\n\n```\n\n## 2019-6-6\n\n```\n14台集群环境：\n调度器\nDirector1（LVS1 + Keepalived1）\nDirector2（LVS2 + Keepalived2）\nWeb服务器\nRealServer1\nRealServer2\nRealServer3\n消息服务器\nActiveMQ1\nActiveMQ2\n缓存服务器\nRedis1\nRedis2\n数据库\nMySQL1\nMySQL2\n分布式存储\nFastDFS1\nFastDFS2\n预览服务器\nOffice1\n\n1. redis在服务器断电时出现pid文件残留，系统重启后服务无法再次启动，需要清除pid文件才能启动成功\n2. ActiveMQ依赖MySQL，但两个服务又不在同一个机器，如何确保服务正常启动？\n3. LVS+Keepalived两台Director网卡都有VIP存在，关闭防火墙后正常\n\n我来贴上解决方法吧，出现这问题的场景是在阿里VPS云服务器网络环境中，因为路由交换层禁用了ARP的广播限制，造成KEEPALIVE主备协议无法通过广播的方式进行通信，造成主备两台服务器都强占HAVIP地址，出现同时两台服务器都有VIP地址的情况出现，必须通过配置来指定IP的两台服务器间进行通讯（阿里说明文档中解释只能支持两台使用同一个HAVIP地址），基于以下方法可以的情况下，多备方式用同样的方式也应该可行，有需要的兄弟可以测试下多IP备的方式（正常情况需要主备一对主备就够了）。\n在网卡配置后面需要加上以下配置：\nunicast_src_ip  192.168.1.21\t##（本地IP地址）\nunicast_peer {\n\t\t192.168.1.22\t##（对端IP地址）此地址一定不能忘记\n}\n\n之前我们用keepalived做集群时一般使用它构建服务器主从，也就是只有一个vip，并且这个vip只是在主节点上，当主节点宕机时，vip漂移到从节点上，从而实现高可用。但随着业务的发展，单个节点随之成为业务的性能瓶颈，及时我们使用的负载均衡再强大，服务器配置再高，也不可能单节点抗住所有流量。而通过这种方案，在keepalived的主从基础上扩展一下，通过配置多个vip，每个keepalived节点互为主从，正常情况下保证所有服务器都能拥有一个vip，然后通过dns负载均衡技术，将业务流量转发到每个vip。从而在一定程度上避免了单服务器的性能瓶颈。\n```\n\n## 2019-6-4\n\n```\n给进入 eth0 的包打包 mark 的标记，当数据包是发给 VIP:80 并且 MAC 不是其它 LVS 服务器的话。才做个 mark，这样才会对指定的 fwmark 进行 loadbalance 放入到 LVS 中处理。只要数据包是从任意其它的 MAC 地址（非 LVS 的转发）会被发往 VIP:port，会不在进行 loadbalanced 而是直接转给后面监听的 demon 程序进行应用的处理。实际就是使用 iptables 来对进入的流量设置 MARK。然后配置 keepalived 只处理有 MARK 过的流量。不在使用以前绑定的 VIP 和端口\n\n# iptables  -t mangle -I PREROUTING -d $VIP -p tcp -m tcp --dport $VPORT -m mac ! --mac-source $MAC_Director2 -j MARK --set-mark 0x3\n$VIP 为VIP地址\n$VPORT 为服务端口\n$MAC_Director2 是备机的MAC (keepalived 之间互相监听的那块网卡)\n\n# iptables  -t mangle -I PREROUTING -d 192.168.23.253 -p tcp -m tcp --dport 80 -m mac ! --mac-source 08:00:27:46:c7:d4 -j MARK --set-mark 0x3\n# iptables  -t mangle -I PREROUTING -d 192.168.23.253 -p tcp -m tcp --dport 80 -m mac ! --mac-source 08:00:27:9e:ef:a0 -j MARK --set-mark 0x4\n\nipvs的防火墙打标，实现基于防火墙的负载均衡集群\n# virtual_server fwmark int\n\nhttp://www.linuxyw.com/linux/fuzaijunheng/20130429/146.html\n```\n\n","tags":["随笔","201906"]},{"title":"【linux】CentOS7 单用户模式修改密码","url":"/2019/06/20/【linux】CentOS7-单用户模式修改密码/","content":"\n## CentOS7 单用户模式修改密码\n\n### 第一步：\n\n\n\n![1.png](1.png)\n\n### 第二步：\n\n![2.png](2.png)\n\n### 第三步：\n\n![3.png](3.png)\n\n","tags":["linux"]},{"title":"【nginx】nginx配置单台主机Web服务挂掉后自动进入维护页面","url":"/2019/06/18/【nginx】nginx配置单台主机Web服务挂掉后自动进入维护页面/","content":"\n线上业务如果挂掉后没有任何补救措施，直接无法访问会影响产品的好感度，针对单台业务环境增加临时维护页面，当业务中断后自动切换到维护页面，再及时处理故障，并使业务恢复正常。\n\n### 安装Apache\n\n用于模拟实际Web服务，修改监听端口为8080，创建一个简单的测试页面。\n\n```\nyum install epel-release -y\nyum install httpd -y\n```\n\n### 安装Nginx\n\n用作反向代理和负载均衡，并作为维护页面Web Server。\n\n```\nyum install nginx -y\n```\n\n### Nginx 配置\n\n正常情况下，通过访问80端口会被转发到8080的业务界面，此时不会和维护页面有任何数据交换；当业务挂掉后会转发到8081的维护页面，业务恢复正常又会自动切换回来。\n\n```\n[root@localhost nginx]# egrep -v \"^$|^#\" nginx.conf\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log;\npid /run/nginx.pid;\ninclude /usr/share/nginx/modules/*.conf;\nevents {\n    worker_connections 1024;\n}\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n    access_log  /var/log/nginx/access.log  main;\n    sendfile            on;\n    tcp_nopush          on;\n    tcp_nodelay         on;\n    keepalive_timeout   65;\n    types_hash_max_size 2048;\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n    # Load modular configuration files from the /etc/nginx/conf.d directory.\n    # See http://nginx.org/en/docs/ngx_core_module.html#include\n    # for more information.\n    include /etc/nginx/conf.d/*.conf;\n    server {\n        listen       80 default_server;\n        listen       [::]:80 default_server;\n        server_name  _;\n        root         /usr/share/nginx/html;\n        # Load configuration files for the default server block.\n        include /etc/nginx/default.d/*.conf;\n        location / {\n            proxy_pass http://websrv; \n        }\n        error_page 404 /404.html;\n            location = /40x.html {\n        }\n        error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n        }\n    }\n    server {\n        listen       8081 default_server;\n        listen       [::]:8081 default_server;\n        server_name  _;\n        root         /usr/share/nginx/html;\n        # Load configuration files for the default server block.\n        include /etc/nginx/default.d/*.conf;\n        location / {\n        }\n        error_page 404 /404.html;\n            location = /40x.html {\n        }\n        error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n        }\n    }\n    upstream websrv {\n        server 127.0.0.1:8080;\n        server 127.0.0.1:8081 backup;\n    }\n}\n```\n\n","tags":["nginx"]},{"title":"【virtualbox】自制OVA镜像信息","url":"/2019/06/06/【virtualbox】自制OVA镜像信息/","content":"\n## OVA镜像信息\n\n### CentOS-7-x86_64-Minimal-1708.ova\n- 登录：root/q\n\n\n\n\n### Jenkins.ova\n\n- 登录：root/q\n\n- Web：liboo/liboo\n- Web地址：http://< ip : 8080 >\n\n\n\n### ZabbixServer.ova\n\n- 登录：root/q\n\n- MySQL：root/liboo，zabbix/password\n- Web地址：http://< ip >/zabbix\n\n\n\n### ZabbixProxy.ova\n\n- 登录：root/q\n\n- MySQL：root/liboo，zabbix/password\n- 修改：/etc/zabbix/zabbix_proxy.conf\n\n```\nHostname=<hostname>\nServer=<zabbix_server>\nDBPassword=<zabbix_proxy_user_password>\n```\n\n\n\n\n### ZabbixAgent.ova\n- 登录：root/q\n\n- 修改：/etc/zabbix/zabbix_agentd.conf\n\n```\nServer=<zabbix_server_or_zabbix_proxy_ip>\nServerActive=<zabbix_server_or_zabbix_proxy_ip>\nHostname=<hostname>\n```\n\n\n\n\n### Nagios.ova\n- 登录：root/q\n\n- Web：nagiosadmin/liboo\n- Web地址：http://< ip >/nagios\n- MySQL：root/liboo，ndoutils/ndoutils_password\n\n\n\n### LVS1+Keepalived1+Web1.ova\n\n- 登录：root/q\n\n- Web地址：http://< ip >\n- 修改：\n\n```\n$ cat /etc/sysconfig/network-scripts/ifcfg-lo:0\n\nDEVICE=lo:0\nIPADDR=192.168.23.253\t# 需要修改\nNETMASK=255.255.255.255\nONBOOT=yes\n\n$ cat /etc/keepalived/keepalived.conf\n\n! Configuration File for keepalived\n\nvrrp_instance VI_1 {\n    state MASTER\n    interface enp0s3\t# 需要修改\n    virtual_router_id 91\n    priority 100\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.23.253\t# 需要修改\n    }\n    notify_backup \"/root/notify_node.sh b\"\n    notify_master \"/root/notify_node.sh m\"\n}\n\nvirtual_server 192.168.23.253 0 {\t# 需要修改\n    delay_loop 6\n    lb_algo wrr\n    lb_kind DR\n    persistence_timeout 50\n    protocol TCP\n\n    real_server 192.168.23.56 0 {\t# 需要修改\n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.56\t# 需要修改\n            connect_port 80\n        }\n    }\n    real_server 192.168.23.58 0 {\t# 需要修改\n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.58\t# 需要修改\n            connect_port 80\n        }\n    }\n}\n```\n\n\n\n### LVS2+Keepalived2+Web2.ova\n\n- 登录：root/q\n- Web地址：http://< ip >\n- 修改：\n\n\n```\n$ cat /etc/sysconfig/network-scripts/ifcfg-lo:0\n\nDEVICE=lo:0\nIPADDR=192.168.23.253\t# 需要修改\nNETMASK=255.255.255.255\nONBOOT=yes\n\n$ cat /etc/keepalived/keepalived.conf\n\n! Configuration File for keepalived\n\nvrrp_instance VI_1 {\n    state BACKUP\n    interface enp0s3\t# 需要修改\n    virtual_router_id 91\n    priority 50\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.23.253\t# 需要修改\n    }\n    notify_backup \"/root/notify_node.sh b\"\n    notify_master \"/root/notify_node.sh m\"\n}\n\nvirtual_server 192.168.23.253 0 {\t# 需要修改\n    delay_loop 6\n    lb_algo wrr\n    lb_kind DR\n    persistence_timeout 50\n    protocol TCP\n\n    real_server 192.168.23.56 0 {\t# 需要修改\n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.56\t# 需要修改\n            connect_port 80\n        }\n    }\n    real_server 192.168.23.58 0 {\t# 需要修改\n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.58\t# 需要修改\n            connect_port 80\n        }\n    }\n}\n```\n\n","tags":["virtualbox","ova"]},{"title":"【随笔】201905","url":"/2019/05/31/【随笔】201905/","content":"\n## 2019-5-31\n\n```\nLinux下查看网关方法：\nroute -n\nip route show\ntraceroute www.prudentwoo.com -s 100 第一行就是自己的默认网关\nnetstat -r\nmore /etc/network/interfaces Debian/Ubuntu Linux\nmore /etc/sysconfig/network-scripts/ifcfg-eth0 Red Hat\n```\n\n## 2019-5-27\n\n```\n[root@localhost ~]# cat /etc/resolv.conf\nnameserver 8.8.8.8\n\n[root@localhost ~]# sysctl -p\nnet.ipv4.conf.lo.arp_ignore = 1\nnet.ipv4.conf.lo.arp_announce = 2\nnet.ipv4.conf.ens160.arp_ignore = 1\nnet.ipv4.conf.ens160.arp_announce = 2\nnet.ipv4.conf.all.arp_ignore = 1\nnet.ipv4.conf.all.arp_announce = 2\n\n[root@localhost ~]# ipvsadm -Lnc|grep ESTABLISHED\n[root@localhost ~]# ipvsadm -Ln\n\narp -d $ip 命令只能清除一个IP地址的对应MAC地址缓存，可以使用组合命令操作。\n组合命令清楚所有arp缓存：\narp -n|awk '/^[1-9]/{system(\"arp -d \"$1)}'\n以上命令必须 root 才可以执行。\n\n使用ip命令清除某一网络接口的arp(下面命令是 eth0 接口)\nip neigh flush  dev eth0\n\nLinux 清除arp缓存是把列表标记为(incomplete)，在下一次系统清理垃圾是会清除。\n```\n\n## 2019-5-27\n\n```\n#PHP数据库连接测试\n<?php\n$link=mysql_connect('192.168.80.181','zabbix','admin123');\nif($link) echo \"<h1>Success!!</h1>\";\nelse echo \"Fail!!\";\nmysql_close();\n?>\n\nps aux|grep zabbix\ntailf /var/log/zabbix/zabbix_agentd.log \n\n使用mailx发送邮件，邮箱开启SMTP\n# yum install -y mailx\n# systemctl stop postfix\n# vi /etc/mail.rc\nset from=striveliboo@163.com\nset smtp=smtp.163.com\nset smtp-auth-user=striveliboo@163.com\nset smtp-auth-password=<password>\nset smtp-auth=login\n\n```\n\n## 2019-5-27\n\n```\n单一监控系统\n - Windows资源管理器\n - top\n - vnstat\n - iostat\n分布式监控系统\n - Zabbix\n - Open-Faicon（小米）\n \n监控系统基本功能：\n1.数据收集\n2.数据展示\n3.告警策略\n4.告警发送\n5.事件管理\n6.报表管理\n7.认证权限\n\nNagios是1999年发布的初始版本，可以监控网络、主机等设备，支持自定义从插件。\nCacti是2001年发布，基于SNMP和RRDTool的网路流量监控分析系统。\nRRDTool - Round Robin Database Tool 是用来处理时间序列数据的套件，是环型数据库\n\nZabbix的LLD低级发现功能，监控系统内部信息（网卡流量，挂载的文件系统）\nCMDB\n命令自动补齐：\nyum install bash-completion bash-completion-extras\n\n```\n\n## 2019-05-23\n\n```\nJenkins、Ansible、SaltStack、Puppet、Rundeck\nPPTV一键发布\n好的运维架构：\n（1）硬件标准化 -- 服务器、内存、系统版本等\n（2）软件标准化 -- 应用版本等\n（3）运维自动化 -- 监控、发布、CMDB\n运维自动化概括：\n（1）监控报警 -- 系统数据，应用指标的监控，和出错时及时报警\n（2）发布系统 -- 代码发布，发布后的检查，代码回滚，灰度发布\n（3）服务器标准化 -- Cobbler装机加上Puppet，可以做到硬件、软件的标准化。每台机器对于运维来说都是一样的\n（4）CMDB -- 配置管理数据库，存储了所有运维相关数据，包括服务器硬件信息、域名和服务器的关系、IDC容量等。它是运维的心脏，所有系统都依赖它。\n```\n\n## 2019-05-20\n\n```\nvsftpd\nwinscp\nSMB, FTP, DLNA\nNRPE-nagios remote plugin executor\nxinetd已经取代了inetd\nLAMP LNMP\n```\n\n## 2019-05-10\n\n```\n单播、组播和广播\ntcp阻塞\n```\n\n## 2019-05-09\n\n```\n#!/bin/sh\n\necho -e \"\"\necho -e \"\\\\033[0;31m系统颜色设置代码调试，此颜色为一号颜色 - 红！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;32m系统颜色设置代码调试，此颜色为二号颜色 - 绿！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;33m系统颜色设置代码调试，此颜色为三号颜色 - 黄！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;34m系统颜色设置代码调试，此颜色为四号颜色 - 蓝！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;35m系统颜色设置代码调试，此颜色为五号颜色 - 紫！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;36m系统颜色设置代码调试，此颜色为六号颜色 - 青！\"\necho -e \"\\\\033[0;39m\"\necho -e \"\\\\033[0;39m系统颜色设置代码调试，此颜色为九号颜色 - 白！\"\necho -e \"\\\\033[0;39m\"\necho -e 'echo -e \"\\\\\\\\033[0;39mThis is the script test!\"'\necho -e \"\"\n\n1. Linux普通用户利用authbind绑定特权端口\n2. sudo usermod -a -G dialout <username>\n\n```\n\n\n\n## 2019-05-08\n\n```shell\n1. linux下磁盘分区类型检测，mbr（55aa）和gpt（ee）， \n2. 新命令学习：hexdump、xxd、od\n3. sg3_utils 是一个Linux的开发包，用来直接使用 SCSI 命令集访问设备。\n4. Dockerfile编写熟悉\n5. lvs使用nat和dr两种模式\n6. 使用Linux自带的hexdump工具来从16进制的层面分析GPT分区表\n然后我们用parted工具，将这sdb和sdc建立一个gpt分区表。\nparted /dev/sdb mklabel gpt & parted /dev/sdc mklabel gpt\n7. 组播：tcpdump -i ens160 -nn host 224.0.0.18\n8. 读指定物理扇区：\ndd  if=<源设备>  of=<输出设备或文件>   skip=<指定扇区值>  bs=512 count=1\n写指定物理扇区：\ndd   if=<输入设备或文件>   of=<输出设备>   seek=<指定扇区值>  bs=512 count=1\n9. keepalived规则配置\nfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT\n\n#lvs dr\nmodprobe ip_vs \ncat /proc/net/ip_vs\nyum install ipvsadm -y\nyum install net-tools -y\nifconfig ens33:0 192.168.23.199 broadcast 192.168.23.199 netmask 255.255.255.255 up\nroute add -host 192.168.23.199 dev ens33:0\nipvsadm -C\nipvsadm -A -t 192.168.23.199:80 -s rr\nipvsadm -a -t 192.168.23.199:80 -r 192.168.23.187:80 -g\nipvsadm -a -t 192.168.23.199:80 -r 192.168.23.190:80 -g\nipvsadm -Ln\nyum install -y httpd\nvi /etc/httpd/conf/httpd.conf\ncd /var/www/html/\nll\necho \"<h1>SERVER 192.168.23.187</h1>\" > index.html\nll\nservice httpd start \nsystemctl stop firewalld\nifconfig lo:0 192.168.23.199 broadcast 192.168.23.199 netmask 255.255.255.255 up\nroute add -host 192.168.23.199 dev lo:0\necho \"1\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\necho \"2\" >/proc/sys/net/ipv4/conf/lo/arp_announce\necho \"1\" >/proc/sys/net/ipv4/conf/all/arp_ignore\necho \"2\" >/proc/sys/net/ipv4/conf/all/arp_announce\nsysctl -p &>/dev/null\nip a\n\n#lvs nat\necho 1 >/proc/sys/net/ipv4/ip_forward\necho 0 > /proc/sys/net/ipv4/conf/all/send_redirects\necho 0 > /proc/sys/net/ipv4/conf/default/send_redirects\necho 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects\necho 0 > /proc/sys/net/ipv4/conf/eth1/send_redirects\nipvsadm -A -t 192.168.244.128:80 -s rr\nipvsadm -a -t 192.168.244.128:80 -r 192.168.137.133 -m -w 1\nipvsadm -a -t 192.168.244.128:80 -r 192.168.137.134 -m -w 2\nservice ipvsadm save\n```\n\n","tags":["随笔","201905"]},{"title":"【zabbix】Zabbix使用JMX监控ActiveMQ","url":"/2019/05/30/【zabbix】Zabbix使用JMX监控ActiveMQ/","content":"\n## Zabbix 使用 JMX 监控 ActiveMQ\n\n### Zabbix Server 安装配置 Zabbix Java Gateway\n\n```\n安装 zabbix-java-gateway\n# yum install zabbix-java-gateway -y\n\n启动并设置开机自启\n# systemctl start zabbix-java-gateway\n# systemctl enable zabbix-java-gateway\n\n修改zabbix_server.conf\n# vi zabbix_server.conf\n\nJavaGateway=172.16.2.224\t//IP address (or hostname) of Zabbix Java gateway.\nJavaGatewayPort=10052\t\t//Port that Zabbix Java gateway listens on.\nStartJavaPollers=5\t\t\t//Number of pre-forked instances of Java pollers.\n\n重启zabbix server\n# systemctl restart zabbix-server\n```\n\n\n\n### ActiveMQ 配置\n\n```\n修改/etc/hosts 为对外地址，否则jmx远程无法使用\n# cat /etc/hosts\n172.16.2.229   localhost localhost.localdomain localhost4 localhost4.localdomain4\n#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n开启jmx\n# vi conf/activemq.xml\n\n<broker useJmx=\"true\" xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"localhost\" dataDirectory=\"${activemq.data}\">\n\n        <managementContext>\n            <managementContext createConnector=\"true\" connectorPort=\"11099\"/>\n        </managementContext>\n        ...\n\n配置启动参数\n# vi bin/env \n\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote.port=11099\"\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote.password.file=${ACTIVEMQ_CONF}/jmx.password\"\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote.access.file=${ACTIVEMQ_CONF}/jmx.access\"\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote.ssl=false\"\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote=true\"\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Dcom.sun.management.jmxremote.authenticate=false\"\t//不需要认证\nACTIVEMQ_SUNJMX_START=\"$ACTIVEMQ_SUNJMX_START -Djava.rmi.server.hostname=172.16.2.229\"\n\n设置权限\nchmod 400 conf/jmx.*\n\n重启服务\n# systemctl restart activemq\n```\n\n\n\n### Web管理界面添加主机，使用 JMX 接口\n\n```\nConfiguration -> Host --> Create host\n\nHost name：host-172-16-2-229\nVisible name：linux_host_233\nGroups：Linux主机测试\n# remove Agent interfaces\nJMX interfaces：172.16.2.229\n\n# Templates\nTemplate App Generic Java JMX\n```\n\n","tags":["zabbix"]},{"title":"【zabbix】Zabbix配置SNMP监控","url":"/2019/05/30/【zabbix】Zabbix配置SNMP监控/","content":"\n## Zabbix 配置SNMP 监控\n\n简单网络管理协议（SNMP），由一组网络管理的标准组成，包含一个应用层协议（application layer protocol）、数据库模型（database schema）和一组资源对象。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。现在服务器、交换机、路由器、打印机等设备都支持SNMP协议。\n\n### Zabbix Server 安装配置SNMP\n\n```\n安装snmpd服务及工具\n# yum install -y net-snmp*\n\n备份配置文件\n# cp /etc/snmp/snmpd.conf{,.bak}\n\n开启如下配置项\n# vi /etc/snmp/snmpd.conf\n\nproc mountd\nproc ntalkd 4\nproc sendmail 10 1\ndisk / 10000\nload 12 14 14\n\nview    systemview    included   .1.3.6.1.2.1.1\nview    systemview    included   .1.3.6.1.2.1.25.1.1\nview    systemview    included   .1\t\t\t\t\t\t//新增\n\n防火墙开启端口161/UDP\nfirewall-cmd --permanent --add-port=161/udp\nfirewall-cmd --reload\n\n# 启动并设置开机自启\nsystemctl start snmpd\nsystemctl enable snmpd\n```\n\n\n\n### Zabbix 被监控设备安装配置SNMP\n\n```\n安装snmpd服务及工具\n# yum install -y net-snmp*\n\n备份配置文件\n# cp /etc/snmp/snmpd.conf{,.bak}\n\n开启如下配置项\n# vi /etc/snmp/snmpd.conf\n\nview    systemview    included   .1.3.6.1.2.1.1\nview    systemview    included   .1.3.6.1.2.1.25.1.1\nview    systemview    included   .1\t\t\t\t\t\t//新增\ncom2sec notConfigUser  default       public\n\n防火墙开启端口161/UDP\nfirewall-cmd --permanent --add-port=161/udp\nfirewall-cmd --reload\n\n# 启动并设置开机自启\nsystemctl start snmpd\nsystemctl enable snmpd\n```\n\n\n\n### 使用snmpwalk命令测试被监控设备计算机名\n\n```\n# snmpwalk -v 2c -c public 172.16.2.228 sysName\nSNMPv2-MIB::sysName.0 = STRING: host-172-16-2-228\n\n2c是指采用SNMP V2版本，172.16.2.228 是开启了SNMP服务的被监控设备ip，否则会获取失败，sysName是指获取被监控设备的计算机名。\n```\n\n\n\n### 管理界面添加主机\n\n```\nConfiguration -> Host --> Create host\n\nHost name：host-172-16-2-228\nVisible name：linux_host_232\nGroups：Linux主机测试\n# remove Agent interfaces\nSNMP interfaces：172.16.2.228\n\n# Templates\nTemplate OS Linux SNMPv2\n```\n\n\n\n","tags":["zabbix"]},{"title":"【zabbix】Zabbix自定义监控项","url":"/2019/05/29/【zabbix】Zabbix自定义监控项/","content":"\n## 自定义监控项（Items）\n\n监控项是从主机收集的数据信息。\n\n配置主机后，你需要添加一些监控项以开始获取实际数据。\n\n一个监控项是一个独立的指标。快速添加多个监控项的一种方法是将一个预定义的模板附加到主机。然而，为了优化系统性能，您可能需要对模板进行微调，使只有真正需要的监控项被频繁的监控到。\n\n在单个监控项中，你可以指定从主机收集哪些数据。\n\n为此，你可以使用监控项key。 从而，具有名称为system.cpu.load的监控项将收集处理器负载的数据，而名为net.if.in的监控项将收集传入的流量信息。\n\n要用key指定更多的参数，请在key后添加方括号。 例如，system.cpu.load[avg5]将返回最近5分钟的处理器负载平均值，而net.if.in[eth0]将显示接口eth0中的流量。\n\n```\n# /etc/zabbix/zabbbix_agent.conf\n\nUserParameter=key[*],[command|sh]\n# <key[参数]>，<命令或者脚本>\n# [*]：固定格式，表示server端是否传过来参数，在命令或者脚本中用$1,23...引用，shell脚本中的引用$$1,2,3..引用，\n# 如果server端不传参数，[*]可以不写\n\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n```\n\n### 方法1：直接向 zabbix_agent 配置文件中添加\n\n```\nUnsafeUserParameters=0  #默认情况下，不允许用户在用户自定义参数中使用某些特殊符号。\n\n定义了一个名为\"os.mem.used\"的key，然后这个key通过后面指定的命令来获取需要的值：\n# UserParameter=os.mem.used,free -m | awk '/^Mem/ {print $3}'  #新增一个key叫作os.mem.used用于查看系统已用内存\n\nUserParameter还可以通过脚本来取得多个key的值：\n# UserParameter=mysql.status[*],/usr/local/zabbix/scripts/check_mysql.sh $1\n# UserParameter=check_port[*],/usr/local/zabbix/scripts/check_port.sh -H 127.0.0.1 -p $1\n[*]代表key接受任意个参数，这些参数就是在web端要明确写出来的参数，也是后面命令或脚本中接受的参数，用$1,$2来表示第几个参数。如果command中的命令本身带有$1等信息（如awk命令），需要写为$$1\n```\n\n\n\n### 方法2：编写独立的配置文件，并在 zabbix_agent 配置中 Include\n\n```\n打开zabbix_agent.conf 中的选项\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n\n为了更好区分和维护，将自定义的监控项写到自己的配置文件中\ncat /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf\n\nUserParameter=mysql.size[*],bash -c 'echo \"select sum($(case \"$3\" in both|\"\") echo \"data_length+index_length\";; data|index) echo \"$3_length\";; free) echo \"data_free\";; esac)) from information_schema.tables$([[ \"$1\" = \"all\" || ! \"$1\" ]] || echo \" where table_schema=\\\"$1\\\"\")$([[ \"$2\" = \"all\" || ! \"$2\" ]] || echo \"and table_name=\\\"$2\\\"\");\" | HOME=/var/lib/zabbix mysql -N'\n\nUserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c alive\nUserParameter=mysql.version,mysql -V\n\n```\n\n###  \n\n### 用户自定义参数\n\n#### 概述\n\n用户定义参数可以用来帮助用户实现通过Zabbix agent执行非Zabbix原生的 agent check。\n\n你可以编写一个命令来检索所需的数据，并将其包含在用户自定义参数[agent 配置文件](https://www.zabbix.com/documentation/4.0/zh/manual/appendix/config/zabbix_agentd)中 ('UserParameter' 参数配置)。 \n\n一条用户自定义参数配置应当使用以下语法：\n\n```\nUserParameter=<key>,<command>\n```\n\n如你所见，一条用户自定义参数除了命令部分，还包括一个key。这个key将在配置监控项时使用。输入你选择的易于引用的key（key在一台主机中必须是唯一的）。重启agent。\n\n接下来，在配置[配置监控项](https://www.zabbix.com/documentation/4.0/zh/manual/config/items/item)时，输入要执行的来自用户自定义参数中的，引用命令的key。\n\n用户自定义参数是由Zabbix agent来执行命令的。在监控项预处理步骤前，最多可以返回512KB的数据。但是，请注意，最终可以存储在数据库中的文本值，在MySQL上的限制为64KB（其他数据库的信息请参阅[数据表](https://www.zabbix.com/documentation/4.0/zh/manual/config/notifications/action/operation/remote_command#overview)）。\n\n**/bin/sh** 在UNIX操作系统中，作为命令行解释器使用。用户自定义参数参照agent check超时；如果超时时间到了，那么执行用户自定义参数的子进程将会被中止。\n\n参见：\n\n- [分布教程](https://www.zabbix.com/documentation/4.0/zh/manual/config/items/userparameters/extending_agent) 配置用户自定参数 parameters\n- [命令执行](https://www.zabbix.com/documentation/4.0/zh/manual/appendix/command_execution)\n\n##### 用户自定义参数用例\n\n一个简单的命令：\n\n```\nUserParameter=ping,echo 1\n```\n\nagent 将始终为使用“ping”为key的监控项返回“1”。\n\n一个复杂一些的例子：\n\n```\nUserParameter=mysql.ping,mysqladmin -uroot ping | grep -c alive\n```\n\n如果Mysql服务器是活动状态，agent将返回“1”，否则会返回“0”。\n\n#### 灵活的用户自定义参数\n\n灵活的用户自定义参数可以从key中接受参数。这是一种使用一个用户自定义参数创建多个监控项的方式。\n\n灵活的用户自定义参数有以下语法：\n\n```\nUserParameter=key[*],command\n```\n\n| Parameter参数 | Description描述                                              |\n| ------------- | ------------------------------------------------------------ |\n| **Key**       | 唯一的监控项key。 [*] 用于定义该key接受括号内的参数。 参数需在配置监控项时给出 |\n| **Command**   | 命令在执行时，引用key中指定的值 *只对灵活的用户参数有效*: 你可以在命令中使用位置引用$1 … $9来引用监控项Key中的相应参数。 Zabbix解析监控项Key的[]中包含的参数，并相应地替换$1，…，$9。 $0会替换为完整的原始命令（在对$0，…，$9执行替换之前的命令）运行。 不管位置参数（$0,…,$9)是用双引号( “ )还是单引号( ' )括起来，都会解析位置引用。 要使用位置引用解析，请指定双美元符号（$） - 例如， `awk '{print $$2}' `。 在这种情况下，执行命令时， `$$2` 实际上会变成 `$2` 。 |\n\n仅对灵活的用户自定义参数进行搜索具有 `$ `符号的位置引用并由Zabbix agent解析替换。 对于简单的用户自定义参数，跳过此类参考处理，因此不需要任何$符号引用。\n\n默认情况下，不允许用户在用户自定义参数中使用某些特殊符号。详情请移步 [UnsafeUserParameters](https://www.zabbix.com/documentation/4.0/zh/manual/appendix/config/zabbix_agentd) ，查询相关的符号列表\n\n##### 示例一\n\n先来一个简单的：\n\n```\nUserParameter=ping[*],echo $1\n```\n\n我们可以定义无数个监控项来监控所有形如ping[something]格式的东西。\n\n- ping[0] - 将总是返回 ‘ 0 ’\n- ping[aaa] - 将总是返回 ‘aaa’\n\n##### 示例二\n\n让我们更进一步！\n\n```\nUserParameter=mysql.ping[*],mysqladmin -u$1 -p$2 ping | grep -c alive\n```\n\n这个用户自定义参数可以用来监控 MySQL 数据库的状态。可以想下面的样式传入用户名和密码：\n\n```\nmysql.ping[zabbix,our_password]\n```\n\n##### 示例三\n\n一个文件中有多少行匹配正则表达式？\n\n```\nUserParameter=wc[*],grep -c \"$2\" $1\n```\n\n这个用户自定义参数能用来计算一个文件中有多少行匹配相应的表达式。就像下面一样：\n\n```\nwc[/etc/passwd,root]\nwc[/etc/services,zabbix]\n```\n\n#### 命令结果\n\n命令的返回值是标准输出和标准错误。\n\n标准错误情况下，不支持文本（字符、日志或是文本类型的信息）的监控项\n\n返回文本的用户自定义参数（字符，日志，文本信息类型）可以返回空格。如果结果不可用，那么这个监控项会变为不支持状态。","tags":["zabbix"]},{"title":"【zabbix】Zabbix监控Mariadb性能状态","url":"/2019/05/29/【zabbix】Zabbix监控Mariadb性能状态/","content":"\n# Zabbix 监控Mariadb 性能状态\n\nZabbix 内置Mysql 的监控模版，因为Mariadb 和Mysql 两者的相关性，所以这个模版也能用在Mariadb Services上\n\n### Mariadb \n\n首先要在mariadb新建一个账户，这个账户不需要有任何权限。这个账户只是用来登入mariadb获取服务状态。\n\n```\nGRANT USAGE ON *.* TO 'zabbix'@'localhost' IDENTIFIED BY 'passwd';\nFLUSH PRIVILEGES;\n```\n\n### Zabbix Agent\n\n完成mariadb的用户添加后，还要在mariadb服务器安装Zabbix Agent。通过以下文件可以得知还需要新建一个文件，并在这个文件内填入mariadb的信息：\n\n```\n/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf \n\n# For all the following commands HOME should be set to the directory that has .my.cnf file with password information.\n\n# Flexible parameter to grab global variables. On the frontend side, use keys like mysql.status[Com_insert].\n# Key syntax is mysql.status[variable].\nUserParameter=mysql.status[*],echo \"show global status where Variable_name='$1';\" | HOME=/var/lib/zabbix mysql -N | awk '{print $$2}'\n\n# Flexible parameter to determine database or table size. On the frontend side, use keys like mysql.size[zabbix,history,data].\n# Key syntax is mysql.size[<database>,<table>,<type>].\n# Database may be a database name or \"all\". Default is \"all\".\n# Table may be a table name or \"all\". Default is \"all\".\n# Type may be \"data\", \"index\", \"free\" or \"both\". Both is a sum of data and index. Default is \"both\".\n# Database is mandatory if a table is specified. Type may be specified always.\n# Returns value in bytes.\n# 'sum' on data_length or index_length alone needed when we are getting this information for whole database instead of a single table\nUserParameter=mysql.size[*],bash -c 'echo \"select sum($(case \"$3\" in both|\"\") echo \"data_length+index_length\";; data|index) echo \"$3_length\";; free) echo \"data_free\";; esac)) from information_schema.tables$([[ \"$1\" = \"all\" || ! \"$1\" ]] || echo \" where table_schema=\\\"$1\\\"\")$([[ \"$2\" = \"all\" || ! \"$2\" ]] || echo \"and table_name=\\\"$2\\\"\");\" | HOME=/var/lib/zabbix mysql -N'\n\nUserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c alive\nUserParameter=mysql.version,mysql -V\n```\n\n然后新建以下文件并进行修改，要注意的是 /var/lib/zabbix 这个路径可能并不存在，需要手动新建：\n\n```\n# mkdir -p /var/lib/zabbix\n\n# vi /var/lib/zabbix/.my.cnf\n\n[mysql]\nuser=zabbix\npassword=zabbix\nhost=127.0.0.1\n\n[mysqladmin]\nuser=zabbix\npassword=zabbix\nhost=127.0.0.1\n```\n\n完成后需要通过以下命令手动重启mariadb services和zabbix agent services：\n\n```\n重启mariadb\n# systemctl restart mariadb\n\n重启zabbix agent\n# systemctl restart zabbix-agent\n```","tags":["zabbix"]},{"title":"【zabbix】Zabbix自定义邮件告警","url":"/2019/05/29/【zabbix】Zabbix自定义邮件告警/","content":"\n## Zabbix自定义邮件告警\n\n### 1. 安装配置mailx\n\n```\n# yum install -y mailx\n\n如果存在Postfix，关闭并禁用\n# systemctl stop postfix\n# systemctl disable postfix\n\n首先登陆163设置启用SMTP，追加如下配置\n# vi /etc/mail.rc\n\nset from=striveliboo@163.com\nset smtp=smtp.163.com\nset smtp-auth-user=striveliboo@163.com\nset smtp-auth-password=<password>\nset smtp-auth=login\n\n```\n\n### 2. 编写邮件发送脚本，并放置到相应位置\n\n```\n[root@host-172-16-2-224 alertscripts]# cd /usr/lib/zabbix/alertscripts/\n[root@host-172-16-2-224 alertscripts]# cat mail.sh \n(1)邮件内容可能会作为附件传递，内容展示会乱码\n#!/bin/bash\n\nSENT_TO=$1\nSENT_SUBJECT=$2\nSENT_CONTENT=$3\n\necho \"$SENT_CONTENT\" |mailx -s \"$SENT_SUBJECT\" $SENT_TO\n\n（2）解决第一种方法的问题，需要安装dos2unix\n#!/bin/bash\n\nSENT_TO=$1\nSENT_SUBJECT=$2\nSENT_CONTENT=\"/tmp/alert_$$.tmp\"\necho \"$3\">$SENT_CONTENT\n\ndos2unix $SENT_CONTENT\n\nmailx -s \"$SENT_SUBJECT\" $SENT_TO<$SENT_CONTENT\n\n[root@host-172-16-2-224 alertscripts]# chmod o+x mail.sh\n[root@host-172-16-2-224 alertscripts]# sh mail.sh striveliboo@163.com subject content\n\n```\n\n### 3. 登陆界面，添加配置Media Types\n\n```\nAdministration --> Media types --> create media type\n# Name：\n邮件告警发送\n# Type：\nScripts\n# Script name\nmail.sh\n# Script parameters\n{ALERT.SENDTO}\n{ALERT.SUBJECT}\n{ALERT.MESSAGE}\n\n```\n\n### 4. 配置Actions\n\n```\nConfiguration --> Actions --> create action\n# Operations\n故障{TRIGGER.STATUS}，服务器：{HOSTNAME1}发生：”{TRIGGER.NAME}“故障！\n\n告警主机IP地址：{HOST.CONN}\n告警主机：{HOSTNAME1}\n告警时间：{EVENT.DATE} {EVENT.TIME}\n告警等级：{TRIGGER.SEVERITY}\n告警信息：{TRIGGER.NAME}\n告警项目：{TRIGGER.KEY1}\n问题详情：{ITEM.NAME}：{ITEM.VALUE}\n当前状态：{TRIGGER.STATUS}：{ITEM.VALUE1}\n事件ID：{EVENT.ID}\n\n# Recovery operations\n恢复{TRIGGER.STATUS}，服务器：{HOSTNAME1}: ”{TRIGGER.NAME}“已恢复！\n\n告警主机IP地址：{HOST.CONN}\n告警主机：{HOSTNAME1}\n告警时间：{EVENT.DATE} {EVENT.TIME}\n告警等级：{TRIGGER.SEVERITY}\n告警信息：{TRIGGER.NAME}\n告警项目：{TRIGGER.KEY1}\n问题详情：{ITEM.NAME}：{ITEM.VALUE}\n当前状态：{TRIGGER.STATUS}：{ITEM.VALUE1}\n事件ID：{EVENT.ID}\n\n```\n\n","tags":["zabbix"]},{"title":"【zabbix】Zabbix集群配置","url":"/2019/05/28/【zabbix】Zabbix集群配置/","content":"\n## Zabbix 集群信息\n\n- zabbix server：172-16-2-224\n- zabbix proxy：172-16-2-226\n- zabbix agent1：172-16-2-224（127.0.0.1，Server 本身监控）\n- zabbix agent2：172-16-2-225（使用Server监控）\n- zabbix agent3：172-16-2-227（使用Proxy 监控）\n\n\n\n## Zabbix 集群配置\n\n### php.ini（172-16-2-224）\n\n```\n[root@host-172-16-2-224 zabbix]# egrep -v '^;|^$' /etc/php.ini \n[PHP]\nengine = On\nshort_open_tag = Off\nasp_tags = Off\nprecision = 14\noutput_buffering = 4096\nzlib.output_compression = Off\nimplicit_flush = Off\nunserialize_callback_func =\nserialize_precision = 17\ndisable_functions =\ndisable_classes =\nzend.enable_gc = On\nexpose_php = On\nmax_execution_time = 300\nmax_input_time = 60\nmax_input_vars = 10000\nmemory_limit = 128M\nerror_reporting = E_ALL & ~E_DEPRECATED & ~E_STRICT\ndisplay_errors = Off\ndisplay_startup_errors = Off\nlog_errors = On\nlog_errors_max_len = 1024\nignore_repeated_errors = Off\nignore_repeated_source = Off\nreport_memleaks = On\ntrack_errors = Off\nhtml_errors = On\nvariables_order = \"GPCS\"\nrequest_order = \"GP\"\nregister_argc_argv = Off\nauto_globals_jit = On\npost_max_size = 16M\nauto_prepend_file =\nauto_append_file =\ndefault_mimetype = \"text/html\"\nalways_populate_raw_post_data = -1\ndoc_root =\nuser_dir =\nenable_dl = Off\nfile_uploads = On\nupload_max_filesize = 2M\nmax_file_uploads = 20\nallow_url_fopen = On\nallow_url_include = Off\ndefault_socket_timeout = 60\n[CLI Server]\ncli_server.color = On\n[Date]\ndate.timezone = Asia/Shanghai\n[filter]\n[iconv]\n[intl]\n[sqlite]\n[sqlite3]\n[Pcre]\n[Pdo]\n[Pdo_mysql]\npdo_mysql.cache_size = 2000\npdo_mysql.default_socket=\n[Phar]\n[mail function]\nSMTP = localhost\nsmtp_port = 25\nsendmail_path = /usr/sbin/sendmail -t -i\nmail.add_x_header = On\n[SQL]\nsql.safe_mode = Off\n[ODBC]\nodbc.allow_persistent = On\nodbc.check_persistent = On\nodbc.max_persistent = -1\nodbc.max_links = -1\nodbc.defaultlrl = 4096\nodbc.defaultbinmode = 1\n[Interbase]\nibase.allow_persistent = 1\nibase.max_persistent = -1\nibase.max_links = -1\nibase.timestampformat = \"%Y-%m-%d %H:%M:%S\"\nibase.dateformat = \"%Y-%m-%d\"\nibase.timeformat = \"%H:%M:%S\"\n[MySQL]\nmysql.allow_local_infile = On\nmysql.allow_persistent = On\nmysql.cache_size = 2000\nmysql.max_persistent = -1\nmysql.max_links = -1\nmysql.default_port =\nmysql.default_socket =\nmysql.default_host =\nmysql.default_user =\nmysql.default_password =\nmysql.connect_timeout = 60\nmysql.trace_mode = Off\n[MySQLi]\nmysqli.max_persistent = -1\nmysqli.allow_persistent = On\nmysqli.max_links = -1\nmysqli.cache_size = 2000\nmysqli.default_port = 3306\nmysqli.default_socket =\nmysqli.default_host =\nmysqli.default_user =\nmysqli.default_pw =\nmysqli.reconnect = Off\n[mysqlnd]\nmysqlnd.collect_statistics = On\nmysqlnd.collect_memory_statistics = Off\n[OCI8]\n[PostgreSQL]\npgsql.allow_persistent = On\npgsql.auto_reset_persistent = Off\npgsql.max_persistent = -1\npgsql.max_links = -1\npgsql.ignore_notice = 0\npgsql.log_notice = 0\n[Sybase-CT]\nsybct.allow_persistent = On\nsybct.max_persistent = -1\nsybct.max_links = -1\nsybct.min_server_severity = 10\nsybct.min_client_severity = 10\n[bcmath]\nbcmath.scale = 0\n[browscap]\n[Session]\nsession.save_handler = files\nsession.use_cookies = 1\nsession.use_only_cookies = 1\nsession.name = PHPSESSID\nsession.auto_start = 0\nsession.cookie_lifetime = 0\nsession.cookie_path = /\nsession.cookie_domain =\nsession.cookie_httponly =\nsession.serialize_handler = php\nsession.gc_probability = 1\nsession.gc_divisor = 1000\nsession.gc_maxlifetime = 1440\nsession.bug_compat_42 = Off\nsession.bug_compat_warn = Off\nsession.referer_check =\nsession.cache_limiter = nocache\nsession.cache_expire = 180\nsession.use_trans_sid = 0\nsession.hash_function = 0\nsession.hash_bits_per_character = 5\nurl_rewriter.tags = \"a=href,area=href,frame=src,input=src,form=fakeentry\"\n[MSSQL]\nmssql.allow_persistent = On\nmssql.max_persistent = -1\nmssql.max_links = -1\nmssql.min_error_severity = 10\nmssql.min_message_severity = 10\nmssql.compatability_mode = Off\nmssql.secure_connection = Off\n[Assertion]\n[mbstring]\n[gd]\n[exif]\n[Tidy]\ntidy.clean_output = Off\n[soap]\nsoap.wsdl_cache_enabled=1\nsoap.wsdl_cache_dir=\"/tmp\"\nsoap.wsdl_cache_ttl=86400\nsoap.wsdl_cache_limit = 5\n[sysvshm]\n[ldap]\nldap.max_links = -1\n[mcrypt]\n[dba]\n```\n\n### Zabbix Server（172-16-2-224）\n\n```\n[root@host-172-16-2-224 zabbix]# egrep -v '^#|^$' zabbix_server.conf \nLogFile=/var/log/zabbix/zabbix_server.log\nLogFileSize=0\nPidFile=/var/run/zabbix/zabbix_server.pid\nSocketDir=/var/run/zabbix\nDBHost=localhost\nDBName=zabbix\nDBUser=zabbix\nDBPassword=password\nSNMPTrapperFile=/var/log/snmptrap/snmptrap.log\nTimeout=4\nAlertScriptsPath=/usr/lib/zabbix/alertscripts\nExternalScripts=/usr/lib/zabbix/externalscripts\nLogSlowQueries=3000\n```\n\n### Zabbix Server Agent（172-16-2-224）\n\n```\n[root@host-172-16-2-224 zabbix]# egrep -v '^#|^$' /etc/zabbix/zabbix_agentd.conf \nPidFile=/var/run/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\nLogFileSize=0\nServer=127.0.0.1\nServerActive=127.0.0.1\nHostname=Zabbix server\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n```\n\n\n\n### Zabbix Agent（172-16-2-225）\n\n```\n[root@host-172-16-2-225 zabbix]# egrep -v '^#|^$' /etc/zabbix/zabbix_agentd.conf \nPidFile=/var/run/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\nLogFileSize=0\nServer=172.16.2.224\nServerActive=172.16.2.224\nHostname=linux_host_230\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n```\n\n\n\n### Zabbix Proxy（172-16-2-226）\n\n```\n[root@host-172-16-2-226 zabbix]# egrep -v '^$|^#' /etc/zabbix/zabbix_proxy.conf \nServer=172.16.2.224\nHostname=linux_host_proxy_229\nLogFile=/var/log/zabbix/zabbix_proxy.log\nLogFileSize=0\nPidFile=/var/run/zabbix/zabbix_proxy.pid\nSocketDir=/var/run/zabbix\nDBName=zabbix_proxy\nDBUser=zabbix\nDBPassword=password\nSNMPTrapperFile=/var/log/snmptrap/snmptrap.log\nTimeout=4\nExternalScripts=/usr/lib/zabbix/externalscripts\nLogSlowQueries=3000\n```\n\n\n\n### Zabbix Proxy Agent（172-16-2-227）\n\n```\n[root@host-172-16-2-227 zabbix]#  egrep -v '^#|^$' /etc/zabbix/zabbix_agentd.conf \nPidFile=/var/run/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\nLogFileSize=0\nServer=172.16.2.226\nServerActive=172.16.2.226\nHostname=linux_host_231\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n```\n\n\n\n*备注：*\n\n*Zabbix Agent默认开放 10050 端口*\n\n*Zabbix Proxy默认开放 10051 端口*","tags":["zabbix"]},{"title":"【zabbix】CentOS7安装Zabbix","url":"/2019/05/27/【zabbix】CentOS7安装Zabbix/","content":"\n## Zabbix 安装（CentOS 7）\n\n### Zabbix Server安装\n\n#### 1. 安装LAMP\n\n```\n yum install -y httpd mariadb-server php php-mysql php-gd libjpeg* php-ldap php-odbc php-pear php-xml php-xmlrpc php-mhash php-mbstring php-bcmath\n```\n\n#### 2. 修改Apache 配置\n\n```\n# vi /etc/httpd/conf/httpd.conf\n\nServerName zabbixserver\nDirectoryIndex index.html index.php\n```\n\n#### 3. 修改PHP 配置\n\n```\n# vi /etc/php.ini\n\ndate.timezone = PRC\t//修改为中国时区\n```\n\n#### 4. 修改Firewalld 和 Selinux \n\n```\nsystemctl stop firewalld\n\nsed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config\nsetenforce 0\n\n# 在 enforcing 模式下启用 SELinux 状态后，您需要执行以下命令以启用 Zabbix 前端和 Zabbix server 之间的通信：\nsetsebool -P httpd_can_connect_zabbix on\nsetsebool -P httpd_can_network_connect_db on\nsystemctl restart httpd\n```\n\n#### 5. 启动服务\n\n```\nsystemctl enable httpd mariadb\nsystemctl start httpd mariadb\n```\n\n#### 6. 初始化数据库\n\n```\nmysql_secure_installation\n```\n\n#### 7. 测试LAMP 是否搭建成功\n\n```\n# vi /var/www/html/index.php\n\n<?php\nphpinfo();\n?>\n\n访问：http://server_ip_or_name\n```\n\n#### 8. 添加zabbix 软件仓库\n\n```\nrpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm\nyum clean all\n```\n\n#### 9. 修改软件仓库，使用国内源（清华源）\n\n```\n# vi /etc/yum.repos.d/zabbix.repo\n\n[zabbix]\nname=Zabbix Official Repository - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/$basearch/\nenabled=1\ngpgcheck=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591\n\n[zabbix-non-supported]\nname=Zabbix Official Repository non-supported - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/non-supported/rhel/7/$basearch/\nenabled=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX\ngpgcheck=0\n```\n\n#### 10. 安装Zabbix server，Web前端，agent\n\n```\nyum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent\n```\n\n#### 11.  创建初始数据库\n\n```\n# mysql -uroot -p\npassword\nmysql> create database zabbix character set utf8 collate utf8_bin;\nmysql> grant all privileges on zabbix.* to zabbix@localhost identified by 'password';\nmysql> quit;\n```\n\n#### 12. 导入初始架构和数据，系统将提示您输入新创建的密码\n\n```\nzcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix\n```\n\n#### 13. 为Zabbix server 配置数据库\n\n```\n# egrep -v \"^$|^#\" /etc/zabbix/zabbix_server.conf \n\nLogFile=/var/log/zabbix/zabbix_server.log\nLogFileSize=0\nPidFile=/var/run/zabbix/zabbix_server.pid\nSocketDir=/var/run/zabbix\nDBName=zabbix\nDBUser=zabbix\nDBPassword=<zabbix_user_password>\nSNMPTrapperFile=/var/log/snmptrap/snmptrap.log\nTimeout=4\nAlertScriptsPath=/usr/lib/zabbix/alertscripts\nExternalScripts=/usr/lib/zabbix/externalscripts\nLogSlowQueries=3000\n```\n\n#### 14. 为Zabbix 前端配置PHP\n\n```\n# vi /etc/httpd/conf.d/zabbix.conf\n\nphp_value date.timezone Asia/Shanghai\n```\n\n#### 15. 启动Zabbix server 和agent 服务\n\n```\nsystemctl enable zabbix-server zabbix-agent\nsystemctl restart zabbix-server zabbix-agent httpd\n```\n\n#### 16. 配置Zabbix 前端\n\n```\n访问：http://server_ip_or_name/zabbix 按提示输入相关信息\n```\n\n#### 17. 开始使用Zabbix\n\n```\n用户名：Admin\n密码：zabbix\n```\n\n\n\n### Zabbix Proxy安装\n\n#### 1. 安装数据库\n\n```\nyum install -y mariadb-server\n```\n\n#### 2. 启动服务\n\n```\nsystemctl enable mariadb\nsystemctl start mariadb\n```\n\n#### 3. 初始化数据库\n\n```\nmysql_secure_installation\n```\n\n#### 4. 添加zabbix 软件仓库\n\n```\nrpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm\nyum clean all\n```\n\n#### 5. 修改软件仓库，使用国内源（清华源）\n\n```\n# vi /etc/yum.repos.d/zabbix.repo\n\n[zabbix]\nname=Zabbix Official Repository - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/$basearch/\nenabled=1\ngpgcheck=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591\n\n[zabbix-non-supported]\nname=Zabbix Official Repository non-supported - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/non-supported/rhel/7/$basearch/\nenabled=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX\ngpgcheck=0\n```\n\n#### 6. 安装Zabbix proxy\n\n```\nyum -y install zabbix-proxy-mysql\n```\n\n#### 7.  创建初始数据库\n\n```\n# mysql -uroot -p\npassword\nmysql> create database zabbix_proxy character set utf8 collate utf8_bin;\nmysql> grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'password';\nmysql> quit;\n```\n\n#### 8. 导入初始架构和数据，系统将提示您输入新创建的密码\n\n```\nzcat /usr/share/doc/zabbix-proxy-mysql*/schema.sql.gz | mysql -uzabbix -p zabbix_proxy\n```\n\n#### 9. 为Zabbix server 配置数据库\n\n```\n# egrep -v \"^$|^#\" /etc/zabbix/zabbix_proxy.conf \n\nServer=<zabbix_server>\nHostname=Zabbix proxy\nLogFile=/var/log/zabbix/zabbix_proxy.log\nLogFileSize=0\nPidFile=/var/run/zabbix/zabbix_proxy.pid\nSocketDir=/var/run/zabbix\nDBName=zabbix_proxy\nDBUser=zabbix\nDBPassword=<zabbix_proxy_user_password>\nSNMPTrapperFile=/var/log/snmptrap/snmptrap.log\nTimeout=4\nExternalScripts=/usr/lib/zabbix/externalscripts\nLogSlowQueries=3000\n```\n\n#### 10. 启动Zabbix proxy服务\n\n```\nsystemctl enable zabbix-proxy\nsystemctl start zabbix-proxy\n```\n\n\n\n### Zabbix Agent安装\n\n#### 1.  添加zabbix 软件仓库\n\n```\nrpm -ivh https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm\nyum clean all\n```\n\n#### 2. 修改软件仓库，使用国内源（清华源）\n\n```\n# vi /etc/yum.repos.d/zabbix.repo\n\n[zabbix]\nname=Zabbix Official Repository - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/4.0/rhel/7/$basearch/\nenabled=1\ngpgcheck=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591\n\n[zabbix-non-supported]\nname=Zabbix Official Repository non-supported - $basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/zabbix/non-supported/rhel/7/$basearch/\nenabled=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX\ngpgcheck=0\n```\n\n#### 3. 安装Zabbix Agent\n\n```\nyum install -y zabbix-agent\n```\n\n#### 4. 配置 Zabbix Agent\n\n```\n# egrep -v \"^$|^#\" /etc/zabbix/zabbix_agentd.conf \n\nPidFile=/var/run/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\nLogFileSize=0\nServer=<zabbix_server_or_zabbix_proxy_ip>\nServerActive=<zabbix_server_or_zabbix_proxy_ip>\nHostname=<hostname>\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n\n```\n\n#### 5. 修改Firewalld 和 Selinux \n\n```\nsystemctl stop firewalld\n\nsed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config\nsetenforce 0\n\n```\n\n#### 6. 启动服务\n\n```\nsystemctl enable zabbix-agent\nsystemctl restart zabbix-agent\n\n```\n\n#### 7. 在WEB平台上增加被控主机\n\n\n\n*备注：*\n\n1. *配置文件中的Hostname 一定要与界面上保持一致*\n2. *agent 配置Server 和ServerActive 时要确定直接被Server 管控还是使用Proxy*\n3. *SELINUX 一定要预先设置为disable，最好设置后重启系统*\n4. *要么关闭防火墙，要么开放对应的端口（agent：10050，proxy：10051）*\n5. *使用二进制包安装时切换到国内源，官方源实在太慢了*\n\n","tags":["zabbix"]},{"title":"【vagrant】Vagrant安装使用","url":"/2019/05/25/【vagrant】Vagrant安装使用/","content":"\n### 简介\n\nVagrant是一个基于Ruby的工具，用于创建和部署虚拟化开发环境。它 使用Oracle的开源 VirtualBox虚拟化系统，使用 Chef创建自动化虚拟环境。\n\n### 下载\n\n[Vagrant Download](https://www.vagrantup.com/downloads.html)\n\n### 安装\n\n#### 在CentOS 7上安装VirtualBox\n\n```\n首先安装VirtualBox依赖项。\n# yum install gcc make perl -y\n\n更新内核并重启生效\n# yum -y install kernel kernel-headers kernel-tools kernel-devel\n# rpm -e kernel-<old>\n# reboot\n\n接下来添加VirtualBox库。\n# cd /etc/yum.repo.d/\n# wget http://download.virtualbox.org/virtualbox/rpm/rhel/virtualbox.repo\n\n现在安装和构建内核模块。\n# yum install -y VirtualBox-6.0\n或\n# yum localinstall -y VirtualBox-6.0-6.0.8_130520_el7-1.x86_64.rpm\n# /sbin/rcvboxdrv setup\n\n```\n\n#### 在CentOS 7上安装Vagrant\n\n```\n下载最新的vagrant，安装\n# yum localinstall -y vagrant_2.2.4_x86_64.rpm\n```\n\n### 使用\n\n```\nmkdir -p ~/dev\ncd ~/dev\nvagrant init centos/7  # 用 centos/7 进行 box 初始化\nvagrant up  # 启动环境\n\nvagrant ssh  # SSH 登录\ncd /vagrant  # 切换到开发目录，也就是宿主机上的 `~/dev`\n\nvagrant package  # 打包开发环境\n\nvagrant box add centos7 ~/box/package.box  # 添加 package.box 镜像并命名为 centos7\ncd ~/dev  # 切换到项目目录\nvagrant init centos7  # 用 centos7 镜像初始化。\n\n# 常用命令\nvagrant init  # 初始化\nvagrant up  # 启动虚拟机\nvagrant halt  # 关闭虚拟机\nvagrant reload  # 重启虚拟机\nvagrant ssh  # SSH 至虚拟机\nvagrant status  # 查看虚拟机运行状态\nvagrant destroy  # 销毁当前虚拟机\n```\n\n","tags":["vagrant"]},{"title":"【docker】Dockerfile参考文档","url":"/2019/05/23/【docker】Dockerfile参考文档/","content":"\n### Dockerfile参考文档\n\n[Dockerfile介绍](http://www.dockerinfo.net/dockerfile%e4%bb%8b%e7%bb%8d)\n\n[Dockerfile instructions](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#dockerfile-instructions)\n\n\n\n## Dockerfile instructions\n\nThese recommendations are designed to help you create an efficient and maintainable `Dockerfile`.\n\n### FROM\n\n[Dockerfile reference for the FROM instruction](https://docs.docker.com/engine/reference/builder/#from)\n\nWhenever possible, use current official images as the basis for your images. We recommend the [Alpine image](https://hub.docker.com/_/alpine/) as it is tightly controlled and small in size (currently under 5 MB), while still being a full Linux distribution.\n\n### LABEL\n\n[Understanding object labels](https://docs.docker.com/config/labels-custom-metadata/)\n\nYou can add labels to your image to help organize images by project, record licensing information, to aid in automation, or for other reasons. For each label, add a line beginning with `LABEL` and with one or more key-value pairs. The following examples show the different acceptable formats. Explanatory comments are included inline.\n\n> Strings with spaces must be quoted **or** the spaces must be escaped. Inner quote characters (`\"`), must also be escaped.\n\n```Dockerfile\n# Set one or more individual labels\nLABEL com.example.version=\"0.0.1-beta\"\nLABEL vendor1=\"ACME Incorporated\"\nLABEL vendor2=ZENITH\\ Incorporated\nLABEL com.example.release-date=\"2015-02-12\"\nLABEL com.example.version.is-production=\"\"\n```\n\nAn image can have more than one label. Prior to Docker 1.10, it was recommended to combine all labels into a single `LABEL`instruction, to prevent extra layers from being created. This is no longer necessary, but combining labels is still supported.\n\n```Dockerfile\n# Set multiple labels on one line\nLABEL com.example.version=\"0.0.1-beta\" com.example.release-date=\"2015-02-12\"\n```\n\nThe above can also be written as:\n\n```Dockerfile\n# Set multiple labels at once, using line-continuation characters to break long lines\nLABEL vendor=ACME\\ Incorporated \\\n      com.example.is-beta= \\\n      com.example.is-production=\"\" \\\n      com.example.version=\"0.0.1-beta\" \\\n      com.example.release-date=\"2015-02-12\"\n```\n\nSee [Understanding object labels](https://docs.docker.com/config/labels-custom-metadata/) for guidelines about acceptable label keys and values. For information about querying labels, refer to the items related to filtering in [Managing labels on objects](https://docs.docker.com/config/labels-custom-metadata/#managing-labels-on-objects). See also [LABEL](https://docs.docker.com/engine/reference/builder/#label) in the Dockerfile reference.\n\n### RUN\n\n[Dockerfile reference for the RUN instruction](https://docs.docker.com/engine/reference/builder/#run)\n\nSplit long or complex `RUN` statements on multiple lines separated with backslashes to make your `Dockerfile` more readable, understandable, and maintainable.\n\n#### APT-GET\n\nProbably the most common use-case for `RUN` is an application of `apt-get`. Because it installs packages, the `RUN apt-get`command has several gotchas to look out for.\n\nAvoid `RUN apt-get upgrade` and `dist-upgrade`, as many of the “essential” packages from the parent images cannot upgrade inside an [unprivileged container](https://docs.docker.com/engine/reference/run/#security-configuration). If a package contained in the parent image is out-of-date, contact its maintainers. If you know there is a particular package, `foo`, that needs to be updated, use `apt-get install -y foo` to update automatically.\n\nAlways combine `RUN apt-get update` with `apt-get install` in the same `RUN` statement. For example:\n\n```Dockerfile\nRUN apt-get update && apt-get install -y \\\n    package-bar \\\n    package-baz \\\n    package-foo\n```\n\nUsing `apt-get update` alone in a `RUN` statement causes caching issues and subsequent `apt-get install` instructions fail. For example, say you have a Dockerfile:\n\n```Dockerfile\nFROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y curl\n```\n\nAfter building the image, all layers are in the Docker cache. Suppose you later modify `apt-get install` by adding extra package:\n\n```Dockerfile\nFROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y curl nginx\n```\n\nDocker sees the initial and modified instructions as identical and reuses the cache from previous steps. As a result the `apt-get update` is *not* executed because the build uses the cached version. Because the `apt-get update` is not run, your build can potentially get an outdated version of the `curl` and `nginx` packages.\n\nUsing `RUN apt-get update && apt-get install -y` ensures your Dockerfile installs the latest package versions with no further coding or manual intervention. This technique is known as “cache busting”. You can also achieve cache-busting by specifying a package version. This is known as version pinning, for example:\n\n```Dockerfile\nRUN apt-get update && apt-get install -y \\\n    package-bar \\\n    package-baz \\\n    package-foo=1.3.*\n```\n\nVersion pinning forces the build to retrieve a particular version regardless of what’s in the cache. This technique can also reduce failures due to unanticipated changes in required packages.\n\nBelow is a well-formed `RUN` instruction that demonstrates all the `apt-get` recommendations.\n\n```Dockerfile\nRUN apt-get update && apt-get install -y \\\n    aufs-tools \\\n    automake \\\n    build-essential \\\n    curl \\\n    dpkg-sig \\\n    libcap-dev \\\n    libsqlite3-dev \\\n    mercurial \\\n    reprepro \\\n    ruby1.9.1 \\\n    ruby1.9.1-dev \\\n    s3cmd=1.1.* \\\n && rm -rf /var/lib/apt/lists/*\n```\n\nThe `s3cmd` argument specifies a version `1.1.*`. If the image previously used an older version, specifying the new one causes a cache bust of `apt-get update` and ensures the installation of the new version. Listing packages on each line can also prevent mistakes in package duplication.\n\nIn addition, when you clean up the apt cache by removing `/var/lib/apt/lists` it reduces the image size, since the apt cache is not stored in a layer. Since the `RUN` statement starts with `apt-get update`, the package cache is always refreshed prior to `apt-get install`.\n\n> Official Debian and Ubuntu images [automatically run `apt-get clean`](https://github.com/moby/moby/blob/03e2923e42446dbb830c654d0eec323a0b4ef02a/contrib/mkimage/debootstrap#L82-L105), so explicit invocation is not required.\n\n#### USING PIPES\n\nSome `RUN` commands depend on the ability to pipe the output of one command into another, using the pipe character (`|`), as in the following example:\n\n```Dockerfile\nRUN wget -O - https://some.site | wc -l > /number\n```\n\nDocker executes these commands using the `/bin/sh -c` interpreter, which only evaluates the exit code of the last operation in the pipe to determine success. In the example above this build step succeeds and produces a new image so long as the `wc -l`command succeeds, even if the `wget` command fails.\n\nIf you want the command to fail due to an error at any stage in the pipe, prepend `set -o pipefail &&` to ensure that an unexpected error prevents the build from inadvertently succeeding. For example:\n\n```Dockerfile\nRUN set -o pipefail && wget -O - https://some.site | wc -l > /number\n```\n\n> Not all shells support the `-o pipefail` option.\n>\n> In cases such as the `dash` shell on Debian-based images, consider using the *exec* form of `RUN` to explicitly choose a shell that does support the `pipefail` option. For example:\n>\n> ```Dockerfile\n> RUN [\"/bin/bash\", \"-c\", \"set -o pipefail && wget -O - https://some.site | wc -l > /number\"]\n> ```\n\n### CMD\n\n[Dockerfile reference for the CMD instruction](https://docs.docker.com/engine/reference/builder/#cmd)\n\nThe `CMD` instruction should be used to run the software contained by your image, along with any arguments. `CMD` should almost always be used in the form of `CMD [\"executable\", \"param1\", \"param2\"…]`. Thus, if the image is for a service, such as Apache and Rails, you would run something like `CMD [\"apache2\",\"-DFOREGROUND\"]`. Indeed, this form of the instruction is recommended for any service-based image.\n\nIn most other cases, `CMD` should be given an interactive shell, such as bash, python and perl. For example, `CMD [\"perl\", \"-de0\"]`, `CMD [\"python\"]`, or `CMD [\"php\", \"-a\"]`. Using this form means that when you execute something like `docker run -it python`, you’ll get dropped into a usable shell, ready to go. `CMD` should rarely be used in the manner of `CMD [\"param\", \"param\"]` in conjunction with [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#entrypoint), unless you and your expected users are already quite familiar with how `ENTRYPOINT` works.\n\n### EXPOSE\n\n[Dockerfile reference for the EXPOSE instruction](https://docs.docker.com/engine/reference/builder/#expose)\n\nThe `EXPOSE` instruction indicates the ports on which a container listens for connections. Consequently, you should use the common, traditional port for your application. For example, an image containing the Apache web server would use `EXPOSE 80`, while an image containing MongoDB would use `EXPOSE 27017` and so on.\n\nFor external access, your users can execute `docker run` with a flag indicating how to map the specified port to the port of their choice. For container linking, Docker provides environment variables for the path from the recipient container back to the source (ie, `MYSQL_PORT_3306_TCP`).\n\n### ENV\n\n[Dockerfile reference for the ENV instruction](https://docs.docker.com/engine/reference/builder/#env)\n\nTo make new software easier to run, you can use `ENV` to update the `PATH` environment variable for the software your container installs. For example, `ENV PATH /usr/local/nginx/bin:$PATH` ensures that `CMD [\"nginx\"]` just works.\n\nThe `ENV` instruction is also useful for providing required environment variables specific to services you wish to containerize, such as Postgres’s `PGDATA`.\n\nLastly, `ENV` can also be used to set commonly used version numbers so that version bumps are easier to maintain, as seen in the following example:\n\n```Dockerfile\nENV PG_MAJOR 9.3\nENV PG_VERSION 9.3.4\nRUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress && …\nENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH\n```\n\nSimilar to having constant variables in a program (as opposed to hard-coding values), this approach lets you change a single `ENV`instruction to auto-magically bump the version of the software in your container.\n\nEach `ENV` line creates a new intermediate layer, just like `RUN` commands. This means that even if you unset the environment variable in a future layer, it still persists in this layer and its value can be dumped. You can test this by creating a Dockerfile like the following, and then building it.\n\n```Dockerfile\nFROM alpine\nENV ADMIN_USER=\"mark\"\nRUN echo $ADMIN_USER > ./mark\nRUN unset ADMIN_USER\n$ docker run --rm test sh -c 'echo $ADMIN_USER'\n\nmark\n```\n\nTo prevent this, and really unset the environment variable, use a `RUN` command with shell commands, to set, use, and unset the variable all in a single layer. You can separate your commands with `;` or `&&`. If you use the second method, and one of the commands fails, the `docker build` also fails. This is usually a good idea. Using `\\` as a line continuation character for Linux Dockerfiles improves readability. You could also put all of the commands into a shell script and have the `RUN` command just run that shell script.\n\n```Dockerfile\nFROM alpine\nRUN export ADMIN_USER=\"mark\" \\\n    && echo $ADMIN_USER > ./mark \\\n    && unset ADMIN_USER\nCMD sh\n$ docker run --rm test sh -c 'echo $ADMIN_USER'\n```\n\n### ADD or COPY\n\n- [Dockerfile reference for the ADD instruction](https://docs.docker.com/engine/reference/builder/#add)\n- [Dockerfile reference for the COPY instruction](https://docs.docker.com/engine/reference/builder/#copy)\n\nAlthough `ADD` and `COPY` are functionally similar, generally speaking, `COPY` is preferred. That’s because it’s more transparent than `ADD`. `COPY` only supports the basic copying of local files into the container, while `ADD` has some features (like local-only tar extraction and remote URL support) that are not immediately obvious. Consequently, the best use for `ADD` is local tar file auto-extraction into the image, as in `ADD rootfs.tar.xz /`.\n\nIf you have multiple `Dockerfile` steps that use different files from your context, `COPY` them individually, rather than all at once. This ensures that each step’s build cache is only invalidated (forcing the step to be re-run) if the specifically required files change.\n\nFor example:\n\n```Dockerfile\nCOPY requirements.txt /tmp/\nRUN pip install --requirement /tmp/requirements.txt\nCOPY . /tmp/\n```\n\nResults in fewer cache invalidations for the `RUN` step, than if you put the `COPY . /tmp/` before it.\n\nBecause image size matters, using `ADD` to fetch packages from remote URLs is strongly discouraged; you should use `curl` or `wget` instead. That way you can delete the files you no longer need after they’ve been extracted and you don’t have to add another layer in your image. For example, you should avoid doing things like:\n\n```Dockerfile\nADD http://example.com/big.tar.xz /usr/src/things/\nRUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things\nRUN make -C /usr/src/things all\n```\n\nAnd instead, do something like:\n\n```Dockerfile\nRUN mkdir -p /usr/src/things \\\n    && curl -SL http://example.com/big.tar.xz \\\n    | tar -xJC /usr/src/things \\\n    && make -C /usr/src/things all\n```\n\nFor other items (files, directories) that do not require `ADD`’s tar auto-extraction capability, you should always use `COPY`.\n\n### ENTRYPOINT\n\n[Dockerfile reference for the ENTRYPOINT instruction](https://docs.docker.com/engine/reference/builder/#entrypoint)\n\nThe best use for `ENTRYPOINT` is to set the image’s main command, allowing that image to be run as though it was that command (and then use `CMD` as the default flags).\n\nLet’s start with an example of an image for the command line tool `s3cmd`:\n\n```Dockerfile\nENTRYPOINT [\"s3cmd\"]\nCMD [\"--help\"]\n```\n\nNow the image can be run like this to show the command’s help:\n\n```\n$ docker run s3cmd\n```\n\nOr using the right parameters to execute a command:\n\n```\n$ docker run s3cmd ls s3://mybucket\n```\n\nThis is useful because the image name can double as a reference to the binary as shown in the command above.\n\nThe `ENTRYPOINT` instruction can also be used in combination with a helper script, allowing it to function in a similar way to the command above, even when starting the tool may require more than one step.\n\nFor example, the [Postgres Official Image](https://hub.docker.com/_/postgres/) uses the following script as its `ENTRYPOINT`:\n\n```\n#!/bin/bash\nset -e\n\nif [ \"$1\" = 'postgres' ]; then\n    chown -R postgres \"$PGDATA\"\n\n    if [ -z \"$(ls -A \"$PGDATA\")\" ]; then\n        gosu postgres initdb\n    fi\n\n    exec gosu postgres \"$@\"\nfi\n\nexec \"$@\"\n```\n\n> Configure app as PID 1\n>\n> This script uses [the `exec` Bash command](http://wiki.bash-hackers.org/commands/builtin/exec) so that the final running application becomes the container’s PID 1. This allows the application to receive any Unix signals sent to the container. For more, see the [`ENTRYPOINT` reference](https://docs.docker.com/engine/reference/builder/#entrypoint).\n\nThe helper script is copied into the container and run via `ENTRYPOINT` on container start:\n\n```Dockerfile\nCOPY ./docker-entrypoint.sh /\nENTRYPOINT [\"/docker-entrypoint.sh\"]\nCMD [\"postgres\"]\n```\n\nThis script allows the user to interact with Postgres in several ways.\n\nIt can simply start Postgres:\n\n```\n$ docker run postgres\n```\n\nOr, it can be used to run Postgres and pass parameters to the server:\n\n```\n$ docker run postgres postgres --help\n```\n\nLastly, it could also be used to start a totally different tool, such as Bash:\n\n```\n$ docker run --rm -it postgres bash\n```\n\n### VOLUME\n\n[Dockerfile reference for the VOLUME instruction](https://docs.docker.com/engine/reference/builder/#volume)\n\nThe `VOLUME` instruction should be used to expose any database storage area, configuration storage, or files/folders created by your docker container. You are strongly encouraged to use `VOLUME` for any mutable and/or user-serviceable parts of your image.\n\n### USER\n\n[Dockerfile reference for the USER instruction](https://docs.docker.com/engine/reference/builder/#user)\n\nIf a service can run without privileges, use `USER` to change to a non-root user. Start by creating the user and group in the `Dockerfile` with something like `RUN groupadd -r postgres && useradd --no-log-init -r -g postgres postgres`.\n\n> Consider an explicit UID/GID\n>\n> Users and groups in an image are assigned a non-deterministic UID/GID in that the “next” UID/GID is assigned regardless of image rebuilds. So, if it’s critical, you should assign an explicit UID/GID.\n\n> Due to an [unresolved bug](https://github.com/golang/go/issues/13548) in the Go archive/tar package’s handling of sparse files, attempting to create a user with a significantly large UID inside a Docker container can lead to disk exhaustion because `/var/log/faillog` in the container layer is filled with NULL (\\0) characters. A workaround is to pass the `--no-log-init` flag to useradd. The Debian/Ubuntu `adduser` wrapper does not support this flag.\n\nAvoid installing or using `sudo` as it has unpredictable TTY and signal-forwarding behavior that can cause problems. If you absolutely need functionality similar to `sudo`, such as initializing the daemon as `root` but running it as non-`root`), consider using [“gosu”](https://github.com/tianon/gosu).\n\nLastly, to reduce layers and complexity, avoid switching `USER` back and forth frequently.\n\n### WORKDIR\n\n[Dockerfile reference for the WORKDIR instruction](https://docs.docker.com/engine/reference/builder/#workdir)\n\nFor clarity and reliability, you should always use absolute paths for your `WORKDIR`. Also, you should use `WORKDIR` instead of proliferating instructions like `RUN cd … && do-something`, which are hard to read, troubleshoot, and maintain.\n\n### ONBUILD\n\n[Dockerfile reference for the ONBUILD instruction](https://docs.docker.com/engine/reference/builder/#onbuild)\n\nAn `ONBUILD` command executes after the current `Dockerfile` build completes. `ONBUILD` executes in any child image derived `FROM` the current image. Think of the `ONBUILD` command as an instruction the parent `Dockerfile` gives to the child `Dockerfile`.\n\nA Docker build executes `ONBUILD` commands before any command in a child `Dockerfile`.\n\n`ONBUILD` is useful for images that are going to be built `FROM` a given image. For example, you would use `ONBUILD` for a language stack image that builds arbitrary user software written in that language within the `Dockerfile`, as you can see in [Ruby’s `ONBUILD`variants](https://github.com/docker-library/ruby/blob/master/2.4/jessie/onbuild/Dockerfile).\n\nImages built from `ONBUILD` should get a separate tag, for example: `ruby:1.9-onbuild` or `ruby:2.0-onbuild`.\n\nBe careful when putting `ADD` or `COPY` in `ONBUILD`. The “onbuild” image fails catastrophically if the new build’s context is missing the resource being added. Adding a separate tag, as recommended above, helps mitigate this by allowing the `Dockerfile` author to make a choice.\n\n\n\n## Additional resources:\n\n- [Dockerfile Reference](https://docs.docker.com/engine/reference/builder/)\n- [More about Base Images](https://docs.docker.com/develop/develop-images/baseimages/)\n- [More about Automated Builds](https://docs.docker.com/docker-hub/builds/)\n- [Guidelines for Creating Official Images](https://docs.docker.com/docker-hub/official_images/)","tags":["docker"]},{"title":"【nagios】Nagios安装NDOUtils","url":"/2019/05/23/【nagios】Nagios安装NDOUtils/","content":"\n### 1. 连接被监控端出现Connection reset by peer 的问题\n\n```\n使用官方安装脚本（./fullinstall）在配置Allow host 时未输入监控端地址或输入错误导致的问题\n\n# vi /etc/xinetd.d/nrpe\nonly_from       = 127.0.0.1 192.168.32.166\n\n# systemctl restart xinetd\n\n监控端测试：\n/usr/local/nagios/libexec/check_nrpe -H 192.168.23.164\n被监控端测试：\n/usr/local/nagios/libexec/check_nrpe -H 127.0.0.1\n\n```\n\n### 2. 监控端只需要编译出check_nrpe 插件，并放到相应的位置即可\n\n```\n1. 直接从被监控端拷贝，并修改权限\n2. 源码安装\n./configure\nmake check_nrpe\nmake install-plugin\n\n```\n\n\n\n## CentOS 安装NDOUtils\n\n### Prerequisites\n\nInstalling MySQL or MariaDB is required.\n\n**CentOS 5.x / 6.x** \n\n```\nyum install -y mysql mysql-server mysql-devel\n```\n\n**CentOS 7.x**\n\n```\nyum install -y mariadb mariadb-server mariadb-devel\n```\n\n\n\n### Start And Configure MySQL / MariaDB\n\nBefore configuring MySQL / MariaDB you must start the service and configure it to boot on startup.\n\n**CentOS 5.x / 6.x**\n\n```\nservice mysqld start\n```\n\nCheck that it is running:\n\n```\nps x | grep mysql | grep -v grep\n```\n\nWhich should output something like:\n\n```\n 1969 pts/0    S      0:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql\n```\n\nConfigure it to start when the system boots:\n\n```\nchkconfig --add mysqld\nchkconfig mysqld on\n```\n\n**CentOS 7.x**\n\n```\nsystemctl start mariadb.service\n```\n\nCheck that it is running:\n\n```\nps ax | grep mysql | grep -v grep\n```\n\nWhich should output something like:\n\n```\n2781 ?        Ss     0:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr\n2938 ?        Sl     0:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mariadb/mariadb.log --pid-file=/var/run/mariadb/mariadb.pid --socket=/var/lib/mysql/mysql.sock\n```\n\nConfigure it to start when the system boots:\n\n```\nsystemctl enable mariadb.service\n```\n\n \n\n### Define MySQL / MariaDB Root Password\n\nNow to define the password for the root account in MySQL / MariaDB.\n\nThe password being defined is '**mypassword**' and will be used in future commands *(we suggest you use a more secure password)*.\n\nThe **'**single quotes**'** are used to define the boundaries of the password, this is extremely important when the password contains a space or special characters.\n\n```\n/usr/bin/mysqladmin -u root password 'mypassword'\n```\n\n \n\n### Password Note:\n\nIn future commands you will see the password is provided using the **-p** argument like follows:\n\n```\nmysql -u root -p'mypassword'\n```\n\n**NOTE:** It's very important to **NOT** put a space between the **-p** and the **'mypassword'**.\n\n \n\n### Create Database\n\nNDOUtils requires a database to be created which will be called **nagios**.\n\nThere will also be a dedicated user account called **ndoutils** with the password **ndoutils_password** *(we suggest you use a more secure password)*.\n\nThe storage location of the database will be the default location that MySQL / MariaDB uses, this can be changed however it is not covered in this guide.\n\nThis command will connect to the local MySQL / MariaDB database engine interface.\n\n```\nmysql -u root -p'mypassword'\n```\n\nNow execute these four commands *(press \\**Enter** after each command)*:\n\n```\nCREATE DATABASE nagios DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\nCREATE USER 'ndoutils'@'localhost' IDENTIFIED BY 'ndoutils_password';\nGRANT USAGE ON *.* TO 'ndoutils'@'localhost' IDENTIFIED BY 'ndoutils_password' WITH MAX_QUERIES_PER_HOUR 0 MAX_CONNECTIONS_PER_HOUR 0 MAX_UPDATES_PER_HOUR 0 MAX_USER_CONNECTIONS 0 ; \nGRANT ALL PRIVILEGES ON nagios.* TO 'ndoutils'@'localhost' WITH GRANT OPTION ; \n```\n\nNow you can exit the local MySQL / MariaDB database engine interface.\n\n```\n\\q\n```\n\nRun this command to ensure that the database has been created:\n\n```\necho 'show databases;' | mysql -u ndoutils -p'ndoutils_password' -h localhost\n```\n\nThe last command should output something like:\n\n```\nDatabase\ninformation_schema\nnagios\ntest\n```\n\n \n\n### Linux Kernel Settings\n\nNDOUtils uses the kernel message queue for transferring the data from Nagios to NDOUtils. We are going to increase the default values the Kernel boots with to ensure it operates optimally.\n\nFirst create a backup copy of the **/etc/sysctl.conf** file:\n\n```\ncp /etc/sysctl.conf /etc/sysctl.conf_backup\n```\n\nNow make the required changes:\n\n```\nsed -i '/msgmnb/d' /etc/sysctl.conf\nsed -i '/msgmax/d' /etc/sysctl.conf\nsed -i '/shmmax/d' /etc/sysctl.conf\nsed -i '/shmall/d' /etc/sysctl.conf\nprintf \"\\n\\nkernel.msgmnb = 131072000\\n\" >> /etc/sysctl.conf\nprintf \"kernel.msgmax = 131072000\\n\" >> /etc/sysctl.conf\nprintf \"kernel.shmmax = 4294967295\\n\" >> /etc/sysctl.conf\nprintf \"kernel.shmall = 268435456\\n\" >> /etc/sysctl.conf\nsysctl -e -p /etc/sysctl.conf\n```\n\nThe last command should output something like:\n\n```\nnet.ipv4.ip_forward = 0\nnet.ipv4.conf.default.rp_filter = 1\nnet.ipv4.conf.default.accept_source_route = 0\nkernel.sysrq = 0\nkernel.core_uses_pid = 1\nnet.ipv4.tcp_syncookies = 1\nkernel.msgmnb = 131072000\nkernel.msgmax = 131072000\nkernel.shmmax = 4294967295\nkernel.shmall = 268435456\n```\n\nThere is no need to reboot the system, the last command ensured the new settings are active in the kernel.\n\n\n\n### Downloading NDOUtils Source\n\n```\ncd /tmp\nwget -O ndoutils.tar.gz https://github.com/NagiosEnterprises/ndoutils/releases/download/ndoutils-2.1.3/ndoutils-2.1.3.tar.gz\ntar xzf ndoutils.tar.gz\n```\n\n \n\n### Compile NDOUtils\n\n```\ncd /tmp/ndoutils-2.1.3/\n./configure\nmake all\n```\n\n \n\n### Install Binaries\n\nThis step installs the binary files.\n\n```\nmake install\n```\n\n \n\n### Initialize Database\n\nThis prepares the database for NDOUtils.\n\n```\ncd db/\n./installdb -u 'ndoutils' -p 'ndoutils_password' -h 'localhost' -d nagios\ncd .. \n```\n\nThe command will produce output similar to the following:\n\n```\nDBD::mysql::db do failed: Table 'nagios.nagios_dbversion' doesn't exist at ./installdb line 52.\n** Creating tables for version 2.0.1\n     Using mysql.sql for installation...\n** Updating table nagios_dbversion\nDone!\n```\n\nThat first line of output that says **failed: Table 'nagios.nagios_dbversion' doesn't exist** is expected, it's testing to make sure the database hasn't already been intiaialized.\n\n \n\n### Install Configuration Files\n\nThis installs the config files as well as configuring the MySQL / MariaDB credentials so NDOUtils can connect to the database.\n\nThe two config files are:\n\n**/usr/local/nagios/etc/ndo2db.cfg**\n\nThe following lines are defined in this file:\n\n```\ndb_user=ndoutils\ndb_pass=ndoutils_password\n```\n\nYou should make sure the username and password are correct.\n\n**/usr/local/nagios/etc/ndomod.cfg**\n\nNo changes are required in this file.\n\nUsing the default username and password the following commands install the configuration files and make the required changes.\n\n```\nmake install-config\nmv /usr/local/nagios/etc/ndo2db.cfg-sample /usr/local/nagios/etc/ndo2db.cfg\nsed -i 's/^db_user=.*/db_user=ndoutils/g' /usr/local/nagios/etc/ndo2db.cfg\nsed -i 's/^db_pass=.*/db_pass=ndoutils_password/g' /usr/local/nagios/etc/ndo2db.cfg\nmv /usr/local/nagios/etc/ndomod.cfg-sample /usr/local/nagios/etc/ndomod.cfg\n```\n\n \n\n### Install Service / Daemon\n\nThis installs the service or daemon files and configure them to start on boot.\n\n**CentOS 5.x / 6.x**\n\n```\nmake install-init\n```\n\n**CentOS 7.x**\n\n```\nmake install-init\nsystemctl enable ndo2db.service\n```\n\nInformation on starting and stopping services will be explained further on.\n\n \n\n### Start Service / Daemon\n\nDifferent Linux distributions have different methods of starting the ndo2db service.\n\n**CentOS 5.x**\n\n```\nservice ndo2db start\n```\n\n**CentOS 6.x**\n\n```\nstart ndo2db\n```\n\n**CentOS 7.x**\n\n```\nsystemctl start ndo2db.service\n```\n\n \n\n### Update Nagios To Use NDO Broker Module\n\nNow you need to tell Nagios to use the NDO broker module. This is as simple as adding the following line to the **nagios.cfg** file:\n\n```\nbroker_module=/usr/local/nagios/bin/ndomod.o config_file=/usr/local/nagios/etc/ndomod.cfg\n```\n\nThe following commands will add that line as well as an extra line that explains what the module is for.\n\n```\nprintf \"\\n\\n# NDOUtils Broker Module\\n\" >> /usr/local/nagios/etc/nagios.cfg\nprintf \"broker_module=/usr/local/nagios/bin/ndomod.o config_file=/usr/local/nagios/etc/ndomod.cfg\\n\" >> /usr/local/nagios/etc/nagios.cfg \n```\n\n \n\n### Restart Nagios\n\nNow you need to restart Nagios to use the NDO broker module. Different Linux distributions have different methods of restarting Nagios Core. We will also check the status of the Nagios service to ensure it's running after these changes.\n\n**CentOS 5.x / 6.x**\n\n```\nservice nagios restart\nservice nagios status\n```\n\n**CentOS 7.x**\n\n```\nsystemctl restart nagios.service\nsystemctl status nagios.service\n```\n\nThe last command should show Nagios running:\n\n**CentOS 5.x / 6.x**\n\n```\nnagios (pid 5345) is running...\n```\n\n**CentOS 7.x**\n\n```\n● nagios.service - LSB: Starts and stops the Nagios monitoring server\n   Loaded: loaded (/etc/rc.d/init.d/nagios)\n   Active: active (running) since Tue 2016-10-04 12:31:00 AEDT; 22s ago\n```\n\n \n\n### Check NDOUtils Is Working\n\nThere are a couple of different ways to ensure NDO2DB is working.\n\nThis command will show Nagios successfully loaded the NDO module:\n\n```\ngrep ndo /usr/local/nagios/var/nagios.log\n```\n\nThe last command should output something like:\n\n```\n[1475544660] ndomod: NDOMOD 2.1.1 (09-06-2016) Copyright (c) 2009 Nagios Core Development Team and Community Contributors\n[1475544660] ndomod: Successfully connected to data sink.  0 queued items to flush.\n[1475544660] ndomod registered for process data\n[1475544660] ndomod registered for timed event data\n[1475544660] ndomod registered for log data'\n[1475544660] ndomod registered for system command data'\n[1475544660] ndomod registered for event handler data'\n[1475544660] ndomod registered for notification data'\n[1475544660] ndomod registered for service check data'\n[1475544660] ndomod registered for host check data'\n[1475544660] ndomod registered for comment data'\n[1475544660] ndomod registered for downtime data'\n[1475544660] ndomod registered for flapping data'\n[1475544660] ndomod registered for program status data'\n[1475544660] ndomod registered for host status data'\n[1475544660] ndomod registered for service status data'\n[1475544660] ndomod registered for adaptive program data'\n[1475544660] ndomod registered for adaptive host data'\n[1475544660] ndomod registered for adaptive service data'\n[1475544660] ndomod registered for external command data'\n[1475544660] ndomod registered for aggregated status data'\n[1475544660] ndomod registered for retention data'\n[1475544660] ndomod registered for contact data'\n[1475544660] ndomod registered for contact notification data'\n[1475544660] ndomod registered for acknowledgement data'\n[1475544660] ndomod registered for state change data'\n[1475544660] ndomod registered for contact status data'\n[1475544660] ndomod registered for adaptive contact data'\n[1475544660] Event broker module '/usr/local/nagios/bin/ndomod.o' initialized successfully.\n```\n\nThis command will show you the database with populated data:\n\n```\necho 'select * from nagios.nagios_logentries;' | mysql -u ndoutils -p'ndoutils_password'\n```\n\nThe last command should output something like:\n\n```\nlogentry_id    instance_id    logentry_time    entry_time    entry_time_usec    logentry_type    logentry_data    realtime_data    inferred_data_extracted\n1    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868450    262144    ndomod registered for log data'    1    1\n2    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868462    262144    ndomod registered for system command data'    1    1\n3    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868467    262144    ndomod registered for event handler data'    1    1\n4    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868472    262144    ndomod registered for notification data'    1    1\n5    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868479    262144    ndomod registered for service check data'    1    1\n6    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868486    262144    ndomod registered for host check data'    1    1\n7    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868491    262144    ndomod registered for comment data'    11\n8    1    2016-10-04 12:31:00    2016-10-04 12:31:00    868496    262144    ndomod registered for downtime data'11\n9    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869866    262144    ndomod registered for flapping data'11\n10    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869878    262144    ndomod registered for program status data'    1    1\n11    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869884    262144    ndomod registered for host status data'    1    1\n12    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869888    262144    ndomod registered for service status data'    1    1\n13    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869893    262144    ndomod registered for adaptive program data'    1    1\n14    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869897    262144    ndomod registered for adaptive host data'    1    1\n15    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869902    262144    ndomod registered for adaptive service data'    1    1\n16    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869906    262144    ndomod registered for external command data'    1    1\n17    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869911    262144    ndomod registered for aggregated status data'    1    1\n18    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869915    262144    ndomod registered for retention data'1    1\n19    1    2016-10-04 12:31:00    2016-10-04 12:31:00    869920    262144    ndomod registered for contact data'    11\n20    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871043    262144    ndomod registered for contact notification data'    1    1\n21    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871055    262144    ndomod registered for acknowledgement data'    1    1\n22    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871062    262144    ndomod registered for state change data'    1    1\n23    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871067    262144    ndomod registered for contact status data'    1    1\n24    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871072    262144    ndomod registered for adaptive contact data'    1    1\n25    1    2016-10-04 12:31:00    2016-10-04 12:31:00    871077    262144    Event broker module '/usr/local/nagios/bin/ndomod.o' initialized successfully.    1    1\n26    1    2016-10-04 12:31:00    2016-10-04 12:31:00    874858    262144    Successfully launched command file worker with pid 6026    1    1\n```\n\n \n\n### Service Commands\n\nDifferent Linux distributions have different methods of starting / stopping / restarting / status ndo2db.\n\n**CentOS 5.x**\n\n```\nservice ndo2db start\nservice ndo2db stop\nservice ndo2db restart\nservice ndo2db status\n```\n\n**CentOS 6.x**\n\n```\nstart ndo2db\nstop ndo2db\nrestart ndo2db\nstatus ndo2db\n```\n\n**CentOS 7.x**\n\n```\nsystemctl start ndo2db.service\nsystemctl stop ndo2db.service\nsystemctl restart ndo2db.service\nsystemctl status ndo2db.service\n```","tags":["nagios"]},{"title":"【nagios】Nagios监控Linux主机内部信息","url":"/2019/05/22/【nagios】Nagios监控Linux主机内部信息/","content":"\n### Installing NRPE Using the Install Script\n\nYou must run the following commands as root.\n\n```\ncd /tmp\n```\n\nFor CentOS & RHEL 5-7, Fedora 14+, SLES & OpenSUSE 11+, Ubuntu 12+, Debian 6+:\n\n```\nwget http://assets.nagios.com/downloads/nagiosxi/agents/linux-nrpe-agent.tar.gz\n```\n\nUnpack the installer, and run the install script:\n\n```\ntar xzf linux-nrpe-agent.tar.gz\ncd linux-nrpe-agent\n./fullinstall\n```\n\nThe script takes care of the following setup:\n\n- Installs prerequisite packages\n- Creates required users and groups\n- Defines services for xinetd\n- Compiles and installs the NRPE agent and Nagios plugins\n- Configures the firewall (except on SLES)\n- Configures the agent\n\nThe script will stop to prompt you once to ask for the IP address(es) for your monitoring server(s).\n\nYou will need to type either a single address or multiple addresses separated by spaces. This will configure the xinetd superdaemon to allow connections from those addresses to the NRPE agent.\n\nYou now have NRPE installed. You may remove any installation files in the tmp directory.\n\n \n\n### Nagios监控Linux主机内部信息\n\n1. 监控端安装软件\n\n```\n# nagioscore\nwget -O nagioscore.tar.gz https://github.com/NagiosEnterprises/nagioscore/archive/nagios-4.4.3.tar.gz\n\n# nagios-plugins\nwget --no-check-certificate -O nagios-plugins.tar.gz https://github.com/nagios-plugins/nagios-plugins/archive/release-2.2.1.tar.gz\n\n# nrpe（需要check_nrpe 插件）\nwget http://assets.nagios.com/downloads/nagiosxi/agents/linux-nrpe-agent.tar.gz\n```\n\n2. 被监控端安装软件\n\n```\n# nrpe\nwget http://assets.nagios.com/downloads/nagiosxi/agents/linux-nrpe-agent.tar.gz\n```\n\n3. 被监控端配置\n\n```\n# egrep -v \"^#|^$\" /usr/local/nagios/etc/nrpe.cfg\n\nlog_facility=daemon\npid_file=/var/run/nrpe.pid\nserver_port=5666\nnrpe_user=nagios\nnrpe_group=nagios\nallowed_hosts=127.0.0.1\n \ndont_blame_nrpe=1\ndebug=0\ncommand_timeout=60\nconnection_timeout=300\ninclude_dir=/usr/local/nagios/etc/nrpe\ncommand[check_users]=/usr/local/nagios/libexec/check_users -w 5 -c 10\ncommand[check_load]=/usr/local/nagios/libexec/check_load -w 15,10,5 -c 30,25,20\ncommand[check_hda1]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/sda2\ncommand[check_zombie_procs]=/usr/local/nagios/libexec/check_procs -w 5 -c 10 -s Z\ncommand[check_total_procs]=/usr/local/nagios/libexec/check_procs -w 150 -c 200\n\n```\n\n4. 监控端配置\n\n```\n# vi /usr/local/naigos/etc/objects/command.cfg\n\ndefine command {\n\n    command_name check_nrpe\n    command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$\n}\n\n# vi /usr/local/nagios/etc/objects/192.168.23.123.cfg\n\ndefine host {\n    use     linux-server   \n    host_name   host123\n    alias       My Linux Server  \n    address     192.168.23.123  \n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description check host alive\n    check_command       check-host-alive\n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description check users\n    check_command       check_nrpe!check_users\n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description Load\n    check_command       check_nrpe!check_load\n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description check sda2\n    check_command       check_nrpe!check_hda1\n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description check zombie procs\n    check_command       check_nrpe!check_zombie_procs\n}\ndefine service {\n    use         generic-service\n    host_name       host123\n    service_description check total procs\n    check_command       check_nrpe!check_total_procs\n}\n\n# vi /usr/local/nagios/etc/nagios.cfg\n\ncfg_file=/usr/local/nagios/etc/objects/192.168.23.123.cfg\n```\n\n5. 验证配置\n\n```\n/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg\n```\n\n6. 重启服务\n\n```\nsystemctl restart nagios\n```\n\n","tags":["nagios"]},{"title":"【nagios】Nagios监控Linux主机对外服务","url":"/2019/05/21/【nagios】Nagios监控Linux主机对外服务/","content":"\n### Nagios安装目录\n\n```\n[root@localhost nagios]# pwd\n/usr/local/nagios\n[root@localhost nagios]# ll\ntotal 12\ndrwxrwxr-x.  2 nagios nagios   38 May 20 10:46 bin\ndrwxrwxr-x.  3 nagios nagios   96 May 21 09:35 etc\ndrwxrwxr-x.  2 nagios nagios 4096 May 21 14:44 libexec\ndrwxrwxr-x.  2 nagios nagios 4096 May 20 10:46 sbin\ndrwxrwxr-x. 15 nagios nagios 4096 May 20 11:05 share\ndrwxrwxr-x.  5 nagios nagios  147 May 21 14:53 var\n[root@localhost nagios]#\n\n```\n\n### Nagios安装目录详解\n\n| 目录名       | 注解                                                         |\n| ------------ | ------------------------------------------------------------ |\n| bin          | Nagios 可执行程序所在目录                                    |\n| etc          | Nagios 配置文件所在目录                                      |\n| sbin         | Nagios CGI 文件所在目录，也就是执行外部命令所需文件所在的目录 |\n| share        | Nagios网页文件所在的目录                                     |\n| libexec      | Nagios 外部插件所在目录                                      |\n| var          | Nagios 日志文件、lock 等文件所在的目录                       |\n| var/archives | Nagios 日志自动归档目录                                      |\n| var/rw       | 用来存放外部命令文件的目录                                   |\n\n### Nagios配置目录详解\n\n| **文件名或目录名**      | **用途**                                                     |\n| ----------------------- | ------------------------------------------------------------ |\n| cgi.cfg                 | 控制CGI访问的配置文件                                        |\n| htpasswd.users          | Nagios账户信息                                               |\n| nagios.cfg              | Nagios 主配置文件                                            |\n| resource.cfg            | 变量定义文件，又称为资源文件，在些文件中定义变量，以便由其他配置文件引用，如$USER1$ |\n| objects                 | objects 是一个目录，在此目录下有很多配置文件模板，用于定义Nagios 对象 |\n| objects/commands.cfg    | 命令定义配置文件，其中定义的命令可以被其他配置文件引用       |\n| objects/contacts.cfg    | 定义联系人和联系人组的配置文件                               |\n| objects/localhost.cfg   | 定义监控本地主机的配置文件                                   |\n| objects/printer.cfg     | 定义监控打印机的一个配置文件模板，默认没有启用此文件         |\n| objects/switch.cfg      | 定义监控路由器的一个配置文件模板，默认没有启用此文件         |\n| objects/templates.cfg   | 定义主机和服务的一个模板配置文件，可以在其他配置文件中引用   |\n| objects/timeperiods.cfg | 定义Nagios 监控时间段的配置文件                              |\n| objects/windows.cfg     | 监控Windows 主机的一个配置文件模板，默认没有启用此文件       |\n\n*参考：*\n\n*[Linux下Nagios的安装与配置](https://www.cnblogs.com/mchina/archive/2013/02/20/2883404.html)*\n\n\n\n### 添加Linux 主机，监控对外开放的服务\n\n1. 添加配置文件\n\n```\ntouch /usr/local/nagios/etc/objects/192.168.23.123.cfg\n\nvi /usr/local/nagios/etc/objects/192.168.23.123.cfg\n\ndefine host {   \n        use                     linux-server \n        host_name               host123\n        alias                   Host 123\n        address                 192.168.23.123\n}     \ndefine hostgroup {      \n        hostgroup_name          host123-servers\n        alias                   Host123 servers\n        members                 host123     \n}\ndefine service {  \n        use                     local-service\n        host_name               host123\n        service_description     check-host-alive\n        check_command           check-host-alive\n}\n\n```\n\n2. 添加配置项\n\n```\nvi /usr/local/nagios/etc/nagios.cfg\n\ncfg_file=/usr/local/nagios/etc/objects/192.168.23.123.cfg\n```\n\n3. 验证配置\n\n```\n/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg\n```\n\n4. 重启服务\n\n```\nsystemctl restart nagios\n```\n\n","tags":["nagios"]},{"title":"【nagios】Nagios安装","url":"/2019/05/20/【nagios】Nagios安装/","content":"\n## What Nagios Provides\n\nDesigned with **scalability** and **flexibility** in mind, Nagios gives you the peace of mind that comes from knowing your organization’s business processes won’t be affected by unknown outages.\n\nNagios is a powerful tool that provides you with instant awareness of your organization’s mission-critical IT infrastructure. Nagios allows you to detect and repair problems and mitigate future issues before they affect end-users and customers.\n\n**By using Nagios, you can:**\n\n- Plan for infrastructure upgrades before outdated systems cause failures\n- Respond to issues at the first sign of a problem\n- Automatically fix problems when they are detected\n- Coordinate technical team responses\n- Ensure your organization’s SLAs are being met\n- Ensure IT infrastructure outages have a minimal effect on your organization’s bottom line\n- Monitor your entire infrastructure and business processes\n\n\n\n## How It Works\n\n### Monitoring\n\nIT staff configure Nagios to monitor critical IT infrastructure components, including system metrics, network protocols, applications, services, servers, and network infrastructure.\n\n### Alerting\n\nNagios sends alerts when critical infrastructure components fail and recover, providing administrators with notice of important events. Alerts can be delivered via email, SMS, or custom script.\n\n### Response\n\nIT staff can acknowledge alerts and begin resolving outages and investigating security alerts immediately. Alerts can be escalated to different groups if alerts are not acknowledged in a timely manner.\n\n### Reporting\n\nReports provide a historical record of outages, events, notifications, and alert response for later review. Availability reports help ensure your SLAs are being met.\n\n### Maintenance\n\nScheduled downtime prevents alerts during scheduled maintenance and upgrade windows.\n\n### Planning\n\nTrending and capacity planning graphs and reports allow you to identify necessary infrastructure upgrades before failures occur.\n\n\n\n## Features\n\n### Comprehensive\n\nMonitoringCore provides monitoring of all mission-critical infrastructure components in your IT infrastructure.\n\n### Visibility\n\nGain a centralized view of your entire IT operations and review detailed status information through the web interface.\n\n### Awareness\n\nAlerts with escalation capabilities are delivered to IT staff via email and SMS to ensure fast detection of outages.\n\n### Problem Remediation\n\nEvent handlers can automatically restart failed applications, servers, devices, and services when problems are found.\n\n### Proactive Planning\n\nTrending and capacity planning extensions allow you to proactively plan for upgrades.\n\n### Reporting\n\nAvailability reports ensure SLAs are being met and historical reports provide record of critical information.\n\n### Multi-Tenant\n\nCapabilitiesMulti-user access and user-specific views can be configured to ensure clients see specific information.\n\n### Extendable Architecture\n\nMultiple API’s provide integration with in-house / third-party applications, and community-developed add-ons.\n\n\n\n## Favorite Nagios Projects\n### NCPA\n\nNCPA is a cross-platform monitoring agent that runs on Windows, Linux/Unix, and Mac OS/X machines. Its features include both active and passive checks, remote management, and a local monitoring interface.\n\n### DNX\n\nDNX is a modular extension of Nagios that offloads a significant portion of the work normally done by Nagios to a distributed network of remote hosts. The DNX module ensures that work is distributed fairly and evenly among the registered DNX client hosts.\n\n### NRPE\n\nNRPE allows you to remotely execute Nagios plugins on other Linux/Unix machines. This allows you to monitor remote machine metrics (disk usage, CPU load, etc.). NRPE can also communicate with Windows agent addons like NSClient++, so you can check metrics on remote Windows machines as well.\n\n### NRDP\n\nNRDP is a flexible data transport mechanism and processor for Nagios. It is designed with a simple and powerful architecture that allows for it to be easily extended and customized to fit individual users’ needs. It uses standard ports protocols (HTTP(S) and XML) and can be implemented as a replacement for NSCA.\n\n### NSCA\n\nNSCA allows you to integrate passive alerts and checks from remote machines and applications with Nagios. Useful for processing security alerts, as well as deploying redundant and distributed Nagios setups.\n\n### NSClient++\n\nNSClient++ is a monitoring agent/daemon for Microsoft Windows systems that works with Nagios. Make monitoring Windows machines easy.\n\n### Nagiosgraph\n\nNagiosgraph is graphing tool that parses output and performance data from Nagios plugins and stores the data in RRD files. nagiosgraph displays data in Nagios trends, as popups for hosts and services, or in separate reports. Easy to set up and eminently customizable.\n\n### NSTI\n\nNSTI is a Nagios addon that makes managing SNMP traps easier. NSTI provide a PHP frontend for the SNMPTT database backend and allows you to filter SNMP results quickly and effectively to get a comprehensive overview of the information you want to see.\n\n### NConf\n\nNConf is a PHP frontend for configuring Nagios. It differs from other tools by offering enterprise-class features like templates, dependencies and the ability to configure a large-scale, distributed Nagios server topology.\n\n### NDOUtils\n\nNDOUtils allows you to export current and historical data from one or more Nagios instances to a MySQL database. Several community addons use this as one of their data sources. NDOUtils consists of a standalone daemon, a Nagios event broker, and several helper utilities.\n\n### BPI\n\nNagios Business Process Intelligence (BPI) is an advanced grouping tool that allows you to set more complex dependencies to determine groups states. Nagios BPI provides an interface to effectively view the ‘real’ state of the network. Rules for group states can be determined by the user, and parent-child relationships are easily identified when you need to ‘drill down’ on a problem. This tool can also be used in conjunction with a check plugin to allow for notifications through Nagios.\n\n### NagVis\n\nNagvis is a visualization addon for Nagios. It can be used to visualize Nagios data, e.g. to display IT processes like a mail system or a network infrastructur\n\n\n\n## CentOS Easy Setup\n\n### Reference\n\n*[Nagios](https://www.nagios.org/)*\n\n*[Nagios Core Document](https://assets.nagios.com/downloads/nagioscore/docs/)*\n\n### Security-Enhanced Linux\n\nThis guide is based on SELinux being disabled or in permissive mode. Steps to do this are as follows.\n\n```\nsed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config\nsetenforce 0\n```\n\n### Prerequisites\n\nPerform these steps to install the pre-requisite packages.\n\n```\nyum install -y gcc glibc glibc-common wget unzip httpd php gd gd-devel perl postfix\n```\n\n### Downloading the Source\n\n```\ncd /tmp\nwget -O nagioscore.tar.gz https://github.com/NagiosEnterprises/nagioscore/archive/nagios-4.4.3.tar.gz\ntar xzf nagioscore.tar.gz\n```\n\n### Compile\n\n```\ncd /tmp/nagioscore-nagios-4.4.3/\n./configure\nmake all\n```\n\n### Create User And Group\n\nThis creates the nagios user and group. The apache user is also added to the nagios group.\n\n```\nmake install-groups-users\nusermod -a -G nagios apache\n```\n\n### Install Binaries\n\nThis step installs the binary files, CGIs, and HTML files.\n\n```\nmake install\n```\n\n### Install Service / Daemon\n\nThis installs the service or daemon files and also configures them to start on boot. The Apache httpd service is also configured at this point.\n\n**CentOS 5.x / 6.x**\n\n```\nmake install-daemoninit\nchkconfig --level 2345 httpd on\n```\n\n**CentOS 7.x**\n\n```\nmake install-daemoninit\nsystemctl enable httpd.service\n```\n\nInformation on starting and stopping services will be explained further on.\n\n### Install Command Mode\n\nThis installs and configures the external command file.\n\n```\nmake install-commandmode\n```\n\n### Install Configuration Files\n\nThis installs the *SAMPLE* configuration files. These are required as Nagios needs some configuration files to allow it to start.\n\n```\nmake install-config\n```\n\n### Install Apache Config Files\n\nThis installs the Apache web server configuration files. Also configure Apache settings if required.\n\n```\nmake install-webconf\n```\n\n### Configure Firewall\n\nYou need to allow port 80 inbound traffic on the local firewall so you can reach the Nagios Core web interface.\n\n**CentOS 5.x / 6.x**\n\n```\niptables -I INPUT -p tcp --destination-port 80 -j ACCEPT\nservice iptables save\nip6tables -I INPUT -p tcp --destination-port 80 -j ACCEPT\nservice ip6tables save\n```\n\n**CentOS 7.x**\n\n```\nfirewall-cmd --zone=public --add-port=80/tcp\nfirewall-cmd --zone=public --add-port=80/tcp --permanent\n```\n\n### Create nagiosadmin User Account\n\nYou'll need to create an Apache user account to be able to log into Nagios.\n\nThe following command will create a user account called nagiosadmin and you will be prompted to provide a password for the account.\n\n```\nhtpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin\n```\n\nWhen adding additional users in the future, you need to remove **-c** from the above command otherwise it will replace the existing nagiosadmin user *(and any other users you may have added)*.\n\n### Start Apache Web Server\n\n**CentOS 5.x / 6.x**\n\n```\nservice httpd start\n```\n\n**CentOS 7.x**\n\n```\nsystemctl start httpd.service\n```\n\n### Start Service / Daemon\n\nThis command starts Nagios Core.\n\n**CentOS 5.x / 6.x**\n\n```\nservice nagios start\n```\n\n **CentOS 7.x**\n\n```\nsystemctl start nagios.service\n```\n\n### Test Nagios\n\nNagios is now running, to confirm this you need to log into the Nagios Web Interface.\n\nPoint your web browser to the ip address or FQDN of your Nagios Core server, for example:\n\nhttp://10.25.5.143/nagios\n\nhttp://core-013.domain.local/nagios\n\nYou will be prompted for a username and password. The username is nagiosadmin (you created it in a previous step) and the password is what you provided earlier.\n\nOnce you have logged in you are presented with the Nagios interface. Congratulations you have installed Nagios Core.\n\n### BUT WAIT ...\n\nCurrently you have only installed the Nagios Core engine. You'll notice some errors under the hosts and services along the lines of:\n\n```\n(No output on stdout) stderr: execvp(/usr/local/nagios/libexec/check_load, ...) failed. errno is 2: No such file or directory \n```\n\nThese errors will be resolved once you install the Nagios Plugins, which is covered in the next step.\n\n### Installing The Nagios Plugins\n\nNagios Core needs plugins to operate properly. The following steps will walk you through installing Nagios Plugins.\n\nThese steps install nagios-plugins 2.2.1. Newer versions will become available in the future and you can use those in the following installation steps. Please see the [releases page on GitHub](https://github.com/nagios-plugins/nagios-plugins/releases) for all available versions.\n\nPlease note that the following steps install most of the plugins that come in the Nagios Plugins package. However there are some plugins that require other libraries which are not included in those instructions. Please refer to the following KB article for detailed installation instructions:\n\n[Documentation - Installing Nagios Plugins From Source](https://support.nagios.com/kb/article.php?id=569)\n\n### Prerequisites\n\nMake sure that you have the following packages installed.\n\n**CentOS 5.x**\n\n```\nyum install -y gcc glibc glibc-common make gettext automake wget openssl-devel net-snmp net-snmp-utils epel-release\nyum install -y perl-Net-SNMP\ncd /tmp\nwget http://ftp.gnu.org/gnu/autoconf/autoconf-2.60.tar.gz\ntar xzf autoconf-2.60.tar.gz \ncd /tmp/autoconf-2.60\n./configure \nmake\nmake install\n```\n\n**CentOS 6.x / 7.x**\n\n```\nyum install -y gcc glibc glibc-common make gettext automake autoconf wget openssl-devel net-snmp net-snmp-utils epel-release\nyum install -y perl-Net-SNMP\n```\n\n### Downloading The Source\n\n```\ncd /tmp\nwget --no-check-certificate -O nagios-plugins.tar.gz https://github.com/nagios-plugins/nagios-plugins/archive/release-2.2.1.tar.gz\ntar zxf nagios-plugins.tar.gz\n```\n\n### Compile + Install\n\n```\ncd /tmp/nagios-plugins-release-2.2.1/\n./tools/setup\n./configure\nmake\nmake install\n```\n\n### Test Plugins\n\nPoint your web browser to the ip address or FQDN of your Nagios Core server, for example:\n\nhttp://10.25.5.143/nagios\n\nhttp://core-013.domain.local/nagios\n\nGo to a host or service object and \"Re-schedule the next check\" under the Commands menu. The error you previously saw should now disappear and the correct output will be shown on the screen.\n\n### Service / Daemon Commands\n\nDifferent Linux distributions have different methods of starting / stopping / restarting / status Nagios.\n\n**CentOS 5.x / 6.x**\n\n```\nservice nagios start\nservice nagios stop\nservice nagios restart\nservice nagios status\n```\n\n**CentOS 7.x**\n\n```\nsystemctl start nagios.service\nsystemctl stop nagios.service\nsystemctl restart nagios.service\nsystemctl status nagios.service\n```\n\n\n\n## Centos7.x-nagios-script \n\n```shell\n#!/bin/bash\n\n#CentOS 7.x\n\n#Security-Enhanced Linux\nsed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config\nsetenforce 0\n\n#Prerequisites\nyum install -y gcc glibc glibc-common wget unzip httpd php gd gd-devel perl postfix\n\n#Downloading the Source\ncd /tmp\nwget -O nagioscore.tar.gz https://github.com/NagiosEnterprises/nagioscore/archive/nagios-4.4.3.tar.gz\ntar xzf nagioscore.tar.gz\n\n#Compile\ncd /tmp/nagioscore-nagios-4.4.3/\n./configure\nmake all\n\n#Create User And Group\nmake install-groups-users\nusermod -a -G nagios apache\n\n#Install Binaries\nmake install\n\n#Install Service / Daemon\nmake install-daemoninit\nsystemctl enable httpd.service\n\n#Install Command Mode\nmake install-commandmode\n\n#Install Configuration Files\nmake install-config\n\n#Install Apache Config Files\nmake install-webconf\n\n#Configure Firewall\nfirewall-cmd --zone=public --add-port=80/tcp --permanent\nfirewall-cmd --reload\n\n#Create nagiosadmin User Account\nhtpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin\n\n#Start Apache Web Server\nsystemctl start httpd.service\n\n#Start Service / Daemon\nsystemctl start nagios.service\n\n\n#Installing The Nagios Plugins\n\n#Prerequisites\nyum install -y gcc glibc glibc-common make gettext automake autoconf wget openssl-devel net-snmp net-snmp-utils epel-release\nyum install -y perl-Net-SNMP\n\n#Downloading The Source\ncd /tmp\nwget --no-check-certificate -O nagios-plugins.tar.gz https://github.com/nagios-plugins/nagios-plugins/archive/release-2.2.1.tar.gz\ntar zxf nagios-plugins.tar.gz\n\n#Compile + Install\ncd /tmp/nagios-plugins-release-2.2.1/\n./tools/setup\n./configure\nmake\nmake install\n\n#Service / Daemon Commands\nsystemctl restart nagios.service\nsystemctl status nagios.service\nsystemctl restart httpd.service\nsystemctl status httpd.service\n\n```\n\n","tags":["nagios"]},{"title":"【python】终端输出颜色设置","url":"/2019/05/08/【python】终端输出颜色设置/","content":"\n### termcolor模块\n\n#### 帮助文档\n\n```python\nFUNCTIONS\n    colored(text, color=None, on_color=None, attrs=None)\n    Colorize text.\n    \n    Available text colors:\n        red, green, yellow, blue, magenta, cyan, white.\n    \n    Available text highlights:\n        on_red, on_green, on_yellow, on_blue, on_magenta, on_cyan, on_white.\n    \n    Available attributes:\n        bold, dark, underline, blink, reverse, concealed.\n    \n    Example:\n        colored('Hello, World!', 'red', 'on_grey', ['blue', 'blink'])\n        colored('Hello, World!', 'green')\n    \n    cprint(text, color=None, on_color=None, attrs=None, **kwargs)\n    Print colorize text.\n    \n    It accepts arguments of print function.\n\nDATA\n    ATTRIBUTES = {'blink': 5, 'bold': 1, 'concealed': 8, 'dark': 2, 'rever...\n    COLORS = {'blue': 34, 'cyan': 36, 'green': 32, 'grey': 30, 'magenta': ...\n    HIGHLIGHTS = {'on_blue': 44, 'on_cyan': 46, 'on_green': 42, 'on_grey':...\n    RESET = '\\x1b[0m'\n    VERSION = (1, 1, 0)\n    __ALL__ = ['colored', 'cprint']\n    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n```\n\n#### 示例代码\n\n```python\nimport sys\nfrom termcolor import colored, cprint\n \n# 红色背景字符不发光\ntext = colored('Hello, World!', 'red', attrs=['reverse', 'blink'])\nprint(text)\n \n# 红色背景上显示绿色字符\ncprint('Hello, World!', 'green', 'on_red')\n \n# 青蓝色背景上显示绿色字符\nprint_red_on_cyan = lambda x: cprint(x, 'red', 'on_cyan')\nprint_red_on_cyan('Hello, World!')\nprint_red_on_cyan('Hello, Universe!')\n \nfor i in range(10):\n    cprint(i, 'magenta', end=' ')\n \n# 红色字符加粗\ncprint(\"Attention!\", 'red', attrs=['bold'], file=sys.stderr)\n```\n\n#### 简单方法\n\n```python\n#!/usr/bin/env python\n\nfrom termcolor import colored, cprint\n\n#灰\nprint_grey = lambda x: cprint(x, 'grey')\nprint_grey('Hello, World!')\n#红\nprint_red = lambda x: cprint(x, 'red')\nprint_red('Hello, World!')\n#绿\nprint_green = lambda x: cprint(x, 'green')\nprint_green('Hello, World!')\n#黄\nprint_yellow = lambda x: cprint(x, 'yellow')\nprint_yellow('Hello, World!')\n#蓝\nprint_blue = lambda x: cprint(x, 'blue')\nprint_blue('Hello, World!')\n#紫\nprint_magenta = lambda x: cprint(x, 'magenta')\nprint_magenta('Hello, World!')\n#青蓝\nprint_cyan = lambda x: cprint(x, 'cyan')\nprint_cyan('Hello, World!')\n#白\nprint_white = lambda x: cprint(x, 'white')\nprint_white('Hello, World!')\n```\n\n\n\n*参考：*\n\n*[python库termcolor用法](https://www.cnblogs.com/everfight/p/python_termcolor.html)*\n\n*[termcolor 1.1.0](https://pypi.org/project/termcolor/)*\n\n\n\n### 自定义颜色显示\n\n#### 显示格式\n\n\\033[显示方式;前景色;背景色m\n\n#### 显示方式\n\n| 显示方式 | 意义         |\n| -------- | ------------ |\n| 0        | 终端默认设置 |\n| 1        | 高亮显示     |\n| 4        | 使用下划线   |\n| 5        | 闪烁         |\n| 7        | 反白显示     |\n| 8        | 不可见       |\n\n#### 前景色和背景色\n\n| 前景色 | 背景色 | 显示颜色 |\n| :----: | :----: | :------: |\n|   30   |   40   |   黑色   |\n|   31   |   41   |   红色   |\n|   32   |   42   |   绿色   |\n|   33   |   43   |   黃色   |\n|   34   |   44   |   蓝色   |\n|   35   |   45   |  紫红色  |\n|   36   |   46   |  青蓝色  |\n|   37   |   47   |   白色   |\n\n#### ANSI控制码的说明 \n\n|     ANSI控制码     |          说明          |\n| :----------------: | :--------------------: |\n|       \\33[0m       |      关闭所有属性      |\n|       \\33[1m       |       设置高亮度       |\n|       \\33[4m       |         下划线         |\n|       \\33[5m       |          闪烁          |\n|       \\33[7m       |          反显          |\n|       \\33[8m       |          消隐          |\n| \\33[30m -- \\33[37m |       设置前景色       |\n| \\33[40m -- \\33[47m |       设置背景色       |\n|       \\33[nA       |      光标上移n行       |\n|       \\33[nB       |      光标下移n行       |\n|       \\33[nC       |      光标右移n行       |\n|       \\33[nD       |      光标左移n行       |\n|      \\33[y;xH      |      设置光标位置      |\n|       \\33[2J       |          清屏          |\n|       \\33[K        | 清除从光标到行尾的内容 |\n|       \\33[s        |      保存光标位置      |\n|       \\33[u        |      恢复光标位置      |\n|      \\33[?25l      |        隐藏光标        |\n|      \\33[?25h      |        显示光标        |\n\n#### 自定义函数\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\ndef text_colors(text, fcolor=None, bcolor=None, style=None):\n    '''\n    自定义字体样式及颜色\n    '''\n    # 字体颜色\n    fg={\n       'black': '\\033[30m',     #字体黑\n       'red': '\\033[31m',       #字体红\n       'green': '\\033[32m',     #字体绿\n       'yellow': '\\033[33m',    #字体黄\n       'blue': '\\033[34m',      #字体蓝\n       'magenta': '\\033[35m',   #字体紫\n       'cyan': '\\033[36m',      #字体青\n       'white':'\\033[37m',      #字体白\n        'end':'\\033[0m'         #默认色\n    }\n    # 背景颜色\n    bg={\n       'black': '\\033[40m',     #背景黑\n       'red': '\\033[41m',       #背景红\n       'green': '\\033[42m',     #背景绿\n       'yellow': '\\033[43m',    #背景黄\n       'blue': '\\033[44m',      #背景蓝\n       'magenta': '\\033[45m',   #背景紫\n       'cyan': '\\033[46m',      #背景青\n       'white':'\\033[47m',      #背景白\n    }\n    # 内容样式\n    st={\n        'bold': '\\033[1m',      #高亮\n        'url': '\\033[4m',       #下划线\n        'blink': '\\033[5m',     #闪烁\n        'seleted': '\\033[7m',   #反显\n    }\n\n    if fcolor in fg:\n        text = fg[fcolor] + text + fg['end']\n    if bcolor in bg:\n        text = bg[bcolor] + text + fg['end']\n    if style in st:\n        text = st[style] + text + fg['end']\n    return text\n\n#使用方法：\nprint(text_colors('文本内容','字体颜色','背景颜色','字体样式'))\n```\n\n\n\n*参考：*\n\n*[python终端颜色设置](http://www.cnblogs.com/zhanmeiliang/p/5948947.html)*\n\n*[Python控制台输出颜色](https://blog.csdn.net/qq_33282586/article/details/80637242)*\n\n","tags":["python"]},{"title":"【linux】MBR和GPT分区表区别","url":"/2019/05/08/【linux】MBR和GPT分区表区别/","content":"\n### MBR分区\n\nMBR的意思是“主引导记录”，是IBM公司早年间提出的。它是存在于磁盘驱动器开始部分的一个特殊的启动扇区。这个扇区包含了已安装的操作系统系统信息，并用一小段代码来启动系统。如果你安装了Windows，其启动信息就放在这一段代码中——如果MBR的信息损坏或误删就不能正常启动Windows，这时候你就需要找一个引导修复软件工具来修复它就可以了。Linux系统中MBR通常会是GRUB加载器。MBR。当一台电脑启动时，它会先启动主板自带的BIOS系统，bios加载MBR，MBR再启动Windows，这就是mbr的启动过程。\n\n### GPT分区\n\nGPT的意思是GUID Partition Table，即“全局唯一标识磁盘分区表”。他是另外一种更加先进新颖的磁盘组织方式，一种使用UEFI启动的磁盘组织方式。最开始是为了更好的兼容性，后来因为其更大的支持内存（mbr分区最多支持2T的磁盘），更多的兼容而被广泛使用，特别是苹果的MAC系统全部使用gpt分区。gtp不在有分区的概念，所有CDEF盘都在一段信息中存储。可以简单的理解为更先进但是使用不够广泛的技术。\n\n### 两者区别\n\n因为兼容问题，gpt其实在引导的最开始部分也有一段mbr引导，也叫做“保护引导”，为了防止设备不支持uefi 区别内存支持：mbr最多支持2T，而gpt理论上是无限制的。\n\n分区：mbr最多支持四个主分区，gpt没有限制。如果你想跑多系统，mbr最多4个而gpt没有限制。\n\n系统：win7只能用mbr分区，从Win8开始微软建议你使用gpt。\n\n其它：gpt是由uefi启动的，而uefi是后来才提出的概念，兼容性和稳定性不如bios+mbr。\n\n### 如何选择\n\n如果你的硬盘超过2T，那么你必须选择GPT+UEFI，2t以下就无所谓了；\n\n如果你对电脑不太懂，那么我建议你使用MBR，因为大多数电脑默认都是MBR bios启动，如果你选择了gpt那么你必须在bios下设置启动项，对于一个新人来说比较复杂，每家电脑的主板还有不同无疑增加了难度。\n\n如果你比较精通，建议gpt。毕竟gpt代表了未来，可以预见早晚uefi会会替代掉bios。\n\n从系统多方面来说，win７用户建议mbr简单易操作，８和１０的用户还是花点力气学习一下gpt吧毕竟是一种趋势。苹果用户就不用说了，gpt没得选。","tags":["linux","mbr","gpt"]},{"title":"【linux】读取磁盘第一扇区信息","url":"/2019/05/08/【linux】读取磁盘第一扇区信息/","content":"\n### 查看磁盘第一个扇区的信息\n\n### 1. 使用dd命令\n\n```shell\n[root@host-172-16-2-221 test]# dd if=/dev/vda of=part.dump bs=512 count=1\n1+0 records in\n1+0 records out\n512 bytes (512 B) copied, 0.000240905 s, 2.1 MB/s\n[root@host-172-16-2-221 test]# vi part.dump\n\n```\n\n> vim中把文件转换为16进制来显示：\n>\n> :%!xxd\n>\n> 返回正常显示：\n>\n> :%!xxd -r\n\n\n\n### 2. 使用c语言输出\n\n```c\n#include <stdio.h>\n\nvoid print(char c){\n    int m = c;\n    int high = 0x000000f0, low = 0x0000000f;\n    high &= m;\n    high >>= 4;\n    low &= m;\n    printf(\"%1X%1X \", high, low);\n}\n\nint main(){\n    FILE* fd = fopen(\"/dev/vda\", \"rb+\");\n    char buffer[512] = {0};\n    fseek(fd, 0, SEEK_SET);\n    char buffer2[512] = {0};\n    fread(buffer2, 512, 1, fd);\n    int i = 1;\n    for (; i <= 512; i++){\n        print(buffer2[i-1]);\n        if (i % 16 == 0){\n            printf(\"\\n\");\n        }\n        else if (i % 8 == 0){\n            printf(\"    \");\n        }\n    }\n    fclose(fd);\n    return 0;\n}\n\n```\n\n\n\n### 3. 使用python输出 \n\n```python\n#!/usr/bin/env python\n#coding=utf8\n\nwith open('/dev/vda', 'rb') as fp:\n\thex_list = [\"{:02x}\".format(ord(c)) for c in fp.read(512)]\n\tprint(hex_list)\n    \n```\n\n> ord(\"a\")\n>\n> 它以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值\n>\n> \"{:02X}\".format(i)\n>\n> 这个输出是将i以16进制输出，当i是15，输出结果是0F；\n>\n> {:X}16进制标准输出形式，02是2位对齐，左补0形式。\n\n*参考：[MBR-extractor](https://github.com/shubham0d/MBR-extractor)*\n\n","tags":["linux","disk"]},{"title":"【shell】终端输出颜色设置","url":"/2019/05/08/【shell】终端输出颜色设置/","content":"\n### 两种方法，两种样式：\n\n```shell\n#!/bin/sh\n\necho\necho -e \"\\\\033[0;31m系统颜色设置代码调试，此颜色为一号颜色 - 红！\"\necho\necho -e \"\\\\033[0;32m系统颜色设置代码调试，此颜色为二号颜色 - 绿！\"\necho\necho -e \"\\\\033[0;33m系统颜色设置代码调试，此颜色为三号颜色 - 黄！\"\necho\necho -e \"\\\\033[0;34m系统颜色设置代码调试，此颜色为四号颜色 - 蓝！\"\necho\necho -e \"\\\\033[0;35m系统颜色设置代码调试，此颜色为五号颜色 - 紫！\"\necho\necho -e \"\\\\033[0;36m系统颜色设置代码调试，此颜色为六号颜色 - 青！\"\necho\necho -e \"\\\\033[0;39m系统颜色设置代码调试，此颜色为九号颜色 - 白！\"\n\nBLACK='\\E[1;30m'\nRED='\\E[1;31m'\nGREEN='\\E[1;32m'\nYLW='\\E[1;33m'\nBLUE='\\E[1;34m'\nPURPLE='\\E[1;35m'\nCYAN='\\E[1;36m'\nWHITE='\\E[1;39m'\nRES='\\E[0m'\n\necho\necho -e \"${BLACK}系统颜色设置代码调试，此颜色为一号颜色 - 黑！${RES}\"\necho\necho -e \"${RED}系统颜色设置代码调试，此颜色为一号颜色 - 红！${RES}\"\necho\necho -e \"${GREEN}系统颜色设置代码调试，此颜色为一号颜色 - 绿！${RES}\"\necho\necho -e \"${YLW}系统颜色设置代码调试，此颜色为一号颜色 - 黄！${RES}\"\necho\necho -e \"${BLUE}系统颜色设置代码调试，此颜色为一号颜色 - 蓝！${RES}\"\necho\necho -e \"${PURPLE}系统颜色设置代码调试，此颜色为一号颜色 - 紫！${RES}\"\necho\necho -e \"${CYAN}系统颜色设置代码调试，此颜色为一号颜色 - 青！${RES}\"\necho\necho -e \"${WHITE}系统颜色设置代码调试，此颜色为一号颜色 - 白！${RES}\"\necho\n```\n\n","tags":["shell"]},{"title":"【docker】Docker安装及基本命令使用","url":"/2019/05/07/【docker】Docker安装及命令使用/","content":"\n### 文档\n\n[DaoCloud Hub](https://hub.daocloud.io/)\n\n[Docker Documentation](https://docs.docker.com/get-started/)\n\n[DockerInfo](http://www.dockerinfo.net/document)\n\n[Docker中文社区](http://www.docker.org.cn/)\n\n[Docker源地址](https://download.docker.com/)\n\n### 安装Docker\n\n```shell\ncd /etc/yum.repos.d/\n#官方源\nwget https://download.docker.com/linux/centos/docker-ce.repo\nwget https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo\n#替换清华源\nsed -i 's@https://download.docker.com@https://mirrors.tuna.tsinghua.edu.cn/docker-ce@g' docker-ce.repo\n#安装docker-ce\nyum install docker-ce -y\n#镜像加速\ncat >> /etc/docker/daemon.json <<EOF\n{\n\t\"registry-mirrors\": [\"https://guxaj7v7.mirror.aliyuncs.com\",\"https://registry.docker-cn.com\"]\n}\nEOF\n#启动服务\nsystemctl enable docker\nsystemctl start docker\n#查看版本信息\ndocker version\ndocker info\n\n```\n\n### 常用命令\n\n```shell\ndocker search centos\t#搜索镜像\ndocker pull centos:7.4.1708\t\t#下载特定版本镜像\ndocker run hello-world /hello\t#启动并执行命令\ndocker run -it centos:7.4.1708 /bin/bash\t#交互模式启动镜像\ndocker run -d centos:7.4.1708 /bin/bash\t#后台启动镜像\ndocker run -itd centos:7.4.1708 /bin/bash\n#罗列容器\ndocker ps\t#罗列启动的容器\ndocker ps -a\t#罗列所有容器\ndocker start/stop/restart centos:7.4.1708\t#启动/关闭/重启\n#交互式进入容器\ndocker attach centos:7.4.1708\t#多端同步，退出后关闭\ndocker exec -it centos:7.4.1708 /bin/bash\t#独立运行\n#退出\nexit\nCTRL+D\n#查看镜像\ndocker images\ndocker images -a\n#导出/导出镜像\ndocker save -o centos.7.4.1708.tar centos:7.4.1708\ndocker save -o centos.7.4.1708.tar e771603453ab centos:7.4.1708\ndocker load -i centos.7.4.1708.tar\n#导出/导入容器\ndocker export -o centos.7.4.1708.tar centos:7.4.1708\ndocker export -o centos.7.4.1708.tar e771603453ab\ndocker import centos.7.4.1708.tar centos:7.4.1708\n#删除镜像/容器\ndocker rm e771603453ab\nfor i in `docker ps -a|awk '{print $1}'|grep -v CONTAINER`;do docker rm $i;done\n\ndocker rmi e771603453ab\nfor i in `docker images -a|awk '{print $3}'|grep -v IMAGE`;do docker rmi $i;done\n\ndocker kill $(docker ps -q) ; docker rm $(docker ps -a -q) ; docker rmi $(docker images -q -a)\n```\n\n","tags":["docker"]},{"title":"【随笔】201904","url":"/2019/04/30/【随笔】201904/","content":"\n## 2019-04-24\n\n```\ntraceroute (Windows系统下是tracert) 命令利用ICMP 协议定位您的计算机和目标计算机之间的所有路由器。TTL值可以反映数据包经过的路由器或网关的数量，通过操纵独立ICMP呼叫报文的TTL值和观察该报文被抛弃的返回信息，traceroute命令能够遍历到数据包传输路径上的所有路由器。traceroute是一条缓慢的命令，因为每经过一台路由器都要花去大约10到15秒。\ntracepath命令 用来追踪并显示报文到达目的主机所经过的路由信息。\nICMP是“Internet Control Message Protocol”（Internet控制消息协议）的缩写。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。\n\n```\n\n\n\n## 2019-04-23\n\nsysctl命令用于运行时配置内核参数，这些参数位于/proc/sys目录下。sysctl配置与显示在/proc/sys目录中的内核参数．可以用sysctl来设置或重新设置联网功能，如IP转发、IP碎片去除以及源路由检查等。用户只需要编辑/etc/sysctl.conf文件，即可手工或自动执行由sysctl控制的功能。\n\n```\n命令格式：\nsysctl [-n] [-e] -w variable=value\nsysctl [-n] [-e] -p <filename> (default /etc/sysctl.conf)\nsysctl [-n] [-e] -a\n\n常用参数的意义：\n-w   临时改变某个指定参数的值，如 sysctl -w net.ipv4.ip_forward=1\n-a   显示所有的系统参数\n-p   从指定的文件加载系统参数，如不指定即从/etc/sysctl.conf中加载\n\n如果仅仅是想临时改变某个系统参数的值，可以用两种方法来实现,例如想启用IP路由转发功能：\n1) #echo 1 > /proc/sys/net/ipv4/ip_forward\n2) #sysctl -w net.ipv4.ip_forward=1\n\n以上两种方法都可能立即开启路由功能，但如果系统重启，或执行了service network restart 命令，所设置的值即会丢失，如果想永久保留配置，可以修改/etc/sysctl.conf文件将 net.ipv4.ip_forward=0改为net.ipv4.ip_forward=1\n```\n\n\n\n## 2019-04-22\n\n### Blog创建规范\n\n```\n1. 大分类：web、windows、linux、shell、python、openstack、tools、others、随笔、nfs、mysql、fastdfs、ansible\n2. 文件命名与blog标题一致，命名开头 eg: 【web】，标签第一个： web\n3. 从命名上分类，便于本地查看查找\n```\n\n\n\n## 2019-04-18\n\n### Centos7 如何减少/home分区，扩大/root分区\n\n```shell\n把/home内容备份，然后将/home文件系统所在的逻辑卷删除，扩大/root文件系统，新建/home：\ntar cvf /tmp/home.tar /home #备份/home\numount /home #卸载/home，如果无法卸载，先终止使用/home文件系统的进程\nlvremove /dev/centos/home #删除/home所在的lv\nlvextend -L +50G /dev/centos/root #扩展/root所在的lv，增加50G\nxfs_growfs /dev/centos/root #扩展/root文件系统\nlvcreate -L 56G -n home centos #重新创建home lv\nmkfs.xfs /dev/centos/home #创建文件系统\nmount /dev/centos/home /home #挂载\ndf -h\n```\n\n\n\n## 2019-04-16\n\n### Linux添加环境变量与GCC编译器添加INCLUDE与LIB环境变量\n\n```shell\n对所有用户有效在/etc/pro\n\nfile增加以下内容。只对当前用户有效在Home目录下的\n.bashrc或.bash_profile 里增加下面的内容：\n(注意：等号前面不要加空格,否则可能出现 command not found)\n\n#在PATH中找到可执行 文件程序的路径。\nexport PATH =$PATH:$HOME/bin\n\n#gcc找到头文件的路径\nC_INCLUDE_PATH=/usr/include/libxml2:/MyLib\nexport C_INCLUDE_PATH\n\n#g++找到头文件的路径\nCPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/include/libxml2:/MyLib\nexport CPLUS_INCLUDE_PATH\n\n#找到动态链接库的路径\nLD_LIBRARY_PATH=$LD_LIBRARY_PATH:/MyLib \nexport LD_LIBRARY_PATH\n\n#找到静态库的路径\nLIBRARY_PATH=$LIBRARY_PATH:/MyLib\nexport LIBRARY_PATH\n```\n\n\n\n## 2019-04-11\n\n### 命令学习\n\n```shell\nreadlink\n输出符号链接值或者权威文件名\n英文为：\nprint value of a symbolic link or canonical file name\n-f 选项：\n可以递归跟随给出文件名的所有符号链接以标准化，除最后一个外所有组件必须存在。\n简单地说，就是一直跟随符号链接，直到非符号链接的文件位置，限制是最后必须存在一个非符号链接的文件。\n\n#Absolute path to this script\nSCRIPT=$(readlink -f $0)\n#Absolute path this script is in\nSCRIPTPATH=$(dirname $SCRIPT)\nSCRIPTNAME=$(basename $SCRIPT)\necho $0\t\t\t\tsetup.sh\necho $SCRIPT\t\t/home/admin/infoShare/setup.sh\necho $SCRIPTPATH\t/home/admin/infoShare\necho $SCRIPTNAME\tsetup.sh\n\ndirname命令去除文件名中的非目录部分，仅显示与目录有关的内容。dirname命令读取指定路径名保留最后一个/及其后面的字符，删除其他部分，并写结果到标准输出。如果最后一个/后无字符，dirname 命令使用倒数第二个/，并忽略其后的所有字符。dirname 和 basename 通常在 shell 内部命令替换使用，以指定一个与指定输入文件名略有差异的输出文件名\n\nbasename命令用于打印目录或者文件的基本名称。\n\nsetfacl命令是用来在命令行里设置ACL（访问控制列表）。在命令行里，一系列的命令跟随以一系列的文件名。\nsetfacl -m u:admin:wx /etc/systemd/system/multi-user.target.wants\n\n```\n\n\n\n## 2019-04-10\n\n### 防火墙简单使用\n\n```shell\n#关闭已开放的端口\n#!/bin/sh\n\nfor port in `sudo firewall-cmd --list-ports`\ndo\necho \"Close port $port\"\nsudo firewall-cmd --permanent --zone=drop --remove-port=$port\ndone\nsudo firewall-cmd --reload\n\n#完全隔离\nfirewall-cmd --panic-on           Enable panic mode\nfirewall-cmd --panic-off          Disable panic mode\nfirewall-cmd --query-panic        Query whether panic mode is enabled\n\n#隔离外部访问，仅开放22端口\nfirewall-cmd --set-default-zone=drop\nfirewall-cmd --load-zone-defaults=drop --permanent\nfirewall-cmd --permanent --zone=drop --add-port=22/tcp\nfirewall-cmd --reload\n\n```\n\n### 生成8位随机密码\n\n```shell\nMATRIX=\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\nLENGTH=\"8\"\nwhile [ \"${n:=1}\" -le \"$LENGTH\" ]\ndo\nPASS=\"$PASS${MATRIX:$(($RANDOM%${#MATRIX})):1}\"\nlet n+=1\ndone\necho $PASS\n```\n\n\n\n## 2019-04-08\n\n### 部署脚本涉及\n\n```\n1. 新建特权用户\nuseradd admin\necho -e '123456\\n123456' | passwd admin\nvisudo\nadmin localhost=NOPASSWD:/usr/bin/systemctl,/usr/bin/firewall-cmd,/sbin/reboot\nfirewall-cmd --zone=public --permanent --add-port=80/tcp\nfirewall-cmd --reload\nyum remove NetworkManager\nyum remove mariadb-libs\n2. 正则匹配\n正整数\n[1-9]\\d*\nIP地址\n(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\n(http|https)://(.*?):(.*?)/(.*)\n3. MySQL\n4. Redis\n5. FastDFS/S3\n6. lvs+keepalived\n7. infoShare\n```\n\n### Linux帮助使用\n\n```\n1.whatis \n2.ls --help \n3.man ls \n4.info ls \n5.help echo\n```\n\n\n\n## 2019-04-04\n\n### Linux权限相关\n\n```\nvisudo\nchmod\nchown\n\n```\n\n### 创建/删除用户\n\n```\nuseradd与adduser都是创建新的用户\n在CentOs下useradd与adduser是没有区别的都是在创建用户，在home下自动创建目录，没有设置密码，需要使用passwd命令修改密码。\n\n而在Ubuntu下useradd与adduser有所不同\n1、useradd在使用该命令创建用户是不会在/home下自动创建与用户名同名的用户目录，而且不会自动选择shell版本，也没有设置密码，那么这个用户是不能登录的，需要使用passwd命令修改密码。\n2、adduser在使用该命令创建用户是会在/home下自动创建与用户名同名的用户目录，系统shell版本，会在创建时会提示输入密码，更加友好。\n\nuserdel 删除用户，\nuserdel只能删除用户，并不会删除相关的目录文件。userdel -r 可以删除用户及相关目录。\n```\n\n### Shell变量\n\n```\n变量说明:\n$$\nShell本身的PID（ProcessID）\n$!\nShell最后运行的后台Process的PID\n$?\n最后运行的命令的结束代码（返回值）\n$-\n使用Set命令设定的Flag一览\n$*\n所有参数列表。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。\n$@\n所有参数列表。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。\n$#\n添加到Shell的参数个数\n$0\nShell本身的文件名\n$1～$n\n```\n\n\n\n## 2019-04-03\n\n### Linux添加永久静态路由的static-routes\n\n```shell\n# 1.在/etc/rc.local里添加\n方法： \nroute add -net 192.168.3.0/24 dev eth0\nroute add -net 192.168.2.0/24 gw 192.168.2.254\n\n# 2.在/etc/sysconfig/network里添加到末尾\n方法：GATEWAY=gw-ip 或者 GATEWAY=gw-dev\n\n# 3./etc/sysconfig/static-routes : (没有static-routes的话就手动建立一个这样的文件)\nany net 192.168.3.0/24 gw 192.168.3.254\nany net 10.250.228.128 netmask 255.255.255.192 gw 10.250.228.129\n \n# 4.开启 IP 转发：\necho \"1\" >/proc/sys/net/ipv4/ip_forward (临时)\nvi /etc/sysctl.conf --> net.ipv4.ip_forward=1 (永久开启)\n```\n\n### 文档存储\n\n```\nXPS是XML Paper Specification的简称，它是微软公司开发的一种文档保存与查看的规范。\n```\n\n### ip命令常用操作\n\n```shell\nip地址管理\n\n# 显示ip地址 \nip a \nip address show \nip addr show dev eth0 \nip a sh eth0\n \n# 增加/删除地址\nip address add 192.0.2.1/24 dev eth0 \nip addr del 192.0.2.2/24 dev eth0\n \n# 显示接口统计 \nip -s link ls eth0\n \n \n网卡和链路配置\n \n# 显示链路 \nip link show \nip link sh eth0\n \n# 修改接口状态 \nip link set eth0 up\nip link s gre01 down\n \n路由表管理\n \n# 显示路由表\nip route\nip ro show dev gre01\n \n# 增加新路由\nip route add 10.2.2.128/27 dev gre01\n \n# 增加默认路由\nip route add default via 192.168.1.1\n \n# 修改默认路由\nip route chg default via 192.168.1.2\n \n# 删除默认路由\nip route del default\n\n \n隧道配置\n \n# 增加删除GRE隧道\nip tunnel add gre01 mode gre local 10.1.1.1 remote 20.2.2.1 ttl 255\nip tunnel del gre01\n \n# IPIP隧道\nip tunl a ipip01 mode ipip local 10.1.1.1 remote 20.2.2.1 ttl 255\n \n# 显示隧道\nip tunnel show\n \n# 显示隧道统计\nip -s tunl ls gre01\n\n \n邻居和arp表管理\n \n# 查看arp表\nip neigh show\n \n# 手工增加删除arp项\nip neighbor add 10.2.2.2 dev eth0\nip neigh del 10.2.2.1 dev eth0\n \n \nsocket统计\n \n# 显示当前监听\nss -l\n \n# 显示当前监听的进程\nss -p\n  \n \n# 常用命令\nip link show #显示链路\nip addr show #显示地址(或ifconfig)\nip route show #显示路由(route -n)\nip neigh show #显示arp表(ping 192.168.95.50，如果主机在同一局域网内，直接加到arp表)\nip neigh delete 192.168.95.50 dev eth0 #删除arp条目，条目仍然存在状态为stale，下次通信需要确认\nip rule show #显示缺省规则\nip route del default dev eth0 #删除接口路由\nip route show table local #查看本地静态路由\nip route show table main #查看直连路由\n  \n# 添加静态路由 \nip route add 10.0.0.0/24 via 192.168.92.129\nip route add 10.10.10.10 via 192.168.92.129\nip route add 172.31.100.0/24 dev eth0\nip route add 172.32.0.2 dev eth0\n  \n# 查看路由表 \nip route show table main\nip route show table local \n \n# 删除\nip route del 10.0.0.0/24 \nip route del 10.10.10.10   \nip route del 172.31.100.0/24\nip route del 172.32.0.2 \n \n# 添加网卡别名并添加标记 label \nip addr add 192.168.1.2/24 label eth0:0 dev eth0\nip addr show eth0\n  \n```\n\n\n\n## 2019-04-02\n\n### 异常/bin/sh^M: bad interpreter: No such file or directory\n\n```shell\n在Linux中执行.sh脚本，异常/bin/sh^M: bad interpreter: No such file or directory。 \n\n分析：\n这是不同系统编码格式引起的：在windows系统中编辑的.sh文件可能有不可见字符，所以在Linux系统下执行会报以上异常信息。 \n解决：\n1）在windows下转换： \n利用一些编辑器如UltraEdit或EditPlus等工具先将脚本编码转换，再放到Linux中执行。转换方式如下（UltraEdit）：File-->Conversions-->DOS->UNIX即可。 \n2）也可在Linux中转换： \n首先要确保文件有可执行权限 \n#sh>chmod a+x filename \n\n然后修改文件格式 \n#sh>vi filename \n\n利用如下命令查看文件格式 \n:set ff 或 :set fileformat \n\n可以看到如下信息 \nfileformat=dos 或 fileformat=unix \n\n利用如下命令修改文件格式 \n:set ff=unix 或 :set fileformat=unix \n\n:wq (存盘退出) \n\n最后再执行文件 \n#sh>./filename \n```\n\n### 杂项\n\n```\nChromium Embedded Framework (CEF) 是一个开源项目，用于嵌入基于 Google Chromium 项目的 Web 浏览器控件。\npywebview 是一个轻量级跨平台的 HTML 浏览器控件，可以在 GUI 应用中显示 HTML 内容。\nhttps://pywebview.flowrl.com/\n```\n\n### 负载均衡\n\n```\n1. DNS解析\n2. Nginx反向代理\n3. lvs+keepalive\n```\n\n```\nifconfig lo:0 125.12.12.77 broadcast125.12.12.77 netmask 255.255.255.255 up\n\nroute add -host 125.12.12.77 dev lo:0\n\nnetmask原意是用于分割子网网络号和子网主机号，所以大部分私有网络（如家庭网络或企业网络）会按需配置或默认的255.255.255.0（表示该子网能容纳255个主机）。在上例中，这个虚拟ip显然不需要配置子网，所以设为4个255表示无子网是自然、合理的。（末尾的up表示update）\n\n这段代码的意图是避免多台RealServer设定了相同的虚拟ip之后导致ip冲突，我猜测：\n\n广播地址设为自己的ip，用于收到同ip发来的消息时，让系统误认为是广播消息（因此系统不觉得ip冲突）\n向路由表加规则，用于向同ip发出消息时，被发送的消息将进入环回接口，即只有该主机自己能收到，不会向网络扩散。\n\n结论：\n掩码设为4个255与防止ip冲突无关。\n\n参考：\nhttp://os.51cto.com/art/201105/264303.htm\nhttp://os.51cto.com/art/201105/262536.htm\n\n```\n\n### net-tools 和 iproute2 \n\n```shell\nnettools（ifconfig、route、arp和netstat）\n# ifconfig\nUsage:\n  ifconfig [-a] [-v] [-s] <interface> [[<AF>] <address>]\n  [add <address>[/<prefixlen>]]\n  [del <address>[/<prefixlen>]]\n  [[-]broadcast [<address>]]  [[-]pointopoint [<address>]]\n  [netmask <address>]  [dstaddr <address>]  [tunnel <address>]\n  [outfill <NN>] [keepalive <NN>]\n  [hw <HW> <address>]  [mtu <NN>]\n  [[-]trailers]  [[-]arp]  [[-]allmulti]\n  [multicast]  [[-]promisc]\n  [mem_start <NN>]  [io_addr <NN>]  [irq <NN>]  [media <type>]\n  [txqueuelen <NN>]\n  [[-]dynamic]\n  [up|down] ...\n\n  <HW>=Hardware Type.\n  List of possible hardware types:\n    loop (Local Loopback) slip (Serial Line IP) cslip (VJ Serial Line IP) \n    slip6 (6-bit Serial Line IP) cslip6 (VJ 6-bit Serial Line IP) adaptive (Adaptive Serial Line IP) \n    ash (Ash) ether (Ethernet) ax25 (AMPR AX.25) \n    netrom (AMPR NET/ROM) rose (AMPR ROSE) tunnel (IPIP Tunnel) \n    ppp (Point-to-Point Protocol) hdlc ((Cisco)-HDLC) lapb (LAPB) \n    arcnet (ARCnet) dlci (Frame Relay DLCI) frad (Frame Relay Access Device) \n    sit (IPv6-in-IPv4) fddi (Fiber Distributed Data Interface) hippi (HIPPI) \n    irda (IrLAP) ec (Econet) x25 (generic X.25) \n    infiniband (InfiniBand) eui64 (Generic EUI-64) \n  <AF>=Address family. Default: inet\n  List of possible address families:\n    unix (UNIX Domain) inet (DARPA Internet) inet6 (IPv6) \n    ax25 (AMPR AX.25) netrom (AMPR NET/ROM) rose (AMPR ROSE) \n    ipx (Novell IPX) ddp (Appletalk DDP) ec (Econet) \n    ash (Ash) x25 (CCITT X.25)\n    \n# route\nUsage: route [-nNvee] [-FC] [<AF>]           List kernel routing tables\n       route [-v] [-FC] {add|del|flush} ...  Modify routing table for AF.\n\n       route {-h|--help} [<AF>]              Detailed usage syntax for specified AF.\n       route {-V|--version}                  Display version/author and exit.\n\n        -v, --verbose            be verbose\n        -n, --numeric            don't resolve names\n        -e, --extend             display other/more information\n        -F, --fib                display Forwarding Information Base (default)\n        -C, --cache              display routing cache instead of FIB\n\n  <AF>=Use -4, -6, '-A <af>' or '--<af>'; default: inet\n  List of possible address families (which support routing):\n    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25) \n    netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP) \n    x25 (CCITT X.25) \n\n# netstat\nusage: netstat [-vWeenNcCF] [<Af>] -r         netstat {-V|--version|-h|--help}\n       netstat [-vWnNcaeol] [<Socket> ...]\n       netstat { [-vWeenNac] -I[<Iface>] | [-veenNac] -i | [-cnNe] -M | -s [-6tuw] } [delay]\n\n        -r, --route              display routing table\n        -I, --interfaces=<Iface> display interface table for <Iface>\n        -i, --interfaces         display interface table\n        -g, --groups             display multicast group memberships\n        -s, --statistics         display networking statistics (like SNMP)\n        -M, --masquerade         display masqueraded connections\n\n        -v, --verbose            be verbose\n        -W, --wide               don't truncate IP addresses\n        -n, --numeric            don't resolve names\n        --numeric-hosts          don't resolve host names\n        --numeric-ports          don't resolve port names\n        --numeric-users          don't resolve user names\n        -N, --symbolic           resolve hardware names\n        -e, --extend             display other/more information\n        -p, --programs           display PID/Program name for sockets\n        -o, --timers             display timers\n        -c, --continuous         continuous listing\n\n        -l, --listening          display listening server sockets\n        -a, --all                display all sockets (default: connected)\n        -F, --fib                display Forwarding Information Base (default)\n        -C, --cache              display routing cache instead of FIB\n        -Z, --context            display SELinux security context for sockets\n\n  <Socket>={-t|--tcp} {-u|--udp} {-U|--udplite} {-S|--sctp} {-w|--raw}\n           {-x|--unix} --ax25 --ipx --netrom\n  <AF>=Use '-6|-4' or '-A <af>' or '--<af>'; default: inet\n  List of possible address families (which support routing):\n    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25) \n    netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP) \n    x25 (CCITT X.25)\n    \n# arp\nUsage:\n  arp [-vn]  [<HW>] [-i <if>] [-a] [<hostname>]             <-Display ARP cache\n  arp [-v]          [-i <if>] -d  <host> [pub]               <-Delete ARP entry\n  arp [-vnD] [<HW>] [-i <if>] -f  [<filename>]            <-Add entry from file\n  arp [-v]   [<HW>] [-i <if>] -s  <host> <hwaddr> [temp]            <-Add entry\n  arp [-v]   [<HW>] [-i <if>] -Ds <host> <if> [netmask <nm>] pub          <-''-\n\n        -a                       display (all) hosts in alternative (BSD) style\n        -e                       display (all) hosts in default (Linux) style\n        -s, --set                set a new ARP entry\n        -d, --delete             delete a specified entry\n        -v, --verbose            be verbose\n        -n, --numeric            don't resolve names\n        -i, --device             specify network interface (e.g. eth0)\n        -D, --use-device         read <hwaddr> from given device\n        -A, -p, --protocol       specify protocol family\n        -f, --file               read new entries from file or from /etc/ethers\n\n  <HW>=Use '-H <hw>' to specify hardware address type. Default: ether\n  List of possible hardware types (which support ARP):\n    ash (Ash) ether (Ethernet) ax25 (AMPR AX.25) \n    netrom (AMPR NET/ROM) rose (AMPR ROSE) arcnet (ARCnet) \n    dlci (Frame Relay DLCI) fddi (Fiber Distributed Data Interface) hippi (HIPPI) \n    irda (IrLAP) x25 (generic X.25) infiniband (InfiniBand) \n    eui64 (Generic EUI-64)\n\n\niproute2（ip和ss）\n# ip\nUsage: ip [ OPTIONS ] OBJECT { COMMAND | help }\n       ip [ -force ] -batch filename\nwhere  OBJECT := { link | address | addrlabel | route | rule | neigh | ntable |\n                   tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm |\n                   netns | l2tp | macsec | tcp_metrics | token }\n       OPTIONS := { -V[ersion] | -s[tatistics] | -d[etails] | -r[esolve] |\n                    -h[uman-readable] | -iec |\n                    -f[amily] { inet | inet6 | ipx | dnet | bridge | link } |\n                    -4 | -6 | -I | -D | -B | -0 |\n                    -l[oops] { maximum-addr-flush-attempts } |\n                    -o[neline] | -t[imestamp] | -ts[hort] | -b[atch] [filename] |\n                    -rc[vbuf] [size] | -n[etns] name | -a[ll] }\n\n# ss\nUsage: ss [ OPTIONS ]\n       ss [ OPTIONS ] [ FILTER ]\n   -h, --help          this message\n   -V, --version       output version information\n   -n, --numeric       don't resolve service names\n   -r, --resolve       resolve host names\n   -a, --all           display all sockets\n   -l, --listening     display listening sockets\n   -o, --options       show timer information\n   -e, --extended      show detailed socket information\n   -m, --memory        show socket memory usage\n   -p, --processes     show process using socket\n   -i, --info          show internal TCP information\n   -s, --summary       show socket usage summary\n   -b, --bpf           show bpf filter socket information\n   -Z, --context       display process SELinux security contexts\n   -z, --contexts      display process and socket SELinux security contexts\n   -N, --net           switch to the specified network namespace name\n\n   -4, --ipv4          display only IP version 4 sockets\n   -6, --ipv6          display only IP version 6 sockets\n   -0, --packet        display PACKET sockets\n   -t, --tcp           display only TCP sockets\n   -S, --sctp          display only SCTP sockets\n   -u, --udp           display only UDP sockets\n   -d, --dccp          display only DCCP sockets\n   -w, --raw           display only RAW sockets\n   -x, --unix          display only Unix domain sockets\n   -f, --family=FAMILY display sockets of type FAMILY\n\n   -A, --query=QUERY, --socket=QUERY\n       QUERY := {all|inet|tcp|udp|raw|unix|unix_dgram|unix_stream|unix_seqpacket|packet|netlink}[,QUERY]\n\n   -D, --diag=FILE     Dump raw information about TCP sockets to FILE\n   -F, --filter=FILE   read filter information from FILE\n       FILTER := [ state STATE-FILTER ] [ EXPRESSION ]\n       STATE-FILTER := {all|connected|synchronized|bucket|big|TCP-STATES}\n         TCP-STATES := {established|syn-sent|syn-recv|fin-wait-{1,2}|time-wait|closed|close-wait|last-ack|listen|closing}\n          connected := {established|syn-sent|syn-recv|fin-wait-{1,2}|time-wait|close-wait|last-ack|closing}\n       synchronized := {established|syn-recv|fin-wait-{1,2}|time-wait|close-wait|last-ack|closing}\n             bucket := {syn-recv|time-wait}\n                big := {established|syn-sent|fin-wait-{1,2}|closed|close-wait|last-ack|listen|closing}\n\n```\n\n\n\n## 2019-04-01\n\n### 1. python标准库-存储对象（pickle、cPickle）\n\n```\n当Python运行时，对象存储在内存中，随时等待系统的调用。然而，内存里的数据会随着计算机关机和消失，如何将对象保存到文件，并储存在硬盘上呢？\n计算机的内存中存储的是二进制的序列 (当然，在Linux眼中，是文本流)。我们可以直接将某个对象所对应位置的数据抓取下来，转换成文本流 (这个过程叫做serialize)，然后将文本流存入到文件中。由于Python在创建对象时，要参考对象的类定义，所以当我们从文本中读取对象时，必须在手边要有该对象的类定义，才能懂得如何去重建这一对象。从文件读取时，对于Python的内建(built-in)对象 (比如说整数、词典、表等等)，由于其类定义已经载入内存，所以不需要我们再在程序中定义类。但对于用户自行定义的对象，就必须要先定义类，然后才能从文件中载入对象。\n\nimport pickle\n# 1) 将内存中的对象转换成为文本流（序列化）：\npickle.dumps() -- 对象转换为字符串，接着存储文本文件\npickle.dump() -- 可同时完成上述两步操作\n# 2) 重建对象（反序列化）：\npickle.load()\npickle.loads()\n\ncPickle包的功能和用法与pickle包几乎完全相同，不同在于cPickle是基于c语言编写的，速度是pickle包的1000倍。\nimport cPickle as pickle\n```\n\n### 2. Ansible模块巩固\n\n```shell\n1）主机连通性测试\nansible web -m ping\n\n2）command 模块\n直接在远程主机上执行命令，并将结果返回本主机。\nansible web -m command -a 'ss -ntl'\n\n3）shell 模块\n在远程主机上调用shell解释器运行命令\nansible web -m shell -a 'cat /etc/passwd |grep \"fdfs\"'\n\n4）copy 模块\n用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。\nansible web -m copy -a 'src=~/hello dest=/data/hello' \n\n5）file 模块\n主要用于设置文件的属性，比如创建文件、创建链接文件、删除文件等。\nansible web -m file -a 'path=/data/app state=directory'\n\n6）fetch 模块\n用于从远程某主机获取（复制）文件到本地。\nansible web -m fetch -a 'src=/data/hello dest=/data'  \n\n7）cron 模块\n用于管理cron计划任务的。其使用的语法跟我们的crontab文件中的语法一致。\nansible web -m cron -a 'name=\"ntp update every 5 min\" minute=*/5 job=\"/sbin/ntpdate 172.17.0.1 &> /dev/null\"'\n \n8）yum 模块\n用于软件的安装。\nansible web -m yum -a 'name=htop state=present'\n\n9）service 模块\n用于服务程序的管理。\nansible web -m service -a 'name=nginx state=started enabled=true' \n\n10）user 模块\n用来管理用户账号。\nansible web -m user -a 'name=fdfs uid=11111'\n\n11）group 模块\n用于添加或删除组。\nansible web -m group -a 'name=ops gid=12222'\n\n12）script 模块\n用于将本机的脚本在被管理端的机器上运行。\nansible web -m script -a '/tmp/df.sh'\n\n13）setup 模块\n用于收集信息，是通过调用facts组件来实现的。\nfacts组件是Ansible用于采集被管机器设备信息的一个功能，我们可以使用setup模块查机器的所有facts信息，可以使用filter来查看指定信息。整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最上层的值。\nfacts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。调用后返回很多对应主机的信息，在后面的操作中可以根据不同的信息来做不同的操作。\nansible web -m setup -a 'filter=\"*mem*\"'\n```\n\n### 3. 磁盘分区\n\n```shell\n#!/bin/bash\ndisk=`fdisk -l | grep \"Disk /dev/sd[a-z]\"`\nfor i in `ls /dev/[sh]d[a-z]`;do\n    echo $i\ndone\ndiskpart() {\ndd if=/dev/zero of=/dev/$chof bs=600 count=1\necho 'n\np\n1\n+512M\nn\np\n2\n+512M\nn\np\n3\n+2G\nt\n2\n82\nw\n' | fdisk $chof\n}\nMount() {\nnum=`grep \"$chof\" /etc/mtab | wc -l`\nfor k in `seq $[$num+1]` ;do\n        fuser -km $chof$k\n        umount $chof$k\n        done\n}\nwhile true ;do\nread -p \"Please Choose a Disk :\" chof\ncase $chof in\n/dev/[sh]d[a-z])\n        [  -e $chof ] && break || continue ;;\nquit)\n        exit 5;;\n*)\n        continue;;\nesac\ndone\nfdisk -l $chof\nwhile true; do\ncat << EOF\n##############################################\n#       this will distory all your data!!    #\n#                BE CAREFUL!!                #\n#             yes|y) continue                #\n#              no|no ) stop                  #\n##############################################\nEOF\nread -p \"Enter Your Choice {yes|no}: \" chos\ncase $chos in\nyes|y)\n        Mount\n        diskpart\n        break ;;\nno|n)\n        exit 3 ;;\n*)\n        echo \"You must give a choice\"\n        continue  ;;\nesac\ndone\n[ ! -d /mnt/boot ] && mkdir /mnt/boot\n[ ! -d /mnt/sysroot ] && mkdir /mnt/sysroot\nfor j in {1..3};do\n        if [ $j -eq 1 ]; then\n                mke2fs -t ext4 $chof$j\n                mount $chof$j /mnt/boot\n        elif [ $j -eq 2 ]; then\n                mkswap $chof$j\n        else\n                mke2fs -t ext4 $chof$j\n                mount $chof$j /mnt/sysroot\n        fi\ndone\necho \"partision successfully\"\n```\n\n","tags":["随笔","201904"]},{"title":"【jenkins】Jenkins安装","url":"/2019/04/29/【jenkins】Jenkins安装/","content":"\n### Jenkins概念\n\nJenkins是一个开源的、可扩展的持续集成、交付、部署（软件/代码的编译、打包、部署）的基于web界面的平台。允许持续集成和持续交付项目，无论用的是什么平台，可以处理任何类型的构建或持续集成。\n\n**官网：**[https://jenkins.io/zh/](https://jenkins.io/zh/)\n\n**官方文档：**[https://jenkins.io/zh/doc/](https://jenkins.io/zh/doc/)\n\n### Jenkins特性：\n\n- 开源的java语言开发持续集成工具，支持CI，CD；\n\n- 易于安装部署配置：可通过yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理；\n\n- 消息通知及测试报告：集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告；\n\n- 分布式构建：支持Jenkins能够让多台计算机一起构建/测试；\n\n- 文件识别:Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等； \n\n- 丰富的插件支持:支持扩展插件，你可以开发适合自己团队使用的工具，如git，svn，maven，docker等。\n\n### Jenkins安装\n\n安装最低配置：不少于256M内存，不低于1G磁盘，JDK版本>=8（openjdk也可以）。\n\n**安装jenkins：**\n\n```\n[root@localhost ~]# yum install -y java-1.8.0-openjdk       //安装openjdk，因为jenkins基于java开发\n\n[root@localhost ~]# wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo      //wget -O 下载文件并以指定的文件名保存\n[root@localhost ~]# cat /etc/yum.repos.d/jenkins.repo \n\n[jenkins]\nname=Jenkins\nbaseurl=http://pkg.jenkins.io/redhat\ngpgcheck=1      //这里会检测key\n\n[root@localhost ~]# rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key         //安装jenkins key\n[root@localhost ~]# yum install -y jenkins\n或\n[root@localhost ~]# wget https://pkg.jenkins.io/redhat-stable/jenkins-2.164.3-1.1.noarch.rpm\n[root@localhost ~]# yum localinstall -y jenkins-2.164.3-1.1.noarch.rpm\n```\n\n**启动jenkins：**\n\n```\n[root@lzx ~]# systemctl start jenkins\n或\n[root@localhost ~]# wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war\n[root@localhost ~]# java -jar jenkins.war --httpPort=8080\n\n[root@lzx ~]# ps aux |grep jenkins\njenkins    1157 84.7 10.0 2320896 100884 ?      Ssl  23:28   0:08 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20\n```\n\n```\n[root@lzx ~]# less /var/log/jenkins/jenkins.log         //查看jenkins日志，截取下面部分\nJenkins initial setup is required. An admin user has been created and a password generated\n.\nPlease use the following password to proceed to installation:\n\n77faa20f2ad544f7bcb6593b1cf1436b        //admin密码，初始化安装时会用到\n\nThis may also be found at: /var/lib/jenkins/secrets/initialAdminPassword        //admin密码也可以在这里查到\n```\n\n**访问安装：**\n\n打开浏览器，访问 http://< ip : port > 进行安装\n\n\n\n*参考链接：*\n\n*[Jenkins入门（一）](https://blog.csdn.net/miss1181248983/article/details/82840006)*\n\n","tags":["jenkins"]},{"title":"【linux】ll或ls -l命令展示信息详解","url":"/2019/04/28/【linux】ll或ls -l命令展示信息详解/","content":"\n ### ll或ls -l命令展示信息详解\n\n```shell\n[root@localhost ~]# ll\ntotal 12\ndrwxr-xr-x. 2 root root    6 Apr 22 10:12 123\ndrwxr-xr-x. 3 root root   17 Apr 22 10:12 234\n-rw-------. 1 root root 1243 Apr  8 14:58 anaconda-ks.cfg\n\n```\n\n|    字段1    |           字段2            | 字段3  |     字段4      |       字段5        |  字段6,7,8   | 字段9 |\n| :---------: | :------------------------: | :----: | :------------: | :----------------: | :----------: | :---: |\n|    属性     | 文件硬链接数或目录子目录数 | 拥有者 | 拥有者所在的组 | 大小(以字节为单位) |     日期     | 名称  |\n| drwxr-xr-x. |             2              |  root  |      root      |         6          | Apr 22 10:12 |  123  |\n\n#### 字段1（文件/目录属性）\n\n#####  第一个字符表示文件类别，如下：\n\n- -：普通文件\n- d：目录文件\n- b：块设备文件\n- c：字符设备文件\n- l：符号链接文件\n- s: 表示该文件为套接字文件（socket），用于进程间通信\n- p: 管道\n\n##### 后9个字符代表3组访问权限：\n\n1. 前3个字符是授权文件所有者的权限；\n2. 中间3个字符是授权同组用户的权限；\n3. 后3个字符是授权其他用户的权限。\n\n每一组的3个字符一次表示读、写、执行权限，其中：\n\n- r：表示有读权限\n- w：表示有写权限\n- x：表示有执行权限\n- -：表示没有相应的权限\n\n##### 最后一个字符点（.）或者加号（+）:\n\n```shell\n# ll -Z\n-rw-r--r--  root root ?                                a.file  #没有SElinux上下文，没有ACL\n-rw-r--r--+ root root ?                                b.file  #只有ACL，没有SElinux上下文\n-rw-------. root root system_u:object_r:admin_home_t:s0 my.cnf #只有SElinux上下文，没有ACL\n-rw-rw-r--+ root root unconfined_u:object_r:user_tmp_t:s0 dd.c #有SElinux上下文，有ACL\n\n```\n\n开启SELinux功能的Linux系统才会有这个点。 点表示文件带有“SELinux的安全上下文”。 \n\nCentOS7默认是开启SELinux的，所以会有这个点， 如果关闭SELinux，然后再创建文件，新创建的文件就不会再有这个点了， 但是以前创建的文件本来有这个点的还会显示这个点（虽然SELinux不起作用了）。\n\n加了ACL权限控制之后，之前具有SELinux属性的文件和目录的权限列最后一个位置全部变成了加号（+）。移除原来的ACL权限之后，恢复原样。\n\n##### 总结：\n\n- Linux权限列的点不是无意义字符。在开启SELinux的情况下创建的目录和文件有具有这个点，权限列有这个点说明该目录或文件以及设置了SELinux相关的权限。在禁用SELinux权限之后，在之前开启SELinux权限时创建的文件或目录保持原来的权限不便，权限列的点依然显示。新创建的目录或文件在权限列无这个点显示。\n- 权限列中最后一个位置如果是加号，说明这个目录或文件已经设置了ACL权限相关的内容。如果加号存在，则已经有点的目录或文件，点的显示会被覆盖，但原来的SELinux属性保持不变。\n\n#### 字段2（文件硬链接数或目录子目录数）\n\n- 新建文件默认数字为1，代表一个硬链接\n- 新建目录默认数字为2，代表拥有两个子目录（ . 和 .. ）","tags":["linux","ll","ls"]},{"title":"【lvs】LVS+Keepalived双主配置","url":"/2019/04/27/【lvs】LVS+Keepalived双主配置/","content":"\n## LVS + Keepalived 双主配置\n\n一般场景中实现LVS高可用及后端的LB，同时只有一台LVS提供服务，另一台作为Backup，显然没有做到最大利用。我们可以让两台LVS都作为Master，并又互为Backup，与master-backup架构相比，master-master架构需要多加一个vip。\n\n### 服务器IP规划\n\n```\nlvs1+keepalived：192.168.1.2\nlvs2+keepalived：192.168.1.3\nweb1：192.168.1.4\nweb2：192.168.1.5\nvip：192.168.1.6，192.168.1.7\n```\n\n### Director（LVS+Keepalvied）主机配置\n\n#### Master Host1 配置\n\n```\n[root@localhost ~]# cat /etc/keepalived/keepalived.conf\nvrrp_instance bl_one {\n    state MASTER             #指定Keepalived的角色，MASTER为主服务器，BACKUP为备用服务器\n    interface eth0           #指定HA监测的接口\n    lvs_sync_daemon_interface eth0\n    virtual_router_id 38     #虚拟路由标识(1-255)，在一个VRRP实例中主备服务器ID必须一样\n    priority 150             #优先级，数字越大越优先，主服务器优先级必须高于备服务器\n    advert_int 3             #设置主备之间同步检查时间间隔，单位秒\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress { #定义虚拟IP地址\n      192.168.1.6\n    }\n}\nvrrp_instance bl_two {\n    state BACKUP\n    interface eth0\n    lvs_sync_daemon_interface eth0\n    virtual_router_id 48\n    priority 120\n    advert_int 3\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n      192.168.1.7\n    }\n}\nvirtual_server 192.168.1.6 80 {\n    delay_loop 3                    #设置健康状态检查时间\n    lb_algo rr                      #设置负载调度算法\n    lb_kind DR                      #设置LVS实现负载均衡的机制\n    persistence_timeout 50          #会话保持时间\n    protocol TCP\n    real_server 192.168.1.4 80 {\n        weight 1\n        TCP_CHECK {\n            connect_timeout 10       #设置响应超时时间\n            nb_get_retry 3           #设置超时重试次数\n            delay_before_retry 3     #设置超时重试间隔\n            connect_port 80\n        }\n    }\n    real_server 192.168.1.5 80 {\n        weight 1\n        TCP_CHECK {\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n}\nvirtual_server 192.168.1.7 80 {\n    delay_loop 3\n    lb_algo rr\n    lb_kind DR\n    persistence_timeout 50\n    protocol TCP\n    real_server 192.168.1.4 80 {\n        weight 1\n        HTTP_GET {\n            url {\n                 path /index.html\n                 status_code 200\n              }\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n    real_server 192.168.1.5 80 {\n        weight 1\n        HTTP_GET {\n            url {\n                 path /index.html\n                 status_code 200\n              }\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n} \n```\n\n#### Master Host2 配置\n\n```\n[root@localhost ~]# cat /etc/keepalived/keepalived.conf\nvrrp_instance bl_one {\n    state BACKUP\n    interface eth0\n    lvs_sync_daemon_interface eth0\n    virtual_router_id 38\n    priority 120\n    advert_int 3\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n      192.168.1.6\n    }\n}\nvrrp_instance bl_two {\n    state MASTER\n    interface eth0\n    lvs_sync_daemon_interface eth0\n    virtual_router_id 48\n    priority 150\n    advert_int 3\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n      192.168.1.7\n    }\n}\nvirtual_server 192.168.1.6 80 {\n    delay_loop 3\n    lb_algo rr\n    lb_kind DR\n    persistence_timeout 50\n    protocol TCP\n    real_server 192.168.1.4 80 {\n        weight 1\n        TCP_CHECK {\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n    real_server 192.168.1.5 80 {\n        weight 1\n        TCP_CHECK {\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n}\nvirtual_server 192.168.1.7 80 {\n    delay_loop 3\n    lb_algo rr\n    lb_kind DR\n    persistence_timeout 50\n    protocol TCP\n    real_server 192.168.1.4 80 {\n        weight 1\n        HTTP_GET {\n            url {\n                 path /index.html\n                 status_code 200\n              }\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n    real_server 192.168.1.5 80 {\n        weight 1\n        HTTP_GET {\n            url {\n                 path /index.html\n                 status_code 200\n              }\n            connect_timeout 10\n            nb_get_retry 3\n            delay_before_retry 3\n            connect_port 80\n        }\n    }\n} \n```\n\n以上创建了两个实例lb_one、lb_two ，其中A主机做为VIP1地址的master，B主机做为VIP2地址的master，A、B主机互为backup 。另外还有一个技巧点，在master-backup架构中也可以配置多个VIP地址，只需要在实例的VIP配置中增加地址、并在后面指定对应的虚地址后面的realserver即可。在主备脚架中配置多个VIP的方法如下：\n\n```\nvirtual_ipaddress {\n  192.168.122.100\n  192.168.122.110\n  ......\n}  \n```\n\n### RealServer主机配置\n\n```\n[root@localhost # cat dr_client.sh\n#!/bin/bash\nVIP1=192.168.1.6\nVIP2=192.168.1.7\n# vip's broadcast\nBROADCAST=192.168.1.255\n. /etc/rc.d/init.d/functions\ncase \"$1\" in\nstart)\n  echo \"reparing for Real Server\"\n    echo \"1\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n    echo \"2\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n    echo \"1\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n    echo \"2\" >/proc/sys/net/ipv4/conf/all/arp_announce\n    ifconfig lo:0 $VIP1 netmask 255.255.255.255 broadcast $BROADCAST up\n    ifconfig lo:1 $VIP2 netmask 255.255.255.255 broadcast $BROADCAST up\n     /sbin/route add -host $VIP1 dev lo:0\n     /sbin/route add -host $VIP2 dev lo:1\n     ;;\nstop)\n     ifconfig lo:0 down\n     ifconfig lo:1 down\n    echo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n    echo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n    echo \"0\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n    echo \"0\" >/proc/sys/net/ipv4/conf/all/arp_announce\n     ;;\n*)\n     echo \"Usage: lvs {start|stop}\"\n     exit 1\nesac \n```\n\n","tags":["lvs"]},{"title":"【lvs】两台主机同时部署LVS（DR）+keepalived+RealServer","url":"/2019/04/26/【lvs】两台主机同时部署LVS（DR）+keepalived+RealServer/","content":"\n## 两台主机同时部署LVS（DR）+keepalived+RealServer\n\n### 问题原因\n\n当 Director1（Master 主)，比如使用 rr 。会转发大约 50% 的包从 Director1 到  Director2 （Backup）。这时 Director2 因为 LVS-DR 的配置规则会接着给这些包在做一次 Load Balance 。又发回给 Director1 。这时会产生一个死的循环。随着时间的推移，不但不能正常的处理连接，服务器也会崩溃。\n\n\n\n### RealServer 配置网卡和ARP 规则\n\n```\n[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-lo:0\n\nDEVICE=lo:0\nIPADDR=192.168.23.253\nNETMASK=255.255.255.255\nONBOOT=yes\n\n[root@localhost ~]# vi /etc/sysctl.conf \n\nnet.ipv4.conf.lo.arp_ignore = 1\nnet.ipv4.conf.lo.arp_announce = 2\n#net.ipv4.conf.enp0s3.arp_ignore = 1\n#net.ipv4.conf.enp0s3.arp_announce = 2\nnet.ipv4.conf.all.arp_ignore = 1\nnet.ipv4.conf.all.arp_announce = 2\n\n[root@localhost ~]# sysctl -p\n[root@localhost ~]# systemctl restart network\n```\n\n\n\n### Keepalived 配置，只能有一个LVS 存活\n\n```\n[root@localhost ~]# vi keepalived.conf\n\n! Configuration File for keepalived\nglobal_defs {\n   #notification_email {\n        #aaa@email.com\n   #}\n   #notification_email_from keepalived@email.com\n   #smtp_server 127.0.0.1\n   #smtp_connect_timeout 30\n}\n\nvrrp_instance web {\n    state BACKUP \n    interface enp0s3 \n    virtual_router_id 51\n    virtual_ipaddress {\n        192.168.23.253 \n    }\n    notify_backup \"/root/notify_node.sh b\"\n    notify_master \"/root/notify_node.sh m\"\n}\n\nvirtual_server 192.168.23.253 0 { \n    delay_loop 6\n    lvs_sched wrr \n    lvs_method DR\n    protocol TCP\n\n    real_server 192.168.23.65 0 { \n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.65 \n            connect_port 80 \n        }\n    }\n    real_server 192.168.23.67 0 { \n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.23.67 \n            connect_port 80 \n        }\n    }\n}\n\n---------------------------------------------------\n\n#!/bin/bash\n# /root/notify_node.sh\n\ncase $1 in\nb)\n/usr/sbin/ipvsadm -C\n;;\nm)\n/usr/sbin/ipvsadm -R <<EOF\n-A -t 192.168.23.253:0 -s wrr -p 360\n-a -t 192.168.23.253:0 -r 192.168.23.65:0 -g -w 3\n-a -t 192.168.23.253:0 -r 192.168.23.67:0 -g -w 3\nEOF\n;;\nesac\n/usr/sbin/ipvsadm -Ln\n```\n\n\n\n### 相关命令操作\n\n```\n# 安装ipvsadm \nyum install -y ipvsadm\n\n# LVS规则保存及恢复\nipvsadm -Sn >/etc/sysconfig/ipvsadm\nipvsadm -R </etc/sysconfig/ipvsadm\n\n# 关闭selinux\nsetenforce 0\nsed -i 's/=enforcing/=disabled/g' /etc/sysconfig/selinux\n\n# 抓包\ntcpdump -i enp0s3 vrrp -n\n\n# 防火墙配置\nfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0  --protocol vrrp -j ACCEPT\nfirewall-cmd --reload\n\n# 测试访问\nfor i in {1..10}; do curl 192.168.23.253 ;done\nfor i in {1..10}; do curl -o /dev/null -s -w %{http_code} 192.168.23.253; echo ;done\n```\n\n","tags":["lvs"]},{"title":"【lvs】LVS+Keepalived实现高可用","url":"/2019/04/25/【lvs】LVS+Keepalived实现高可用/","content":"\n## 使用keepalived 实现LVS 的高可用\n\n#### 服务器IP 信息\n\n```\nlvs1+keepalived：192.168.1.2\nlvs2+keepalived：192.168.1.3\nweb1：192.168.1.4\nweb2：192.168.1.5\nvip：192.168.1.6\n```\n\n### LVS 服务器安配置\n\n```\n# 安装相关软件\n[root@localhost ~]# yum install -y ipvsadm keepalived\n\n# 配置keepalived.conf\n[root@localhost ~]# vi keepalived.conf\n\n! Configuration File for keepalived\nglobal_defs {\n   #notification_email {\n        #aaa@email.com\n   #}\n   #notification_email_from keepalived@email.com\n   #smtp_server 127.0.0.1\n   #smtp_connect_timeout 30\n}\n\nvrrp_instance lvs_web {\n    state MASTER\t#另一个设置BACKUP\n    interface ens160\n    virtual_router_id 51\n    virtual_ipaddress {\n        192.168.1.6 \n    }\n}\n\nvirtual_server 192.168.1.6 0 {\n    delay_loop 6\n    lvs_sched wrr \n    lvs_method DR\n    protocol TCP\n\n    real_server 192.168.1.4 0 { \n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.1.4 \n            connect_port 80\n        }\n    }\n    real_server 192.168.1.5 0 { \n        weight 3\n        TCP_CHECK {\n            connect_ip 192.168.1.5 \n            connect_port 80\n        }\n    }\n}\n\n# 启动服务\n[root@localhost ~]# systemctl restart keepalived\n[root@localhost ~]# systemctl enable keepalived\n\n# 查看lvs状态\n[root@localhost ~]# ipvsadm -Ln\n```\n\n### Web 服务器（RealServer）配置\n\n```\n# 安装httpd\n[root@localhost ~]# yum install -y httpd\n\n# 配置回环网卡\n[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-lo:0\n\nDEVICE=lo:0\nBOOTPROTO=static\nIPADDR=192.168.23.253\nNETMASK=255.255.255.255\nGATEWAY=192.168.23.1\nONBOOT=yes\n\n# 配置ARP规则\n[root@localhost ~]# vi /etc/sysctl.conf \n\nnet.ipv4.conf.enp0s3.arp_ignore = 1\nnet.ipv4.conf.enp0s3.arp_announce = 2\nnet.ipv4.conf.all.arp_ignore = 1\nnet.ipv4.conf.all.arp_announce = 2\n\n[root@localhost ~]# sysctl -p\n\n# 配置Apache服务\n[root@localhost ~]# vi /var/www/html/index.html\n\nHOST 52 192.168.1.*\n\n# 重启服务服务\n[root@localhost ~]# systemctl restart network\n[root@localhost ~]# systemctl restart httpd\n[root@localhost ~]# systemctl enable httpd\n\n# 设置防火墙规则\n[root@localhost ~]# firewalld-cmd --permanent --add-port=80/tcp\n[root@localhost ~]# firewalld-cmd --reload\n```\n\n","tags":["lvs"]},{"title":"【lvs】LVS配置DR模式","url":"/2019/04/24/【lvs】LVS配置DR模式/","content":"\n## LVS 使用DR 模式\n\n#### 服务器IP 信息\n\n```\nlvs：192.168.1.2\nweb1：192.168.1.3\nweb2：192.168.1.4\nvip：192.168.1.5\n```\n\n### LVS 服务器安装配置\n\n```\n# 安装 ipvsadm（lvs管理软件）\n[root@localhost ~]# yum install -y ipvsadm\n\n# 添加vip\n[root@localhost ~]# ifconfig enp0s3:1 192.168.1.5 netmask 255.255.255.0\n[root@localhost ~]# route add -host 192.168.1.5 dev eth1\n或\n[root@localhost ~]# ip address add 192.168.1.5/24 broadcast 192.168.1.255 label enp0s3:1 dev enp0s3\n[root@localhost ~]# ip route add 192.168.1.5/24 dev enp0s3:1\n或\n[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-enp0s3:1\n\nDEVICE=enp0s3:1\nIPADDR=192.168.1.5\nNETMASK=255.255.255.0\nONBOOT=yes\n\n# 创建虚拟服务并设置适合的调度算法\n[root@localhost ~]# ipvsadm -A -t 192.168.1.5:80 -s wrr # Zero port specified for non-persistent service\n# 添加RealServer组\n[root@localhost ~]# ipvsadm -a -t 192.168.1.5:80 -r 192.168.1.3:80 -g -w 1\n[root@localhost ~]# ipvsadm -a -t 192.168.1.5:80 -r 192.168.1.4:80 -g -w 2\n\n# 保存调度规则\n[root@localhost ~]# ipvsadm -Sn > /etc/sysconfig/ipvsadm\n\n# 设置防火墙规则\n[root@localhost ~]# firewalld-cmd --permanent --add-port=80/tcp\n[root@localhost ~]# firewalld-cmd --reload\n\n# 开启服务\n[root@localhost ~]# systemctl start ipvsadm\n[root@localhost ~]# systemctl enable ipvsadm\n```\n\n### Web 服务器（RealServer）配置\n\n```\n# 安装httpd\n[root@localhost ~]# yum install -y httpd\n\n# 配置回环网卡\n[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-lo:0\n\nDEVICE=lo:0\nBOOTPROTO=static\nIPADDR=192.168.23.253\nNETMASK=255.255.255.255\nGATEWAY=192.168.23.1\nONBOOT=yes\n\n# 配置ARP规则\n[root@localhost ~]# vi /etc/sysctl.conf \n\nnet.ipv4.conf.enp0s3.arp_ignore = 1\nnet.ipv4.conf.enp0s3.arp_announce = 2\nnet.ipv4.conf.all.arp_ignore = 1\nnet.ipv4.conf.all.arp_announce = 2\n\n[root@localhost ~]# sysctl -p\n\n# 配置Apache服务\n[root@localhost ~]# vi /var/www/html/index.html\n\nHOST 52 192.168.1.*\n\n# 重启服务服务\n[root@localhost ~]# systemctl restart network\n[root@localhost ~]# systemctl restart httpd\n[root@localhost ~]# systemctl enable httpd\n\n# 设置防火墙规则\n[root@localhost ~]# firewalld-cmd --permanent --add-port=80/tcp\n[root@localhost ~]# firewalld-cmd --reload\n```\n\n### ipvsadm 配置\n\n```\n[root@localhost ~]# cat /etc/sysconfig/ipvsadm-config \n# Unload modules on restart and stop\n#   Value: yes|no,  default: yes\n# This option has to be 'yes' to get to a sane state for a ipvs\n# restart or stop. Only set to 'no' if there are problems unloading ipvs\n# modules.\nIPVS_MODULES_UNLOAD=\"yes\"\n\n# Save current ipvs rules on stop.\n#   Value: yes|no,  default: no\n# Saves all ipvs rules to /etc/sysconfig/ipvsadm if ipvsadm gets stopped\n# (e.g. on system shutdown).\nIPVS_SAVE_ON_STOP=\"no\"\n\n# Save current ipvs rules on restart.\n#   Value: yes|no,  default: no\n# Saves all ipvs rules to /etc/sysconfig/ipvsadm if ipvsadm gets\n# restarted.\nIPVS_SAVE_ON_RESTART=\"no\"\n\n# Numeric status output\n#   Value: yes|no,  default: yes\n# Print IP addresses and port numbers in numeric format in the status output.\nIPVS_STATUS_NUMERIC=\"yes\"\n\n```\n\n### ipvsadm 用法\n\n```\nipvsadm v1.27 2008/5/15 (compiled with popt and IPVS v1.2.1)\nUsage:\n  ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pe persistence_engine] [-b sched-flags]\n  ipvsadm -D -t|u|f service-address\n  ipvsadm -C\n  ipvsadm -R\n  ipvsadm -S [-n]\n  ipvsadm -a|e -t|u|f service-address -r server-address [options]\n  ipvsadm -d -t|u|f service-address -r server-address\n  ipvsadm -L|l [options]\n  ipvsadm -Z [-t|u|f service-address]\n  ipvsadm --set tcp tcpfin udp\n  ipvsadm --start-daemon state [--mcast-interface interface] [--syncid sid]\n  ipvsadm --stop-daemon state\n  ipvsadm -h\n\nCommands:\nEither long or short options are allowed.\n  --add-service     -A        add virtual service with options\n  --edit-service    -E        edit virtual service with options\n  --delete-service  -D        delete virtual service\n  --clear           -C        clear the whole table\n  --restore         -R        restore rules from stdin\n  --save            -S        save rules to stdout\n  --add-server      -a        add real server with options\n  --edit-server     -e        edit real server with options\n  --delete-server   -d        delete real server\n  --list            -L|-l     list the table\n  --zero            -Z        zero counters in a service or all services\n  --set tcp tcpfin udp        set connection timeout values\n  --start-daemon              start connection sync daemon\n  --stop-daemon               stop connection sync daemon\n  --help            -h        display this help message\n\nOptions:\n  --tcp-service  -t service-address   service-address is host[:port]\n  --udp-service  -u service-address   service-address is host[:port]\n  --fwmark-service  -f fwmark         fwmark is an integer greater than zero\n  --ipv6         -6                   fwmark entry uses IPv6\n  --scheduler    -s scheduler         one of rr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq,\n                                      the default scheduler is wlc.\n  --pe            engine              alternate persistence engine may be sip,\n                                      not set by default.\n  --persistent   -p [timeout]         persistent service\n  --netmask      -M netmask           persistent granularity mask\n  --real-server  -r server-address    server-address is host (and port)\n  --gatewaying   -g                   gatewaying (direct routing) (default)\n  --ipip         -i                   ipip encapsulation (tunneling)\n  --masquerading -m                   masquerading (NAT)\n  --weight       -w weight            capacity of real server\n  --u-threshold  -x uthreshold        upper threshold of connections\n  --l-threshold  -y lthreshold        lower threshold of connections\n  --mcast-interface interface         multicast interface for connection sync\n  --syncid sid                        syncid for connection sync (default=255)\n  --connection   -c                   output of current IPVS connections\n  --timeout                           output of timeout (tcp tcpfin udp)\n  --daemon                            output of daemon information\n  --stats                             output of statistics information\n  --rate                              output of rate information\n  --exact                             expand numbers (display exact values)\n  --thresholds                        output of thresholds information\n  --persistent-conn                   output of persistent connection info\n  --nosort                            disable sorting output of service/server entries\n  --sort                              does nothing, for backwards compatibility\n  --ops          -o                   one-packet scheduling\n  --numeric      -n                   numeric output of addresses and ports\n  --sched-flags  -b flags             scheduler flags (comma-separated)\n\n```\n\n","tags":["lvs"]},{"title":"【lvs】LVS相关概念","url":"/2019/04/23/【lvs】LVS相关概念/","content":"\n## 概念了解\n\n### LVS\n\nLVS是Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。\n\n针对可伸缩，高可用服务的需求，给予IP层和内容请求分发的负载均衡调度解决方法，并在Linux的内核中实现，将一组服务器构成一个实现可伸缩，高可用网络服务的虚拟服务器。\n\n#### 负载调度器\n一组服务器通过高速的局域网或者地理分布的广域网相互相连，在他们的前端有一个负载均衡调度器（Load Balancer），负载均衡调度器能无缝的将网络请求调度到真实的服务器上，从而使得服务器集群的结构对用户是透明的，用户通过访问集群系统提供的网络服务，就像访问一台高性能，高可用的服务器。\n\n#### 三种IP负载均衡技术\n1.VS/NAT（网络地址转换）\n通过网络地址转换，调度器重写请求报文的目标地址，根据预设的调度算法，将请求分发给后端的真实服务器，真实服务器的响应报文通过调度器时，报文的源地址被重写，再返回到客户端，完成整个调度的过程。\n\n2.VS/TUN（IP隧道模式）\n调度器将请求的报文通过IP隧道转发至真实服务器，而真实的服务器直接将结果返回给用户，调度器只处理请求报文，由于一般网路服务的应答大于请求，采用IP隧道模式，集群系统的最大吞吐量可以提高10倍。\n\n3.VS/DR（直接路由）\n通过改写请求报文的MAC地址，将请求发送到真是服务器，真实服务器将响应直接返回给用户，之际额路由模式可以极大的提高集群系统的伸缩性，这种方法没有IP隧道的开销，集群中真实的服务器也没有必要必须支持IP隧道协议，只是需要调度器与真实服务器有一块网卡连在同一物理网段上。\n\n*PS: DR和TUN模式都需要在真实服务器上对arp_ignore和arp_announce参数进行配置，主要是实现禁止响应对VIP的ARP请求。*\n\n#### 参数配置\n\n**arp_ignore**\n\n- 0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求 \n- 1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求 \n- 2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内 \n- 3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应 \n- 4-7 - 保留未使用 \n- 8 -不回应所有（本地地址）的arp查询\n\n**arp_announce**\n\n- 0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址 \n\n- 1 - 尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理. \n- 2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送.\n\n```shell\necho \"1\" > /proc/sys/net/ipv4/conf/all/arp_ignore\necho \"1\" > /proc/sys/net/ipv4/conf/lo/arp_ignore\necho \"2\" > /proc/sys/net/ipv4/conf/lo/arp_announce\necho \"2\" > /proc/sys/net/ipv4/conf/all/arp_announce\n```\n\n### ARP\n\n地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。\n\n## DR 模式Real Server 配置\n\n### CentOS 6（CentOS 7 安装net-tools 包也可使用）\n\n```shell\n#!/bin/sh\n# chkconfig: - 80 20\n# description: RealServer\n\nVIP=192.168.10.12\n/etc/rc.d/init.d/functions\ncase \"$1\" in\n    start)\n        echo \"Start LVS of RealServer\"\n        ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up\n        route add -host $VIP dev lo:0\n        echo \"1\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"2\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"1\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"2\" >/proc/sys/net/ipv4/conf/all/arp_announce\n        ;;\n    stop)\n        ifconfig lo:0 down\n        route del -host $VIP dev lo:0\n        echo \"Stop LVS of RealServer\"\n        echo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"0\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"0\" >/proc/sys/net/ipv4/conf/all/arp_announce\n        ;;\n    *)\n        echo \"Usage:$0{start|stop}\"\n        exit 1\nesac\n```\n\n### CentOS 7\n\n```shell\n#!/bin/sh\n# chkconfig: - 80 20\n# description: RealServer\n\nVIP=192.168.10.12\n/etc/rc.d/init.d/functions\ncase \"$1\" in\nstart)\n\tip address add $VIP/32 broadcast $VIP label lo:0 dev lo\n\tip route add $VIP/32 dev lo:0\n\techo \"1\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n\techo \"2\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n\techo \"1\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n\techo \"2\" >/proc/sys/net/ipv4/conf/all/arp_announce\n\tsysctl -p >/dev/null 2>&1\n\techo \"RealServer Start OK\"\n\t;;\nstop)\n\tip link set dev lo:0 down\n\tip route del $VIP/32 dev lo:0 >/dev/null 2>&1\n\techo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_ignore\n\techo \"0\" >/proc/sys/net/ipv4/conf/lo/arp_announce\n\techo \"0\" >/proc/sys/net/ipv4/conf/all/arp_ignore\n\techo \"0\" >/proc/sys/net/ipv4/conf/all/arp_announce\n\techo \"RealServer Stoped\"\n\t;;\n*)\n\techo \"Usage: $0 {start|stop}\"\n\texit 1\nesac\n```\n\n","tags":["lvs"]},{"title":"【activemq】ActiveMQ绿色部署","url":"/2019/04/23/【activemq】ActiveMQ绿色部署/","content":"\n### ActiveMQ下载地址\n\n[Download](http://activemq.apache.org/download)\n\n### ActiveMQ官方安装文档\n\n[Getting Started](http://activemq.apache.org/getting-started)\n\n### Linux安装jre\n\n[How do I download and install 32-bit Java for Linux?](https://www.java.com/en/download/help/linux_install.xml)\n\n### ActiveMQ绿色安装\n\n1. 下载activemq和jre，并解压到同一目下\n2. 配置activemq的Java环境\n\n```shell\nCURRENTPATH=$(dirname $(readlink -f $0))\nsed -i '/^JAVACMD=/cJAVACMD=\\\"'$CURRENTPATH'/jre/bin/java\\\"' $CURRENTPATH/activemq/bin/env\nsed -i 's#<transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600\"/>#<transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?transport.hbGracePeriodMultiplier=1.5\"/>#' $CURRENTPATH/activemq/conf/activemq.xml\n```\n\n3. 编写systemd服务\n\n```shell\n# 服务管理使用伪用户\n# useradd -r -s /bin/false activemq\n\n[Unit]\nDescription=ActiveMQ\n\n[Service]\nUser=activemq\nType=forking\nExecStart=/home/user/activemq/bin/activemq start\nExecStop=/home/user/activemq/bin/activemq stop\nPIDFile=/home/user/activemq/data/activemq.pid\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\n4. 开放防火墙端口\n\n```shell\nsudo firewall-cmd --permanent --add-port=61613/tcp\nsudo firewall-cmd --permanent --add-port=61616/tcp\nsudo firewall-cmd --reload\n```\n\n5. 设置伪用户权限\n\n```shell\nif ! id activemq &>/dev/null; then\n\tsudo useradd -r -s /bin/false activemq\n\tUPPERPATH=$CURRENTPATH\n\twhile true\n\tdo\n\t\tif [ \"$HOME\" == \"$UPPERPATH\" ]; then\n\t\t\tbreak\n\t\tfi\n\t\tUPPERPATH=$(dirname $UPPERPATH)\n\t\tsetfacl -m u:activemq:rwx $UPPERPATH\n\t\tsetfacl -d -m u:activemq:rwx $UPPERPATH\n\tdone\n\tsetfacl -R -m u:activemq:rwx $CURRENTPATH\n\tsetfacl -dR -m u:activemq:rwx $CURRENTPATH\nfi\n```\n\n6. 设置开机自启并启动服务\n\n```\nsudo systemctl enable activemq\nsudo systemctl daemon-reload\nsudo systemctl restart activemq\n```\n\n","tags":["activemq"]},{"title":"【mysql】MySQL常用操作命令","url":"/2019/04/22/【mysql】MySQL常用操作命令/","content":"\n### 1. 权限解释\n\n#### 全局管理权限：\n- FILE: 在MySQL服务器上读写文件。\n- PROCESS: 显示或杀死属于其它用户的服务线程。\n- RELOAD: 重载访问控制表，刷新日志等。\n- SHUTDOWN: 关闭MySQL服务。\n\n#### 数据库/数据表/数据列权限：\n- ALTER: 修改已存在的数据表(例如增加/删除列)和索引。\n- CREATE: 建立新的数据库或数据表。\n- DELETE: 删除表的记录。\n- DROP: 删除数据表或数据库。\n- INDEX: 建立或删除索引。\n- INSERT: 增加表的记录。\n- SELECT: 显示/搜索表的记录。\n- UPDATE: 修改表中已存在的记录。\n\n#### 特别的权限：\n- ALL: 允许做任何事(和root一样)。\n- USAGE: 只允许登录–其它什么也不允许做。\n\n### 2. 备份、恢复（mysqldump）\n\n","tags":["mysql"]},{"title":"【tools】优质资源集合","url":"/2019/04/17/【tools】优质资源集合/","content":"\n### Ansible\n\n[Ansible Documentation](https://docs.ansible.com/)\n\n[Ansible中文权威指南- 国内最专业的Ansible中文官方学习手册](http://www.ansible.com.cn/)\n\n[自动化运维工具——ansible详解（一） - 珂儿吖 - 博客园](http://www.cnblogs.com/keerya/p/7987886.html)\n\n### CentOS\n\n[HowTos/OS Protection - CentOS Wiki](https://wiki.centos.org/HowTos/OS_Protection)\n\n[Michael Kerrisk - man7.org](http://man7.org/index.html)\n\n### ClusterShell\n\n[Linux运维利器之ClusterShell | 火丁笔记](https://huoding.com/2011/11/12/133)\n\n### Cobbler\n\n[Cobbler-自动化部署神器 - REN的博客 - 51CTO技术博客](http://renjunjie622.blog.51cto.com/2913680/1782190)\n\n[Cobbler Web界面操作（一） - zhanguo1110 - 51CTO技术博客](http://zhanguo1110.blog.51cto.com/5750817/1671137)\n\n[Centos7 下cobbler安装及配置 - linuxliu - 博客园](https://www.cnblogs.com/linuxliu/p/7668048.html)\n\n### Dialog\n\n[pythondialog web site](http://pythondialog.sourceforge.net/)\n\n[The Dialog widgets — pythondialog 3.4.0 documentation](http://pythondialog.sourceforge.net/doc/widgets.html#dialog.Dialog.form)\n\n[firewalldtui/firewalldtui.py at master · aldenso/firewalldtui · GitHub](https://github.com/aldenso/firewalldtui/blob/master/firewalldtui.py)\n\n### Docker\n\n### Documents\n\n[Knowledge Base](https://wiki2.xbits.net:4430/)\n\n### FastDFS\n\n[Home · happyfish100/fastdfs Wiki · GitHub](https://github.com/happyfish100/fastdfs/wiki)\n\n### Fiddler\n\n### Firewalld\n\n[Home | firewalld](https://firewalld.org/)\n\n### Git\n\n[Git的使用--如何将本地项目上传到Github](https://blog.csdn.net/zamamiro/article/details/70172900)\n\n[Git使用详细教程 - seven-ahz - 博客园](https://www.cnblogs.com/seven-ahz/p/7712125.html)\n\n### Jenkins\n\n[Jenkins](https://jenkins.io/)\n\n### keepalived\n\n### Kickstart\n\n[Anaconda/Kickstart/zh-cn](https://fedoraproject.org/wiki/Anaconda/Kickstart/zh-cn)\n\n### Kubernetes\n\n[Kubernetes（k8s）中文文档 Kubernetes概述_Kubernetes中文社区](https://www.kubernetes.org.cn/k8s)\n\n### KVM\n\n### LibreOffice\n\n[Index of /libreoffice](http://download.documentfoundation.org/libreoffice/)\n\n[JODConverter - Browse /JODConverter/2.2.2 at SourceForge.net](https://sourceforge.net/projects/jodconverter/files/JODConverter/2.2.2/)\n\n[linux下libreoffice安装测试 - bethal - 博客园](https://www.cnblogs.com/bethal/p/5242130.html?tdsourcetag=s_pctim_aiomsg)\n\n[关于centos7安装libreoffice遇到的问题 - xujingcheng123的博客 - CSDN博客](https://blog.csdn.net/xujingcheng123/article/details/84636750)\n\n### Libvirt\n\n[Libvirt 虚拟化库剖析](https://www.ibm.com/developerworks/cn/linux/l-libvirt/index.html)\n\n### LVS\n\n### Makedown\n\n### MySQL\n\n### Nagios\n\n### Ngnix\n\n[Nginx中文文档](http://www.nginx.cn/doc/)\n\n### NSSM\n\n### PHP\n\n### Puppet\n\n[自动化运维工具——puppet详解（一） - 珂儿吖 - 博客园](http://www.cnblogs.com/keerya/p/8040071.html)\n\n### RPM\n\n[Search the RPM repository on rpmfind.net](http://rpmfind.net/linux/rpm2html/search.php)\n\n[rpm(8): RPM Package Manager - Linux man page](https://linux.die.net/man/8/rpm)\n\n[Welcome to RPM Packaging Guide’s documentation! — RPM Packaging Guide 0.0.1 documentation](https://rpm-guide.readthedocs.io/en/latest/index.html)\n\n### Shell\n\n[Advanced Bash-Scripting Guide](http://www.tldp.org/LDP/abs/html/index.html?tdsourcetag=s_pctim_aiomsg)\n\n[【 专栏 】- shell高级脚本编程指南 - Seal--学海无涯（嵌入式 Linux Android 内核 驱动） - CSDN博客](https://blog.csdn.net/xinyuwuxian/column/info/shell-daily-study)\n\n### Systemd\n\n[systemd.service 中文手册 [金步国]](http://www.jinbuguo.com/systemd/systemd.service.html)\n\n[systemd (简体中文) - ArchWiki](https://wiki.archlinux.org/index.php/systemd_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29)\n\n[Systemd 入门教程：命令篇 - 阮一峰的网络日志](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)\n\n[编写systemd service文件 - CSDN博客](https://blog.csdn.net/djskl/article/details/46671453)\n\n### VIM\n\n[强大的vim配置文件，让编程更随意 - ma6174 - 博客园](https://www.cnblogs.com/ma6174/archive/2011/12/10/2283393.html)\n\n### Whiptail\n\n[whiptail(1): dialog boxes from shell scripts - Linux man page](https://linux.die.net/man/1/whiptail)\n\n### Wireshark\n\n### Zabbix\n\n[Zabbix | 系统运维](https://www.osyunwei.com/archives/category/monitor/zabbix)","tags":["tools","资源"]},{"title":"【linux】普通用户使用小于1024的端口","url":"/2019/04/02/【linux】普通用户使用小于1024的端口/","content":"\n普通用户启动服务需要绑定80和443端口，而在linux中，1024以下端口被称为privileged port，即特权端口，特权端口只能被由root启动的进程监听。\n\n### 1. 权限绑定\n\n#### 设置特权\n\n为特定可执行文件赋予绑定特权端口的权限（永久）： \n\n```shell\nsetcap 'cap_net_bind_service=+ep' /path/to/program \n\nsudo setcap 'cap_net_bind_service=+ep' $(readlink -f $(which node))\n```\n\n#### 取消特权\n\n```shell\nsetcap -r /path/to/program \n```\n\n#### Now for the caveats:\n\n1. You will need at least a 2.6.24 kernel\n2. This won't work if your file is a script. (ie, uses a #! line to launch an interpreter). In this case, as far I as understand, you'd have to apply the capability to the interpreter executable itself, which of course is a security nightmare, since any program using that interpreter will have the capability. I wasn't able to find any clean, easy way to work around this problem.\n3. Linux will disable LD_LIBRARY_PATH on any `program` that has elevated privileges like `setcap` or `suid`. So if your `program` uses its own `.../lib/`, you might have to look into another option like port forwarding.\n\n#### 参考链接\n\n[Is there a way for non-root processes to bind to “privileged” ports on Linux?](https://stackoverflow.com/questions/413807/is-there-a-way-for-non-root-processes-to-bind-to-privileged-ports-on-linux)\n\n[Unset `setcap` additional capabilities on excutable](https://unix.stackexchange.com/questions/303423/unset-setcap-additional-capabilities-on-excutable)\n\n\n\n### 2. 端口转发\n\n 首先绑定1024以上的端口，检查IP FORWARD功能是否开启：\n\n```shell\n#修改文件\nvi /etc/sysctl.conf\nnet.ipv4.ip_forward = 1\n#重新加载\nsysctl -p /etc/sysctl.conf\n```\n\n配置端口转发，root权限执行\n\n```shell\niptables -A PREROUTING -t nat -p tcp --dport 80 -j REDIRECT --to-port 8080\n```\n\n\n\n### 3. setuid（不安全）\n\n```shell\nchown root:root nginx\nchmod 4755 nginx\n```\n\n\n\n### 4. 反向代理（nginx）","tags":["linux"]},{"title":"【Linux】Linux磁盘管理相关命令","url":"/2019/04/01/【linux】Linux磁盘管理操作/","content":"\n**1. df命令**\n\n```shell\n# df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。\n\nUsage: df [OPTION]... [FILE]...\nShow information about the file system on which each FILE resides,\nor all file systems by default.\n\nMandatory arguments to long options are mandatory for short options too.\n  -a, --all             include dummy file systems\n  -B, --block-size=SIZE  scale sizes by SIZE before printing them; e.g.,\n                           '-BM' prints sizes in units of 1,048,576 bytes;\n                           see SIZE format below\n      --direct          show statistics for a file instead of mount point\n      --total           produce a grand total\n  -h, --human-readable  print sizes in human readable format (e.g., 1K 234M 2G)\n  -H, --si              likewise, but use powers of 1000 not 1024\n  -i, --inodes          list inode information instead of block usage\n  -k                    like --block-size=1K\n  -l, --local           limit listing to local file systems\n      --no-sync         do not invoke sync before getting usage info (default)\n      --output[=FIELD_LIST]  use the output format defined by FIELD_LIST,\n                               or print all fields if FIELD_LIST is omitted.\n  -P, --portability     use the POSIX output format\n      --sync            invoke sync before getting usage info\n  -t, --type=TYPE       limit listing to file systems of type TYPE\n  -T, --print-type      print file system type\n  -x, --exclude-type=TYPE   limit listing to file systems not of type TYPE\n  -v                    (ignored)\n      --help     display this help and exit\n      --version  output version information and exit\n\nDisplay values are in units of the first available SIZE from --block-size,\nand the DF_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE environment variables.\nOtherwise, units default to 1024 bytes (or 512 if POSIXLY_CORRECT is set).\n\nSIZE is an integer and optional unit (example: 10M is 10*1024*1024).  Units\nare K, M, G, T, P, E, Z, Y (powers of 1024) or KB, MB, ... (powers of 1000).\n\nFIELD_LIST is a comma-separated list of columns to be included.  Valid\nfield names are: 'source', 'fstype', 'itotal', 'iused', 'iavail', 'ipcent',\n'size', 'used', 'avail', 'pcent', 'file' and 'target' (see info page).\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\nFor complete documentation, run: info coreutils 'df invocation'\n```\n\n**2. fdisk命令**\n\n```shell\n# fdisk命令用于观察硬盘实体使用情况，也可对硬盘分区。它采用传统的问答式界面，而非类似DOS fdisk的cfdisk互动式操作界面，因此在使用上较为不便，但功能却丝毫不打折扣。\n\nUsage:\n fdisk [options] <disk>    change partition table\n fdisk [options] -l <disk> list partition table(s)\n fdisk -s <partition>      give partition size(s) in blocks\n\nOptions:\n -b <size>             sector size (512, 1024, 2048 or 4096)\n -c[=<mode>]           compatible mode: 'dos' or 'nondos' (default)\n -h                    print this help text\n -u[=<unit>]           display units: 'cylinders' or 'sectors' (default)\n -v                    print program version\n -C <number>           specify the number of cylinders\n -H <number>           specify the number of heads\n -S <number>           specify the number of sectors per track\n\n```\n\n**3. lsblk命令**\n\n```shell\n# lsblk命令用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，cd-ROM等等。lsblk命令包含在util-linux-ng包中，现在该包改名为util-linux。这个包带了几个其它工具，如dmesg。\n\nUsage:\n lsblk [options] [<device> ...]\n\nOptions:\n -a, --all            print all devices\n -b, --bytes          print SIZE in bytes rather than in human readable format\n -d, --nodeps         don't print slaves or holders\n -D, --discard        print discard capabilities\n -e, --exclude <list> exclude devices by major number (default: RAM disks)\n -I, --include <list> show only devices with specified major numbers\n -f, --fs             output info about filesystems\n -h, --help           usage information (this)\n -i, --ascii          use ascii characters only\n -m, --perms          output info about permissions\n -l, --list           use list format output\n -n, --noheadings     don't print headings\n -o, --output <list>  output columns\n -p, --paths          print complate device path\n -P, --pairs          use key=\"value\" output format\n -r, --raw            use raw output format\n -s, --inverse        inverse dependencies\n -t, --topology       output info about topology\n -S, --scsi           output info about SCSI devices\n\n -h, --help     display this help and exit\n -V, --version  output version information and exit\n\nAvailable columns (for --output):\n        NAME  device name\n       KNAME  internal kernel device name\n     MAJ:MIN  major:minor device number\n      FSTYPE  filesystem type\n  MOUNTPOINT  where the device is mounted\n       LABEL  filesystem LABEL\n        UUID  filesystem UUID\n   PARTLABEL  partition LABEL\n    PARTUUID  partition UUID\n          RA  read-ahead of the device\n          RO  read-only device\n          RM  removable device\n       MODEL  device identifier\n      SERIAL  disk serial number\n        SIZE  size of the device\n       STATE  state of the device\n       OWNER  user name\n       GROUP  group name\n        MODE  device node permissions\n   ALIGNMENT  alignment offset\n      MIN-IO  minimum I/O size\n      OPT-IO  optimal I/O size\n     PHY-SEC  physical sector size\n     LOG-SEC  logical sector size\n        ROTA  rotational device\n       SCHED  I/O scheduler name\n     RQ-SIZE  request queue size\n        TYPE  device type\n    DISC-ALN  discard alignment offset\n   DISC-GRAN  discard granularity\n    DISC-MAX  discard max bytes\n   DISC-ZERO  discard zeroes data\n       WSAME  write same max bytes\n         WWN  unique storage identifier\n        RAND  adds randomness\n      PKNAME  internal parent kernel device name\n        HCTL  Host:Channel:Target:Lun for SCSI\n        TRAN  device transport type\n         REV  device revision\n      VENDOR  device vendor\n\nFor more details see lsblk(8).\n\n```\n\n**4. blkid命令**\n\n```shell\n# 在Linux下可以使用blkid命令对查询设备上所采用文件系统类型进行查询。blkid主要用来对系统的块设备（包括交换分区）所使用的文件系统类型、LABEL、UUID等信息进行查询。要使用这个命令必须安装e2fsprogs软件包。\n\nblkid from util-linux 2.23.2  (libblkid 2.23.0, 25-Apr-2013)\nUsage:\n blkid -L <label> | -U <uuid>\n\n blkid [-c <file>] [-ghlLv] [-o <format>] [-s <tag>] \n       [-t <token>] [<dev> ...]\n\n blkid -p [-s <tag>] [-O <offset>] [-S <size>] \n       [-o <format>] <dev> ...\n\n blkid -i [-s <tag>] [-o <format>] <dev> ...\n\nOptions:\n -c <file>   read from <file> instead of reading from the default\n               cache file (-c /dev/null means no cache)\n -d          don't encode non-printing characters\n -h          print this usage message and exit\n -g          garbage collect the blkid cache\n -o <format> output format; can be one of:\n               value, device, export or full; (default: full)\n -k          list all known filesystems/RAIDs and exit\n -s <tag>    show specified tag(s) (default show all tags)\n -t <token>  find device with a specific token (NAME=value pair)\n -l          look up only first device with token specified by -t\n -L <label>  convert LABEL to device name\n -U <uuid>   convert UUID to device name\n -V          print version and exit\n <dev>       specify device(s) to probe (default: all devices)\n\nLow-level probing options:\n -p          low-level superblocks probing (bypass cache)\n -i          gather information about I/O limits\n -S <size>   overwrite device size\n -O <offset> probe at the given offset\n -u <list>   filter by \"usage\" (e.g. -u filesystem,raid)\n -n <list>   filter by filesystem type (e.g. -n vfat,ext3)\n\n```\n\n**5. mkfs.xfs命令**\n\n```shell\nUsage: mkfs.xfs\n/* blocksize */\t\t[-b log=n|size=num]\n/* metadata */\t\t[-m crc=0|1,finobt=0|1,uuid=xxx]\n/* data subvol */\t[-d agcount=n,agsize=n,file,name=xxx,size=num,\n\t\t\t    (sunit=value,swidth=value|su=num,sw=num|noalign),\n\t\t\t    sectlog=n|sectsize=num\n/* force overwrite */\t[-f]\n/* inode size */\t[-i log=n|perblock=n|size=num,maxpct=n,attr=0|1|2,\n\t\t\t    projid32bit=0|1]\n/* no discard */\t[-K]\n/* log subvol */\t[-l agnum=n,internal,size=num,logdev=xxx,version=n\n\t\t\t    sunit=value|su=num,sectlog=n|sectsize=num,\n\t\t\t    lazy-count=0|1]\n/* label */\t\t[-L label (maximum 12 characters)]\n/* naming */\t\t[-n log=n|size=num,version=2|ci,ftype=0|1]\n/* no-op info only */\t[-N]\n/* prototype file */\t[-p fname]\n/* quiet */\t\t[-q]\n/* realtime subvol */\t[-r extsize=num,size=num,rtdev=xxx]\n/* sectorsize */\t[-s log=n|size=num]\n/* version */\t\t[-V]\n\t\t\tdevicename\n<devicename> is required unless -d name=xxx is given.\n<num> is xxx (bytes), xxxs (sectors), xxxb (fs blocks), xxxk (xxx KiB),\n      xxxm (xxx MiB), xxxg (xxx GiB), xxxt (xxx TiB) or xxxp (xxx PiB).\n<value> is xxx (512 byte blocks).\n```\n\n**6. mkfs.ext4命令**\n\n```shell\nUsage: mkfs.ext4 [-c|-l filename] [-b block-size] [-C cluster-size]\n\t[-i bytes-per-inode] [-I inode-size] [-J journal-options]\n\t[-G flex-group-size] [-N number-of-inodes]\n\t[-m reserved-blocks-percentage] [-o creator-os]\n\t[-g blocks-per-group] [-L volume-label] [-M last-mounted-directory]\n\t[-O feature[,...]] [-r fs-revision] [-E extended-option[,...]]\n\t[-t fs-type] [-T usage-type ] [-U UUID] [-jnqvDFKSV] device [blocks-count]\n\n```\n\n**7. partprobe命令**\n\n```shell\n# partprobe命令用于重读分区表，当出现删除文件后，出现仍然占用空间。可以partprobe在不重启的情况下重读分区。\n\nUsage: partprobe [OPTION] [DEVICE]...\nInform the operating system about partition table changes.\n\n  -d, --dry-run    do not actually inform the operating system\n  -s, --summary    print a summary of contents\n  -h, --help       display this help and exit\n  -v, --version    output version information and exit\n\nWhen no DEVICE is given, probe all partitions.\n\nReport bugs to <bug-parted@gnu.org>.\n```\n\n","tags":["linux","磁盘"]},{"title":"【随笔】201903","url":"/2019/03/31/【随笔】201903/","content":"\n## 2019-03-28\n\n### 1. Linux常用操作命令\n\n```shell\nsed\nawk\ngrep\nps\nnetstat/ss\nip/ifconfig\ntop\ndf\ncat/more/less/tail/head\nfdisk\nfind\nuname\n```\n\n### 2. 硬链接和软连接\n\n```\n硬链接和软链接的区别\n\n1.原理上：\n\n硬链接(hard link)：文件A是文件B的硬链接，则A的目录项中的inode节点号与B的目录项中的inode节点号相同，即一个inode节点对应两个不同的文件名，两个文件名指向同一个文件，A和B对文件系统来说是完全平等的。如果删除了其中一个，对另外一个没有影响。每增加一个文件名，inode节点上的链接数增加一，每删除一个对应的文件名，inode节点上的链接数减一，直到为0，inode节点和对应的数据块被回收。注：文件和文件名是不同的东西，rm A删除的只是A这个文件名，而A对应的数据块（文件）只有在inode节点链接数减少为0的时候才会被系统回收。\n\n软链接(soft link)：A是B的软链接（A和B都是文件名），A的目录项中的inode节点号与B的目录项中的inode节点号不相同，A和B指向的是两个不同的inode，继而指向两块不同的数据块。但是A的数据块中存放的只是B的路径名（可以根据这个找到B的目录项）。A和B之间是“主从”关系，如果B被删除了，A仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。\n\n2.使用限制上：\n\n硬链接：\na：不能对目录创建硬链接，原因有几种，最重要的是：文件系统不能存在链接环（目录创建时的”..”除外，这个系统可以识别出来）,存在环的后果会导致例如文件遍历等操作的混乱(du，pwd等命令的运作原理就是基于文件硬链接，顺便一提，ls -l结果的第二列也是文件的硬链接数，即inode节点的链接数)\nb：不能对不同的文件系统创建硬链接,即两个文件名要在相同的文件系统下。\nc：不能对不存在的文件创建硬链接，由原理即可知原因。\n\n软链接：\na.可以对目录创建软链接，遍历操作会忽略目录的软链接。\nb:可以跨文件系统\nc:可以对不存在的文件创建软链接，因为放的只是一个字符串，至于这个字符串是不是对于一个实际的文件，就是另外一回事了\n\n3.命令\n\n硬链接：ln 源文件名 链接名\n软链接：ln -s 源文件名 链接名\n\n4.硬链接和软链接的作用\n\n硬链接：\n硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。只删除一个连接并不影响节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。\n\n还有如果把链接名创建为一个以.开头的隐藏文件，还能很好的隐藏自己的隐私（你们懂的..呵呵呵）。\n\n软链接：\n软链接又称之为符号连接（Symbolic Link）。软链接文件类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。\n\n\n```\n\n### 3. 大文件删除后空间未释放\n\n```\n（1）在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。 \n\n查找原因：\n　　/data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。 \n\n解决方案：\n　　1、删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。\n　　2、用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题：\n　　ln -s /opt/newcache /data/cache \n\n（2）现象：删除log后df看空间未释放\n\n解决方案：\n1.rm删除文件后，用lsof | grep XXX 查找使用该文件的进程，kill进程即可立即释放空间。\n2.更好的方法是使用echo \" \">file命令在线清空该文件。\n\nlsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为lsof命令需要访问核心内存和各种文件，所以需要root用户执行。\n```\n\n### 4. 数据库（mysql）的主从复制和双机热备\n\n```shell\n#主从复制处理不同步\nslave\n```\n\n### 5. 数据库最大连接数配置、简单数据库优化\n\n```shell\n#mysql最大连接数\nset GLOBAL max_connections=200\nshow processlist\n\n\n```\n\n### 6. 网络抓包\n\n```shell\n#wireshark\nwireshark使用pcap network library来进行封包捕捉。Lipcap（Linux）或者Winpcap（Windows）。\n因为使用winpcap是直接进行网卡抓包的，所以Wireshark能够捕获到经过网卡的所有包，但是这样也造成在用wireshark对HTTPS包抓取的时候它只能抓到解析前的包数据，一般情况下不能直接解析，当然如果你一定要解析内容页是可以做到的，网上搜索一下也能找到相关的教程。\n#fiddler\nfiddler的实现方式和wireshark不同，它并不对网卡进行监听，而只是以代理web服务器的形式工作。它使用代理地址:127.0.0.1，端口:8888。当Fiddler退出的时候它会自动注销，这样就不会影响别的程序。他的实现方式也解释了为什么使用fiddler进行网络抓包的时候，当某些应用进行没有真实证书的https访问的时候，fiddler会有一个弹出框警示。\n# 路由跟踪\ntracerouter\n```\n\n### 7. vi/vim操作快捷键\n\n```\n1、vi的三种模式\n命令（默认）、编辑、尾行\n\n2、切换到编辑模式的四种方式，编辑模式可以输入任意内容\n　　a 光标向后移动一位\n　　i  当前位置\n　　o 另起新行\n　　s 删除光标所在字符\n　　r 替换光标所在字符\n\n3、尾行模式，用于保存内容、查找替换、设置行号等等功能性操作\n　　:q　　  //quit退出vi编辑器\n　　:w　　 //write保存修改的内容\n　　:wq　　//保存并退出\n　　:q!　　//强制退出，当对文本内容作了修改而不想要保存时\n　　:w!　　//强制保存，当没有文本的写权限时\n　　:set number　　或　　:set nu　　//显示行号\n　　:set nonumber　　或　　:set nonu　　//取消显示行号 \n　　:/内容/　　或　　/内容　　//查找指定内容　　//n将光标移动到下一个目标　　//N上一个\n　　:n　　//跳转到第n行\n　　:s/targetContent/newContent　　//替换当前行第一个targetContent为newContent\n　　:s/targetContent/newContent/g　　//整行相应内容替换\n　　:%s/targetContent/newContent  <==>　:1,$s/word1/word2/g　//整个文本相应内容替换     \n　　:n1,n2s/word1/word2/gc　　　　　　//:100,200s/word1/word2/g   把100行到200行之间的word1替换为word2，并提示是否替换  c->confirm　\n\n4、命令模式\n　　1）光标移动\n　　　　a、字符级\n　　　　　　左（h）　　下（j）　　上（k）　　右（l）\n　　　　b、单词级\n　　　　　　w word移动到下个单词首字母\n　　　　　　b before上个单词首字母\n　　　　　　e end下个单词结尾\n　　　　c、行级\n　　　　　　0 行首\n　　　　　　$ 行尾\n　　　　d、段落级{ 上  } 下(没必要记忆)\n　　　　e、屏幕级 H屏首　　L屏尾(没必要记忆)\n　　　　f、文档级\n　　　　　　G 文档尾部\n　　　　　　nG 文档第n行\n　　　　　　gg 文档第一行\n　　　　　　crtl+f  <--> pagedown向下翻页\n　　　　　　crtl+b <--> pageup向上翻页\n　　　　　　n+enter      向下移动n行\n　　2）内容删除\n　　　　dd　　//删除当前行\n　　　　ndd　　//自当前行向下删除n行\n　　　　x　　//删除当前字符\n　　　　cw　　//删除光标所在字母后面的字符\n　　3）内容复制\n　　　　yy　　//复制光标当前行\n　　　　nyy　　//自当前行复制n行\n　　　　p　　//对（删除）复制的内容进行粘贴\n　　4）相关快捷操作\n　　　　u　　//撤销\n　　　　.　　//重复上次操作\n```\n\n### 8. Django框架使用\n\n```\n中间件（缓存机制mencache Redis）\n高并发，大批量数据访问\n```\n\n### 9. Docker和K8S\n\n```\ncrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。\n容器导出（import/export元数据丢失），镜像导出（save/load保留历史）\n容器生命周期管理\nrun\nstart/stop/restart\nkill\nrm\npause/unpause\ncreate\nexec\n容器操作\nps\ninspect\ntop\nattach\nevents\nlogs\nwait\nexport\nport\n容器rootfs命令\ncommit\ncp\ndiff\n镜像仓库\nlogin\npull\npush\nsearch\n本地镜像管理\nimages\nrmi\ntag\nbuild\nhistory\nsave\nimport\ninfo|version\ninfo\nversion\n```\n\n### 10. Python\n\n```\n多线程、\n方法1：直接使用threading.Thread()\n方法2：继承threading.Thread来自定义线程类，重写run方法\nJoin函数执行顺序是逐个执行每个线程，执行完毕后继续往下执行。主线程结束后，子线程还在运行，join函数使得主线程等到子线程结束时才退出。\n\n多进程、\n方法1：直接使用Process\n方法2：继承Process来自定义进程类，重写run方法\nQueue 是多进程安全的队列，可以实现多进程之间的数据传递。它主要有两个函数,put和get。\n\n协程（yield）\n根据维基百科给出的定义，“协程 是为非抢占式多任务产生子程序的计算机程序组件，协程允许不同入口点在不同位置暂停或开始执行程序”。从技术的角度来说，“协程就是你可以暂停执行的函数”。如果你把它理解成“就像生成器一样”，那么你就想对了。\n\nGIL（全局解释锁）\n\n先到先得\n\n装饰器\n简言之，python装饰器就是用于拓展原来函数功能的一种函数，这个函数的特殊之处在于它的返回值也是一个函数，使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。\n\n类\n\n异常捕获\ntry/except（捕获异常继续运行）\ntry/except/else\ntry/finally（退出try总会执行finally）\ntry/except/finally\nraise（捕获到异常直接退出）\n\n单例模式（实现__new__方法/共享属性/使用__metaclass__（元类））\n```\n\n### 11. Shell\n\n```shell\n\n```\n\n### 12. OpenStack\n\n```\nhorizon\nnova\nneutron\nglance\ncinder\nswift\nkeystone\n\nkvm/qemu\nlibvirt/virsh\nopenvswitch\nvxlan、openflow、SDN、BGP\n```\n\n### 13. 监控Nagios、Zabbix\n\n```\n\n```\n\n### 14. Nginx、Tomcat、Apache\n\n```\n缓存\n代理/反向代理\n负载均衡\n集群\n高可用\n```\n\n### 15. 网络5/7层模型\n\n```\n应用层（表示层，会话层）（ftp/http/https/dhcp）\n传输层（tcp/udp）\n网络层（ip）\n数据链路层（mac）\n物理层（物理连接）\n\n```\n\n### 16. TCP三次握手四次断开\n\n```\n置位概念：根据TCP的包头字段，存在三个重要的标识ACK、SYN、FIN\nACK：表示验证字段\nSYN：位数置为1，表示建立TCP连接\nFIN：位数置为1，表示断开TCP连接\n\n1、TCP与UDP区别总结：\n\n1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接\n2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付\n\nTcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。\n\n3、UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。\n4.每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信\n5、TCP对系统资源要求较多，UDP对系统资源要求较少。\n\n\n2、为什么UDP有时比TCP更有优势?\n\nUDP以其简单、传输快的优势，在越来越多场景下取代了TCP,如实时游戏。\n（1）网速的提升给UDP的稳定性提供可靠网络保障，丢包率很低，如果使用应用层重传，能够确保传输的可靠性。\n（2）TCP为了实现网络通信的可靠性，使用了复杂的拥塞控制算法，建立了繁琐的握手过程，由于TCP内置的系统协议栈中，极难对其进行改进。\n\n采用TCP，一旦发生丢包，TCP会将后续的包缓存起来，等前面的包重传并接收到后再继续发送，延时会越来越大，基于UDP对实时性要求较为严格的情况下，采用自定义重传机制，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成影响。\n\n```\n\n### 17. FTP传输的两种模式\n\n```\nFTP的两种连接方式：PORT模式和PASV模式，中文意思为主动式和被动式。\n\nPORT（主动）模式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。\n工作原理：当需要传送数据时，客户端在命令链路上用 PORT命令告诉服务器：“我打开了**端口，你过来连接我”。当服务端收到这个Port命令后就会向客户端打开的那个端口发送连接请求，建立一条数据链路来传送数据。\n\nPASV（被动）模式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。\n工作原理：需要传送数据时，服务器在命令链路上用 PASV命令告诉客户端：“我打开了**端口，你过来连接我”。当客户端收到这个信息后，就可以向服务端的端口发送连接请求，建立一条数据链路来传送数据。\n\nFTP的两种传输方式：ASCII 和 BINARY\n\nASCII模式和Binary模式的区别是回车换行的处理，Binary模式不对数据进行任何处理，ASCII模式将回车换行转换为本机的回车字符，比如：UNIX下是\\n,Windows下是\\r\\n，Mac下是\\r。\nASCII模式下会转换文件，不能说是不同系统对回车换行解释不同，而是不同的系统有不同的行结束符。UNIX系统下行结束符是一个字节，即十六进制的0A，而Windows的系统是两个字节，即十六进制的0D0A，所以当你用ASCII方式从UNIX的FTP Server下载文件到Windows系统上时(不管是二进制或者文本文件)，每检测到一个字节是0A，就会自动插入一个0D，所以如果你的文件是二进制文件，比如可执行文件、压缩包什么的，就肯定不能用了。如果你的文件就是UNIX下的文本文件，你用ASCII模式是正确的，要是误用了Binary模式，你在Windows上看这个文件是没有换行的，里面是一个个的黑方块。\n一般来说，我们最好都用Binary方式，这样可以保证不出错。如果有文本格式转换的问题，即UNIX格式的文本和DOS格式的文本之间的转换，有很多工具可以做的，不要在ftp传输的时候冒险，尤其是你如果对这些东西不是非常清楚的话。\n\n如何设置FTP的传输方式呢？\n在ftp>提示符下输入ascii即转换到ACSII方式，输入bin，即转换到Binary方式.\nftp> ascii\n200 Type set to A.\n\nftp> bin\n200 Type set to I.\n\n```\n\n### 18. Ansible\n\n```\nansible 常用模块\n1）主机连通性测试\n2）command 模块\n3）shell 模块\n4）copy 模块\n5）file 模块\n6）fetch 模块\n7）cron 模块\n8）yum 模块\n9）service 模块\n10）user 模块\n11）group 模块\n12）script 模块\n13）setup 模块\n```\n\n### 19. 存储相关\n\n```\nlvm\nceph\nfastDFS\n```\n\n\n\n## 2019-03-26\n\n### 一、NAS存储特点（Network Attached Storage 网络直连存储)\n\nNAS(网络附加存储)方式则全面改进了以前低效的DAS存储方式。它采用独立于服务器，单独为网络数据存储而开发的一种文件服务器来连接所存储设备，自形成一个网络。这样数据存储就不再是服务器的附属，而是作为独立网络节点而存在于网络之中，可由所有的网络用户共享。\n\n同时NAS存储真正做到了即插即用，并且部署起来也相对灵活，再加上管理成本低，是目前企业选择较多的，但它同时也有存储性能低和可靠度不高等缺点。\n\n### 二、DAS存储特点（Direct-attached Storage 直连存储）\n\nDAS这种存储方式与我们普通的PC存储架构一样，外部存储设备都是直接挂接在服务器内部总线上，数据存储设备是整个服务器结构的一部份，DAS存储方式主要适用于小型网络、地理位置分散的网络和特殊服务器上。\n\nDAS已经存在了很长时间，并且在很多情况下仍然是一种不错的存储选择。由于这种存储方式在磁盘系统和服务器之间具有很快的传输速率，因此，虽然在一些部门中一些新的SAN设备已经开始取代DAS，但是在要求快速磁盘访问的情况下，DAS仍然是一种理想的选择。更进一步地，在DAS环境中，运转大多数的应用程序都不会存在问题，所以你没有必要担心应用程序问题，从而可以将注意力集中于其他可能会导致问题的领域。\n\n### 三、SAN存储（Storage Area Networking 光纤存储）\n\nSAN存储是基于光纤介质，最大传输速率达17MB/s的服务器访问存储器的一种连接方式，同时SAN也是最昂贵和最复杂的存储选项，SAN存储方式创造了存储的网络化，存储网络化顺应了计算机服务器体系结构网络化的趋势，SAN的支撑技术是光纤通道(FC Fiber Channel)技术，它是ANSI为网络和通道I/O接口建立的一个标准集成，FC技术支持HIPPI、IPI、SCSI、IP、ATM等多种高级协议，其最大特性是将网络和设备的通信协议与传输物理介质隔离开，这样多种协议可在同一个物理连接上同时传送。\n\n如今的SAN解决方案通常会采取以下两种形式：光纤信道以及iSCSI或者基于IP的SAN。光纤信道是SAN解决方案中大家最熟悉的类型，但是，最近一段时间以来，基于iSCSI的SAN解决方案开始大量出现在市场上，与光纤通道技术相比较而言，这种技术具有良好的性能，而且价格低廉。\n\nSAN真正的综合了DAS和NAS两种存储解决方案的优势。例如，在一个很好的SAN解决方案实现中，你可以得到一个完全冗余的存储网络，这个存储网络具有不同寻常的扩展性，确切地说，你可以得到只有NAS存储解决方案才能得到的几百T字节的存储空间，但是你还可以得到块级数据访问功能，而这些功能只能在DAS解决方案中才能得到。对于数据访问来说，你还可以得到一个合理的速度，对于那些要求大量磁盘访问的操作来说，SAN显得具有更好的性能。利用SAN解决方案，你还可以实现存储的集中管理，从而能够充分利用那些处于空闲状态的空间。更有优势的一点是，在某些实现中，你甚至可以将服务器配置为没有内部存储空间的服务器，要求所有的系统都直接从SAN（只能在光纤通道模式下实现）引导。这也是一种即插即用技术。\n\nSAN确实具有这些伟大的优点，那么，SAN的缺陷在哪里？SAN有两个较大的缺陷：成本和复杂性，特别是在光纤信道中这些缺陷尤其明显。使用光纤信道的情况下，合理的成本大约是1TB或者2TB大概需要五万到六万美金。从另一个角度来看，虽然新推出的基于iSCSI的SAN解决方案大约只需要两万到三万美金，但是其性能却无法和光纤信道相比较。在价格上的差别主要是由于iSCSI技术使用的是现在已经大量生产的吉比特以太网硬件，而光纤通道技术要求特定的价格昂贵的设备。\n\n### DAS、NAS和SAN存储的主要区别\n\n从连接方式上对比，DAS采用了存储设备直接连接应用服务器，具有一定的灵活性和限制性；NAS通过网络（TCP/IP,ATM,FDDI）技术连接存储设备和应用服务器，存储设备位置灵活，随着万兆网的出现，传输速率有了很大的提高；SAN则是通过光纤通道（Fibre Channel）技术连接存储设备和应用服务器，具有很好的传输速率和扩展性能。三种存储方式各有优势，相互共存，占到了现在磁盘存储市场的70%以上。\n\n通过这个图表，大家可以一目了然的了解NAS、DAS和SAN存储的区别，在这个图表中，SAN分成iSCSI和光纤通道两种类型，以帮助你区分这两种技术的不同。\n\n| **存储类型**         | **DAS**          | **NAS**                                  | **iSCSI/IP SANs**                                            | **光纤通道**                                                 |\n| -------------------- | ---------------- | ---------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 价格                 | 价格较低         | 价格中等                                 | 价格中等到较高                                               | 价格较高                                                     |\n| 可扩展性             | 非常有限         | 依赖于解决方案                           | 依赖于解决方案                                               | 依赖于解决方案                                               |\n| 可管理性             | 效率较低         | 效率较低                                 | 非常高效                                                     | 非常高效                                                     |\n| 容错性               | 一定程度的容错性 | 一定程度的容错性                         | 容错性很好                                                   | 容错性很好                                                   |\n| 是否适合文件存储     | 是               | 是                                       | 是                                                           | 是                                                           |\n| 是否适合数据库存储   | 是               | 否                                       | 通常适合                                                     | 是                                                           |\n| 是否适合网页服务     | 是               | 是                                       | 是                                                           | 是                                                           |\n| 是否适合Exchange存储 | 是               | 否                                       | 通常适合                                                     | 是                                                           |\n| 安装的简易性         | 简单             | 简单                                     | 有一定的困难                                                 | 非常困难                                                     |\n| 灾难恢复的能力       | 没有             | 没有                                     | 很多                                                         | 很多                                                         |\n| 操作系统的支持       | 全部             | N/A                                      | Windows, Linux, UNIX, NetWare （其他系统是否支持依赖于驱动器本身） | Windows, Linux, UNIX, NetWare（其他系统是否支持依赖于驱动器本身） |\n| 主要提供商           | 任何服务器提供商 | Huawei、IBM, Dell, HP, Network Appliance | Huawei、LeftHand, EMC, HP, IBM, Network，Appliance           | Huawei、IBM, EMC, HP, Network Appliance                      |\n\n","tags":["随笔","201903","面试"]},{"title":"【redis】Redis绿色部署","url":"/2019/03/22/【redis】Redis绿色部署/","content":"\n## Linux 下安装\n\n**下载地址：**<http://redis.io/download>，下载最新稳定版本。\n\n```\n$ wget http://download.redis.io/releases/redis-5.0.5.tar.gz\n$ tar xzf redis-5.0.5.tar.gz\n$ cd redis-5.0.5\n$ make\n```\n\nmake完后 redis-5.0.5目录下会出现编译后的redis服务程序redis-server，还有用于测试的客户端程序redis-cli，两个程序位于安装目录 src 目录下：\n\n下面启动redis服务。\n\n```\n$ cd src\n$ ./redis-server\n```\n\n注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。\n\n```\n$ cd src\n$ ./redis-server ../redis.conf\n```\n\n**redis.conf** 是一个默认的配置文件。我们可以根据需要使用自己的配置文件。\n\n启动redis服务进程后，就可以使用测试客户端程序redis-cli和redis服务交互了。 比如：\n\n```\n$ cd src\n$ ./redis-cli\nredis> set foo bar\nOK\nredis> get foo\n\"bar\"\n```\n\n\n\n## redis绿色安装\n\n### 安装到指定目录\n\n```\n# 安装到 /usr/local/redis\n\ninstallpath=/usr/local/redis\nmkdir -p $installpath\ncd redis-5.0.5\nmake MALLOC=libc\nmake PREFIX=$installpath install\n\\cp -f redis.conf $installpath\n```\n\n### 功能测试（耗时较长，非必须执行）\n\n```\n在安装成功之后，可以运行测试，确认Redis的功能是否正常\n[root@localhost ~]# make test\n\n出现报错：\nhadoop@stormspark:~/workspace/redis2.6.13/src$ make test\nYou need tcl 8.5 or newer in order to run the Redis test\nmake: *** [test] Error 1\n\n解决方式\nyum install -y tcl\n\n重新执行测试\n[root@localhost ~]# make test\n\n......\n\n\\o/ All tests passed without errors!\n\nCleanup: may take some time... OK\n\n```\n\n### 修改配置文件\n\n```\ninstallpath=/usr/local/redis\nsed -i '/^bind/c#bind 127.0.0.1' \"$installpath/redis.conf\"\nsed -i '/^protected-mode/cprotected-mode no' \"$installpath/redis.conf\"\nsed -i '/^logfile/clogfile \"'$installpath'/redis.log\"' \"$installpath/redis.conf\"\nsed -i '/^pidfile/cpidfile \"'$installpath'/redis.pid\"' \"$installpath/redis.conf\"\n```\n\n### 编写Redis启停脚本\n\n```\n[root@localhost ~]# vi /usr/local/redis/redis.sh\n\n#!/bin/sh\n#Configurations injected by install_server below....\n\nEXEC=/usr/local/redis/bin/redis-server\nCLIEXEC=/usr/local/redis/bin/redis-cli\nPIDFILE=/usr/local/redis/redis.pid\nCONF=\"/usr/local/redis/redis.conf\"\nREDISPORT=\"6379\"\n###############\n# SysV Init Information\n# chkconfig: - 58 74\n# description: redis_6379 is the redis daemon.\n### BEGIN INIT INFO\n# Provides: redis_6379\n# Required-Start: $network $local_fs $remote_fs\n# Required-Stop: $network $local_fs $remote_fs\n# Default-Start: 2 3 4 5\n# Default-Stop: 0 1 6\n# Should-Start: $syslog $named\n# Should-Stop: $syslog $named\n# Short-Description: start and stop redis_6379\n# Description: Redis daemon\n### END INIT INFO\n\n\ncase \"$1\" in\n    start)\n        if [ -f $PIDFILE ]\n        then\n            echo \"$PIDFILE exists, process is already running or crashed\"\n        else\n            echo \"Starting Redis server...\"\n            $EXEC $CONF\n        fi\n        ;;\n    stop)\n        if [ ! -f $PIDFILE ]\n        then\n            echo \"$PIDFILE does not exist, process is not running\"\n        else\n            PID=$(cat $PIDFILE)\n            echo \"Stopping ...\"\n            $CLIEXEC -p $REDISPORT shutdown\n            while [ -x /proc/${PID} ]\n            do\n                echo \"Waiting for Redis to shutdown ...\"\n                sleep 1\n            done\n            echo \"Redis stopped\"\n        fi\n        ;;\n    status)\n        PID=$(cat $PIDFILE)\n        if [ ! -x /proc/${PID} ]\n        then\n            echo 'Redis is not running'\n        else\n            echo \"Redis is running ($PID)\"\n        fi\n        ;;\n    restart)\n        $0 stop\n        $0 start\n        ;;\n    *)\n        echo \"Please use start, stop, restart or status as first argument\"\n        ;;\nesac\n\n[root@localhost ~]# chmod u+x /usr/local/redis/redis.sh\n```\n\n### 使用redis 用户以systemd 服务启动\n\n```\n编写systemd服务\n[root@localhost ~]# vi /usr/local/redis/redis.service\n\n-----------------------------------------\n[Unit]\nDescription=redis server\n\n[Service]\nUser=redis\nWorkingDirectory=/usr/local/redis\nExecStart=/usr/bin/sh redis.sh start\nExecStop=/usr/bin/sh redis.sh stop\n\n[Install]\nWantedBy=multi-user.target\n-----------------------------------------\n[Unit]\nDescription=redis server\n\n[Service]\nUser=redis\nWorkingDirectory=/usr/local/redis\nExecStart=/usr/local/redis/bin/redis-server redis.conf\n\n[Install]\nWantedBy=multi-user.target\n-----------------------------------------\n\n放置服务文件\n[root@localhost ~]# \\cp -f /usr/local/redis/redis.service /usr/lib/systemd/system/redis.service\n\n创建redis用户\n[root@localhost ~]# useradd -r -s /bin/false redis\n\n修改文件所属\n[root@localhost ~]# chown -R redis.redis /usr/local/redis\n\n启动并设置开机自启\n[root@localhost ~]# systemctl start redis\n[root@localhost ~]# systemctl enable redis\n```\n\n### 防火墙配置\n\n```\nsudo firewall-cmd --permanent --add-port=6379/tcp\nsudo firewall-cmd --reload\n```","tags":["redis"]},{"title":"【keepalived】Keepalived配置及示例","url":"/2019/03/21/【keepalived】Keepalived配置及示例/","content":"\n### keepalived 简介\n\nKeepalived的作用是检测服务器的状态，如果有一台web服务器宕机，或工作出现故障，Keepalived将检测到，并将有故障的服务器从系统中剔除，同时使用其他服务器代替该服务器的工作，当服务器工作正常后Keepalived自动将服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的服务器。\n\n### keepalived 源码下载地址\n\n[keepalived software](https://www.keepalived.org/software/)\n\n### keepalived 官网\n\n[Keepalived for Linux](https://www.keepalived.org/index.html)\n\n### MySQL、Redis、ActiveMQ 高可用简单配置\n\n```\n[root@localhost keepalived]# vi keepalived.conf\n\n! Configuration File for keepalived\nglobal_defs {\n   #notification_email {\n        #aaa@email.com\n   #}\n   #notification_email_from keepalived@email.com\n   #smtp_server 127.0.0.1\n   #smtp_connect_timeout 30\n}\n\nvrrp_track_process mysql {\n  process \"mysqld\"\n}\nvrrp_instance mysql {\n    state BACKUP\n    nopreempt\n    interface ens160\n    virtual_router_id 61\n    track_process{\n\t\tmysql\n    }\n    virtual_ipaddress {\n        192.168.1.2\n    }\n}\n\nvrrp_track_process redis {\n  process \"redis-server\"\n}\nvrrp_instance redis {\n    state BACKUP\n    nopreempt\n    interface ens160\n    virtual_router_id 62\n    track_process{\n\t\tredis\n    }\n    virtual_ipaddress {\n        192.168.1.3\n    }\n    notify_master \"/home/admin/redis/bin/redis-cli slaveof no one\"\n    notify_backup \"/home/admin/redis/bin/redis-cli slaveof 192.168.1.191 6379\"\n}\n\nvrrp_script activemq {\n  script \"/bin/activemq status\"\n}\nvrrp_instance activemq {\n    state BACKUP\n    nopreempt\n    interface ens160\n    virtual_router_id 63\n    track_script{\n\t\tactivemq\n    }\n    virtual_ipaddress {\n        192.168.1.4\n    }\n}\n\n```\n\n### keepalived 配置手册\n\n```\nkeepalived.conf(5)     Keepalived Configuration's Manual    keepalived.conf(5)\n\n\nNAME\n       keepalived.conf - configuration file for Keepalived\n\nDESCRIPTION\n       keepalived.conf   is   the  configuration  file  which\n       describes all the Keepalived keywords. Keywords are placed  in  hierar-\n       chies  of  blocks  and subblocks, each layer being delimited by '{' and\n       '}' pairs.\n\n       Comments start with '#' or '!' to the end of the  line  and  can  start\n       anywhere in a line.\n\n       The  keyword  'include'  allows  inclusion of other configuration files\n       from within the main configuration file, or from subsequently  included\n       files.\n\n       The format of the include directive is:\n\n       include FILENAME\n\n       FILENAME can be a fully qualified or relative pathname, and can include\n       wildcards,   including   csh   style   brace   expressions   such    as\n       \"{foo/{,cat,dog},bar}\" if glob() supports them.\n\n       After  opening  an  included  file, the current directory is set to the\n       directory of the file itself, so any relative  paths  included  from  a\n       file are relative to the directory of the including file itself.\n\n       Note:  This  documentation  MUST  be considered as THE\n       exhaustive source of information in order to configure Keepalived. This\n       documenation is supported and maintained by Keepalived Core-Team.\n\nPARAMETER SYNTAX\n       <BOOL> is one of on|off|true|false|yes|no\n       <TIMER>  is  a  time value in seconds, including\n       fractional seconds, e.g. 2.71828 or 3; resolution of  timer  is  micro-\n       seconds.\n\nSCRIPTS\n       There are three classes of scripts can be configured to be executed.\n\n       (a)  Notify  scripts  that  are  run when a vrrp instance or vrrp group\n       changes state, or a virtual server quorum changes between up and down.\n\n       (b) vrrp tracking scripts that will cause vrrp instances to go down  it\n       they exit a non-zero exist status, or if a weight is specified will add\n       or subtract the weight to/from the priority of that vrrp instance.\n\n       (c) LVS checker misc scripts that will cause a real server to  be  con-\n       figured down if they exit with a non-zero status.\n\n       By  default  the  scripts will be executed by user keepalived_script if\n       that user exists, or if not by root, but for each script the user/group\n       under which it is to be executed can be specified.\n\n       There  are  significant  security  implications if scripts are executed\n       with root privileges, especially if the scripts themselves are  modifi-\n       able  or  replaceable by a non root user. Consequently, security checks\n       are made at startup to ensure that if a script  is  executed  by  root,\n       then it cannot be modified or replaced by a non root user.\n\n       All scripts should be written so that they will terminate on receipt of\n       a SIGTERM signal. Scripts will be sent SIGTERM if their  parent  termi-\n       nates, or it is a script the keepalived is awaiting its exit status and\n       it has run for too long.\n\nQuoted strings\n       Quoted strings are specified between \" characters; more specifically  a\n       string  will  only  end  after  a  quoted string if there is whitespace\n       afterwards. For example:\n              \"abcd\" efg h jkl \"mnop\"\n       will be the single string \"abcd efg h jkl mnop\", i.e.  the  embedded  \"\n       characters are removed.\n\n       Quoted  strings  can  also have escaped characters, like the shell. \\a,\n       \\b, \\E, \\f, \\n, \\r, \\t, \\v, \\nnn and \\xXX (where nnn is up to  3  octal\n       digits,  and  XX is any sequence of hex digits) and \\cC (which produces\n       the control version of character C) are all supported. \\C for any other\n       character C is just treated as an escaped version of character C, so \\\\\n       is a \\ character and \\\" will be a \" character, but it  won't  start  or\n       terminate a quoted string.\n\n       For  specifying  scripts with parameters, unquoted spaces will separate\n       the parameters.  If it is required for a parameter to contain a  space,\n       it should be enclosed in single quotes (').\n\n\nCONFIGURATION PARSER\n       Traditionally  the  configuration  file  parser has not been one of the\n       strengths of keepalived. Lot of efforts have been put to  correct  this\n       even if this is not the primal goal of the project.\n\nTOP HIERACHY\n       Keepalived configuration file is articulated around a set of configura-\n       tion blocks.  Each block is focusing and targetting a  specific  daemon\n       family feature. These features are:\n\n       GLOBAL CONFIGURATION\n\n       BFD CONFIGURATION\n\n       VRRPD CONFIGURATION\n\n       LVS CONFIGURATION\n\nGLOBAL CONFIGURATION\n       contains  subblocks of Global definitions, Linkbeat interfaces,\n       Static track groups,  Static  addresses,  Static  routes,  and\n       Static rules\n\nGlobal definitions\n       # Following are global daemon facilities for running\n       # keepalived in a separate network namespace:\n       # --\n       # Set the network namespace to run in.\n       # The directory /var/run/keepalived will be created as an\n       # unshared mount point, for example for pid files.\n       # syslog entries will have _NAME appended to the ident.\n       # Note: the namespace cannot be changed on a configuration reload.\n       net_namespace NAME\n\n       # ipsets wasn't network namespace aware until Linux 3.13, and so\n       # if running with # an earlier version of the kernel, by default\n       # use of ipsets is disabled if using a namespace and vrrp_ipsets\n       # has not been specified. This options overrides the default and\n       # allows ipsets to be used with a namespace on kernels prior to 3.13.\n       namespace_with_ipsets\n\n       # If multiple instances of keepalived are run in the same namespace,\n       # this will create pid files with NAME as part of the file names,\n       # in /var/run/keepalived.\n       # Note: the instance name cannot be changed on a configuration reload\n       instance NAME\n\n       # Create pid files in /var/run/keepalived\n       use_pid_dir\n\n       # Poll to detect media link failure using ETHTOOL, MII or ioctl interface\n       # otherwise uses netlink interface.\n       linkbeat_use_polling\n\n       # Time for main process to allow for child processes to exit on termination\n       # in seconds. This can be needed for very large configurations.\n       # (default: 5)\n       child_wait_time SECS\n\n       # Global definitions configuration block\n       global_defs {\n           # Set the process names of the keepalived processes to the default values:\n           #   keepalived, keepalived_vrrp, keepalived_ipvs, keepalived_bfd\n           process_names\n\n           # Specify the individual process names\n\t   process_name NAME\n\t   vrrp_process_name NAME\n\t   ipvs_process_name NAME\n\t   bfd_process_name NAME\n\n           # Set of email To: notify\n           notification_email {\n               admin@example1.com\n               ...\n           }\n\n           # email from address that will be in the header\n           # (default: keepalived@<local host name>)\n           notification_email_from admin@example.com\n\n           # Remote SMTP server used to send notification email.\n           # IP address or domain name with optional port number.\n           # (default port number: 25)\n           smtp_server 127.0.0.1 [<PORT>]\n\n           # Name to use in HELO messages.\n           # (default: local host name)\n           smtp_helo_name <STRING>\n\n           # SMTP server connection timeout in seconds.\n           smtp_connect_timeout 30\n\n           # Sets default state for all smtp_alerts\n           smtp_alert <BOOL>\n\n           # Sets default state for vrrp smtp_alerts\n           smtp_alert_vrrp <BOOL>\n\n           # Sets default state for checker smtp_alerts\n           smtp_alert_checker <BOOL>\n\n           # Sets logging all checker failes while checker up\n           checker_log_all_failures <BOOL>\n\n\t   # If set, keepalived only removes virtual servers at shutdown\n\t   #  (the kernel will remove the real servers). This is faster\n\t   #  for large configurations.\n\t   checker_shutdown_vs_only\n\n           # Don't send smtp alerts for fault conditions\n           no_email_faults\n\n           # String identifying the machine (doesn't have to be hostname).\n           # (default: local host name)\n           router_id <STRING>\n\n           # Multicast Group to use for IPv4 VRRP adverts\n           # (default: 224.0.0.18)\n           vrrp_mcast_group4 224.0.0.18\n\n           # Multicast Group to use for IPv6 VRRP adverts\n           # (default: ff02::12)\n           vrrp_mcast_group6 ff02::12\n\n           # sets the default interface for static addresses.\n           # (default: eth0)\n           default_interface p33p1.3\n\n           # Sync daemon as provided by IPVS kernel code only support\n           # a single daemon instance at a time to synchronize connection table.\n           # Binding interface, vrrp instance and optional\n           #  syncid for lvs syncd\n           #  syncid (0 to 255) for lvs syncd\n           #  maxlen (1..65507) maximum packet length\n           #  port (1..65535) UDP port number to use\n           #  ttl (1..255)\n           #  group - multicast group address (IPv4 or IPv6)\n           # NOTE: maxlen, port, ttl and group are only available on Linux 4.3 or later.\n           lvs_sync_daemon <INTERFACE> <VRRP_INSTANCE> [id <SYNC_ID>] [maxlen <LEN>] \\\n                           [port <PORT>] [ttl <TTL>] [group <IP ADDR>]\n\n           # flush any existing LVS configuration at startup\n           lvs_flush\n\n           # flush remaining LVS configuration at shutdown\n\t   lvs_flush_onstop\n\n           # delay for second set of gratuitous ARPs after transition to MASTER.\n           # in seconds, 0 for no second set.\n           # (default: 5)\n           vrrp_garp_master_delay 10\n\n           # number of gratuitous ARP messages to send at a time after\n           # transition to MASTER.\n           # (default: 5)\n           vrrp_garp_master_repeat 1\n\n           # delay for second set of gratuitous ARPs after lower priority\n           # advert received when MASTER.\n           vrrp_garp_lower_prio_delay 10\n\n           # number of gratuitous ARP messages to send at a time after\n           # lower priority advert received when MASTER.\n           vrrp_garp_lower_prio_repeat 1\n\n           # minimum time interval for refreshing gratuitous ARPs while MASTER.\n           # in seconds.\n           # (default: 0 (no refreshing))\n           vrrp_garp_master_refresh 60\n\n           # number of gratuitous ARP messages to send at a time while MASTER\n           # (default: 1)\n           vrrp_garp_master_refresh_repeat 2\n\n           # Delay in ms between gratuitous ARP messages sent on an interface\n           # decimal, seconds (resolution usecs).\n           # (default: 0)\n           vrrp_garp_interval 0.001\n\n           # Delay in ms between unsolicited NA messages sent on an interface\n           # decimal, seconds (resolution usecs).\n           # (default: 0)\n           vrrp_gna_interval 0.000001\n\n           # By default keepalived sends 5 gratuitions ARP/NA messages at a\n           # time, and after transitioning to MASTER sends a second block of\n           # 5 messages 5 seconds later.\n           # With modern switches this is unnecessary, so setting vrrp_min_garp\n           # causes only one ARP/NA message to be sent, with no repeat 5 seconds\n           # later.\n           vrrp_min_garp [<BOOL>]\n\n           # If a lower priority advert is received, don't send another advert.\n           # This causes adherence to the RFCs. Defaults to false, unless\n           # strict_mode is set.\n           vrrp_lower_prio_no_advert [<BOOL>]\n\n           # If we are master and receive a higher priority advert, send an advert\n           # (which will be lower priority than the other master), before we\n           # transition to backup. This means that if the other master has\n           # garp_lower_priority_repeat set, it will resend garp messages.\n           # This is to get around the problem of their having been two simultaneous\n           # masters, and the last GARP messages seen were from us.\n           vrrp_higher_prio_send_advert [<BOOL>]\n\n           # Set the default VRRP version to use\n           # (default: 2 , but IPv6 instances will use version 3)\n           vrrp_version <2 or 3>\n\n           # Specify the iptables chain for ensuring a version 3 instance\n           # doesn't respond on addresses that it doesn't own.\n           # Note: it is necessary for the specified chain to exist in\n           # the iptables and/or ip6tables configuration, and for the chain\n           # to be called from an appropriate point in the iptables configuration.\n           # It will probably be necessary to have this filtering after accepting\n           # any ESTABLISHED,RELATED packets, because IPv4 might select the VIP as\n           # the source address for outgoing connections.\n           # (default: INPUT)\n           vrrp_iptables keepalived\n\n           # Use nftables to implement no_accept mode.\n           #   TABLENAME must not exist, and must be different for each\n           #   instance of keepalived running in the same network namespace.\n           #   Default tablename is keepalived, and priority is -1.\n           #   keepalived will create base chains in the table.\n           #   counters means counters are added to the rules (primarily for\n           #   debugging purposes).\n           #   ifindex means create IPv6 link local sets using ifindex rather\n           #   than ifnames. This is the default unless the vrrp_instance has\n           #   set dont_track_primary. The alternative is to use interface names\n           #   as part of the set key, but nftables prior to v0.8.3 will then no\n           #   longer work.\n           nftables [TABLENAME]\n           nftables_priority PRIORITY\n           nftables_counters\n           nftables_ifindex\n\n           # or for outbound filtering as well\n           # Note, outbound filtering won't work with IPv4, since the VIP can be\n           # selected as the source address for an outgoing connection. With IPv6\n           # this is unlikely since the addresses are deprecated.\n           vrrp_iptables keepalived_in keepalived_out\n\n           # or to not add any iptables rules:\n           vrrp_iptables\n\n           # Keepalived may have the option to use ipsets in conjunction with\n           # iptables. If so, then the ipset names can be specified, defaults\n           # as below. If no names are specified, ipsets will not be used,\n           # otherwise any omitted names will be constructed by adding \"_if\"\n           # and/or \"6\" to previously specified names.\n           vrrp_ipsets [keepalived [keepalived6 [keepalived_if6]]]\n\n           # The following enables checking that when in unicast mode, the\n           # source address of a VRRP packet is one of our unicast peers.\n           vrrp_check_unicast_src\n\n           # Checking all the addresses in a received VRRP advert can be time\n           # consuming. Setting this flag means the check won't be carried out\n           # if the advert is from the same master router as the previous advert\n           # received.\n           # (default: don't skip)\n           vrrp_skip_check_adv_addr\n\n           # Enforce strict VRRP protocol compliance. This will prohibit:\n           #   0 VIPs\n           #   unicast peers\n           #   IPv6 addresses in VRRP version 2\n           vrrp_strict\n\n\t   # Send vrrp instance priority notifications on notify FIFOs.\n\t   vrrp_notify_priority_changes <BOOL>\n\n           # The following options can be used if vrrp or checker processes\n           # are timing out. This can be seen by a backup vrrp instance becoming\n           # master even when the master is still running because the master or\n           # backup system is too busy to process vrrp packets.\n           # --\n           # Set the vrrp child process priority (Negative values increase priority)\n           vrrp_priority <-20 to 19>\n\n           # Set the checker child process priority\n           checker_priority <-20 to 19>\n\n           # Set the BFD child process priority\n           bfd_priority <-20 to 19>\n\n           # Set the vrrp child process non swappable\n           vrrp_no_swap\n\n           # Set the checker child process non swappable\n           checker_no_swap\n\n           # Set the BFD child process non swappable\n           bfd_no_swap\n\n           # Set the vrrp child process to use real-time scheduling\n           # at the specified priority\n           vrrp_rt_priority <1..99>\n\n           # Set the checker child process to use real-time scheduling\n           # at the specified priority\n           checker_rt_priority <1..99>\n\n           # Set the BFD child process to use real-time scheduling\n           # at the specified  priority\n           bfd_rt_priority <1..99>\n\n           # Set the limit on CPU time between blocking system calls,\n           # in microseconds\n           # (default: 1000)\n           vrrp_rlimit_rtime >=1\n           checker_rlimit_rtime >=1\n           bfd_rlimit_rtime >=1\n\n           # If Keepalived has been build with SNMP support, the following\n           # keywords are available.\n           # Note: Keepalived, checker and RFC support can be individually\n           # enabled/disabled\n           # --\n           # Specify socket to use for connecting to SNMP master agent\n           # (see source module keepalived/vrrp/vrrp_snmp.c for more details)\n           # (default: unix:/var/agentx/master)\n           snmp_socket udp:1.2.3.4:705\n\n           # enable SNMP handling of vrrp element of KEEPALIVED MIB\n           enable_snmp_vrrp\n\n           # enable SNMP handling of checker element of KEEPALIVED MIB\n           enable_snmp_checker\n\n           # enable SNMP handling of RFC2787 and RFC6527 VRRP MIBs\n           enable_snmp_rfc\n\n           # enable SNMP handling of RFC2787 VRRP MIB\n           enable_snmp_rfcv2\n\n           # enable SNMP handling of RFC6527 VRRP MIB\n           enable_snmp_rfcv3\n\n           # enable SNMP traps\n           enable_traps\n\n           # If Keepalived has been build with DBus support, the following\n           # keywords are available.\n           # --\n           # Enable the DBus interface\n           enable_dbus\n\n           # Name of DBus service\n           # Useful if you want to run multiple keepalived processes with DBus enabled\n           # (default: org.keepalived.Vrrp1)\n           dbus_service_name SERVICE_NAME\n\n           # Specify the default username/groupname to run scripts under.\n           # If this option is not specified, the user defaults to keepalived_script\n           # if that user exists, otherwise root.\n           # If groupname is not specified, it defaults to the user's group.\n           script_user username [groupname]\n\n           # Don't run scripts configured to be run as root if any part of the path\n           # is writable by a non-root user.\n           enable_script_security\n\n           # Rather than using notify scripts, specifying a fifo allows more\n           # efficient processing of notify events, and guarantees that they\n           # will be delivered in the correct sequence.\n           # NOTE: the FIFO names must all be different\n           # --\n           # FIFO to write notify events to\n           # See vrrp_notify_fifo and lvs_notify_fifo for format of output\n\t   # For further details, see the description under vrrp_sync_group.\n\t   # see doc/samples/sample_notify_fifo.sh for sample usage.\n           notify_fifo FIFO_NAME [username [groupname]]\n\n           # script to be run by keepalived to process notify events\n           # The FIFO name will be passed to the script as the last parameter\n           notify_fifo_script STRING|QUOTED_STRING [username [groupname]]\n\n           # FIFO to write vrrp notify events to.\n           # The string written will be a line of the form: INSTANCE \"VI_1\" MASTER 100\n           # and will be terminated with a new line character.\n           # For further details of the output, see the description under vrrp_sync_group\n           # and doc/samples/sample_notify_fifo.sh for sample usage.\n           vrrp_notify_fifo FIFO_NAME [username [groupname]]\n\n           # script to be run by keepalived to process vrrp notify events\n           # The FIFO name will be passed to the script as the last parameter\n           vrrp_notify_fifo_script STRING|QUOTED_STRING [username [groupname]]\n\n           # FIFO to write notify healthchecker events to\n           # The string written will be a line of the form:\n           # VS [192.168.201.15]:tcp:80 {UP|DOWN}\n           # RS [1.2.3.4]:tcp:80 [192.168.201.15]:tcp:80 {UP|DOWN}\n           # and will be terminated with a new line character.\n           lvs_notify_fifo FIFO_NAME [username [groupname]]\n\n           # script to be run by keepalived to process healthchecher notify events\n           # The FIFO name will be passed to the script as the last parameter\n           lvs_notify_fifo_script STRING|QUOTED_STRING [username [groupname]]\n\n           # Allow configuration to include interfaces that don't exist at startup.\n           # This allows keepalived to work with interfaces that may be deleted and restored\n           #   and also allows virtual and static routes and rules on VMAC interfaces.\n           #   allow_if_changes allows an interface to be deleted and recreated with a\n           #   different type or underlying interface, eg changing from vlan to macvlan\n           #   or changing a macvlan from eth1 to eth2. This is predominantly used for\n           #   reporting duplicate VRID errors at startup if allow_if_changes is not set.\n           dynamic_interfaces [allow_if_changes]\n\n           # The following options are only needed for large configurations, where either\n           # keepalived creates a large number of interface, or the system has a large\n           # number of interface. These options only need using if\n           # \"Netlink: Receive buffer overrun\" messages are seen in the system logs.\n           # If the buffer size needed exceeds the value in /proc/sys/net/core/rmem_max\n           #  the corresponding force option will need to be set.\n           # --\n           # Set netlink receive buffer size. This is useful for\n           # very large configurations where a large number of interfaces exist, and\n           # the initial read of the interfaces on the system causes a netlink buffer\n           # overrun.\n           vrrp_netlink_cmd_rcv_bufs BYTES\n           vrrp_netlink_cmd_rcv_bufs_force <BOOL>\n           vrrp_netlink_monitor_rcv_bufs BYTES\n           vrrp_netlink_monitor_rcv_bufs_force <BOOL>\n\n           # The vrrp netlink command and monitor socket the checker command and\n           # and monitor socket and process monitor buffer sizes can be independently set.\n           # The force flag means to use SO_RCVBUFFORCE, so that the buffer size\n           # can exceed /proc/sys/net/core/rmem_max.\n           lvs_netlink_cmd_rcv_bufs BYTES\n           lvs_netlink_cmd_rcv_bufs_force <BOOL>\n           lvs_netlink_monitor_rcv_bufs BYTES\n           lvs_netlink_monitor_rcv_bufs_force <BOOL>\n\n           # As a guide for process_monitor_rcv_bufs for 1400 processes terminating\n           # simultaneously, 212992 (the default on some systems) is insufficient, whereas\n           # 500000 is sufficient.\n           process_monitor_rcv_bufs BYTES\n           process_monitor_rcv_bufs_force <BOOL>\n\n           # When a socket is opened, the kernel configures the max rx buffer size for\n           # the socket to /proc/sys/net/core/rmem_default. On some systems this can be\n           # very large, and even generally this can be much larger than necessary.\n           # This isn't a problem so long as keepalived is reading all queued data from\n           # it's sockets, but if rmem_default was set sufficiently large, and if for\n           # some reason keepalived stopped reading, it could consume all system memory.\n           # The vrrp_rx_bufs_policy allows configuring of the rx bufs size when the\n           # sockets are opened. If the policy is MTU, the rx buf size is configured\n           # to the total of interface's MTU * vrrp_rx_bufs_multiplier for each vrrp\n           # instance using the socket. Likewise, if the policy is ADVERT, then it is\n           # the total of each vrrp instances advert packet size * multiplier.\n           # (default: use system default)\n           vrrp_rx_bufs_policy [MTU|ADVERT|NUMBER]\n\n           # (default: 3)\n           vrrp_rx_bufs_multiplier NUMBER\n\n           # Send notifies at startup for real servers that are starting up\n           rs_init_notifies\n\n           # Don't send an email every time a real server checker changes state;\n           # only send email when a real server is added or removed\n           no_checker_emails\n\n           # The umask to use for creating files. The number can be specified in hex,\n           #   octal or decimal. BITS are I{R|W|X}{USR|GRP|OTH}, e.g. IRGRP, separated\n           #   by '|'s. The default umask is IWGRP | IWOTH. This option cannot override\n           #   the command-line option.\n           umask [NUMBER|BITS] \n\n           # On some systems when bond interfaces are created, they can start\n\t   # passing traffic and then have a several second gap when they stop\n\t   # passing traffic inbound. This can mean that if keepalived is started\n\t   # at boot time, i.e. at the same time as bond interfaces are being\n\t   # created, keepalived doesn't receive adverts and hence can become master\n\t   # despite an instance with higher priority sending adverts. This option\n\t   # specifies a delay in seconds before vrrp instances start up after\n           # keepalived starts,\n           vrrp_startup_delay 5.5\n\n\t   # Specify random seed for ${_RANDOM}, to make configurations repeatable\n\t   # (default is to use a seed based on the time, so that each time a\n\t   # different configuration will be generated).\n\t   random_seed  UNSIGNED_INT\n       }\n\nLinkbeat interfaces\n       The linkbeat_interfaces block allows specifying which interfaces should\n       use polling via MII, Ethtool  or  ioctl  status  rather  than  rely  on\n       netlink  status  updates.  This  allows more granular control of global\n       definition linkbeat_use_polling.\n\n       This   option   is   preferred   over    the    deprecated    use    of\n       linkbeat_use_polling  in  a vrrp_instance block, since\n       the  latter  only  allows  using  linkbeat  on  the  interface  of  the\n       vrrp_instance  itself,  whereas  track_interface  and\n       virtual_ipaddresses and virtual_iproutes may require  monitoring  other\n       interfaces, which may need to use linkbeat polling.\n\n       The  default polling type to use is MII, unless that isn't supported in\n       which case ETHTOOL is used, and if  that  isn't  supported  then  ioctl\n       polling. The preferred type of polling to use can be specified with MII\n       or ETHTOOL or IOCTL after the interface name, but if  that  type  isn't\n       supported, a supported type will be used.\n\n       The synfax for linkbeat_interfaces is:\n           linkbeat_interfaces {\n               eth2\n               enp2s0 ETHTOOL\n           }\n\nStatic track groups\n       Static  track  groups  are used to allow vrrp instances to track static\n       addresses, routes and rules. If a static address/route/rule specifies a\n       track  group,  then  if the address/route/rule is deleted and cannot be\n       restored, the vrrp instance will transition to fault state.\n\n       The syntax for a track group is:\n           track_group GROUP1 {\n               group {\n                   VI_1\n                   VI_2\n               }\n           }\n\nStatic routes/addresses/rules\n       Keepalived can configure static addresses,  routes,  and  rules.  These\n       addresses  are  NOT  moved  by vrrpd, they stay on the\n       machine.  If you already have IPs and routes on your machines and  your\n       machines  can ping each other, you don't need this section.  The syntax\n       for rules and routes is that same as  for  ip  rule  add/ip  route  add\n       (except shorted option names aren't supported due to ambiguities).  The\n       track_group specification refers to a named track_group which lists the\n       vrrp  instances  which  will  track the address, i.e. if the address is\n       deleted the vrrp instances will transition to backup.\n\n       NOTE: since rules without preferences can be added in different  orders\n       due  to  vrrp  instances transitioning from master to backup etc, rules\n       need to have a preference. If a preference is not specified, keepalived\n       will assign one, but it will probably not be what you want.\n\n       The  syntax is the same for virtual addresses and virtual routes. If no\n       dev element is specified, it  defaults  to  default_interface  (default\n       eth0).   Note:  the broadcast address may be specified as '-' or '+' to\n       clear or set the host bits of the address.\n\n       If a route or rule could apply to  either IPv4 or IPv6  it will default\n       to IPv4. To force a route/rule to be IPv6, add the keyword \"inet6\".\n\n           static_ipaddress {\n               <IPADDR>[/<MASK>] [brd <IPADDR>] [dev <STRING>] [scope <SCOPE>]\n                                 [label <LABEL>] [peer <IPADDR>] [home]\n                                 [-nodad] [mngtmpaddr] [noprefixroute]\n                                 [autojoin] [track_group GROUP]\n               192.168.1.1/24 dev eth0 scope global\n               ...\n           }\n\n           static_routes {\n               192.168.2.0/24 via 192.168.1.100 dev eth0 track_group GROUP1\n\n               192.168.100.0/24 table 6909 nexthop via 192.168.101.1 dev wlan0\n                                onlink weight 1 nexthop via 192.168.101.2\n                                dev wlan0 onlink weight 2\n\n               192.168.200.0/24 dev p33p1.2 table 6909 tos 0x04 protocol bird\n                                scope link priority 12 mtu 1000 hoplimit 100\n                                advmss 101 rtt 102 rttvar 103 reordering 104\n                                window 105 cwnd 106 ssthresh lock 107 realms\n                                PQA/0x14 rto_min 108 initcwnd 109 initrwnd 110\n                                features ecn\n\n               2001:470:69e9:1:2::4 dev p33p1.2 table 6909 tos 0x04 protocol\n                                    bird scope link priority 12 mtu 1000\n                                    hoplimit 100 advmss 101 rtt 102 rttvar 103\n                                    reordering 104 window 105 cwnd 106 ssthresh\n                                    lock 107 rto_min 108 initcwnd 109\n                                    initrwnd 110 features ecn fastopen_no_cookie 1\n               ...\n           }\n\n           static_rules {\n               from 192.168.2.0/24 table 1 track_group GROUP1\n\n               to 192.168.2.0/24 table 1\n\n               from 192.168.28.0/24 to 192.168.29.0/26 table small iif p33p1\n                                    oif wlan0 tos 22 fwmark 24/12\n                                    preference 39 realms 30/20 goto 40\n\n               to 1:2:3:4:5:6:7:0/112 from 7:6:5:4:3:2::/96 table 6908\n                                      uidrange 10000-19999\n\n               to 1:2:3:4:6:6:7:0/112 from 8:6:5:4:3:2::/96 l3mdev protocol 12\n                                      ip_proto UDP sport 10-20 dport 20-30\n               ...\n           }\n\nVRRP track processes\n       The configuration block looks like:\n\n           vrrp_track_process <STRING> {\n               # process to monitor (with optional parameters)\n               process <STRING>|<QUOTED_STRING> [<STRING>|<QUOTED_STRING> ...]\n\n               # If matching parameters, specifies a partial match (i.e. the first\n               #   n parameters match exactly, or an initial match, i.e. the last\n               #   parameter may be longer that the parameter configured.\n               # To specify that a command must have no parameters, don't specify\n               #   any parameters, but specify param_match.\n               param_match {initial|partial}\n\n               # default weight (default is 1)\n               weight <-254..254>\n\n               # minimum number of processes for success\n               quorum NUM\n\n               # maximum number of processes for success. For example, setting\n               #   this to 1 would cause a failure if two instances of the process\n               #   were running (but beware forks - see fork_delay below).\n               #   Setting this to 0 would mean failure if the matching process were\n               #   running at all.\n               quorum_max NUM\n\n\t       # time to delay after process quorum gained after fork before\n\t       #   consider process up (in fractions of second)\n\t       #   This is to avoid up/down bounce for fork/exec\n\t       fork_delay\n  \n               # time to delay after process quorum lost before\n\t       #   consider process down (in fractions of second)\n\t       #   This is to avoid down/up bounce after terminate/parent refork.\n\t       terminate_delay SECS\n\n\t       # this sets fork_delay and terminate_delay\n               delay SECS\n\n               # Normally process string is matched against the process name,\n\t       #   as shown on the Name: line in /proc/PID/status, unless\n\t       #   parameters are specified.\n\t       #   This option forces matching the full command line\n               full_command\n           }\n\n       To  avoid  having to frequently run a track_script to monitor the exis-\n       tance of processes (often haproxy  or  nginx),  vrrp_track_process  can\n       monitor whether other processes are running.\n\n       One difference from pgrep is track_process doesn't do a regular expres-\n       sion match of the command string, but does an exact match. 'pgrep  ssh'\n       will  match an sshd process, this track_process will not (it is equiva-\n       lent to pgrep \"^ssh$\").\n\n       If full_command is used (equivalent to pgrep -f), /proc/PID/cmdline  is\n       used,  but  any  updates  to  cmdline  will  not be detected (a process\n       shouldn't normally change it, although it is possible with great  care,\n       for example systemd).\n\n       Prior to Linux v3.2 track_process will not support detection of changes\n       to a process name, since the kernel did not notify changes  of  process\n       name  prior  to  3.2.  Most processes do not change their process name,\n       but, for example, firefox forks processes  that  change  their  process\n       name  to  \"Web  Content\". The process name referred to here is the con-\n       tents of /proc/PID/comm.\n\n       Quorum  is  the number of matching processes that must be run for an OK\n       status.\n\n       Delay might be useful if it anticipated that a process may be  reloaded\n       (stopped  and  restarted),  and  it isn't desired to down and up a vrrp\n       instance.\n\n       A positive weight means that an OK status will  add  <weight>  to\n       the priority of all VRRP instances which monitor it. On the opposite, a\n       negative weight will be subtracted from the initial priority in case of\n       insufficient processes.\n\n       If  the  vrrp  instance  or sync group is not the address owner and the\n       result is between -253 and 253, the result will be added to the initial\n       priority  of the VRRP instance (a negative value will reduce the prior-\n       ity), although the effective priority will  be  limited  to  the  range\n       [1,254].\n\n       If  a  vrrp instance using a track_process is a member of a sync group,\n       unless sync_group_tracking_weight is set on the group weight 0 must  be\n       set.   Likewise,  if  the  vrrp instance is the address owner, weight 0\n       must also be set.\n\n       Rational for not using pgrep/pidof/killall and the likes:\n\n       Every time pgrep or its equivalent  is  run,  it  iterates  though  the\n       /proc/[1-9][0-9]*  directories, and opens the status and cmdline pseudo\n       files in each directory.  The cmdline pseudo  file  is  mapped  to  the\n       process's  address space, and so if that part of the process is swapped\n       out, it will have to be fetched from the swap space.   pgrep  etc  also\n       include zombie processes whereas keepalived does not, since they aren't\n       running.\n\n       This implementation only iterates though /proc/[1-9][0-9]*/ directories\n       at  start  up,  and  it  won't  even  read  the cmdline pseudo files if\n       'full_command' is not  specified  for  any  of  the  vrrp_track_process\n       entries.  After  startup,  it  uses the process_events kernel <->\n       userspace connector to receive  notification  of  process  changes.  If\n       full_command  is  specified for any track_process instance, the cmdline\n       pseudo file will have to be read upon notification of the  creation  of\n       the new process, but at that time it is very unlikely that it will have\n       already been swapped out.\n\n       On a busy system with a high number of process  creations/terminations,\n       using  a  track_script  with pgrep/pidof/killall may be more efficient,\n       although those processes are inefficient compared to the  minimum  that\n       keepalived needs.\n\n       Using  pgrep  etc  on  a system that is swapping can have a significant\n       detrimental impact on the performance of the system, due to  having  to\n       fetch  swapped  memory  from the swap space, thereby causing additional\n       swapping.\n\nBFD CONFIGURATION\n       This  is  an implementation of RFC5880 (Bidirectional forwarding detec-\n       tion), and  this  can  be  configured  to  work  between  2  keepalived\n       instances, but using unweighted track_bfds between a master/backup pair\n       of VRRP instances means that the VRRP instance will  only  be  able  to\n       come  up  if both VRRP instance are running, which somewhat defeats the\n       purpose of VRRP.\n\n       This  imlpementation  has  been  tested  with  OpenBFDD  (available  at\n       https://github.com/dyninc/OpenBFDD).\n\n       The syntax for bfd instance is :\n\n       bfd_instance <STRING> {\n           # BFD Neighbor IP (synonym neighbour_ip)\n           neighbor_ip <IP ADDRESS>\n\n           # Source IP to use (optional)\n           source_ip <IP ADDRESS>\n\n           # Required min RX interval, in ms\n           # (default is 10 ms)\n           min_rx <INTEGER>\n\n           # Desired min TX interval, in ms\n           # (default is 10 ms)\n           min_tx <INTEGER>\n\n           # Desired idle TX interval, in ms\n           # (default is 1000 ms)\n           idle_tx <INTEGER>\n\n           # Number of missed packets after\n           # which the session is declared down\n           # (default is 5)\n           multiplier <INTEGER>\n\n           # Operate in passive mode (default is active)\n           passive\n\n           # outgoing IPv4 ttl to use (default 255)\n           ttl <INTEGER>\n\n           # outgoing IPv6 hoplimit to use (default 64)\n           hoplimit <INTEGER>\n\n           # maximum reduction of ttl/hoplimit\n           #  in received packet (default 0)\n           #  (255 disables hop count checking)\n           max_hops <INTEGER>\n\n           # Default tracking weight\n           weight\n       }\n\nVRRPD CONFIGURATION\n       contains  subblocks  of  VRRP  script(s),  VRRP synchronization\n       group(s), VRRP gratuitous ARP and unsolicited  neighbour  advert  delay\n       group(s) and VRRP instance(s)\n\nVRRP script(s)\n       The  script  will be executed periodically, every <interval> sec-\n       onds. Its exit code will be recorded for all VRRP instances which moni-\n       tor  it.   Note  that  the script will only be executed if at least one\n       VRRP instance monitors it.\n\n       The default weight equals 0, which means that any VRRP  instance  moni-\n       toring the script will transition to the fault state after <fall>\n       consecutive failures of the script. After that,  <rise>  consecu-\n       tive  successes  will  cause  VRRP  instances to leave the fault state,\n       unless they are also in the fault state due to other scripts or  inter-\n       faces that they are tracking.\n\n       A   positive   weight   means  that  <rise>  successes  will  add\n       <weight> to the priority of all VRRP instances which monitor  it.\n       On  the opposite, a negative weight will be subtracted from the initial\n       priority in case of <fall> failures.\n\n       The syntax for the vrrp script is:\n\n       # Adds a script to be executed periodically. Its exit code will be\n       # recorded for all VRRP instances and sync groups which are monitoring it.\n       vrrp_script <SCRIPT_NAME> {\n           # path of the script to execute\n           script <STRING>|<QUOTED-STRING>\n\n           # seconds between script invocations, (default: 1 second)\n           interval <INTEGER>\n\n           # seconds after which script is considered to have failed\n           timeout <INTEGER>\n\n           # adjust priority by this weight, (default: 0)\n           weight <INTEGER:-253..253>\n\n           # required number of successes for OK transition\n           rise <INTEGER>\n\n           # required number of successes for KO transition\n           fall <INTEGER>\n\n           # user/group names to run script under.\n           #  group default to group of user\n           user USERNAME [GROUPNAME]\n\n           # assume script initially is in failed state\n           init_fail\n       }\n\nVRRP track files\n       Adds a file to be monitored. The script will be  read  whenever  it  is\n       modified. The value in the file will be recorded for all VRRP instances\n       and sync groups which monitor it.  Note that the file will only be read\n       if at least one VRRP instance or sync group monitors it.\n\n       A  value will be read as a number in text from the file.  If the weight\n       configured against the track_file is 0, a non-zero value  in  the  file\n       will  be  treated as a failure status, and a zero value will be treaded\n       as an OK status, otherwise the value will be  multiplied by the  weight\n       configured in the track_file statement. If the result is less than -253\n       any VRRP instance or sync group monitoring the script  will  transition\n       to the fault state (the weight can be 254 to allow for a negative value\n       being read from the file).\n\n       If the vrrp instance or sync group is not the  address  owner  and  the\n       result is between -253 and 253, the result will be added to the initial\n       priority of the VRRP instance (a negative value will reduce the  prior-\n       ity),  although  the  effective  priority  will be limited to the range\n       [1,254].\n\n       If a vrrp instance using a track_file is a  member  of  a  sync  group,\n       unless  sync_group_tracking_weight is set on the group weight 0 must be\n       set.  Likewise, if the vrrp instance is the  address  owner,  weight  0\n       must also be set.\n\n       The syntax for vrrp track file is :\n\n       vrrp_track_file <STRING> {    # VRRP track file declaration\n           # file to track (weight defaults to 1)\n           file <QUOTED_STRING>\n\n           # optional default weight\n           weight <-254..254>\n\n           # create the file and/or initialise the value\n           # This causes VALUE (default 0) to be written to\n           # the specified file at startup if the file doesn't\n           # exist, unless overwrite is specified in which case\n           # any existing file contents will be overwritten with\n           # the specified value.\n           init_file [VALUE] [overwrite]\n       }\n\nVRRP synchronization group(s)\n       VRRP  Sync  Group is an extension to VRRP protocol. The main goal is to\n       define a bundle of VRRP instance to get synchronized together  so  that\n       transition of one instance will be reflected to others group members.\n\n       In  addition there is an enhanced notify feature for fine state transi-\n       tion catching.\n\n       You can also define multiple track policy in order to force state tran-\n       sition  according  to  a  third party event such as interface, scripts,\n       file, BFD.\n\n       Important: for a SYNC group to  run  reliably,  it  is\n       vital  that  all instances in the group are MASTER or that they are all\n       either BACKUP or FAULT. A situation with half instances  having  higher\n       priority  on  machine  A  half others with higher priority on machine B\n       will lead to constant re-elections. For this reason, when instances are\n       grouped,   any  track  scripts/files  configured  against  member  VRRP\n       instances will have their tracking weights automatically set  to  zero,\n       in order to avoid inconsistent priorities across instances.\n\n       The syntax for vrrp_sync_group is :\n\n       vrrp_sync_group <STRING> {\n           group {\n               # name of the vrrp_instance (see below)\n               # Set of VRRP_Instance string\n               <STRING>\n               <STRING>\n               ...\n           }\n\n           # Synchronization group tracking interface, script, file & bfd will\n           # update the status/priority of all VRRP instances which are members\n           # of the sync group.\n           track_interface {\n               eth0\n               eth1\n               eth2 weight <-253..253>\n               ...\n           }\n\n           # add a tracking script to the sync group (<SCRIPT_NAME> is the name\n           # of the vrrp_script entry) go to FAULT state if any of these go down\n           # if unweighted.\n           track_script {\n               <SCRIPT_NAME>\n               <SCRIPT_NAME> weight <-253..253>\n           }\n\n           # Files whose state we monitor, value is added to effective priority.\n           # <STRING> is the name of a vrrp_status_file\n           # weight defaults to weight configured in vrrp_track_file\n           track_file {\n               <STRING>\n               <STRING> weight <-254..254>\n               ...\n           }\n\n           # BFD instances we monitor, value is added to effective priority.\n           # <STRING> is the name of a BFD instance\n           track_bfd {\n               <STRING>\n               <STRING>\n               <STRING> weight <INTEGER: -253..253>\n               ...\n           }\n\n           # notify scripts and alerts are optional\n           #\n           # filenames of scripts to run on transitions can be unquoted (if\n           # just filename) or quoted (if it has parameters)\n           # The username and groupname specify the user and group\n           # under which the scripts should be run. If username is\n           # specified, the group defaults to the group of the user.\n           # If username is not specified, they default to the\n           # global script_user and script_group to MASTER transition\n           notify_master /path/to_master.sh [username [groupname]]\n\n           # to BACKUP transition\n           notify_backup /path/to_backup.sh [username [groupname]]\n\n           # FAULT transition\n           notify_fault \"/path/fault.sh VG_1\" [username [groupname]]\n\n           # executed when stopping vrrp\n           notify_stop <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # for ANY state transition.\n           # \"notify\" script is called AFTER the notify_* script(s) and\n           # is executed with 4 additional arguments after the configured\n           # arguments provided by Keepalived:\n           #   $(n-3) = \"GROUP\"|\"INSTANCE\"\n           #   $(n-2) = name of the group or instance\n           #   $(n-1) = target state of transition (stop only applies to instances)\n           #            (\"MASTER\"|\"BACKUP\"|\"FAULT\"|\"STOP\")\n           #   $(n)   = priority value\n           #   $(n-3) and $(n-1) are ALWAYS sent in uppercase, and the possible\n           #\n           # strings sent are the same ones listed above\n           #   (\"GROUP\"/\"INSTANCE\", \"MASTER\"/\"BACKUP\"/\"FAULT\"/\"STOP\")\n           # (note: STOP is only applicable to instances)\n           notify <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # The notify fifo output is the same as the last 4 parameters for the \"notify\"\n           # script, with the addition of \"MASTER_RX_LOWER_PRI\" instead of state for an\n\t   # instance, and also \"MASTER_PRIORITY\" and \"BACKUP_PRIORITY\" if the priority\n           # changes and notify_priority_changes is configured.\n           # MASTER_RX_LOWER_PRI is used if a master needs to set some external state, such\n           # as setting a secondary IP address when using Amazon AWS; if another keepalived\n           # has transitioned to master due to a communications break, the lower priority\n           # instance will have taken over the secondary IP address, and the proper master\n           # needs to be able to restore it.\n\n           # Send FIFO notifies for vrrp priority changes\n\t   notify_priority_changes <BOOL>\n\n           # Send email notification during state transition,\n           # using addresses in global_defs above (default no,\n           # unless global smtp_alert/smtp_alert_vrrp set)\n           smtp_alert <BOOL>\n\n           # DEPRECATED. Use track_interface, track_script and\n           # track_file on vrrp_sync_groups instead.\n           global_tracking\n\n           # allow sync groups to use differing weights.\n           # This probably WON'T WORK, but is a replacement for\n           # global_tracking in case different weights were used\n           # across different vrrp instances in the same sync group.\n           sync_group_tracking_weight\n       }\n\nVRRP gratuitous ARP and unsolicited neighbour advert delay group(s)\n       specifies  the  setting  of  delays between sending gratuitous ARPs and\n       unsolicited neighbour advertisements. This  is  intended  for  when  an\n       upstream switch is unable to handle being flooded with ARPs/NAs.\n\n       Use  interface  when the limits apply on the single physical interface.\n       Use interfaces when a group of interfaces are linked to the same switch\n       and the limits apply to the switch as a whole.\n\n       Note:  Only  one  of interface or interfaces should be\n       used per block.\n\n       If the global vrrp_garp_interval and/or vrrp_gna_interval are set,  any\n       interfaces  that  aren't  specified  in  a  garp_group will inherit the\n       global settings.\n\n       The syntax for garp_group is :\n\n       garp_group {\n           # Sets the interval between Gratuitous ARP (in seconds, resolution microseconds)\n           garp_interval <DECIMAL>\n\n           # Sets the default interval between unsolicited NA (in seconds, resolution microseconds)\n           gna_interval <DECIMAL>\n\n           # The physical interface to which the intervals apply\n           interface <STRING>\n\n           # A list of interfaces accross which the delays are aggregated.\n           interfaces {\n               <STRING>\n               <STRING>\n               ...\n           }\n       }\n\nVRRP instance(s)\n       A VRRP Instance is the VRRP protocol key feature. It defines  and  con-\n       figures  VRRP  behaviour  to  run  on  a  specific interface. Each VRRP\n       Instances are related to a uniq interface.\n\n       The syntax for vrrp_instance is :\n\n       vrrp_instance <STRING> {\n           # Initial state, MASTER|BACKUP\n           # As soon as the other machine(s) come up,\n           # an election will be held and the machine\n           # with the highest priority will become MASTER.\n           # So the entry here doesn't matter a whole lot.\n           state MASTER\n\n           # interface for inside_network, bound by vrrp\n           interface eth0\n\n           # Use VRRP Virtual MAC.\n           # NOTE: If sysctl net.ipv4.conf.all.rp_filter is set,\n           # and this vrrp_instance is an IPv4 instance, using\n           # this option will cause the individual interfaces to be\n           # updated to the greater of their current setting, and\n           # all.rp_filter, as will default.rp_filter, and all.rp_filter\n           # will be set to 0.\n           # The original settings are restored on termination.\n           use_vmac [<VMAC_INTERFACE>]\n\n           # Send/Recv VRRP messages from base interface instead of\n           # VMAC interface\n           vmac_xmit_base\n\n           # force instance to use IPv6 (this option is deprecated since\n           # the virtual ip addresses determine whether IPv4 or IPv6 is used).\n           native_ipv6\n\n           # Ignore VRRP interface faults (default unset)\n           dont_track_primary\n\n           # optional, monitor these as well.\n           # go to FAULT state if any of these go down if unweighted.\n           # When a weight is specified in track_interface, instead of setting the vrrp\n           # instance to the FAULT state in case of failure, its priority will be\n           # increased by the weight when the interface is up (for positive weights),\n           # or decreased by the weight's absolute value when the interface is down\n           # (for negative weights). The weight must be comprised between -254 and +254\n           # inclusive. 0 is the default behaviour which means that a failure implies a\n           # FAULT state. The common practice is to use positive weights to count a\n           # limited number of good services so that the server with the highest count\n           # becomes master. Negative weights are better to count unexpected failures\n           # among a high number of interfaces, as it will not saturate even with high\n           # number of interfaces.\n           track_interface {\n               eth0\n               eth1\n               eth2 weight <-253..253>\n                ...\n           }\n\n           # add a tracking script to the interface\n           # (<SCRIPT_NAME> is the name of the vrrp_track_script entry)\n           # The same principle as track_interface can be applied to track_script entries,\n           # except that an unspecified weight means that the default weight declared in\n           # the script will be used (which itself defaults to 0).\n           track_script {\n               <SCRIPT_NAME>\n               <SCRIPT_NAME> weight <-253..253>\n           }\n\n           # Files whose state we monitor, value is added to effective priority.\n           # <STRING> is the name of a vrrp_track_file\n           track_file {\n               <STRING>\n               <STRING>\n               <STRING> weight <-254..254>\n               ...\n           }\n\n           # BFD instances we monitor, value is added to effective priority.\n           # <STRING> is the name of a BFD instance\n           track_bfd {\n               <STRING>\n               <STRING>\n               <STRING> weight <INTEGER: -253..253>\n               ...\n           }\n\n           # default IP for binding vrrpd is the primary IP\n           # on interface. If you want to hide the location of vrrpd,\n           # use this IP as src_addr for multicast or unicast vrrp\n           # packets. (since it's multicast, vrrpd will get the reply\n           # packet no matter what src_addr is used).\n           # optional\n           mcast_src_ip <IPADDR>\n           unicast_src_ip <IPADDR>\n\n           # if the configured src_ip doesn't exist or is removed put the\n           # instance into fault state\n           track_src_ip\n\n           # VRRP version to run on interface\n\t   # default is global parameter vrrp_version, but IPv6 instances will\n\t   # always use version 3.\n           version <2 or 3>\n\n           # Do not send VRRP adverts over a VRRP multicast group.\n           # Instead it sends adverts to the following list of\n           # ip addresses using unicast. It can be cool to use\n           # the VRRP FSM and features in a networking\n           # environment where multicast is not supported!\n           # IP addresses specified can be IPv4 as well as IPv6.\n           unicast_peer {\n               <IPADDR>\n               ...\n           }\n\n           # The checksum calculation when using VRRPv3 changed after v1.3.6.\n           #  Setting this flag forces the old checksum algorithm to be used\n           #  to maintain backward compatibility, although keepalived will\n           #  attempt to maintain compatibility anyway if it sees an old\n           #  version checksum. Specifying never will turn off auto detection\n           #  of old checksums. [This option may not be enabled - check output\n           #  of `keepalived -v` for OLD_CHKSUM_COMPAT.]\n           old_unicast_checksum [never]\n\n           # interface specific settings, same as global parameters.\n           # default to global parameters\n           garp_master_delay 10\n           garp_master_repeat 1\n           garp_lower_prio_delay 10\n           garp_lower_prio_repeat 1\n           garp_master_refresh 60\n           garp_master_refresh_repeat 2\n           garp_interval 100\n           gna_interval 100\n\n           # If a lower priority advert is received, don't send another advert.\n           # This causes adherence to the RFCs (defaults to global\n           # vrrp_lower_priority_dont_send_advert).\n           lower_prio_no_advert [<BOOL>]\n\n           # If we are master and receive a higher priority advert, send an advert\n           # (which will be lower priority than the other master), before we transition\n           # to backup. This means that if the other master has garp_lower_prio_repeat\n           # set, it will resend garp messages. This is to get around the problem of\n           # their having been two simultaneous masters, and the last GARP\n           # messages seen were from us.\n           higher_prio_send_advert [<BOOL>]\n\n           # arbitrary unique number from 0 to 255\n           # used to differentiate multiple instances of vrrpd\n           # running on the same NIC (and hence same socket).\n           virtual_router_id 51\n\n           # for electing MASTER, highest priority wins.\n           # to be MASTER, make this 50 more than on other machines.\n           priority 100\n\n           # VRRP Advert interval in seconds (e.g. 0.92) (use default)\n           advert_int 1\n\n           # Note: authentication was removed from the VRRPv2 specification by\n           # RFC3768 in 2004.\n           #   Use of this option is non-compliant and can cause problems; avoid\n           #   using if possible, except when using unicast, where it can be helpful.\n           authentication {\n               # PASS|AH\n               # PASS - Simple password (suggested)\n               # AH - IPSEC (not recommended))\n               auth_type PASS\n\n               # Password for accessing vrrpd.\n               # should be the same on all machines.\n               # Only the first eight (8) characters are used.\n               auth_pass 1234\n           }\n\n           # addresses add|del on change to MASTER, to BACKUP.\n           # With the same entries on other machines,\n           # the opposite transition will be occurring.\n           # For virutal_ipaddress, virtual_ipaddress_excluded,\n           #   virtual_routes and virtual_rules most of the options\n           #   match the options of the command ip address/route/rule add.\n           #   The track_group option only applies to static addresses/routes/rules.\n           #   no_track is specific to keepalived and means that the\n           #   vrrp_instance will not transition out of master state\n           #   if the address/route/rule is deleted and the address/route/rule\n           #   will not be reinstated until the vrrp instance next transitions\n           #   to master.\n           # <LABEL>: is optional and creates a name for the alias.\n                      For compatibility with \"ifconfig\", it should\n                      be of the form <realdev>:<anytext>, for example\n                      eth0:1 for an alias on eth0.\n           # <SCOPE>: (\"site\"|\"link\"|\"host\"|\"nowhere\"|\"global\")\n           virtual_ipaddress {\n               <IPADDR>[/<MASK>] [brd <IPADDR>] [dev <STRING>] [scope <SCOPE>]\n                                 [label <LABEL>] [peer <IPADDR>] [home]\n                                 [-nodad] [mngtmpaddr] [noprefixroute]\n                                 [autojoin] [no_track]\n               192.168.200.17/24 dev eth1\n               192.168.200.18/24 dev eth2 label eth2:1\n           }\n\n           # VRRP IP excluded from VRRP optional.\n           # For cases with large numbers (eg 200) of IPs\n           # on the same interface. To decrease the number\n           # of addresses sent in adverts, you can exclude\n           # most IPs from adverts.\n           # The IPs are add|del as for virtual_ipaddress.\n           # Can also be used if you want to be able to add\n           # a mixture of IPv4 and IPv6 addresses, since all\n           # addresses in virtual_ipaddress must be of the\n           # same family.\n           virtual_ipaddress_excluded {\n               <IPADDR>[/<MASK>] [brd <IPADDR>] [dev <STRING>] [scope <SCOPE>]\n                                 [label <LABEL>] [peer <IPADDR>] [home]\n                                 [-nodad] [mngtmpaddr] [noprefixroute]\n                                 [autojoin] [no_track]\n               <IPADDR>[/<MASK>] ...\n               ...\n           }\n\n           # Set the promote_secondaries flag on the interface to stop other\n           # addresses in the same CIDR being removed when 1 of them is removed\n           # For example if 10.1.1.2/24 and 10.1.1.3/24 are both configured on an\n           # interface, and one is removed, unless promote_secondaries is set on\n           # the interface the other address will also be removed.\n\t   prompte_secondaries\n\n           # routes add|del when changing to MASTER, to BACKUP.\n           # See static_routes for more details\n           virtual_routes {\n               # src <IPADDR> [to] <IPADDR>/<MASK> via|gw <IPADDR>\n               #   [or <IPADDR>] dev <STRING> scope <SCOPE> table <TABLE>\n               src 192.168.100.1 to 192.168.109.0/24 via 192.168.200.254 dev eth1\n               192.168.110.0/24 via 192.168.200.254 dev eth1\n               192.168.111.0/24 dev eth2 no_track\n               192.168.112.0/24 via 192.168.100.254\n               192.168.113.0/24 via 192.168.200.254 or 192.168.100.254 dev eth1\n               blackhole 192.168.114.0/24\n               0.0.0.0/0 gw 192.168.0.1 table 100  # To set a default gateway into table 100.\n           }\n\n           # rules add|del when changing to MASTER, to BACKUP\n           # See static_rules for more details\n           virtual_rules {\n               from 192.168.2.0/24 table 1\n               to 192.168.2.0/24 table 1 no_track\n           }\n\n           # VRRPv3 has an Accept Mode to allow the virtual router when not the\n           # address owner to receive packets addressed to a VIP. This is the default\n           # setting unless strict mode is set. As an extension, this also works for\n           # VRRPv2 (RFC 3768 doesn't define an accept mode).\n           # --\n           # Accept packets to non address-owner\n           accept\n\n           # Drop packets to non address-owner.\n           no_accept\n\n           # VRRP will normally preempt a lower priority machine when a higher priority\n           # machine comes online.  \"nopreempt\" allows the lower priority machine to\n           # maintain the master role, even when a higher priority machine comes back\n           # online.\n           # NOTE: For this to work, the initial state of this\n           # entry must be BACKUP.\n           # --\n           nopreempt\n\n           # for backwards compatibility\n           preempt\n\n           # See description of global vrrp_skip_check_adv_addr, which\n           # sets the default value. Defaults to vrrp_skip_check_adv_addr\n           skip_check_adv_addr [on|off|true|false|yes|no]\n\n           # See description of global vrrp_strict\n           # If vrrp_strict is not specified, it takes the value of vrrp_strict\n           # If strict_mode without a parameter is specified, it defaults to on\n           strict_mode [on|off|true|false|yes|no]\n\n           # Seconds after startup or seeing a lower priority master until preemption\n           # (if not disabled by \"nopreempt\").\n           # Range: 0 (default) to 1000 (e.g. 4.12)\n           # NOTE: For this to work, the initial state of this\n           # entry must be BACKUP.\n           preempt_delay 300    # waits 5 minutes\n\n           # Debug level, not implemented yet.\n           # LEVEL is a number in the range 0 to 4\n           debug <LEVEL>\n\n           # notify scripts, alert as above\n           notify_master <STRING>|<QUOTED-STRING> [username [groupname]]\n           notify_backup <STRING>|<QUOTED-STRING> [username [groupname]]\n           notify_fault <STRING>|<QUOTED-STRING> [username [groupname]]\n           # executed when stopping vrrp\n           notify_stop <STRING>|<QUOTED-STRING> [username [groupname]]\n           notify <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # The notify_master_rx_lower_pri script is executed if a master\n           #  receives an advert with priority lower than the master's advert.\n           notify_master_rx_lower_pri <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # Send vrrp instance priority notifications on notify FIFOs.\n\t   notify_priority_changes <BOOL>\n\n           # Send SMTP alerts\n           smtp_alert <BOOL>\n\n           # Set socket receive buffer size (see global_defs\n           # vrrp_rx_bufs_policy for explanation)\n           kernel_rx_buf_size\n\n           # Set use of linkbeat for the interface of this VRRP instance. This option is\n           # deprecated - use linkbeat_interfaces block instead.\n\t   linkbeat_use_polling\n       }\n\nLVS CONFIGURATION\n       contains subblocks  of  Virtual  server  group(s)  and\n       Virtual server(s)\n\n       The  subblocks  contain arguments for configuring Linux IPVS (LVS) fea-\n       ture.  Knowledge of ipvsadm(8) will be helpful here. Configuring LVS is\n       achieved by defining virtual server groups, virtual servers and option-\n       ally SSL configuration. Every virtual server  defines  a  set  of  real\n       servers,  you can attach healthcheckers to each real server. Keepalived\n       will then lead LVS operation by dynamically maintaining topology.\n\n       For details of what  configuration  combinations  are  valid,  see  the\n       ipvsadm(8) man page.\n\n       Note: Where an option can be configured for a  virtual\n       server,  real  server, and possibly checker, the virtual server setting\n       is the default for real servers, and the real  server  setting  is  the\n       default for checkers.\n\n       Note: Tunnelled real/sorry servers can differ from the\n       address family of the  virtual  server  and  non  tunnelled  real/sorry\n       servers,  which  all  have  to  be the same. If a virtual server uses a\n       fwmark, and all the real/sorry servers are tunnelled, the address  fam-\n       ily of the virtual server will be the same as the address family of the\n       real/sorry servers if they are all the same, otherwise it will  default\n       to IPv4 (use ip_family inet6 to override this).\n\n       Note: The port for the  virtual  server  can  only  be\n       omitted if the virtual service is persistent.\n\nVirtual server group(s)\n       This feature offers a way to simplify your configuration by factorizing\n       virtual server definitions. If you need to define a  bunch  of  virtual\n       servers  with  exactly  the same real server topology then this feature\n       will make your configuration  much  more  readable  and  will  optimize\n       healthchecking  task by only spawning one healthchecking where multiple\n       virtual server declaration will spawn  a  dedicated  healthchecker  for\n       every real server which will waste system resources.\n\n       Any  combination  of IP addresses, IP address ranges and firewall marks\n       can be used. Use of this option is intended for very large LVSs.\n\n       The syntax for virtual_server_group is :\n\n       virtual_server_group <STRING> {\n           # Virtual IP Address and Port\n           <IPADDR> [<PORT>]\n           <IPADDR> [<PORT>]\n           ...\n           # <IPADDR RANGE> has the form\n           # XXX.YYY.ZZZ.WWW-VVV eg 192.168.200.1-10\n           # range includes both .1 and .10 address\n           <IPADDR RANGE> [<PORT>] # VIP range [VPORT]\n           <IPADDR RANGE> [<PORT>]\n           ...\n           # Firewall Mark (fwmark)\n           fwmark <INTEGER>\n           fwmark <INTEGER>\n           ...\n       }\n\nVirtual server(s)\n       A virtual_server can be a declaration of one of  <IPADDR>\n       [<PORT>]  ,  fwmark  <INTEGER> or\n       group <STRING>\n\n       The syntax for virtual_server is :\n\n       virtual_server <IPADDR> [<PORT>]  |\n       virtual_server fwmark <INTEGER> |\n       virtual_server group <STRING> {\n           # LVS scheduler\n           lvs_sched rr|wrr|lc|wlc|lblc|sh|mh|dh|fo|ovf|lblcr|sed|nq\n\n           # Enable hashed entry\n           hashed\n           # Enable flag-1 for scheduler (-b flag-1 in ipvsadm)\n           flag-1\n           # Enable flag-2 for scheduler (-b flag-2 in ipvsadm)\n           flag-2\n           # Enable flag-3 for scheduler (-b flag-3 in ipvsadm)\n           flag-3\n           # Enable sh-port for sh scheduler (-b sh-port in ipvsadm)\n           sh-port\n           # Enable sh-fallback for sh scheduler  (-b sh-fallback in ipvsadm)\n           sh-fallback\n           # Enable mh-port for mh scheduler (-b mh-port in ipvsadm)\n           mh-port\n           # Enable mh-fallback for mh scheduler  (-b mh-fallback in ipvsadm)\n           mh-fallback\n           # Enable One-Packet-Scheduling for UDP (-O in ipvsadm)\n           ops\n\n           # Default LVS forwarding method\n           lvs_method NAT|DR|TUN\n           # LVS persistence engine name\n           persistence_engine <STRING>\n           # LVS persistence timeout in seconds, default 6 minutes\n           persistence_timeout [<INTEGER>]\n           # LVS granularity mask (-M in ipvsadm)\n           persistence_granularity <NETMASK>\n           # L4 protocol\n           protocol TCP|UDP|SCTP\n           # If VS IP address is not set,\n           # suspend healthchecker's activity\n           ha_suspend\n\n           # Send email notification during quorum up/down transition,\n           # using addresses in global_defs above (default no,\n           # unless global smtp_alert/smtp_alert_checker set)\n           smtp_alert <BOOL>\n\n           # Default VirtualHost string for HTTP_GET or SSL_GET\n           # eg virtualhost www.firewall.loc\n           # Overridden by virtualhost config of real server or checker\n           virtualhost <STRING>\n\n           # On daemon startup assume that all RSs are down\n           # and healthchecks failed. This helps to prevent\n           # false positives on startup. Alpha mode is\n           # disabled by default.\n           alpha\n\n           # On daemon shutdown consider quorum and RS\n           # down notifiers for execution, where appropriate.\n           # Omega mode is disabled by default.\n           omega\n\n           # Minimum total weight of all live servers in\n           # the pool necessary to operate VS with no\n           # quality regression. Defaults to 1.\n           quorum <INTEGER>\n\n           # Tolerate this much weight units compared to the\n           # nominal quorum, when considering quorum gain\n           # or loss. A flap dampener. Defaults to 0.\n           hysteresis <INTEGER>\n\n           # Script to execute when quorum is gained.\n           quorum_up <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # Script to execute when quorum is lost.\n           quorum_down <STRING>|<QUOTED-STRING> [username [groupname]]\n\n           # IP family for a fwmark service (optional)\n           ip_family inet|inet6\n\n           # setup realserver(s)\n\n           # RS to add to LVS topology when the quorum isn't achieved.\n           #  If a sorry server is configured, all real servers will\n           #  be brought down when the quorum is not achieved.\n           sorry_server <IPADDR> [<PORT>]\n           # applies inhibit_on_failure behaviour to the sorry_server\n           sorry_server_inhibit\n           # Sorry server LVS forwarding method\n           sorry_server_lvs_method NAT|DR|TUN\n\n           # Optional connection timeout in seconds.\n           # The default is 5 seconds\n           connect_timeout <TIMER>\n\n           # Retry count to make additional checks if check\n           # of an alive server fails. Default: 1 unless specified below\n           retry <INTEGER>\n\n           # delay before retry after failure\n           delay_before_retry <TIMER>\n\n           # Optional random delay to start the initial check\n           # for maximum N seconds.\n           # Useful to scatter multiple simultaneous\n           # checks to the same RS. Enabled by default, with\n           # the maximum at delay_loop. Specify 0 to disable\n           warmup <TIMER>\n\n           # delay timer for checker polling\n           delay_loop <TIMER>\n\n           # Set weight to 0 when healthchecker detects failure\n           inhibit_on_failure\n\n           # one entry for each realserver\n           real_server <IPADDR> [<PORT>] {\n               # relative weight to use, default: 1\n               weight <INTEGER>\n               # LVS forwarding method\n               lvs_method NAT|DR|TUN\n\n               # Script to execute when healthchecker\n               # considers service as up.\n               notify_up <STRING>|<QUOTED-STRING> [username [groupname]]\n               # Script to execute when healthchecker\n               # considers service as down.\n               notify_down <STRING>|<QUOTED-STRING> [username [groupname]]\n\n               # maximum number of connections to server\n               uthreshold <INTEGER>\n               # minimum number of connections to server\n               lthreshold <INTEGER>\n\n               # Send email notification during state transition,\n               # using addresses in global_defs above (default yes,\n               # unless global smtp_alert/smtp_alert_checker set)\n               smtp_alert <BOOL>\n\n               # Default VirtualHost string for HTTP_GET or SSL_GET\n               # eg virtualhost www.firewall.loc\n               # Overridden by virtualhost config of a checker\n               virtualhost <STRING>\n\n               alpha <BOOL>                    # see above\n\t       connect_timeout <TIMER>         # see above\n               retry <INTEGER>                 # see above\n               delay_before_retry <TIMER>      # see above\n               warmup <TIMER>                  # see above\n               delay_loop <TIMER>              # see above\n               inhibit_on_failure <BOOL>       # see above\n               log_all_failures <BOOL>         # log all failures when checker up\n\n               # healthcheckers. Can be multiple of each type\n               # HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|DNS_CHECK|MISC_CHECK|BFD_CHECK\n\n               # All checkers have the following options, except MISC_CHECK\n               # which only has options alpha onwards, and BFD_CHECK which has none\n               # of the standard options:\n               CHECKER_TYPE {\n                   # ======== generic connection options\n                   # Optional IP address to connect to.\n                   # The default is the realserver IP\n                   connect_ip <IPADDR>\n\n                   # Optional port to connect to\n                   # The default is the realserver port\n                   connect_port <PORT>\n\n                   # Optional address to use to\n                   # originate the connection\n                   bindto <IPADDR>\n\n                   # Optional interface to use; needed if\n                   # the bindto address is IPv6 link local\n                   bind_if <IFNAME>\n\n                   # Optional source port to\n                   # originate the connection from\n                   bind_port <PORT>\n\n                   # Optional fwmark to mark all outgoing\n                   # checker packets with\n                   fwmark <INTEGER>\n\n                   alpha <BOOL>                    # see above\n\t\t   connect_timeout <TIMER>         # see above\n                   retry <INTEGER>                 # see above\n                   delay_before_retry <TIMER>      # see above\n                   warmup <TIMER>                  # see above\n                   delay_loop <TIMER>              # see above\n                   inhibit_on_failure <BOOL>       # see above\n               }\n\n               # The following options are additional checker specific\n\n               # HTTP and SSL healthcheckers\n               HTTP_GET|SSL_GET {\n                   # An url to test\n                   # can have multiple entries here\n                   url {\n                     #eg path / , or path /mrtg2/\n                     path <STRING>\n                     # healthcheck needs status_code\n                     # or status_code and digest\n                     # Digest computed with genhash\n                     # eg digest 9b3a0c85a887a256d6939da88aabd8cd\n                     digest <STRING>\n                     # status code returned in the HTTP header\n                     # eg status_code 200. Default is any 2xx value\n                     status_code <INTEGER>\n                     # VirtualHost string. eg virtualhost www.firewall.loc\n                     # If not set, uses virtualhost from real or virtual server\n                     virtualhost <STRING>\n                     # Regular expression to search returned data against.\n                     # A failure to match causes the check to fail.\n                     regex <STRING>\n                     # Reverse the sense of the match, so a match of the\n                     # returned text causes the check to fail.\n                     regex_no_match\n                     # Space separated list of options for regex.\n                     #  See man pcre2api for a description of the options.\n                     #  The following option are supported:\n                     #   allow_empty_class alt_bsux auto_callout caseless\n                     #   dollar_endonly dotall dupnames extended firstline\n                     #   match_unset_backref multiline never_ucp never_utf\n                     #   no_auto_capture no_auto_possess no_dotstar_anchor\n                     #   no_start_optimize ucp ungreedy utf never_backslash_c\n                     #   alt_circumflex alt_verbnames use_offset_limit\n                     regex_options OPTIONS \n                     # For complicated regular expressions a larger stack\n                     #   may be needed, and this allows the start and maximum\n                     #   sizes in bytes to be specified. For more details see\n                     #   the documentation for pcre2_jit_stack_create()\n                     regex_stack <START> <MAX>\n                     # The minimum offset into the returned data to start\n                     #   checking for the regex pattern match. This can save\n                     #   processing time if the returned data is large.\n                     regex_min_offset <OFFSET>\n                     # The maximum offset into the returned data for the\n                     #   start of the subject match.\n                     regex_max_offset <OFFSET>\n                   }\n               }\n\n               SSL_GET {\n                   # when provided, send Server Name Indicator during SSL handshake\n                   enable_sni\n               }\n\n               # TCP healthchecker\n               TCP_CHECK {\n                   # No additional options\n               }\n\n               # SMTP healthchecker\n               SMTP_CHECK {\n                   # Optional string to use for the SMTP HELO request\n                   helo_name <STRING>|<QUOTED-STRING>\n               }\n\n               # DNS healthchecker\n               DNS_CHECK {\n                   # The retry default is 3.\n\n                   # DNS query type\n                   #   A|NS|CNAME|SOA|MX|TXT|AAAA\n                   # The default is SOA\n                   type <STRING>\n\n                   # Domain name to use for the DNS query\n                   # The default is . (dot)\n                   name <STRING>\n               }\n\n               # MISC healthchecker, run a program\n               MISC_CHECK {\n                   # The retry default is 0.\n\n                   # External script or program\n                   misc_path <STRING>|<QUOTED-STRING>\n                   # Script execution timeout\n                   misc_timeout <INTEGER>\n\n                   # If set, the exit code from healthchecker is used\n                   # to dynamically adjust the weight as follows:\n                   #   exit status 0: svc check success, weight\n                   #     unchanged.\n                   #   exit status 1: svc check failed.\n                   #   exit status 2-255: svc check success, weight\n                   #     changed to 2 less than exit status.\n                   #   (for example: exit status of 255 would set\n                   #     weight to 253)\n                   # NOTE: do not have more than one dynamic MISC_CHECK per real_server.\n                   misc_dynamic\n\n                   # Specify the username/groupname that the script should\n                   #   be run under.\n                   # If GROUPNAME is not specified, the group of the user\n                   #   is used\n                   user USERNAME [GROUPNAME]\n               }\n\n               # BFD instance name to check\n               BFD_CHECK {\n                   name <STRING>\n               }\n           }\n       }\n\n       # Parameters used for SSL_GET check.\n       # If none of the parameters are specified, the SSL context\n       # will be auto generated.\n       SSL {\n           # Password\n           password <STRING>\n           # CA file\n           ca <STRING>\n           # Certificate file\n           certificate <STRING>\n           # Key file\n           key <STRING>\n       }\n\nADVANCED CONFIGURATION\n       Configuration  parser  has  been  extended to support advanced features\n       such as conditional configuration  and  parameter  substitution.  These\n       features are very usefull for any scripted env where configuration tem-\n       plate are generated (datacenters).\n\nConditional configuration and configuration id\n       The config-id defaults to the first part of the node name  as  returned\n       by uname, and can be overridden with the -i or --config-id command line\n       option.\n\n       Any configuration line starting with '@' is a conditional configuration\n       line.   The word immediately following (i.e. without any space) the '@'\n       character is compared against the config-id, and if they  don't  match,\n       the configuration line is ignored.\n\n       Alternatively,  '@^'  is  a negative comparison, so if the word immedi-\n       ately following does NOT match the config-id, the configuration line IS\n       included.\n\n       The  purpose of this is to allow a single configuration file to be used\n       for multiple systems, where the only differences are likely to  be  the\n       router_id,  vrrp  instance priorities, and possibly interface names and\n       unicast addresses.\n\n       For example:\n\n           global_defs {\n               @main   router_id main_router\n               @backup router_id backup_router\n           }\n           ...\n           vrrp_instance VRRP {\n               ...\n               @main    unicast_src_ip 1.2.3.4\n               @backup  unicast_src_ip 1.2.3.5\n               @backup2 unicast_src_ip 1.2.3.6\n               unicast_peer {\n                   @^main    1.2.3.4\n                   @^backup  1.2.3.5\n                   @^backup2 1.2.3.6\n               }\n               ...\n           }\n\n       If keepalived is invoked with -i main, then the router_id will  be  set\n       to  main_router,  if invoked with -i backup, then backup_router, if not\n       invoked with -i, or with -i anything else, then the router_id will  not\n       be set. The unicast peers for main will be 1.2.3.5 and 1.2.3.6.\n\nParameter substitution\n       Substitutable  parameters  can  be specified. The format for defining a\n       parameter is:\n\n       $PARAMETER=VALUE\n\n       where there must be no space before the '='  and  only  whitespace  may\n       preceed to '$'.  Empty values are allowed.\n\n       Parameter  names  can be made up of any combination of A-Za-z0-9 and _,\n       but cannot start with a digit. Parameter names starting with an  under-\n       score  should  be considered reserved names that keepalived will define\n       for various pre-defined options.\n\n       After a parameter is defined, any occurrence of $PARAMETER followed  by\n       whitespace,  or  any occurrence of ${PARAMETER} (which need not be fol-\n       lowed by whitespace) will be replaced by VALUE.\n\n       Replacement is recursive, so that if a parameter value itself  includes\n       a replaceable parameter, then after the first substitution, the parame-\n       ter in the value will then be replaced; the  substitution  is  done  at\n       replacement time and not at definition time, so for example:\n\n           $ADDRESS_BASE=10.2.${ADDRESS_BASE_SUB}\n           $ADDRESS_BASE_SUB=0\n           ${ADDRESS_BASE}.100/32\n           $ADDRESS_BASE_SUB=10\n           ${ADDRESS_BASE}.100/32\n\n           will produce:\n               10.2.0.100/32\n               10.2.10.100/32\n\n       Note   in   the  above  examples  the  use  of  both  ADDRESS_BASE  and\n       ADDRESS_BASE_SUB required braces ({}) since  the  parameters  were  not\n       followed  by  whitespace  (after  the first substitution which produced\n       10.2.${ADDRESS_BASE_SUB}.100/32 the parameter is still not followed  by\n       whitespace).\n\n       If  a  parameter is not defined, it will not be replaced at all, so for\n       example ${UNDEF_PARAMETER} will remain in the configuration  if  it  is\n       undefined;  this  means that existing configuration that contains a '$'\n       character (for example in a script definition) will not be  changed  so\n       long as no new parameter definitions are added to the configuration.\n\n       Parameter substitution works in conjunction with conditional configura-\n       tion.  For example:\n\n           @main $PRIORITY=240\n           @backup $PRIORITY=200\n           ...\n           vrrp_instance VI_0 {\n               priority $PRIORITY\n           }\n\n           will produce:\n               ...\n               vrrp_instance VI_0 {\n                   priority 240\n               }\n               if the config_id is main.\n\n           $IF_MAIN=@main\n           $IF_MAIN priority 240\n\n           will produce:\n               priority 240\n               if the config_id is main and nothing if the config_id is not main,\n               although why anyone would want to use this rather than simply the\n               following is not known (but still possible):\n                   @main priority 240\n\n       Multiline definitions are also supported, but when used there  must  be\n       nothing on the line after the parameter name. A multiline definition is\n       specified by ending each line except the last with a '\\' character.\n\n       Example:\n           $INSTANCE= \\\n           vrrp_instance VI_${NUM} { \\\n               interface eth0.${NUM} \\\n               use_vmac vrrp${NUM}.1 \\\n               virtual_router_id 1 \\\n               @high priority 130 \\\n               @low priority 120 \\\n               advert_int 1 \\\n               virtual_ipaddress { \\\n                   10.0.${NUM}.254/24 \\\n               } \\\n               track_script { \\\n                   offset_instance_${NUM} \\\n               } \\\n           }\n\n           $NUM=0\n           $INSTANCE\n\n           $NUM=1\n           $INSTANCE\n\n       The use of multiline definitions can be nested.\n\n       Example:\n           $RS= \\\n           real_server 192.168.${VS_NUM}.${RS_NUM} 80 { \\\n               weight 1 \\\n               inhibit_on_failure \\\n               smtp_alert \\\n               MISC_CHECK { \\\n                   misc_path \"${_PWD}/scripts/vs.sh RS_misc.${INST}.${VS_NUM}.${RS_NUM}.0 10.0.${VS_NUM}.4:80->192.168.${VS_NUM}.${RS_NUM}:80\" \\\n               } \\\n\n               MISC_CHECK { \\\n                   misc_path \"${_PWD}/scripts/vs.sh RS_misc.${INST}.${VS_NUM}.${RS_NUM}.1 10.0.${VS_NUM}.4:80->192.168.${VS_NUM}.${RS_NUM}:80\" \\\n               } \\\n\n               notify_up \"${_PWD}/scripts/notify.sh RS_notify.${INST}.${VS_NUM}.${RS_NUM} UP 10.0.${VS_NUM}.4:80->192.168.${VS_NUM}.${RS_NUM}:80\" \\\n\n               notify_down \"${_PWD}/scripts/notify.sh RS_notify.${INST}.${VS_NUM}.${RS_NUM} DOWN 10.0.${VS_NUM}.4:80->192.168.${VS_NUM}.${RS_NUM}:80\" \\\n\n           }\n\n           $VS= \\\n           virtual_server 10.0.${VS_NUM}.4 80 { \\\n               quorum 2 \\\n               quorum_up \"${_PWD}/scripts/notify.sh VS_notify.${INST} UP 10.0.${VS_NUM}.4:80\" \\\n               quorum_down \"${_PWD}/scripts/notify.sh VS_notify.${INST} DOWN 10.0.${VS_NUM}.4:80\" \\\n               $RS_NUM=1 \\\n               $RS \\\n               $RS_NUM=2 \\\n               $RS \\\n               $RS_NUM=3 \\\n               $RS \\\n           }\n\n           $VS_NUM=0\n           $ALPHA=alpha\n           $VS\n\n           $VS_NUM=1\n           $ALPHA=\n           $VS\n\n       The above will create 2 virtual servers, each with 3 real servers\n\nPre-defined definitions\n       The following pre-defined definitions are defined:\n\n       ${_PWD} : The directory of the  current  configuration\n       file (this can be changed if using the include directive).\n       ${_INSTANCE} : The instance name (as defined by the -i\n       option, defaults to hostname).\n       ${_RANDOM  [MIN [MAX]]} : This is replaced by a random\n       integer in the range [MIN, MAX], where MIN and MAX  are  optional  non-\n       negative integers. Defaults are MIN=0 and MAX=32767.\n\n       Additional pre-defined definitions will be added as their need is iden-\n       tified.   It  will  normally be quite straightforward to add additional\n       pre-defined definitions, so if you need one, or have a  good  idea  for\n       one,          then          raise          an          issue         at\n       https://github.com/acassen/keepalived/issues requesting it.\n\nSequence blocks\n       A line starting ~SEQ(var, start, step, end) will cause the remainder of\n       the line to be processed multiple times, with  the  variable  $var  set\n       initially  to  start, and then $var will be incremented by step repeat-\n       edly, terminating when it is greater than end. step may be omitted,  in\n       which  case it defaults to 1 or -1, depending on whether end is greater\n       or less than start. start  may  also  be  omitted,  in  which  case  it\n       defaults to 1 if end > 0 or -1 if end < 0. so, for example:\n\n           ~SEQ(SUBNET, 0, 3) ip_address 10.0.$SUBNET.1\n\n           would produce:\n               ip_address 10.0.0.1\n               ip_address 10.0.1.1\n               ip_address 10.0.2.1\n               ip_address 10.0.3.1\n\n       There can be multiple ~SEQ elements on a line, so for example:\n\n           $VI4= \\\n           vrrp_track_file offset_instance_4.${IF}.${NUM}.${ID} { \\\n               file \"${_PWD}/679/track_files/4.${IF}.${NUM}.${ID}\" \\\n               weight -100 \\\n           } \\\n           vrrp_instance vrrp4.${IF}.${NUM}.${ID} { \\\n               interface bond${IF}.${NUM} \\\n               use_vmac vrrp4.${IF}.${NUM}.${ID} \\\n               virtual_router_id ${ID} \\\n               priority 130 \\\n               virtual_ipaddress { \\\n                   10.${IF}.${NUM}.${ID}/24 \\\n               } \\\n               track_file { \\\n                   offset_instance_4.${IF}.${NUM}.${ID} \\\n               } \\\n           }\n\n           ~SEQ(IF,0,7) ~SEQ(NUM,0,31) ~SEQ(ID,1,254) $VI4\n\n           will produce 65024 vrrp instances with names from vrrp4.0.0.1 through to\n           vrrp4.7.31.254.\n\n\nAUTHORS\n       Initial by Joseph Mack. Extensive updates by Alexandre Cassen & Quentin\n       Armitage.\n\nSEE ALSO\n       ipvsadm(8), ip --help.\n\n\n\nKeepalived                        2018-11-08                keepalived.conf(5)\n```\n\n","tags":["keepalived"]},{"title":"【shell】Shell常用脚本集合（2）","url":"/2019/03/19/【shell】Shell常用脚本集合（2）/","content":"\n### 批量修改文件后缀名\n\n```shell\n#!/bin/bash\n\nread -p \"old extension:\" oldext\nread -p \"new extension:\" newext\nread -p \"The directory:\" dir\ncd $dir\n\nfor file in $(ls $dir | grep .$oldext)\n        do\n        name=$(ls $file | cut -d. -f1)\n        mv $file ${name}.$newext\n        echo \"$name.$oldext ====> $name.$newext\"\n        done\necho \"all files has been modified.\"\n```\n\n```shell\n#!/bin/sh\n \necho \"input what suffix will be replaced :\"\nread SUFFIX_SRC\necho \"input what suffix of file to rename to:\"\nread SUFFIX_DST\n \nfor i in *.$SUFFIX_SRC\ndo\n    if [ -e $i ]; then\n        #echo \"mv $i to ${i%.*}.$SUFFIX_DST\"\n        #mv $i ${i%.*}.$SUFFIX_DST\n        echo \"mv $i to `basename $i .$SUFFIX_SRC`.$SUFFIX_DST\"\n        mv $i `basename $i .$SUFFIX_SRC`.$SUFFIX_DST\n    else\n        echo \"file does not exist.\"\n        exit -1\n    fi\ndone\necho \"all files has been modified.\"\n```\n\n### 禁止使用root账号运行\n\n```shell\nif [ $UID -eq 0 ]; then\n\techo \"禁止以root帐号运行此脚本\"\n\texit 1\nfi\n```\n\n### 禁止使用普通账号运行\n\n```shell\nif [ $UID -ne 0 ]; then\n\techo \"请以root帐号运行此脚本\"\n\texit 1\nfi\n```\n\n### 获取运行脚本的所在目录\n\n```shell\nSCRIPTPATH=$(dirname $(readlink -f $0))\n```\n\n### 多角色安装，交互询问\n\n```shell\nread -p \"请选择该服务器的角色 (t:tracker, s:storage, b:both) [t/s/b]:\" installRole\nwhile ! echo $installRole | egrep -q '^[tsbTSB]$'\ndo\n\tread -p \"输入错误，请重新输入 (t:tracker, s:storage, b:both) [t/s/b]:\" installRole\ndone\n```\n\n### 解压缩（*.tar.gz）\n\n```shell\n#压缩\ntar zcvf file.tar.gz file/\n#解压到当前目录\ntar xzvf file.tar.gz\n#解压到指定目录\ntar xzvf file.tar.gz -C /tmp\n```\n\n### RPM常见操作\n\n```shell\nrpm -ivh/e/U\n#不考虑依赖\nrpm -ivh/e/U --nodeps\n#不考虑依赖，并强制\nrpm -ivh/e/U --nodep --force\n\nyum install\n#本地安装，没有的包会用源安装\nyum localinstall\n#组安装\nyum groupinstall\n#会移除依赖\nyum remove\n#查询命令来源那个包\nyum provides\n```\n\n### 10个环境变量\n\n```shell\n变量名称\t\t\t作用\nHOME\t\t\t用户的家目录（即主目录）\nSHELL\t\t\t用户在使用的shell解释器名称\nHISTSIZE\t\t输出的历史命令记录条数\nHISTFILESIZE\t保存的历史命令记录条数\nMAIL\t\t\t邮件保存路径\nLANG\t\t\t系统语言、语系名称\nRANDOM\t\t\t生成一个随机数字\nPS1\t\t\t\tbash解释器的提示符\nPATH\t\t\t定义解释器搜索用户执行命令的路径\nEDITOR\t\t\t用户默认的文本编辑器\n\nPS: \n1.可以用 env 命令来查看当前linux系统中所有的环境变量； \n2.用export命令可以把linux的一般变量转换成全局变量。\n```\n\n### 设置环境变量\n\n```shell\n#指明头文件的搜索路径\nexport C_INCLUDE_PATH=$CURRENTPATH/include\n#指明库搜索路径\nexport LD_LIBRARY_PATH=/home/admin/fdfs/lib64\n```\n\n### 常用文件操作\n\n```shell\n#替换\nsed -i '/^WorkingDirectory=/cWorkingDirectory='$CURRENTPATH'/realserver' $CURRENTPATH/realserver.service\n#删除\nsed -i '/^tracker_server=/d' $TARGET_CONF_PATH/storage.conf\n#追加\nsed -i '$a tracker_server='$ip $TARGET_CONF_PATH/storage.conf\n```\n\n### 移除32位软件包\n\n```shell\nrpm -e --nodeps *.i?86\n```\n\n### 禁止yum安装32位的软件包\n\n```shell\nif ! egrep -q '^exclude=.*' /etc/yum.conf; then\n\techo \"exclude=*.i?86\" >> /etc/yum.conf\nfi\n```\n\n### 禁用usb存储\n\n```shell\necho \"blacklist usb-storage\" > /etc/modprobe.d/blacklist-usbstorage\n```\n\n### 主机连通性测试\n\n```shell\necho \"Tracker Server配置示例：192.168.1.2:22122 192.168.1.3:22122 ...\"\nREPLY=\nwhile true\ndo\n    msg='输入Tracker Server地址，多个值用空格隔开：'\n    if [ \"$REPLY\" ]; then\n        echo \"正在检测网络连通性\"\n        failedHost=\n        for host in $REPLY\n        do\n        #if ! echo \"HEAD / HTTP/1.0\" >/dev/tcp/${host/://}; then\n        if ! echo \"HEAD / HTTP/1.0\" >/dev/tcp/${host%:*}/22; then\n            failedHost=$host\n            break\n        fi\n        done\n        if [ $failedHost ]; then\n            prompt=\"与$failedHost的网络不通，请重新$msg\"\n        else\n            break\n        fi\n    else\n    \tprompt=\"请$msg\"\n    fi\n    read -p \"$prompt\"\ndone\n```\n\n### 从变量中切割字符串\n\n```shell\n#定义变量\n[admin@localhost ~]$ str=1.2.3.4:5\n#获取长度\n[admin@localhost ~]$ echo ${#str}\n9\n#替换字符\n[admin@localhost ~]$ echo ${str/://}\n1.2.3.4/5\n#从左开始删除至第一个匹配字符\n[admin@localhost ~]$ echo ${str#*.}\n2.3.4:5\n[admin@localhost ~]$ echo ${str##*.}\n4:5\n#从右开始删除至匹配到的第一个字符\n[admin@localhost ~]$ echo ${str%:*}\n1.2.3.4\n[admin@localhost ~]$ echo ${str%.*}\n1.2.3\n[admin@localhost ~]$ echo ${str%%.*}\n1\n[root@localhost ~]$ echo ${str:3}\n.3.4:5\n[root@localhost ~]$ echo ${str:0:3}\n1.2\n[root@localhost ~]$ echo ${str:0-3}\n4:5\n[root@localhost ~]$ echo ${str:0-3:1}\n4\n\n```\n\n### 远程和控制台登录添加登录失败超时控制\n\n```shell\nfor file in \"/etc/pam.d/sshd\" \"/etc/pam.d/login\"\ndo\n\tif ! egrep -q '^auth\\s*required\\s*pam_tally2.*' $file; then\n\t\tsed -i \"1 aauth       required     pam_tally2.so deny=3 unlock_time=28800 even_deny_root root_unlock_time=3600\" $file\n\tfi\ndone\n```\n\n### 新建普通用户并设置随机密码\n\n```shell\nif ! id admin &>/dev/null;then\n\tuseradd admin\n\techo \"为admin设置随机8位密码\"\n\tMATRIX='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~!@#$%^&*()_+=-'\n\tLENGTH=12\n\twhile [ \"${n:=1}\" -le \"$LENGTH\" ]\n\tdo\n\t\tPASS=\"$PASS${MATRIX:$(($RANDOM%${#MATRIX})):1}\"\n\t\tlet n+=1\n\tdone\n\techo $PASS | passwd --stdin admin\n\techo $PASS >/root/adminPassword.txt\nfi\n```\n\n### ACL规则设置、查看、取消\n\n- 除特权用户，所属某用户文件/夹不能被其他用户删除\n- 暂时总结：删除是从右到左询问权限，新建是从左到右询问权限\n\n- 使用 -d 参数将默认权限延伸到新产生的文件夹，权限延伸必须是连续的，也就是父目录必须有默认权限设置\n\n- 如果没有设置任何ACL权限，使用 -d 参数设置的默认权限最大为基础权限\n- 如果设置过ACL权限，使用 -d 参数设置的默认权限最大为已设置的ACL权限\n\n```shell\n#先使用 -m 设置权限，在使用 -d 将设置的权限延伸到新产生的文件或文件夹\n#文件或文件夹设置ACL规则\nsetfacl -m u:admin:rwx file\nsetfacl -m u:admin:rwx fodler/\n#设置默认ACL规则，只对文件夹有效，可延伸到新建的子文件夹\nsetfacl -d -m u:admin:rwx fodler/\n#递归设置，只对已存在的文件和文件夹有效\nsetfacl -R -m u:admin:rwx fodler/\n\n#查看ACL规则\ngetfacl file\ngetfacl fodler/\n\n#删除文件的acl规则\nsetfacl -x u:admin file\n#删除所有扩展的acl规则，基本的acl规则(所有者，群组，其他）将被保留.\nsetfacl -b fodler/\n```\n\n### 向上递归设置ACL\n\n```shell\n#脚本必须位于用户HOME目录下\n#!/bin/bash\n\nif [ $UID -eq 0 ]; then\n        echo \"禁止以root帐号运行此脚本\"\n        exit 1\nfi\n\nCURRENTPATH=$(dirname $(readlink -f $0))\n\nif ! id activemq &>/dev/null; then\n\tsudo useradd -r -s /bin/false activemq\n\tUPPERPATH=$CURRENTPATH\n\twhile true\n\tdo\n\t\tif [ \"$HOME\" == \"$UPPERPATH\" ]; then\n\t\t\tbreak\n\t\tfi\n\t\tUPPERPATH=$(dirname $UPPERPATH)\n\t\tsetfacl -m u:admin:rwx $UPPERPATH\n\t\tsetfacl -d -m u:admin:rwx $UPPERPATH\n\t\tsetfacl -m u:activemq:rwx $UPPERPATH\n\t\tsetfacl -d -m u:activemq:rwx $UPPERPATH\n\tdone\n\tsetfacl -R -m u:admin:rwx $CURRENTPATH\n\tsetfacl -dR -m u:admin:rwx $CURRENTPATH\n\tsetfacl -R -m u:activemq:rwx $CURRENTPATH\n\tsetfacl -dR -m u:activemq:rwx $CURRENTPATH\nfi\n```\n\n### 防火墙常用设置\n\n```shell\n#禁止外部连接，只开放ssh\nfirewall-cmd --set-default-zone=drop\nfirewall-cmd --load-zone-defaults=drop --permanent\nfirewall-cmd --permanent --zone=drop --add-port=22/tcp\nfirewall-cmd --reload\n\n#firewall-offline-cmd is an offline command line client of the firewalld daemon. It should be used only if the firewalld service is not running. For example to migrate from system-config-firewall/lokkit or in the install environment to configure firewall settings with kickstart.\nfirewall-offline-cmd --set-default-zone=drop\nfirewall-offline-cmd --load-zone-defaults=drop\nfirewall-offline-cmd --add-port=22/tcp\n\n#keepalived配置规则开放\nfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT\n```\n\n### 自动交互\n\n```shell\n[root@localhost ~]# echo -e '123456\\n123456'|passwd tom\nChanging password for user tom.\nNew password: BAD PASSWORD: The password is shorter than 8 characters\nRetype new password: passwd: all authentication tokens updated successfully.\n[root@localhost ~]# echo 123456|passwd --stdin tom\nChanging password for user tom.\npasswd: all authentication tokens updated successfully.\n[root@localhost ~]# passwd tom <<EOF\n123456\n123456\nEOF\nChanging password for user tom.\nNew password: BAD PASSWORD: The password is shorter than 8 characters\nRetype new password: passwd: all authentication tokens updated successfully.\n[root@localhost ~]#\n```\n\n### 模板写入\n\n```shell\n#!/bin/sh\n\na=1\nb=2\n\ncat > t1.txt <<EOF\na=$a\nb=$b\nEOF\n\ncat <<EOF > t2.txt\na=$a\nb=$b\nEOF\n\n```\n\n### Sed常用操作\n\n```shell\n#第一行前面添加（1i）\nsed -i '1istr' file\n#第一行后面添加（1a）\nsed -i '1astr' file\n#替换第一行（1c）\nsed -i '1cstr' file\n#删除第一行（1d）\nsed -i '1d' file\n#末尾追加（$a）\nsed -i '$astr' file\n#匹配替换开头是a的字符为str\nsed -i 's/^a/str/' file\n#匹配全局替换\nsed -i 's/^a/str/g' file\n#匹配行前面添加（1i）\nsed -i '/^a/istr' file\n#匹配行后面添加（1a）\nsed -i '/^a/astr' file\n#替换匹配行（1c）\nsed -i '/^a/cstr' file\n#删除匹配行（1d）\nsed -i '/^a/d' file\n#删除文件中行首的空格\nsed -i 's/^[ \\t]*//' result.data \n#删除文件中行末空格：\nsed -i 's/[ \\t]*$//g' result.data\n#删除文件中所有的空格：\nsed -i s/[[:space:]]//g result.data\n#把文件中空格变为‘，’：\nsed -i 's/[ \\t]/,/g' result.data\n```\n\n","tags":["shell"]},{"title":"【tools】postfix发送邮件配置","url":"/2019/03/18/【tools】postfix发送邮件配置/","content":"\n### 简单配置及测试脚本\n\n```shell\n#!/bin/sh\n\nyum install cyrus-sasl-* -y\n\ncat >/etc/postfix/sasl_passwd <<EOF\n[smtp.abc.cn]:25   abc@163.cn:password\nEOF\npostmap /etc/postfix/sasl_passwd\nrm -f /etc/postfix/sasl_passwd \n\ncat >/etc/postfix/sender_canonical <<EOF\nroot abc@163.cn\nEOF\npostmap /etc/postfix/sender_canonical\nrm -f postmap /etc/postfix/sender_canonical\n\ncat >>/etc/postfix/main.cf <<EOF\n#指定默认的邮件发送服务器\nrelayhost = [smtp.abc.cn]:25\n#激活sasl认证\nsmtp_sasl_auth_enable = yes\n#指定sasl密码配置文件\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\n#非匿名登录\nsmtp_sasl_security_options = noanonymous\n#指定认证类型 （提示：需要yum安装cyrus-sasl-*组件，否则发邮件时会报错：no mechanism available）\nsmtp_sasl_type = cyrus\n#linux用户与发件人的对应关系配置文件\nsender_canonical_maps = hash:/etc/postfix/sender_canonical\nEOF\n\n\necho \"test mail\" | sendmail abc@163.cn\n#yum install mailx -y\necho \"邮件正文\" | mail -s 邮件主题 test@126.com \n\n```\n\n","tags":["tools","postfix"]},{"title":"【python】python2-dialog模块使用总结","url":"/2019/03/18/【python】python2-dialog使用总结/","content":"\n### 简单示例\n\n```python\n#!/usr/bin/env python\n\nimport locale\nfrom dialog import Dialog\n\n# This is almost always a good thing to do at the beginning of your programs.\nlocale.setlocale(locale.LC_ALL, '')\n\n# You may want to use 'autowidgetsize=True' here (requires pythondialog >= 3.1)\nd = Dialog(dialog=\"dialog\")\n# Dialog.set_background_title() requires pythondialog 2.13 or later\nd.set_background_title(\"My little program\")\n# For older versions, you can use:\n#   d.add_persistent_args([\"--backtitle\", \"My little program\"])\n\n# In pythondialog 3.x, you can compare the return code to d.OK, Dialog.OK or\n# \"ok\" (same object). In pythondialog 2.x, you have to use d.DIALOG_OK, which\n# is deprecated since version 3.0.0.\nif d.yesno(\"Are you REALLY sure you want to see this?\") == d.DIALOG_OK:\n    d.msgbox(\"You have been warned...\")\n\n    # We could put non-empty items here (not only the tag for each entry)\n    code, tags = d.checklist(\"What sandwich toppings do you like?\",\n                             choices=[(\"Catsup\", \"\",             False),\n                                      (\"Mustard\", \"\",            False),\n                                      (\"Pesto\", \"\",              False),\n                                      (\"Mayonnaise\", \"\",         True),\n                                      (\"Horse radish\",\"\",        True),\n                                      (\"Sun-dried tomatoes\", \"\", True)],\n                             title=\"Do you prefer ham or spam?\",\n                             backtitle=\"And now, for something \"\n                             \"completely different...\")\n    if code == d.DIALOG_OK:\n        # 'tags' now contains a list of the toppings chosen by the user\n        pass\nelse:\n    code, tag = d.menu(\"OK, then you have two options:\",\n                       choices=[(\"(1)\", \"Leave this fascinating example\"),\n                                (\"(2)\", \"Leave this fascinating example\")])\n    if code == d.DIALOG_OK:\n        # 'tag' is now either \"(1)\" or \"(2)\"\n        pass\n```\n\n### 以mixform为例的参数解释\n\n```python\n# Dialog.mixedform(text, elements, height=0, width=0, form_height=0, **kwargs)\n\n# (label, yl, xl, item, yi, xi, field_length, input_length, attributes)\n# label is a string that will be displayed at row yl, column xl. item is a string giving the initial value for the field, which will be displayed at row yi, column xi (row and column numbers starting from 1).\n\n#attributes is an integer interpreted as a bit mask with the following meaning (bit 0 being the least significant bit):\nBit number\tMeaning\n0\tthe field should be hidden (e.g., a label)\n1\tthe field should be read-only (e.g., a password)\n# 经实践得0为label，1为password，与官网所述刚好相反\n\n# 一个字符代表一列\nd.mixedform('text',\n            [('one',1,1,'item',1,10,10,20,0),\n             ('passwd', 2, 1, '', 2, 10, 10, 20, 1)],\n            9,      #height 表格高度，比form_height多5，下面的操作按钮刚好正常显示\n            50,     #width 表格宽度\n            3)      #form_height 表格行数\n```\n\n","tags":["python","dialog"]},{"title":"【firewalld】Firewalld常用操作","url":"/2019/03/12/【firewalld】Firewalld常用操作/","content":"\n### Firewalld引入 Zone 的概念\n\n```shell\nfirewall-cmd --list-all-zones    #查看所有zone信息\n```\n\n- drop: 丢弃所有进入的包，而不给出任何响应\n\n- block: 拒绝所有外部发起的连接，允许内部发起的连接\n\n- public: 允许指定的进入连接\n\n- external: 同上，对伪装的进入连接，一般用于路由转发\n\n- dmz: 允许受限制的进入连接\n\n- work: 允许受信任的计算机被限制的进入连接，类似 workgroup\n\n- home: 同上，类似 homegroup\n\n- internal: 同上，范围针对所有互联网用户\n- trusted: 信任所有连接\n\n*参考链接：[防火墙（firewalld）端口转发](http://www.itlnmp.com/373.html)*\n\n### 端口开放与移除\n\n```shell\n# 添加端口\nfirewall-cmd --permanent --zone=<ZONE> --add-port=80/tcp\n# 移除端口\nfirewall-cmd --permanent --zone=<ZONE> --remove-port=80/tcp\n# 重启生效\nfirewall-cmd --reload\n# 罗列开放端口\nfirewall-cmd --list-ports\n```\n\n### IP伪装\n\n```shell\nfirewall-cmd --permanent --zone=<ZONE> --add-masquerade\n\nfirewall-cmd --permanent --zone=<ZONE> --add-rich-rule='rule family=ipv4 source address=192.168.122.0/24 masquerade'\n```\n\n### 端口转发\n\n```shell\nfirewall-cmd --permanent --zone=<ZONE> --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=192.168.122.7\n\nfirewall-cmd --permanent --zone=<ZONE> --add-rich-rule='rule family=ipv4 source address=192.168.122.0/24 forward-port port=80 to-port=8080 protocol=tcp accept'\n```\n\n\n\n### 一、firewalld 守护进程\n\nfirewall-cmd命令需要firewalld进程处于运行状态。我们可以使用systemctl status/start/stop/restart firewalld来控制这个守护进程。firewalld进程为防火墙提供服务。\n\n当我们修改了某些配置之后（尤其是配置文件的修改），firewall并不会立即生效。可以通过两种方式来激活最新配置`systemctl restart firewalld`和`firewall-cmd --reload`两种方式，前一种是重启firewalld服务，建议使用后一种“重载配置文件”。重载配置文件之后不会断掉正在连接的tcp会话，而重启服务则会断开tcp会话。\n\n### 二、控制端口/服务\n\n可以通过两种方式控制端口的开放，一种是指定端口号另一种是指定服务名。虽然开放http服务就是开放了80端口，但是还是不能通过端口号来关闭，也就是说通过指定服务名开放的就要通过指定服务名关闭；通过指定端口号开放的就要通过指定端口号关闭。还有一个要注意的就是指定端口的时候一定要指定是什么协议，tcp还是udp。知道这个之后以后就不用每次先关防火墙了，可以让防火墙真正的生效。\n\n```\n`firewall-cmd --add-service=mysql ``# 开放mysql端口``firewall-cmd --remove-service=http ``# 阻止http端口``firewall-cmd --list-services  ``# 查看开放的服务``firewall-cmd --add-port=3306``/tcp` `# 开放通过tcp访问3306``firewall-cmd --remove-port=80tcp ``# 阻止通过tcp访问3306``firewall-cmd --add-port=233``/udp`  `# 开放通过udp访问233``firewall-cmd --list-ports  ``# 查看开放的端口`\n```\n\n### 三、伪装IP\n\n防火墙可以实现伪装IP的功能，下面的端口转发就会用到这个功能。\n\n```\n`firewall-cmd --query-masquerade ``# 检查是否允许伪装IP``firewall-cmd --add-masquerade ``# 允许防火墙伪装IP``firewall-cmd --remove-masquerade``# 禁止防火墙伪装IP`\n```\n\n### 四、端口转发\n\n端口转发可以将指定地址访问指定的端口时，将流量转发至指定地址的指定端口。转发的目的如果不指定ip的话就默认为本机，如果指定了ip却没指定端口，则默认使用来源端口。\n\n如果配置好端口转发之后不能用，可以检查下面两个问题：\n\n- 比如我将80端口转发至8080端口，首先检查本地的80端口和目标的8080端口是否开放监听了\n- 其次检查是否允许伪装IP，没允许的话要开启伪装IP\n\n```\n`# 将80端口的流量转发至8080``firewall-cmd --add-forward-port=port=80:proto=tcp:toport=8080``# 将80端口的流量转发至``firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.1.0.1192.168.0.1``# 将80端口的流量转发至192.168.0.1的8080端口``firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1:toport=8080`\n```\n\n- 当我们想把某个端口隐藏起来的时候，就可以在防火墙上阻止那个端口访问，然后再开一个不规则的端口，之后配置防火墙的端口转发，将流量转发过去。\n- 端口转发还可以做流量分发，一个防火墙拖着好多台运行着不同服务的机器，然后用防火墙将不同端口的流量转发至不同机器。\n\n*参考链接：[CentOS 7下用firewall-cmd控制端口与端口转发详解](https://www.jb51.net/article/112698.htm)*","tags":["firewalld"]},{"title":"【ansible】Ansible学习笔记（1）","url":"/2019/03/10/【ansible】Ansible学习笔记（1）/","content":"\n## ansible 简介\n\n\n\n### ansible 是什么？\n\n　　ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。\n　　ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远\n程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。\n\n\n\n### ansible 特点\n\n1. 部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作；\n2. 默认使用SSH协议对设备进行管理；\n3. 有大量常规运维操作模块，可实现日常绝大部分操作；\n4. 配置简单、功能强大、扩展性强；\n5. 支持API及自定义模块，可通过Python轻松扩展；\n6. 通过Playbooks来定制强大的配置、状态管理；\n7. 轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；\n8. 提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。\n\n\n\n### ansible 架构图\n\n![img](https://images2017.cnblogs.com/blog/1204916/201712/1204916-20171205163000628-69838828.png)\n　　上图中我们看到的主要模块如下：\n\n> `Ansible`：Ansible核心程序。\n> `HostInventory`：记录由Ansible管理的主机信息，包括端口、密码、ip等。\n> `Playbooks`：“剧本”YAML格式文件，多个任务定义在一个文件中，定义主机需要调用哪些模块来完成的功能。\n> `CoreModules`：**核心模块**，主要操作是通过调用核心模块来完成管理任务。\n> `CustomModules`：自定义模块，完成核心模块无法完成的功能，支持多种语言。\n> `ConnectionPlugins`：连接插件，Ansible和Host通信使用\n\n\n\n## ansible 任务执行\n\n\n\n### ansible 任务执行模式\n\n　　Ansible 系统由控制主机对被管节点的操作方式可分为两类，即`adhoc`和`playbook`：\n\n- ad-hoc模式(点对点模式)\n  　　使用单个模块，支持批量执行单条命令。ad-hoc 命令是一种可以快速输入的命令，而且不需要保存起来的命令。**就相当于bash中的一句话shell。**\n- playbook模式(剧本模式)\n  　　是Ansible主要管理方式，也是Ansible功能强大的关键所在。**playbook通过多个task集合完成一类功能**，如Web服务的安装部署、数据库服务器的批量备份等。可以简单地把playbook理解为通过组合多条ad-hoc操作的配置文件。\n\n\n\n### ansible 执行流程\n\n![img](https://images2017.cnblogs.com/blog/1204916/201712/1204916-20171205162615738-1292598736.png)\n　　简单理解就是Ansible在运行时， 首先读取`ansible.cfg`中的配置， 根据规则获取`Inventory`中的管理主机列表， 并行的在这些主机中执行配置的任务， 最后等待执行返回的结果。\n\n\n\n### ansible 命令执行过程\n\n1. 加载自己的配置文件，默认`/etc/ansible/ansible.cfg`；\n2. 查找对应的主机配置文件，找到要执行的主机或者组；\n3. 加载自己对应的模块文件，如 command；\n4. 通过ansible将模块或命令生成对应的临时py文件(python脚本)， 并将该文件传输至远程服务器；\n5. 对应执行用户的家目录的`.ansible/tmp/XXX/XXX.PY`文件；\n6. 给文件 +x 执行权限；\n7. 执行并返回结果；\n8. 删除临时py文件，`sleep 0`退出；\n\n\n\n## ansible 配置详解\n\n\n\n### ansible 安装方式\n\n　　ansible安装常用两种方式，`yum安装`和`pip程序安装`。下面我们来详细介绍一下这两种安装方式。\n\n\n\n#### 使用 pip（python的包管理模块）安装\n\n　　首先，我们需要安装一个`python-pip`包，安装完成以后，则直接使用`pip`命令来安装我们的包，具体操作过程如下：\n\n```\n    yum install python-pip\n    pip install ansible\n```\n\n\n\n#### 使用 yum 安装\n\n　　yum 安装是我们很熟悉的安装方式了。我们需要先安装一个`epel-release`包，然后再安装我们的 ansible 即可。\n\n```\n    yum install epel-release -y\n    yum install ansible –y\n```\n\n\n\n### ansible 程序结构\n\n安装目录如下(yum安装)：\n　　配置文件目录：/etc/ansible/\n　　执行文件目录：/usr/bin/\n　　Lib库依赖目录：/usr/lib/pythonX.X/site-packages/ansible/\n　　Help文档目录：/usr/share/doc/ansible-X.X.X/\n　　Man文档目录：/usr/share/man/man1/\n\n\n\n### ansible配置文件查找顺序\n\n　　ansible与我们其他的服务在这一点上有很大不同，这里的配置文件查找是从多个地方找的，顺序如下：\n\n1. 检查环境变量`ANSIBLE_CONFIG`指向的路径文件(export ANSIBLE_CONFIG=/etc/ansible.cfg)；\n2. `~/.ansible.cfg`，检查当前目录下的ansible.cfg配置文件；\n3. `/etc/ansible.cfg`检查etc目录的配置文件。\n\n\n\n### ansible配置文件\n\n　　ansible 的配置文件为`/etc/ansible/ansible.cfg`，ansible 有许多参数，下面我们列出一些常见的参数：\n\n```\n    inventory = /etc/ansible/hosts      #这个参数表示资源清单inventory文件的位置\n    library = /usr/share/ansible        #指向存放Ansible模块的目录，支持多个目录方式，只要用冒号（：）隔开就可以\n    forks = 5       #并发连接数，默认为5\n    sudo_user = root        #设置默认执行命令的用户\n    remote_port = 22        #指定连接被管节点的管理端口，默认为22端口，建议修改，能够更加安全\n    host_key_checking = False       #设置是否检查SSH主机的密钥，值为True/False。关闭后第一次连接不会提示配置实例\n    timeout = 60        #设置SSH连接的超时时间，单位为秒\n    log_path = /var/log/ansible.log     #指定一个存储ansible日志的文件（默认不记录日志）\n```\n\n\n\n### ansuble主机清单\n\n　　在配置文件中，我们提到了资源清单，这个清单就是我们的主机清单，里面保存的是一些 ansible 需要连接管理的主机列表。我们可以来看看他的定义方式：\n\n```\n1、 直接指明主机地址或主机名：\n    ## green.example.com#\n    # blue.example.com#\n    # 192.168.100.1\n    # 192.168.100.10\n2、 定义一个主机组[组名]把地址或主机名加进去\n    [mysql_test]\n    192.168.253.159\n    192.168.253.160\n    192.168.253.153\n```\n\n　　需要注意的是，这里的组成员可以使用通配符来匹配，这样对于一些标准化的管理来说就很轻松方便了。\n　　我们可以根据实际情况来配置我们的主机列表，具体操作如下：\n\n```\n[root@server ~]# vim /etc/ansible/hosts\n    [web]\n    192.168.37.122\n    192.168.37.133\n```\n\n\n\n## ansible 常用命令\n\n\n\n### ansible 命令集\n\n> `/usr/bin/ansible`　　Ansibe AD-Hoc 临时命令执行工具，常用于临时命令的执行\n> `/usr/bin/ansible-doc` 　　Ansible 模块功能查看工具\n> `/usr/bin/ansible-galaxy`　　下载/上传优秀代码或Roles模块 的官网平台，基于网络的\n> `/usr/bin/ansible-playbook`　　Ansible 定制自动化的任务集编排工具\n> `/usr/bin/ansible-pull`　　Ansible远程执行命令的工具，拉取配置而非推送配置（使用较少，海量机器时使用，对运维的架构能力要求较高）\n> `/usr/bin/ansible-vault`　　Ansible 文件加密工具\n> `/usr/bin/ansible-console`　　Ansible基于Linux Consoble界面可与用户交互的命令执行工具\n\n　　其中，我们比较常用的是`/usr/bin/ansible`和`/usr/bin/ansible-playbook`。\n\n\n\n### ansible-doc 命令\n\n　　ansible-doc 命令常用于获取模块信息及其使用帮助，一般用法如下：\n\n```\n    ansible-doc -l              #获取全部模块的信息\n    ansible-doc -s MOD_NAME     #获取指定模块的使用帮助\n```\n\n　　我们也可以查看一下ansible-doc的全部用法：\n\n```\n[root@server ~]# ansible-doc\nUsage: ansible-doc [options] [module...]\n\nOptions:\n  -h, --help            show this help message and exit　　# 显示命令参数API文档\n  -l, --list            List available modules　　#列出可用的模块\n  -M MODULE_PATH, --module-path=MODULE_PATH　　#指定模块的路径\n                        specify path(s) to module library (default=None)\n  -s, --snippet         Show playbook snippet for specified module(s)　　#显示playbook制定模块的用法\n  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable　　# 显示ansible-doc的版本号查看模块列表：\n                        connection debugging)\n  --version             show program's version number and exit\n```\n\n　　我们可以来看一下，以mysql相关的为例：\n\n```\n[root@server ~]# ansible-doc -l |grep mysql\nmysql_db                           Add or remove MySQL databases from a remote...\nmysql_replication                  Manage MySQL replication                   \nmysql_user                         Adds or removes a user from a MySQL databas...\nmysql_variables                    Manage MySQL global variables      \n[root@server ~]# ansible-doc -s mysql_user\n```\n\n![img](https://images2017.cnblogs.com/blog/1204916/201712/1204916-20171205163026644-674759103.png)\n\n\n\n### ansible 命令详解\n\n　　命令的具体格式如下：\n\n```\nansible <host-pattern> [-f forks] [-m module_name] [-a args]\n```\n\n　　也可以通过`ansible -h`来查看帮助，下面我们列出一些比较常用的选项，并解释其含义：\n\n> `-a MODULE_ARGS`　　　#模块的参数，如果执行默认COMMAND的模块，即是命令参数，如： “date”，“pwd”等等\n> `-k`，`--ask-pass` #ask for SSH password。登录密码，提示输入SSH密码而不是假设基于密钥的验证\n> `--ask-su-pass` #ask for su password。su切换密码\n> `-K`，`--ask-sudo-pass` #ask for sudo password。提示密码使用sudo，sudo表示提权操作\n> `--ask-vault-pass` #ask for vault password。假设我们设定了加密的密码，则用该选项进行访问\n> `-B SECONDS` #后台运行超时时间\n> `-C` #模拟运行环境并进行预运行，可以进行查错测试\n> `-c CONNECTION` #连接类型使用\n> `-f FORKS` #并行任务数，默认为5\n> `-i INVENTORY` #指定主机清单的路径，默认为`/etc/ansible/hosts`\n> `--list-hosts` #查看有哪些主机组\n> `-m MODULE_NAME` #执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数\n> `-o` #压缩输出，尝试将所有结果在一行输出，一般针对收集工具使用\n> `-S` #用 su 命令\n> `-R SU_USER` #指定 su 的用户，默认为 root 用户\n> `-s` #用 sudo 命令\n> `-U SUDO_USER` #指定 sudo 到哪个用户，默认为 root 用户\n> `-T TIMEOUT` #指定 ssh 默认超时时间，默认为10s，也可在配置文件中修改\n> `-u REMOTE_USER` #远程用户，默认为 root 用户\n> `-v` #查看详细信息，同时支持`-vvv`，`-vvvv`可查看更详细信息\n\n\n\n### ansible 配置公私钥\n\n　　上面我们已经提到过 ansible 是基于 ssh 协议实现的，所以其配置公私钥的方式与 ssh 协议的方式相同，具体操作步骤如下：\n\n```\n#1.生成私钥\n[root@server ~]# ssh-keygen \n#2.向主机分发私钥\n[root@server ~]# ssh-copy-id root@192.168.37.122\n[root@server ~]# ssh-copy-id root@192.168.37.133\n```\n\n　　这样的话，就可以实现无密码登录，我们的实验过程也会顺畅很多。\n　　注意，如果出现了一下报错：\n\n```\n    -bash: ssh-copy-id: command not found\n```\n\n　　那么就证明我们需要安装一个包：\n\n```\n    yum -y install openssh-clientsansible\n```\n\n　　把包安装上即可。\n\n\n\n## ansible 常用模块\n\n\n\n### 1）主机连通性测试\n\n　　我们使用`ansible web -m ping`命令来进行主机连通性测试，效果如下：\n\n```\n[root@server ~]# ansible web -m ping\n192.168.37.122 | SUCCESS => {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n```\n\n　　这样就说明我们的主机是连通状态的。接下来的操作才可以正常进行。\n\n\n\n### 2）command 模块\n\n　　这个模块可以直接在远程主机上执行命令，并将结果返回本主机。\n　　举例如下：\n\n```\n[root@server ~]# ansible web -m command -a 'ss -ntl'\n192.168.37.122 | SUCCESS | rc=0 >>\nState      Recv-Q Send-Q Local Address:Port               Peer Address:Port              \nLISTEN     0      128          *:111                      *:*                  \nLISTEN     0      5      192.168.122.1:53                       *:*                  \nLISTEN     0      128          *:22                       *:*                  \nLISTEN     0      128    127.0.0.1:631                      *:*                  \nLISTEN     0      128          *:23000                    *:*                  \nLISTEN     0      100    127.0.0.1:25                       *:*                  \nLISTEN     0      128         :::111                     :::*                  \nLISTEN     0      128         :::22                      :::*                  \nLISTEN     0      128        ::1:631                     :::*                  \nLISTEN     0      100        ::1:25                      :::*                  \n\n192.168.37.133 | SUCCESS | rc=0 >>\nState      Recv-Q Send-Q Local Address:Port               Peer Address:Port              \nLISTEN     0      128          *:111                      *:*                  \nLISTEN     0      128          *:22                       *:*                  \nLISTEN     0      128    127.0.0.1:631                      *:*                  \nLISTEN     0      128          *:23000                    *:*                  \nLISTEN     0      100    127.0.0.1:25                       *:*                  \nLISTEN     0      128         :::111                     :::*                  \nLISTEN     0      128         :::22                      :::*                  \nLISTEN     0      128        ::1:631                     :::*                  \nLISTEN     0      100        ::1:25                      :::*  \n```\n\n　　命令模块接受命令名称，后面是空格分隔的列表参数。给定的命令将在所有选定的节点上执行。它不会通过shell进行处理，比如$HOME和操作如\"<\"，\">\"，\"|\"，\";\"，\"&\" 工作（需要使用（shell）模块实现这些功能）。注意，该命令不支持`| 管道命令`。\n　　下面来看一看该模块下常用的几个命令：\n\n> chdir　　　　　　 # 在执行命令之前，先切换到该目录\n> executable # 切换shell来执行命令，需要使用命令的绝对路径\n> free_form 　 # 要执行的Linux指令，一般使用Ansible的-a参数代替。\n> creates 　# 一个文件名，当这个文件存在，则该命令不执行,可以\n> 用来做判断\n> removes # 一个文件名，这个文件不存在，则该命令不执行\n\n　　下面我们来看看这些命令的执行效果：\n\n```\n[root@server ~]# ansible web -m command -a 'chdir=/data/ ls'    #先切换到/data/ 目录，再执行“ls”命令\n192.168.37.122 | SUCCESS | rc=0 >>\naaa.jpg\nfastdfs\nmogdata\ntmp\nweb\nwKgleloeYoCAMLtZAAAWEekAtkc497.jpg\n\n192.168.37.133 | SUCCESS | rc=0 >>\naaa.jpg\nfastdfs\nmogdata\ntmp\nweb\nwKgleloeYoCAMLtZAAAWEekAtkc497.jpg\n[root@server ~]# ansible web -m command -a 'creates=/data/aaa.jpg ls'       #如果/data/aaa.jpg存在，则不执行“ls”命令\n192.168.37.122 | SUCCESS | rc=0 >>\nskipped, since /data/aaa.jpg exists\n\n192.168.37.133 | SUCCESS | rc=0 >>\nskipped, since /data/aaa.jpg exists\n[root@server ~]# ansible web -m command -a 'removes=/data/aaa.jpg cat /data/a'      #如果/data/aaa.jpg存在，则执行“cat /data/a”命令\n192.168.37.122 | SUCCESS | rc=0 >>\nhello\n\n192.168.37.133 | SUCCESS | rc=0 >>\nhello\n```\n\n\n\n### 3）shell 模块\n\n　　shell模块可以在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等。\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /etc/passwd |grep \"keer\"'\n192.168.37.122 | SUCCESS | rc=0 >>\nkeer:x:10001:1000:keer:/home/keer:/bin/sh\n\n192.168.37.133 | SUCCESS | rc=0 >>\nkeer:x:10001:10001::/home/keer:/bin/sh\n```\n\n　　只要是我们的shell命令，都可以通过这个模块在远程主机上运行，这里就不一一举例了。\n\n\n\n### 4）copy 模块\n\n　　这个模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。\n　　其相关选项如下：\n\n> `src`　　　　#被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于\"rsync\"\n> `content`　　　#用于替换\"src\"，可以直接指定文件的值\n> `dest`　　　　#必选项，将源文件复制到的远程主机的**绝对路径**\n> `backup`　　　#当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息\n> `directory_mode`　　　　#递归设定目录的权限，默认为系统默认权限\n> `force`　　　　#当目标主机包含该文件，但内容不同时，设为\"yes\"，表示强制覆盖；设为\"no\"，表示目标主机的目标位置不存在该文件才复制。默认为\"yes\"\n> `others`　　　　#所有的 file 模块中的选项可以在这里使用\n\n用法举例如下：\n**① 复制文件：**\n\n```\n[root@server ~]# ansible web -m copy -a 'src=~/hello dest=/data/hello' \n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"dest\": \"/data/hello\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"6f5902ac237024bdd0c176cb93063dc4\", \n    \"mode\": \"0644\", \n    \"owner\": \"root\", \n    \"size\": 12, \n    \"src\": \"/root/.ansible/tmp/ansible-tmp-1512437093.55-228281064292921/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"dest\": \"/data/hello\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"6f5902ac237024bdd0c176cb93063dc4\", \n    \"mode\": \"0644\", \n    \"owner\": \"root\", \n    \"size\": 12, \n    \"src\": \"/root/.ansible/tmp/ansible-tmp-1512437093.74-44694985235189/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n```\n\n**② 给定内容生成文件，并制定权限**\n\n```\n[root@server ~]# ansible web -m copy -a 'content=\"I am keer\\n\" dest=/data/name mode=666'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"0421570938940ea784f9d8598dab87f07685b968\", \n    \"dest\": \"/data/name\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"497fa8386590a5fc89090725b07f175c\", \n    \"mode\": \"0666\", \n    \"owner\": \"root\", \n    \"size\": 10, \n    \"src\": \"/root/.ansible/tmp/ansible-tmp-1512437327.37-199512601767687/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"0421570938940ea784f9d8598dab87f07685b968\", \n    \"dest\": \"/data/name\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"497fa8386590a5fc89090725b07f175c\", \n    \"mode\": \"0666\", \n    \"owner\": \"root\", \n    \"size\": 10, \n        \"src\": \"/root/.ansible/tmp/ansible-tmp-1512437327.55-218104039503110/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n```\n\n　　我们现在可以去查看一下我们生成的文件及其权限：\n\n```\n[root@server ~]# ansible web -m shell -a 'ls -l /data/'\n192.168.37.122 | SUCCESS | rc=0 >>\ntotal 28\n-rw-rw-rw-   1 root root   12 Dec  6 09:45 name\n\n192.168.37.133 | SUCCESS | rc=0 >>\ntotal 40\n-rw-rw-rw- 1 root     root       12 Dec  5 09:45 name\n```\n\n　　可以看出我们的name文件已经生成，并且权限为666。\n**③ 关于覆盖**\n　　我们把文件的内容修改一下，然后选择覆盖备份：\n\n```\n[root@server ~]# ansible web -m copy -a 'content=\"I am keerya\\n\" backup=yes dest=/data/name mode=666'\n192.168.37.122 | SUCCESS => {\n    \"backup_file\": \"/data/name.4394.2017-12-06@09:46:25~\", \n    \"changed\": true, \n    \"checksum\": \"064a68908ab9971ee85dbc08ea038387598e3778\", \n    \"dest\": \"/data/name\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"8ca7c11385856155af52e560f608891c\", \n    \"mode\": \"0666\", \n    \"owner\": \"root\", \n    \"size\": 12, \n    \"src\": \"/root/.ansible/tmp/ansible-tmp-1512438383.78-228128616784888/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n192.168.37.133 | SUCCESS => {\n    \"backup_file\": \"/data/name.5962.2017-12-05@09:46:24~\", \n    \"changed\": true, \n    \"checksum\": \"064a68908ab9971ee85dbc08ea038387598e3778\", \n    \"dest\": \"/data/name\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"md5sum\": \"8ca7c11385856155af52e560f608891c\", \n    \"mode\": \"0666\", \n    \"owner\": \"root\", \n    \"size\": 12, \n    \"src\": \"/root/.ansible/tmp/ansible-tmp-1512438384.0-170718946740009/source\", \n    \"state\": \"file\", \n    \"uid\": 0\n}\n```\n\n　　现在我们可以去查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'ls -l /data/'\n192.168.37.122 | SUCCESS | rc=0 >>\ntotal 28\n-rw-rw-rw-   1 root root   12 Dec  6 09:46 name\n-rw-rw-rw-   1 root root   10 Dec  6 09:45 name.4394.2017-12-06@09:46:25~\n\n192.168.37.133 | SUCCESS | rc=0 >>\ntotal 40\n-rw-rw-rw- 1 root     root       12 Dec  5 09:46 name\n-rw-rw-rw- 1 root     root       10 Dec  5 09:45 name.5962.2017-12-05@09:46:24~\n```\n\n　　可以看出，我们的源文件已经被备份，我们还可以查看一下`name`文件的内容：\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /data/name'\n192.168.37.122 | SUCCESS | rc=0 >>\nI am keerya\n\n192.168.37.133 | SUCCESS | rc=0 >>\nI am keerya\n```\n\n　　证明，这正是我们新导入的文件的内容。\n\n\n\n### 5）file 模块\n\n　　该模块主要用于设置文件的属性，比如创建文件、创建链接文件、删除文件等。\n　　下面是一些常见的命令：\n\n> `force`　　#需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no\n> `group`　　#定义文件/目录的属组。后面可以加上`mode`：定义文件/目录的权限\n> `owner`　　#定义文件/目录的属主。后面必须跟上`path`：定义文件/目录的路径\n> `recurse`　　#递归设置文件的属性，只对目录有效，后面跟上`src`：被链接的源文件路径，只应用于`state=link`的情况\n> `dest`　　#被链接到的路径，只应用于`state=link`的情况\n> `state`　　#状态，有以下选项：\n>\n> > `directory`：如果目录不存在，就创建目录\n> > `file`：即使文件不存在，也不会被创建\n> > `link`：创建软链接\n> > `hard`：创建硬链接\n> > `touch`：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间\n> > `absent`：删除目录、文件或者取消链接文件\n\n　　用法举例如下：\n**① 创建目录：**\n\n```\n[root@server ~]# ansible web -m file -a 'path=/data/app state=directory'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"mode\": \"0755\", \n    \"owner\": \"root\", \n    \"path\": \"/data/app\", \n    \"size\": 6, \n    \"state\": \"directory\", \n    \"uid\": 0\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"mode\": \"0755\", \n    \"owner\": \"root\", \n    \"path\": \"/data/app\", \n    \"size\": 4096, \n    \"state\": \"directory\", \n    \"uid\": 0\n}\n```\n\n　　我们可以查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'ls -l /data'\n192.168.37.122 | SUCCESS | rc=0 >>\ntotal 28\ndrwxr-xr-x   2 root root    6 Dec  6 10:21 app\n\n192.168.37.133 | SUCCESS | rc=0 >>\ntotal 44\ndrwxr-xr-x 2 root     root     4096 Dec  5 10:21 app\n```\n\n　　可以看出，我们的目录已经创建完成。\n**② 创建链接文件**\n\n```\n[root@server ~]# ansible web -m file -a 'path=/data/bbb.jpg src=aaa.jpg state=link'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"dest\": \"/data/bbb.jpg\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"mode\": \"0777\", \n    \"owner\": \"root\", \n    \"size\": 7, \n    \"src\": \"aaa.jpg\", \n    \"state\": \"link\", \n    \"uid\": 0\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"dest\": \"/data/bbb.jpg\", \n    \"gid\": 0, \n    \"group\": \"root\", \n    \"mode\": \"0777\", \n    \"owner\": \"root\", \n    \"size\": 7, \n    \"src\": \"aaa.jpg\", \n    \"state\": \"link\", \n    \"uid\": 0\n}\n```\n\n　　我们可以去查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'ls -l /data'\n192.168.37.122 | SUCCESS | rc=0 >>\ntotal 28\n-rw-r--r--   1 root root 5649 Dec  5 13:49 aaa.jpg\nlrwxrwxrwx   1 root root    7 Dec  6 10:25 bbb.jpg -> aaa.jpg\n\n192.168.37.133 | SUCCESS | rc=0 >>\ntotal 44\n-rw-r--r-- 1 root     root     5649 Dec  4 14:44 aaa.jpg\nlrwxrwxrwx 1 root     root        7 Dec  5 10:25 bbb.jpg -> aaa.jpg\n```\n\n　　我们的链接文件已经创建成功。\n**③ 删除文件**\n\n```\n[root@server ~]# ansible web -m file -a 'path=/data/a state=absent'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"path\": \"/data/a\", \n    \"state\": \"absent\"\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"path\": \"/data/a\", \n    \"state\": \"absent\"\n}\n```\n\n　　我们可以查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'ls /data/a'\n192.168.37.122 | FAILED | rc=2 >>\nls: cannot access /data/a: No such file or directory\n\n192.168.37.133 | FAILED | rc=2 >>\nls: cannot access /data/a: No such file or directory\n```\n\n　　发现已经没有这个文件了。\n　　\n\n\n\n### 6）fetch 模块\n\n　　该模块用于从远程某主机获取（复制）文件到本地。\n　　有两个选项：\n\n> `dest`：用来存放文件的目录\n> `src`：在远程拉取的文件，并且必须是一个**file**，不能是**目录**\n\n　　具体举例如下：\n\n```\n[root@server ~]# ansible web -m fetch -a 'src=/data/hello dest=/data'  \n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"dest\": \"/data/192.168.37.122/data/hello\", \n    \"md5sum\": \"6f5902ac237024bdd0c176cb93063dc4\", \n    \"remote_checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"remote_md5sum\": null\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"dest\": \"/data/192.168.37.133/data/hello\", \n    \"md5sum\": \"6f5902ac237024bdd0c176cb93063dc4\", \n    \"remote_checksum\": \"22596363b3de40b06f981fb85d82312e8c0ed511\", \n    \"remote_md5sum\": null\n}\n```\n\n　　我们可以在本机上查看一下文件是否复制成功。要注意，文件保存的路径是我们设置的接收目录下的`被管制主机ip`目录下：\n\n```\n[root@server ~]# cd /data/\n[root@server data]# ls\n1  192.168.37.122  192.168.37.133  fastdfs  web\n[root@server data]# cd 192.168.37.122\n[root@server 192.168.37.122]# ls\ndata\n[root@server 192.168.37.122]# cd data/\n[root@server data]# ls\nhello\n[root@server data]# pwd\n/data/192.168.37.122/data\n```\n\n\n\n### 7）cron 模块\n\n　　该模块适用于管理`cron`计划任务的。\n　　其使用的语法跟我们的`crontab`文件中的语法一致，同时，可以指定以下选项：\n\n> `day=` #日应该运行的工作( 1-31, *,* /2, )\n> `hour=` # 小时 ( 0-23, *,* /2, )\n> `minute=` #分钟( 0-59, *,* /2, )\n> `month=` # 月( 1-12, *, /2, )\n> `weekday=` # 周 ( 0-6 for Sunday-Saturday,, )\n> `job=` #指明运行的命令是什么\n> `name=` #定时任务描述\n> `reboot` # 任务在重启时运行，不建议使用，建议使用special_time\n> `special_time` #特殊的时间范围，参数：reboot（重启时），annually（每年），monthly（每月），weekly（每周），daily（每天），hourly（每小时）\n> `state` #指定状态，present表示添加定时任务，也是默认设置，absent表示删除定时任务\n> `user` # 以哪个用户的身份执行\n\n　　举例如下：\n**① 添加计划任务**\n\n```\n[root@server ~]# ansible web -m cron -a 'name=\"ntp update every 5 min\" minute=*/5 job=\"/sbin/ntpdate 172.17.0.1 &> /dev/null\"'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"envs\": [], \n    \"jobs\": [\n        \"ntp update every 5 min\"\n    ]\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"envs\": [], \n    \"jobs\": [\n        \"ntp update every 5 min\"\n    ]\n}\n```\n\n　　我们可以去查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'crontab -l'\n192.168.37.122 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n\n192.168.37.133 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n```\n\n　　可以看出，我们的计划任务已经设置成功了。\n**② 删除计划任务**\n　　如果我们的计划任务添加错误，想要删除的话，则执行以下操作：\n　　首先我们查看一下现有的计划任务：\n\n```\n[root@server ~]# ansible web -m shell -a 'crontab -l'\n192.168.37.122 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n#Ansible: df everyday\n* 15 * * * df -lh >> /tmp/disk_total &> /dev/null\n\n192.168.37.133 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n#Ansible: df everyday\n* 15 * * * df -lh >> /tmp/disk_total &> /dev/null\n```\n\n　　然后执行删除操作：\n\n```\n[root@server ~]# ansible web -m cron -a 'name=\"df everyday\" hour=15 job=\"df -lh >> /tmp/disk_total &> /dev/null\" state=absent'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"envs\": [], \n    \"jobs\": [\n        \"ntp update every 5 min\"\n    ]\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"envs\": [], \n    \"jobs\": [\n        \"ntp update every 5 min\"\n    ]\n}\n```\n\n　　删除完成后，我们再查看一下现有的计划任务确认一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'crontab -l'\n192.168.37.122 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n\n192.168.37.133 | SUCCESS | rc=0 >>\n#Ansible: ntp update every 5 min\n*/5 * * * * /sbin/ntpdate 172.17.0.1 &> /dev/null\n```\n\n　　我们的删除操作已经成功。\n\n\n\n### 8）yum 模块\n\n　　顾名思义，该模块主要用于软件的安装。\n　　其选项如下：\n\n> `name=`　　#所安装的包的名称\n> `state=`　　#`present`--->安装， `latest`--->安装最新的, `absent`---> 卸载软件。\n> `update_cache`　　#强制更新yum的缓存\n> `conf_file`　　#指定远程yum安装时所依赖的配置文件（安装本地已有的包）。\n> `disable_pgp_check`　　#是否禁止GPG checking，只用于`present`or `latest`。\n> `disablerepo`　　#临时禁止使用yum库。 只用于安装或更新时。\n> `enablerepo`　　#临时使用的yum库。只用于安装或更新时。\n\n　　下面我们就来安装一个包试试看：\n\n```\n[root@server ~]# ansible web -m yum -a 'name=htop state=present'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"msg\": \"\", \n    \"rc\": 0, \n    \"results\": [\n        \"Loaded plugins: fastestmirror, langpacks\\nLoading mirror speeds from cached hostfile\\nResolving Dependencies\\n--> Running transaction check\\n---> Package htop.x86_64 0:2.0.2-1.el7 will be installed\\n--> Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n================================================================================\\n Package         Arch              Version                Repository       Size\\n================================================================================\\nInstalling:\\n htop            x86_64            2.0.2-1.el7            epel             98 k\\n\\nTransaction Summary\\n================================================================================\\nInstall  1 Package\\n\\nTotal download size: 98 k\\nInstalled size: 207 k\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n  Installing : htop-2.0.2-1.el7.x86_64                                      1/1 \\n  Verifying  : htop-2.0.2-1.el7.x86_64                                      1/1 \\n\\nInstalled:\\n  htop.x86_64 0:2.0.2-1.el7                                                     \\n\\nComplete!\\n\"\n    ]\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"msg\": \"Warning: RPMDB altered outside of yum.\\n** Found 3 pre-existing rpmdb problem(s), 'yum check' output follows:\\nipa-client-4.4.0-12.el7.centos.x86_64 has installed conflicts freeipa-client: ipa-client-4.4.0-12.el7.centos.x86_64\\nipa-client-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-client-common: ipa-client-common-4.4.0-12.el7.centos.noarch\\nipa-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-common: ipa-common-4.4.0-12.el7.centos.noarch\\n\", \n    \"rc\": 0, \n    \"results\": [\n        \"Loaded plugins: fastestmirror, langpacks\\nLoading mirror speeds from cached hostfile\\nResolving Dependencies\\n--> Running transaction check\\n---> Package htop.x86_64 0:2.0.2-1.el7 will be installed\\n--> Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n================================================================================\\n Package         Arch              Version                Repository       Size\\n================================================================================\\nInstalling:\\n htop            x86_64            2.0.2-1.el7            epel             98 k\\n\\nTransaction Summary\\n================================================================================\\nInstall  1 Package\\n\\nTotal download size: 98 k\\nInstalled size: 207 k\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n  Installing : htop-2.0.2-1.el7.x86_64                                      1/1 \\n  Verifying  : htop-2.0.2-1.el7.x86_64                                      1/1 \\n\\nInstalled:\\n  htop.x86_64 0:2.0.2-1.el7                                                     \\n\\nComplete!\\n\"\n    ]\n}\n```\n\n　　安装成功。\n\n\n\n### 9）service 模块\n\n　　该模块用于服务程序的管理。\n　　其主要选项如下：\n\n> `arguments` #命令行提供额外的参数\n> `enabled` #设置开机启动。\n> `name=` #服务名称\n> `runlevel` #开机启动的级别，一般不用指定。\n> `sleep` #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)\n> `state` #有四种状态，分别为：`started`--->启动服务， `stopped`--->停止服务， `restarted`--->重启服务， `reloaded`--->重载配置\n\n　　下面是一些例子：\n**① 开启服务并设置自启动**\n\n```\n[root@server ~]# ansible web -m service -a 'name=nginx state=started enabled=true' \n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"enabled\": true, \n    \"name\": \"nginx\", \n    \"state\": \"started\", \n    ……\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"enabled\": true, \n    \"name\": \"nginx\", \n    \"state\": \"started\", \n    ……\n}\n```\n\n　　我们可以去查看一下端口是否打开：\n\n```\n[root@server ~]# ansible web -m shell -a 'ss -ntl'\n192.168.37.122 | SUCCESS | rc=0 >>\nState      Recv-Q Send-Q Local Address:Port               Peer Address:Port              \nLISTEN     0      128          *:80                       *:*                                  \n\n192.168.37.133 | SUCCESS | rc=0 >>\nState      Recv-Q Send-Q Local Address:Port               Peer Address:Port                    \nLISTEN     0      128          *:80                       *:*                  \n```\n\n　　可以看出我们的80端口已经打开。\n**② 关闭服务**\n　　我们也可以通过该模块来关闭我们的服务：\n\n```\n[root@server ~]# ansible web -m service -a 'name=nginx state=stopped'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"name\": \"nginx\", \n    \"state\": \"stopped\", \n    ……\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"name\": \"nginx\", \n    \"state\": \"stopped\", \n    ……\n}\n```\n\n　　一样的，我们来查看一下端口：\n\n```\n[root@server ~]# ansible web -m shell -a 'ss -ntl | grep 80'\n192.168.37.122 | FAILED | rc=1 >>\n\n192.168.37.133 | FAILED | rc=1 >>\n```\n\n　　可以看出，我们已经没有80端口了，说明我们的nginx服务已经关闭了。\n\n\n\n### 10）user 模块\n\n　　该模块主要是用来管理用户账号。\n　　其主要选项如下：\n\n> `comment`　　# 用户的描述信息\n> `createhome`　　# 是否创建家目录\n> `force`　　# 在使用state=absent时, 行为与userdel –force一致.\n> `group`　　# 指定基本组\n> `groups`　　# 指定附加组，如果指定为(groups=)表示删除所有组\n> `home`　　# 指定用户家目录\n> `move_home`　　# 如果设置为home=时, 试图将用户主目录移动到指定的目录\n> `name`　　# 指定用户名\n> `non_unique`　　# 该选项允许改变非唯一的用户ID值\n> `password`　　# 指定用户密码\n> `remove`　　# 在使用state=absent时, 行为是与userdel –remove一致\n> `shell`　　# 指定默认shell\n> `state`　　# 设置帐号状态，不指定为创建，指定值为absent表示删除\n> `system`　　# 当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户\n> `uid`　　# 指定用户的uid\n\n　　举例如下：\n**① 添加一个用户并指定其 uid**\n\n```\n[root@server ~]# ansible web -m user -a 'name=keer uid=11111'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"comment\": \"\", \n    \"createhome\": true, \n    \"group\": 11111, \n    \"home\": \"/home/keer\", \n    \"name\": \"keer\", \n    \"shell\": \"/bin/bash\", \n    \"state\": \"present\", \n    \"stderr\": \"useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\nCreating mailbox file: File exists\\n\", \n    \"system\": false, \n    \"uid\": 11111\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"comment\": \"\", \n    \"createhome\": true, \n    \"group\": 11111, \n    \"home\": \"/home/keer\", \n    \"name\": \"keer\", \n    \"shell\": \"/bin/bash\", \n    \"state\": \"present\", \n    \"stderr\": \"useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\nCreating mailbox file: File exists\\n\", \n    \"system\": false, \n    \"uid\": 11111\n}\n```\n\n　　添加完成，我们可以去查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /etc/passwd |grep keer'\n192.168.37.122 | SUCCESS | rc=0 >>\nkeer:x:11111:11111::/home/keer:/bin/bash\n\n192.168.37.133 | SUCCESS | rc=0 >>\nkeer:x:11111:11111::/home/keer:/bin/bash\n```\n\n**② 删除用户**\n\n```\n[root@server ~]# ansible web -m user -a 'name=keer state=absent'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"force\": false, \n    \"name\": \"keer\", \n    \"remove\": false, \n    \"state\": \"absent\"\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"force\": false, \n    \"name\": \"keer\", \n    \"remove\": false, \n    \"state\": \"absent\"\n}\n```\n\n　　一样的，删除之后，我们去看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /etc/passwd |grep keer'\n192.168.37.122 | FAILED | rc=1 >>\n\n192.168.37.133 | FAILED | rc=1 >>\n```\n\n　　发现已经没有这个用户了。\n\n\n\n### 11）group 模块\n\n　　该模块主要用于添加或删除组。\n　　常用的选项如下：\n\n> `gid=`　　#设置组的GID号\n> `name=`　　#指定组的名称\n> `state=`　　#指定组的状态，默认为创建，设置值为`absent`为删除\n> `system=`　　#设置值为`yes`，表示创建为系统组\n\n　　举例如下：\n**① 创建组**\n\n```\n[root@server ~]# ansible web -m group -a 'name=sanguo gid=12222'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"gid\": 12222, \n    \"name\": \"sanguo\", \n    \"state\": \"present\", \n    \"system\": false\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"gid\": 12222, \n    \"name\": \"sanguo\", \n    \"state\": \"present\", \n    \"system\": false\n}\n```\n\n　　创建过后，我们来查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /etc/group | grep 12222' \n192.168.37.122 | SUCCESS | rc=0 >>\nsanguo:x:12222:\n\n192.168.37.133 | SUCCESS | rc=0 >>\nsanguo:x:12222:\n```\n\n　　可以看出，我们的组已经创建成功了。\n**② 删除组**\n\n```\n[root@server ~]# ansible web -m group -a 'name=sanguo state=absent'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"name\": \"sanguo\", \n    \"state\": \"absent\"\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"name\": \"sanguo\", \n    \"state\": \"absent\"\n}\n```\n\n　　照例查看一下：\n\n```\n[root@server ~]# ansible web -m shell -a 'cat /etc/group | grep 12222' \n192.168.37.122 | FAILED | rc=1 >>\n\n192.168.37.133 | FAILED | rc=1 >>\n```\n\n　　已经没有这个组的相关信息了。\n\n\n\n### 12）script 模块\n\n　　该模块用于将本机的脚本在被管理端的机器上运行。\n　　该模块直接指定脚本的路径即可，我们通过例子来看一看到底如何使用的：\n　　首先，我们写一个脚本，并给其加上执行权限：\n\n```\n[root@server ~]# vim /tmp/df.sh\n    #!/bin/bash\n\n    date >> /tmp/disk_total.log\n    df -lh >> /tmp/disk_total.log \n[root@server ~]# chmod +x /tmp/df.sh \n```\n\n　　然后，我们直接运行命令来实现在被管理端执行该脚本：\n\n```\n[root@server ~]# ansible web -m script -a '/tmp/df.sh'\n192.168.37.122 | SUCCESS => {\n    \"changed\": true, \n    \"rc\": 0, \n    \"stderr\": \"Shared connection to 192.168.37.122 closed.\\r\\n\", \n    \"stdout\": \"\", \n    \"stdout_lines\": []\n}\n192.168.37.133 | SUCCESS => {\n    \"changed\": true, \n    \"rc\": 0, \n    \"stderr\": \"Shared connection to 192.168.37.133 closed.\\r\\n\", \n    \"stdout\": \"\", \n    \"stdout_lines\": []\n}\n```\n\n　　照例查看一下文件内容：\n\n```repl\n[root@server ~]# ansible web -m shell -a 'cat /tmp/disk_total.log'\n192.168.37.122 | SUCCESS | rc=0 >>\nTue Dec  5 15:58:21 CST 2017\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda2        47G  4.4G   43G  10% /\ndevtmpfs        978M     0  978M   0% /dev\ntmpfs           993M   84K  993M   1% /dev/shm\ntmpfs           993M  9.1M  984M   1% /run\ntmpfs           993M     0  993M   0% /sys/fs/cgroup\n/dev/sda3        47G   33M   47G   1% /app\n/dev/sda1       950M  153M  798M  17% /boot\ntmpfs           199M   16K  199M   1% /run/user/42\ntmpfs           199M     0  199M   0% /run/user/0\n\n192.168.37.133 | SUCCESS | rc=0 >>\nTue Dec  5 15:58:21 CST 2017\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda2        46G  4.1G   40G  10% /\ndevtmpfs        898M     0  898M   0% /dev\ntmpfs           912M   84K  912M   1% /dev/shm\ntmpfs           912M  9.0M  903M   1% /run\ntmpfs           912M     0  912M   0% /sys/fs/cgroup\n/dev/sda3       3.7G   15M  3.4G   1% /app\n/dev/sda1       1.9G  141M  1.6G   9% /boot\ntmpfs           183M   16K  183M   1% /run/user/42\ntmpfs           183M     0  183M   0% /run/user/0\n```\n\n　　可以看出已经执行成功了。\n\n\n\n### 13）setup 模块\n\n　　该模块主要用于收集信息，是通过调用facts组件来实现的。\n　　facts组件是Ansible用于采集被管机器设备信息的一个功能，我们可以使用setup模块查机器的所有facts信息，可以使用filter来查看指定信息。整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最上层的值。\n　　facts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。调用后返回很多对应主机的信息，在后面的操作中可以根据不同的信息来做不同的操作。如redhat系列用yum安装，而debian系列用apt来安装软件。\n**① 查看信息**\n　　我们可以直接用命令获取到变量的值，具体我们来看看例子：\n\n```\n[root@server ~]# ansible web -m setup -a 'filter=\"*mem*\"'   #查看内存\n192.168.37.122 | SUCCESS => {\n    \"ansible_facts\": {\n        \"ansible_memfree_mb\": 1116, \n        \"ansible_memory_mb\": {\n            \"nocache\": {\n                \"free\": 1397, \n                \"used\": 587\n            }, \n            \"real\": {\n                \"free\": 1116, \n                \"total\": 1984, \n                \"used\": 868\n            }, \n            \"swap\": {\n                \"cached\": 0, \n                \"free\": 3813, \n                \"total\": 3813, \n                \"used\": 0\n            }\n        }, \n        \"ansible_memtotal_mb\": 1984\n    }, \n    \"changed\": false\n}\n192.168.37.133 | SUCCESS => {\n    \"ansible_facts\": {\n        \"ansible_memfree_mb\": 1203, \n        \"ansible_memory_mb\": {\n            \"nocache\": {\n                \"free\": 1470, \n                \"used\": 353\n            }, \n            \"real\": {\n                \"free\": 1203, \n                \"total\": 1823, \n                \"used\": 620\n            }, \n            \"swap\": {\n                \"cached\": 0, \n                \"free\": 3813, \n                \"total\": 3813, \n                \"used\": 0\n            }\n        }, \n        \"ansible_memtotal_mb\": 1823\n    }, \n    \"changed\": false\n}\n```\n\n　　我们可以通过命令查看一下内存的大小以确认一下是否一致：\n\n```\n[root@server ~]# ansible web -m shell -a 'free -m'\n192.168.37.122 | SUCCESS | rc=0 >>\n              total        used        free      shared  buff/cache   available\nMem:           1984         404        1122           9         457        1346\nSwap:          3813           0        3813\n\n192.168.37.133 | SUCCESS | rc=0 >>\n              total        used        free      shared  buff/cache   available\nMem:           1823         292        1207           9         323        1351\nSwap:          3813           0        3813\n```\n\n　　可以看出信息是一致的。\n**② 保存信息**\n　　我们的setup模块还有一个很好用的功能就是可以保存我们所筛选的信息至我们的主机上，同时，文件名为我们被管制的主机的IP，这样方便我们知道是哪台机器出的问题。\n　　我们可以看一看例子：\n\n```\n[root@server tmp]# ansible web -m setup -a 'filter=\"*mem*\"' --tree /tmp/facts\n192.168.37.122 | SUCCESS => {\n    \"ansible_facts\": {\n        \"ansible_memfree_mb\": 1115, \n        \"ansible_memory_mb\": {\n            \"nocache\": {\n                \"free\": 1396, \n                \"used\": 588\n            }, \n            \"real\": {\n                \"free\": 1115, \n                \"total\": 1984, \n                \"used\": 869\n            }, \n            \"swap\": {\n                \"cached\": 0, \n                \"free\": 3813, \n                \"total\": 3813, \n                \"used\": 0\n            }\n        }, \n        \"ansible_memtotal_mb\": 1984\n    }, \n    \"changed\": false\n}\n192.168.37.133 | SUCCESS => {\n    \"ansible_facts\": {\n        \"ansible_memfree_mb\": 1199, \n        \"ansible_memory_mb\": {\n            \"nocache\": {\n                \"free\": 1467, \n                \"used\": 356\n            }, \n            \"real\": {\n                \"free\": 1199, \n                \"total\": 1823, \n                \"used\": 624\n            }, \n            \"swap\": {\n                \"cached\": 0, \n                \"free\": 3813, \n                \"total\": 3813, \n                \"used\": 0\n            }\n        }, \n        \"ansible_memtotal_mb\": 1823\n    }, \n    \"changed\": false\n}\n```\n\n　　然后我们可以去查看一下：\n\n```\n[root@server ~]# cd /tmp/facts/\n[root@server facts]# ls\n192.168.37.122  192.168.37.133\n[root@server facts]# cat 192.168.37.122 \n{\"ansible_facts\": {\"ansible_memfree_mb\": 1115, \"ansible_memory_mb\": {\"nocache\": {\"free\": 1396, \"used\": 588}, \"real\": {\"free\": 1115, \"total\": 1984, \"used\": 869}, \"swap\": {\"cached\": 0, \"free\": 3813, \"total\": 3813, \"used\": 0}}, \"ansible_memtotal_mb\": 1984}, \"changed\": false}\n```\n\n*作者：[珂儿吖](http://www.cnblogs.com/keerya/)*\n\n*出处：<http://www.cnblogs.com/keerya/>*\n\n","tags":["ansible"]},{"title":"【libreoffice】LibreOffice安装测试","url":"/2019/03/02/【libreoffice】LibreOffice安装测试/","content":"\n### LibreOffice下载地址\n\n[libreoffice-6.2.3](http://download.documentfoundation.org/libreoffice/stable/6.2.3/rpm/x86_64/)\n\n### JODConverter下载地址\n\n[jodconverter-2.2.2](https://sourceforge.net/projects/jodconverter/files/JODConverter/2.2.2/)\n\n### LibreOffice安装\n\n```shell\n#下载\nwget http://download.documentfoundation.org/libreoffice/stable/6.2.3/rpm/x86_64/LibreOffice_6.2.3_Linux_x86-64_rpm.tar.gz\nwget http://download.documentfoundation.org/libreoffice/stable/6.2.3/rpm/x86_64/LibreOffice_6.2.3_Linux_x86-64_rpm_sdk.tar.gz\n#解压\ntar xzvf LibreOffice_6.2.3_Linux_x86-64_rpm.tar.gz\ntar xzvf LibreOffice_6.2.3_Linux_x86-64_rpm_sdk.tar.gz\n#安装\nyum localinstall LibreOffice_6.2.3_Linux_x86-64_rpm/RPMS/*.rpm\nyum localinstall LibreOffice_6.2.3_Linux_x86-64_rpm_sdk/RPMS/*.rpm\n#启动\n/opt/libreoffice6.2/program/soffice --headless --accept=\"socket,host=127.0.0.1,port=8100;urp;\" --nofirststartwizard &\n```\n\n### LibreOffice测试\n\n1. 下载jodconverter，解压\n2. 将test.doc拷贝到lib目录下\n3. 执行 java -jar jodconverter-cli-2.2.2.jar  test.doc test.pdf 命令，查看是否生成pdf文件\n\n### LibreOffice安装排错\n\n```shell\n#执行命令：\n/opt/libreoffice6.0/program/soffice -help\n\n#错误信息：\n/opt/libreoffice6.0/program/soffice.bin: error while loading shared libraries: libcairo.so.2: cannot open shared object file: No such file or directory\n#解决方案：\nyum install cairo\n\n#错误信息：\n/opt/libreoffice6.0/program/soffice.bin: error while loading shared libraries: libcups.so.2: cannot open shared object file: No such file or directory\n#解决方案：\nyum install cups-libs\n\n#错误信息：\n/opt/libreoffice6.0/program/soffice.bin: error while loading shared libraries: libSM.so.6: cannot open shared object file: No such file or directory\n#解决方案：\nyum install libSM\n\n```\n\n","tags":["libreoffice"]},{"title":"【python】python基础巩固（1）","url":"/2019/03/01/【python】python基础巩固（1）/","content":"\n### python高阶函数\n\n#### map\n\n```python\n# map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。\n>>> def func(x):\n...    return x*x\n...\n>>> r = map(func, [1,2,3,4,5,6])\n# 由于结果r是一个Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list。\n>>> list(r)\n[1,4,9,16,25,36]\n```\n\n#### reduce\n\n```python\n# reduce把一个函数作用在一个序列[x1, x2, x3, ...]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：\n# reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)\n# 比方说对一个序列求和，就可以用reduce实现：\n>>> from functools import reduce\n>>> def add(x, y):\n...    return x + y\n...\n>>> reduce(add, [1, 3, 5, 7, 9])\n25\n```\n\n#### filter\n\n```python\n# 和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。\n# filter()函数返回的是一个Iterator，也就是一个惰性序列，所以要强迫filter()完成计算结果，需要用list()函数获得所有结果并返回list。\n>>> def is_odd(n):\n...    return n % 2 == 1\n...\n>>> list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))\n[1, 5, 9, 15]\n```\n\n#### sorted\n\n```python\n# sorted()函数也是一个高阶函数，它还可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序：\n>>> sorted([36, 5, -12, 9, -21], key=abs)\n[5, 9, -12, -21, 36]\n# key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。对比原始的list和经过key=abs处理过的list：\nlist = [36, 5, -12, 9, -21]\nkeys = [36, 5,  12, 9,  21]\n\n# 默认情况下，对字符串排序，是按照ASCII的大小比较的，由于'Z' < 'a'，结果，大写字母Z会排在小写字母a的前面。\n# 现在，我们提出排序应该忽略大小写，按照字母序排序。要实现这个算法，不必对现有代码大加改动，只要我们能用一个key函数把字符串映射为忽略大小写排序即可。忽略大小写来比较两个字符串，实际上就是先把字符串都变成大写（或者都变成小写），再比较。\n>>> sorted(['bob', 'about', 'Zoo', 'Credit'])\n['Credit', 'Zoo', 'about', 'bob']\n\n# 这样，我们给sorted传入key函数，即可实现忽略大小写的排序：\n>>> sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)\n['about', 'bob', 'Credit', 'Zoo']\n\n# 要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True：\n>>> sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)\n['Zoo', 'Credit', 'bob', 'about']\n\n```\n\n### 返回函数（闭包）\n\n```python\n# 我们在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”的程序结构拥有极大的威力。\n# 返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。\n```\n\n### 匿名函数（lambda）\n\n```python\n# 以map()函数为例，计算f(x)=x2时，除了定义一个f(x)的函数外，还可以直接传入匿名函数：\n>>> list(map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9]))\n[1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n# 关键字lambda表示匿名函数，冒号前面的x表示函数参数。\n# 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。\n# 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数：\n>>> f = lambda x: x * x\n>>> f\n<function <lambda> at 0x101c6ef28>\n>>> f(5)\n25\n\n# 同样，也可以把匿名函数作为返回值返回，比如：\ndef build(x, y):\n    return lambda: x * x + y * y\n```\n\n### 装饰器（@）\n\n```python\n# 在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。\n# 本质上，decorator就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的decorator，可以定义如下：\ndef log(func):\n    def wrapper(*args, **kw):\n        print('call %s():' % func.__name__)\n        return func(*args, **kw)\n    return wrapper\n\n# 观察上面的log，因为它是一个decorator，所以接受一个函数作为参数，并返回一个函数。我们要借助Python的@语法，把decorator置于函数的定义处：\n@log\ndef now():\n    print('2015-3-25')\n\n# 调用now()函数，不仅会运行now()函数本身，还会在运行now()函数前打印一行日志：\n>>> now()\ncall now():\n2015-3-25\n\n# 把@log放到now()函数的定义处，相当于执行了语句：\nnow = log(now)\n```\n\n### 偏函数\n\n```python\n# 在介绍函数参数的时候，我们讲到，通过设定参数的默认值，可以降低函数调用的难度。而偏函数也可以做到这一点。\n# 当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数，从而在调用时更简单。\n```\n\n","tags":["python"]},{"title":"【fastdfs】FastDFS官方部署文档","url":"/2019/03/01/【fastdfs】FastDFS官方部署文档/","content":"\n# 环境准备\n\n## 使用的系统软件\n\n| 名称                 | 说明                          |\n| -------------------- | ----------------------------- |\n| centos               | 7.x                           |\n| libfatscommon        | FastDFS分离出的一些公用函数包 |\n| FastDFS              | FastDFS本体                   |\n| fastdfs-nginx-module | FastDFS和nginx的关联模块      |\n| nginx                | nginx1.15.4                   |\n\n## 编译环境\n\n```\nyum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel wget vim -y\n```\n\n## 磁盘目录\n\n| 说明                                   | 位置           |\n| -------------------------------------- | -------------- |\n| 所有安装包                             | /usr/local/src |\n| 数据存储位置                           | /home/dfs/     |\n| #这里我为了方便把日志什么的都放到了dfs |                |\n\n```\nmkdir /home/dfs #创建数据存储目录\ncd /usr/local/src #切换到安装目录准备下载安装包\n```\n\n## 安装libfatscommon\n\n```\ngit clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh && ./make.sh install #编译安装\n```\n\n## 安装FastDFS\n\n```\ncd ../ #返回上一级目录\ngit clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh && ./make.sh install #编译安装\n#配置文件准备\ncp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/src/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/src/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n```\n\n## 安装fastdfs-nginx-module\n\n```\ncd ../ #返回上一级目录\ngit clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/src/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n```\n\n## 安装nginx\n\n```\nwget http://nginx.org/download/nginx-1.15.4.tar.gz #下载nginx压缩包\ntar -zxvf nginx-1.15.4.tar.gz #解压\ncd nginx-1.15.4/\n#添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/src/fastdfs-nginx-module/src/ \nmake && make install #编译安装\n```\n\n# 单机部署\n\n## tracker配置\n\n```\n#服务器ip为 192.168.52.1\n#我建议用ftp下载下来这些文件 本地修改\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/home/dfs  # 存储日志和数据的根目录\n```\n\n## storage配置\n\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/home/dfs  # 数据和日志文件存储根目录\nstore_path0=/home/dfs  # 第一个存储目录\ntracker_server=192.168.52.1:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n```\n\n## client测试\n\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/home/dfs\ntracker_server=192.168.52.1:22122    #tracker服务器IP和端口\n#保存后测试,返回ID表示成功 如：group1/M00/00/00/xx.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.15.4.tar.gz\n```\n\n## 配置nginx访问\n\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\ntracker_server=192.168.52.1:22122  #tracker服务器IP和端口\nurl_have_group_name=true\nstore_path0=/home/dfs\n#配置nginx.config\nvim /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/ {\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    root   html;\n    }\n}\n#测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.52.1:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n#弹出下载单机部署全部跑通\n```\n\n# 分布式部署\n\n## tracker配置\n\n```\n#服务器ip为 192.168.52.2,192.168.52.3,192.168.52.4\n#我建议用ftp下载下来这些文件 本地修改\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/home/dfs  # 存储日志和数据的根目录\n```\n\n## storage配置\n\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/home/dfs  # 数据和日志文件存储根目录\nstore_path0=/home/dfs  # 第一个存储目录\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n```\n\n## client测试\n\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/home/moe/dfs\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\n#保存后测试,返回ID表示成功 如：group1/M00/00/00/xx.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.15.4.tar.gz\n```\n\n## 配置nginx访问\n\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\nurl_have_group_name=true\nstore_path0=/home/dfs\n#配置nginx.config\nvim /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/ {\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    root   html;\n    }\n}\n```\n\n# 启动\n\n## 防火墙\n\n```\n#不关闭防火墙的话无法使用\nsystemctl stop firewalld.service #关闭\nsystemctl restart firewalld.service #重启\n```\n\n## tracker\n\n```\n/etc/init.d/fdfs_trackerd start #启动tracker服务\n/etc/init.d/fdfs_trackerd restart #重启动tracker服务\n/etc/init.d/fdfs_trackerd stop #停止tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n```\n\n## storage\n\n```\n/etc/init.d/fdfs_storaged start #启动storage服务\n/etc/init.d/fdfs_storaged restart #重动storage服务\n/etc/init.d/fdfs_storaged stop #停止动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n```\n\n## nginx\n\n```\n/usr/local/nginx/sbin/nginx #启动nginx\n/usr/local/nginx/sbin/nginx -s reload #重启nginx\n/usr/local/nginx/sbin/nginx -s stop #停止nginx\n```\n\n## 检测集群\n\n```\n/usr/bin/fdfs_monitor /etc/fdfs/storage.conf\n# 会显示会有几台服务器 有3台就会 显示 Storage 1-Storage 3的详细信息\n```\n\n# 说明\n\n## 配置文件\n\n```\ntracker_server #有几台服务器写几个\ngroup_name #地址的名称的命名\nbind_addr #服务器ip绑定\nstore_path_count #store_path(数字)有几个写几个\nstore_path(数字) #设置几个储存地址写几个 从0开始\n```\n\n## 可能遇到的问题\n\n```\n如果不是root 用户 你必须在除了cd的命令之外 全部加sudo\n如果不是root 用户 编译和安装分开进行 先编译再安装\n如果上传成功 但是nginx报错404 先检查mod_fastdfs.conf文件中的store_path0是否一致\n如果nginx无法访问 先检查防火墙 和 mod_fastdfs.conf文件tracker_server是否一致\n如果不是在/usr/local/src文件夹下安装 可能会编译出错\n```\n\n\n\n*官方部署文档地址：[FastDFS](https://github.com/happyfish100/fastdfs/wiki)*\n\n","tags":["fastdfs"]},{"title":"【fastdfs】使用ClusterShell安装fastDFS","url":"/2019/02/27/【fastdfs】fastDFS-clustershell/","content":"\n# clustershell 使用\n\n### 1. 部署clush环境\n\n```shell\n# 安装clush（可以yum直接安装，也可以源码安装）\nshell> yum install -y clustershell\n\n# clush命令：\nclush -a 全部 等于 clush -g all\nclush -g 指定组\nclush -w 操作主机名字，多个主机之间用逗号隔开\nclush -g 组名 -c --dest 文件群发 （-c等于--copy）\n\n# 注意：clush 是不支持环境变量的$PATH\n\n# 常用的是下面几个参数：\n-g 后面指定设置的组\n-a 表示所有的组\n-w 后面跟主机节点，多个主机中间用逗号隔开\n-x 表示去掉某个节点进行操作。后面跟主机节点，多个主机中间用逗号隔开\n-X 表示去掉某个组进行操作，多个组之间用逗号隔开\n-b 相同输出结果合并\n\n# 注意，clush操作远程机器，执行动作要放在双引号或单引号内进行\n```\n\n### 2. 配置 /etc/hosts\n\n```\neg:\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.10.214 host-172-16-2-208\n```\n\n### 3. 配置 /etc/clustershell/groups\n\n```shell\n# 配置clush：\n# 在/etc/clustershell目录下，手动创建groups文件\neg:\nshell> touch /etc/clustershell/groups\nshell> vim /etc/clustershell/groups\nall: a1 host1 host2\nname:host3 host4\n\n# 需要注意的是all 是必须配置的，clush 有 -a 这个参数，主机间用空格分离。\n\neg:\nshell> touch /etc/clustershell/groups\nshell> vim /etc/clustershell/groups\nall: host-172-16-2-208\n```\n\n### 4. 配置免密登录\n\n```shell\n# 如果没有事先生成ssh密匙的话，需要先生成：\nshell> ssh-keygen\n# 可选操作：为了方便，我们可以给需要登录的服务器起一个可读性更好的别名，如果你做了类似的操作，那么后面的<USER>@<SERVER>都可以换成对应的<HOST>：\nshell> cat ~/.ssh/config\nHost db_1\nHostname <SERVER>\nUser <USER>\nPort <PORT>\n\nHost db_2\nHostname <SERVER>\nUser <USER>\nPort <PORT>\n\nHost db_3\nHostname <SERVER>\nUser <USER>\nPort <PORT>\n# 然后把生成的公钥添加到需要登录的服务器指定位置：\nshell> cat ~/.ssh/id_rsa.pub | ssh <USER>@<SERVER> \"cat - >> ~/.ssh/authorized_keys\"\n\n# 如果你和我一样总记不清如何正确拼写authorized_keys，可以接着学一下ssh-copy-id的用法，这个命令可以让操作更简单点：\nshell> ssh-copy-id -i ~/.ssh/id_rsa.pub \"<USER>@<SERVER>\"\n\n# 注：每配置好一台免密码登录的服务器，最好手动实际操作一下，因为第一次连接会要求手动确认是否保存信息到~/.ssh/known_hosts文件。\n\neg:\n[root@host-172-16-2-207 ~]# ssh-copy-id host-172-16-2-208\nThe authenticity of host 'host-172-16-2-208 (192.168.10.214)' can't be established.\nECDSA key fingerprint is 16:2a:df:68:97:e0:2a:e1:c2:3c:d7:ac:99:d7:76:d0.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@host-172-16-2-208's password: \n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'host-172-16-2-208'\"\nand check to make sure that only the key(s) you wanted were added.\n\n```\n\n### 5. 利用clush管理命令进行远程机器集群管理\n\n```shell\n# ssh首次登陆的时候，会提示输入\"yes/no\"，需要提前将这个执行。\nshell> ssh 'host-172-16-2-208'\n\neg:\nshell> clush -g db uptime\nshell> clush -a hostname\nshell> clush -b -a hostname\nshell> clush -a \"echo asdfsdf > /tmp/test\"\n```\n\n# fastDFS 部署\n\n## 1. 环境准备\n\n### 1.1 使用的系统软件\n\n| 名称                 | 说明                          |\n| -------------------- | ----------------------------- |\n| centos               | 7.x                           |\n| libfatscommon        | FastDFS分离出的一些公用函数包 |\n| FastDFS              | FastDFS本体                   |\n| fastdfs-nginx-module | FastDFS和nginx的关联模块      |\n| nginx                | nginx1.15.4                   |\n\n### 1.2 编译环境\n\n```\nyum install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel wget vim -y\n```\n\n### 1.3 磁盘目录\n\n| 说明                                   | 位置           |\n| -------------------------------------- | -------------- |\n| 所有安装包                             | /usr/local/src |\n| 数据存储位置                           | /home/dfs/     |\n| #这里我为了方便把日志什么的都放到了dfs |                |\n\n```\nmkdir /home/dfs #创建数据存储目录\ncd /usr/local/src #切换到安装目录准备下载安装包\n```\n\n### 1.4 安装libfatscommon\n\n```\ngit clone https://github.com/happyfish100/libfastcommon.git --depth 1\ncd libfastcommon/\n./make.sh && ./make.sh install #编译安装\n```\n\n### 1.5 安装FastDFS\n\n```\ncd ../ #返回上一级目录\ngit clone https://github.com/happyfish100/fastdfs.git --depth 1\ncd fastdfs/\n./make.sh && ./make.sh install #编译安装\n#配置文件准备\ncp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf\ncp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf\ncp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用\ncp /usr/local/src/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用\ncp /usr/local/src/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用\n```\n\n### 1.6 安装fastdfs-nginx-module\n\n```\ncd ../ #返回上一级目录\ngit clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1\ncp /usr/local/src/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs\n```\n\n### 1.7 安装nginx\n\n```\nwget http://nginx.org/download/nginx-1.15.4.tar.gz #下载nginx压缩包\ntar -zxvf nginx-1.15.4.tar.gz #解压\ncd nginx-1.15.4/\n#添加fastdfs-nginx-module模块\n./configure --add-module=/usr/local/src/fastdfs-nginx-module/src/ \nmake && make install #编译安装\n```\n\n## 2. rpm 安装\n\n### 2.1 编译后的rpm 安装包 \n\n```sh\n[root@host-172-16-2-207 ~]# ll fdfs/\ntotal 512\n-rw-r--r--. 1 root root   1924 Feb 12 01:04 fastdfs-5.0.12-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root 170680 Feb 12 01:05 fastdfs-server-5.0.12-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root 133872 Feb 12 01:05 fastdfs-tool-5.0.12-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root 110888 Feb 12 01:05 libfastcommon-1.0.40-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root  40664 Feb 12 01:05 libfastcommon-devel-1.0.40-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root  36428 Feb 12 01:05 libfdfsclient-5.0.12-1.el7.centos.x86_64.rpm\n-rw-r--r--. 1 root root  18284 Feb 12 01:05 libfdfsclient-devel-5.0.12-1.el7.centos.x86_64.rpm\n[root@host-172-16-2-207 ~]# yum install -y ./fdfs/*.rpm\n\n```\n\n### 2.2 默认数据存储及日志位置\n\n```shell\n[root@host-172-16-2-207 ~]# mkdir -p /home/yuqing/fastdfs/\n# 服务正常启动后\n[root@host-172-16-2-207 ~]# ll /home/yuqing/fastdfs/\ntotal 12\ndrwxr-xr-x. 259 root root 8192 Feb 12 03:17 data\ndrwxr-xr-x.   2 root root   46 Feb 12 01:13 logs\n```\n\n## 3. 单机部署\n\n### 3.1 tracker配置\n\n```\n#服务器ip为 192.168.52.1\n#我建议用ftp下载下来这些文件 本地修改\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/home/dfs  # 存储日志和数据的根目录\n```\n\n### 3.2 storage配置\n\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/home/dfs  # 数据和日志文件存储根目录\nstore_path0=/home/dfs  # 第一个存储目录\ntracker_server=192.168.52.1:22122  # tracker服务器IP和端口\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n```\n\n### 3.3 client测试\n\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/home/dfs\ntracker_server=192.168.52.1:22122    #tracker服务器IP和端口\n#保存后测试,返回ID表示成功 如：group1/M00/00/00/xx.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.15.4.tar.gz\n```\n\n### 3.4 配置nginx访问\n\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\ntracker_server=192.168.52.1:22122  #tracker服务器IP和端口\nurl_have_group_name=true\nstore_path0=/home/dfs\n#配置nginx.config\nvim /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/ {\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    root   html;\n    }\n}\n#测试下载，用外部浏览器访问刚才已传过的nginx安装包,引用返回的ID\nhttp://192.168.52.1:8888/group1/M00/00/00/wKgAQ1pysxmAaqhAAA76tz-dVgg.tar.gz\n#弹出下载单机部署全部跑通\n```\n\n## 4. 分布式部署\n\n### 4.1 tracker配置\n\n```\n#服务器ip为 192.168.52.2,192.168.52.3,192.168.52.4\n#我建议用ftp下载下来这些文件 本地修改\nvim /etc/fdfs/tracker.conf\n#需要修改的内容如下\nport=22122  # tracker服务器端口（默认22122,一般不修改）\nbase_path=/home/dfs  # 存储日志和数据的根目录\n```\n\n### 4.2 storage配置\n\n```\nvim /etc/fdfs/storage.conf\n#需要修改的内容如下\nport=23000  # storage服务端口（默认23000,一般不修改）\nbase_path=/home/dfs  # 数据和日志文件存储根目录\nstore_path0=/home/dfs  # 第一个存储目录\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\nhttp.server_port=8888  # http访问文件的端口(默认8888,看情况修改,和nginx中保持一致)\n```\n\n### 4.3 client测试\n\n```\nvim /etc/fdfs/client.conf\n#需要修改的内容如下\nbase_path=/home/moe/dfs\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\n#保存后测试,返回ID表示成功 如：group1/M00/00/00/xx.tar.gz\nfdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.15.4.tar.gz\n```\n\n### 4.4 配置nginx访问\n\n```\nvim /etc/fdfs/mod_fastdfs.conf\n#需要修改的内容如下\ntracker_server=192.168.52.2:22122  # 服务器1\ntracker_server=192.168.52.3:22122  # 服务器2\ntracker_server=192.168.52.4:22122  # 服务器3\nurl_have_group_name=true\nstore_path0=/home/dfs\n#配置nginx.config\nvim /usr/local/nginx/conf/nginx.conf\n#添加如下配置\nserver {\n    listen       8888;    ## 该端口为storage.conf中的http.server_port相同\n    server_name  localhost;\n    location ~/group[0-9]/ {\n        ngx_fastdfs_module;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n    root   html;\n    }\n}\n```\n\n## 5. 启动\n\n### 5.1 防火墙\n\n```\n#不关闭防火墙的话无法使用\nsystemctl stop firewalld.service #关闭\nsystemctl restart firewalld.service #重启\n```\n\n### 5.2 tracker\n\n```\n/etc/init.d/fdfs_trackerd start #启动tracker服务\n/etc/init.d/fdfs_trackerd restart #重启动tracker服务\n/etc/init.d/fdfs_trackerd stop #停止tracker服务\nchkconfig fdfs_trackerd on #自启动tracker服务\n```\n\n### 5.3 storage\n\n```\n/etc/init.d/fdfs_storaged start #启动storage服务\n/etc/init.d/fdfs_storaged restart #重动storage服务\n/etc/init.d/fdfs_storaged stop #停止动storage服务\nchkconfig fdfs_storaged on #自启动storage服务\n```\n\n### 5.4 nginx\n\n```\n/usr/local/nginx/sbin/nginx #启动nginx\n/usr/local/nginx/sbin/nginx -s reload #重启nginx\n/usr/local/nginx/sbin/nginx -s stop #停止nginx\n```\n\n### 5.5 检测集群\n\n```\n/usr/bin/fdfs_monitor /etc/fdfs/storage.conf\n# 会显示会有几台服务器 有3台就会 显示 Storage 1-Storage 3的详细信息\n```\n\n## 6. 说明\n\n### 6.1 配置文件\n\n```\ntracker_server #有几台服务器写几个\ngroup_name #地址的名称的命名\nbind_addr #服务器ip绑定\nstore_path_count #store_path(数字)有几个写几个\nstore_path(数字) #设置几个储存地址写几个 从0开始\n```\n\n### 6.2 可能遇到的问题\n\n```\n如果不是root 用户 你必须在除了cd的命令之外 全部加sudo\n如果不是root 用户 编译和安装分开进行 先编译再安装\n如果上传成功 但是nginx报错404 先检查mod_fastdfs.conf文件中的store_path0是否一致\n如果nginx无法访问 先检查防火墙 和 mod_fastdfs.conf文件tracker_server是否一致\n如果不是在/usr/local/src文件夹下安装 可能会编译出错\n```","tags":["fastdfs","clustershell"]},{"title":"【fastdfs】使用普通用户安装fastDFS","url":"/2019/02/26/【fastdfs】使用普通用户安装启动fastDFS/","content":"\n# 普通用户安装fastDFS\n\n## 一、安装依赖\n\n```shell\nyum install -y zlib zlib-devel pcre pcre-devel gcc gcc-c++ openssl openssl-devel libevent libevent-devel perl unzip\n```\n\n\n\n## 二、创建fastdfs用户并设置密码\n\n```shell\nuseradd fastdfs\npasswd fastdfs\n```\n\n\n\n## 三、下载libfastcommon源码进行安装\n\n```shell\ncd /tmp\nwget -c https://github.com/happyfish100/libfastcommon/archive/V1.0.7.tar.gz\ntar -xvf V1.0.7.tar.gz\ncd libfastcommon-1.0.7\n./make.sh\n./make.sh install\n```\n\n\n\n## 四、设置软连接\n\n```shell\n # 此时 libfastcommon.so默认安装到了/usr/lib64/libfastcommon.so，而FastDFS主程序设置的lib目录是/usr/local/lib，所以设置软连接\n ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so\n ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so\n ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so\n ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so\n```\n\n\n\n## 五、使用fastdfs登录系统，在/home/fastdfs创建目录\n\n```shell\nmkdir src\nmkdir tracker\nmkdir storage\n```\n\n\n\n## 六、下载fastdfs5.05源码并解压\n\n```shell\ncd src\nwget -c https://github.com/happyfish100/fastdfs/archive/V5.05.tar.gz\ntar -zxvf V5.05.tar.gz\ncd fastdfs-5.05\n```\n\n\n\n## 七、修改make.sh并进行安装\n\n```shell\n修改make.sh中的TARGET_PREFIX、TARGET_CONF_PATH和TARGET_INIT_PATH：\nTARGET_PREFIX=/home/fastdfs\nTARGET_CONF_PATH=/home/fastdfs/conf\nTARGET_INIT_PATH=/home/fastdfs/init.d\n\n然后执行\n./make.sh\n./make.sh install\n注：安装时报如下的错误不用理会，因为配置文件在/home/fastdfs/conf里\n\nmkdir: cannot create directory `/etc/fdfs': Permission denied\n```\n\n\n\n## 八、修改配置文件名，去掉.sample后缀\n\n```shell\ncd /home/fastdfs/conf\nmv client.conf.sample client.conf\nmv storage.conf.sample storage.conf\nmv storage_ids.conf.sample  storage_ids.conf\nmv tracker.conf.sample tracker.conf\n```\n\n\n\n## 九、修改storage.conf\n\n```shell\ngroup_name=group1\nbind_addr=121.42.155.178 #改为实际的地址\nbase_path=/home/fastdfs/storage\nstore_path0=/home/fastdfs/storage\ntracker_server=121.42.155.178:22122 #改为实际的地址\nrun_by_group=fastdfs\nrun_by_user=fastdfs\n```\n\n\n\n## 十、修改tracker.conf\n\n```shell\nbind_addr=121.42.155.178 #改为实际的地址\nbase_path=/home/fastdfs/tracker\nrun_by_group=fastdfs\nrun_by_user=fastdfs\nuse_storage_id = true\nstorage_ids_filename = storage_ids.conf\nid_type_in_filename = id\n```\n\n\n\n## 十一、修改storage_ids.conf\n\n```shell\n100001   group1  121.42.155.178 #改为实际的地址\n```\n\n\n\n## 十二、修改client.conf\n\n```shell\nbase_path=/home/fastdfs\ntracker_server=121.42.155.178:22122 #改为实际的地址\n```\n\n\n\n## 十三、修改 /home/fastdfs/init.d/fdfs_storaged\n\n```shell\nPRG=/home/fastdfs/bin/fdfs_storaged\nCONF=/home/fastdfs/conf/storage.conf\n\n将fdfs_storaged中所有的usr/local替换为home/fastdfs：\nsed  -i  's/usr\\/local/home\\/fastdfs/g'  fdfs_storaged \n```\n\n\n\n## 十四、修改 /home/fastdfs/init.d/fdfs_trackerd\n\n```shell\nPRG=/home/fastdfs/bin/fdfs_trackerd\nCONF=/home/fastdfs/conf/tracker.conf\n\n将fdfs_trackerd中所有的usr/local替换为home/fastdfs：\nsed  -i  's:usr/local:home/fastdfs:g'  fdfs_trackerd\n```\n\n\n\n## 十五、启动\n\n```shell\n/home/fastdfs/init.d/fdfs_trackerd start\n/home/fastdfs/init.d/fdfs_storaged start\n```\n\n\n\n## 十六、常见问题\n\n```shell\n1.如何让server进程退出运行？\n\n直接kill即可让server进程正常退出，可以使用killall命令，例如：\n\nkillall fdfs_trackerd\n\nkillall fdfs_storaged\n\n也可以使用如下命令：\n\n/home/fastdfs/bin/fdfs_trackerd /home/fastdfs/conf/tracker.conf stop\n\n/home/fastdfs/bin/fdfs_storaged /home/fastdfs/conf/storage.conf stop\n\n千万不要使用-9参数强杀，否则可能会导致binlog数据丢失的问题。\n\n \n\n2.如何查看storage状态？\n\nfdfs_monitor  /home/fastdfs/conf/storage.conf\n```\n\n\n\n# 普通用户开机启动服务\n\n```shell\n# 1. 使用root账户登录，修改/etc/rc.local 文件\n[root@host-172-16-2-210 ~]# cat /etc/rc.local \n#!/bin/bash\n# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES\n#\n# It is highly advisable to create own systemd services or udev rules\n# to run scripts during boot instead of using this file.\n#\n# In contrast to previous versions due to parallel execution during boot\n# this script will NOT be run after all other services.\n#\n# Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure\n# that this script will be executed during boot.\n\ntouch /var/lock/subsys/local\n\nsu - test -c \"/bin/sh /home/test/init.d/fdfs_trackerd start\"\nsu - test -c \"/bin/sh /home/test/init.d/fdfs_storaged start\"\n\n# 2. 给/etc/rc.local 文件赋予执行权限\nchmod +x /etc/rc.d/rc.local\n\n# 3. 禁用防火墙\nsystemctl disable firewalld\nsystemctl stop firewalld\n\n# 4. 重启测试\n\n```\n\n\n\n","tags":["fastdfs"]},{"title":"【mysql】MySQL主从复制","url":"/2019/02/18/【mysql】mysql主从复制/","content":"\n**mysql主从复制**\n（超简单）\n\n怎么安装mysql数据库，这里不说了，只说它的主从复制，步骤如下：\n\n1、主从服务器分别作以下操作：\n  1.1、版本一致\n  1.2、初始化表，并在后台启动mysql\n  1.3、修改root的密码\n\n2、修改主服务器master:\n   #vi /etc/my.cnf\n       [mysqld]\n       log-bin=mysql-bin   //[必须]启用二进制日志\n       server-id=222      //[必须]服务器唯一ID，默认是1，一般取IP最后一段\n\n3、修改从服务器slave:\n   #vi /etc/my.cnf\n       [mysqld]\n       log-bin=mysql-bin   //[不是必须]启用二进制日志\n       server-id=226      //[必须]服务器唯一ID，默认是1，一般取IP最后一段\n\n4、重启两台服务器的mysql\n   /etc/init.d/mysql restart\n\n5、在主服务器上建立帐户并授权slave:\n   #/usr/local/mysql/bin/mysql -uroot -pmttang   \n   mysql>GRANT REPLICATION SLAVE ON *.* to 'mysync'@'%' identified by 'q123456'; //一般不用root帐号，&ldquo;%&rdquo;表示所有客户端都可能连，只要帐号，密码正确，此处可用具体客户端IP代替，如192.168.145.226，加强安全。\n\n6、登录主服务器的mysql，查询master的状态\n   mysql>show master status;\n   +------------------+----------+--------------+------------------+\n   | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n   +------------------+----------+--------------+------------------+\n   | mysql-bin.000004 |      308 |              |                  |\n   +------------------+----------+--------------+------------------+\n   1 row in set (0.00 sec)\n   注：执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化\n\n7、配置从服务器Slave：\n   mysql>change master to master_host='192.168.145.222',master_user='mysync',master_password='q123456',\n         master_log_file='mysql-bin.000004',master_log_pos=308;   //注意不要断开，308数字前后无单引号。\n\n   Mysql>start slave;    //启动从服务器复制功能\n\n8、检查从服务器复制功能状态：\n\n   mysql> show slave status\\G\n\n   *************************** 1. row ***************************\n\n              Slave_IO_State: Waiting for master to send event\n              Master_Host: 192.168.2.222  //主服务器地址\n              Master_User: mysync   //授权帐户名，尽量避免使用root\n              Master_Port: 3306    //数据库端口，部分版本没有此行\n              Connect_Retry: 60\n              Master_Log_File: mysql-bin.000004\n              Read_Master_Log_Pos: 600     //#同步读取二进制日志的位置，大于等于Exec_Master_Log_Pos\n              Relay_Log_File: ddte-relay-bin.000003\n              Relay_Log_Pos: 251\n              Relay_Master_Log_File: mysql-bin.000004\n              Slave_IO_Running: Yes    //此状态必须YES\n              Slave_SQL_Running: Yes     //此状态必须YES\n                    ......\n\n注：Slave_IO及Slave_SQL进程必须正常运行，即YES状态，否则都是错误的状态(如：其中一个NO均属错误)。\n\n以上操作过程，主从服务器配置完成。\n\n9、主从服务器测试：\n\n主服务器Mysql，建立数据库，并在这个库中建表插入一条数据：\n\n  mysql> create database hi_db;\n  Query OK, 1 row affected (0.00 sec)\n\n  mysql> use hi_db;\n  Database changed\n\n  mysql>  create table hi_tb(id int(3),name char(10));\n  Query OK, 0 rows affected (0.00 sec)\n\n  mysql> insert into hi_tb values(001,'bobu');\n  Query OK, 1 row affected (0.00 sec)\n\n  mysql> show databases;\n   +--------------------+\n   | Database           |\n   +--------------------+\n   | information_schema |\n   | hi_db                |\n   | mysql                |\n   | test                 |\n   +--------------------+\n   4 rows in set (0.00 sec)\n\n从服务器Mysql查询：\n\n   mysql> show databases;\n\n   +--------------------+\n   | Database               |\n   +--------------------+\n   | information_schema |\n   | hi_db                 |       //I'M here，大家看到了吧\n   | mysql                 |\n   | test          |\n\n   +--------------------+\n   4 rows in set (0.00 sec)\n\n   mysql> use hi_db\n   Database changed\n   mysql> select * from hi_tb;           //查看主服务器上新增的具体数据\n   +------+------+\n   | id   | name |\n   +------+------+\n   |    1 | bobu |\n   +------+------+\n   1 row in set (0.00 sec)\n\n\n**10、完成：**\n​    编写一shell脚本，用nagios监控slave的两个yes（Slave_IO及Slave_SQL进程），如发现只有一个或零个yes，就表明主从有问题了，发短信警报吧。","tags":["mysql"]},{"title":"【Linux】常用的46个linux命令","url":"/2019/02/10/【linux】Linux常用的46个命令/","content":"\n## 常用的46个linux命令\n\n### 问题一：\n\n绝对路径用什么符号表示？当前目录、上层目录用什么表示？主目录用什么表示? 切换目录用什么命令？\n\n答案：\n绝对路径： 如/etc/init.d\n当前目录和上层目录： ./  ../\n主目录： ~/\n切换目录： cd\n\n### 问题二：\n\n怎么查看当前进程？怎么执行退出？怎么查看当前路径？\n答案：\n查看当前进程： ps\n执行退出： exit\n查看当前路径： pwd\n\n### 问题三：\n\n怎么清屏？怎么退出当前命令？怎么执行睡眠？怎么查看当前用户 id？查看指定帮助用什么命令？\n答案：\n清屏： clear\n退出当前命令： ctrl+c 彻底退出\n执行睡眠 ： ctrl+z 挂起当前进程fg 恢复后台\n查看当前用户 id： ”id“：查看显示目前登陆账户的 uid 和 gid 及所属分组及用户名\n查看指定帮助： 如 man adduser 这个很全 而且有例子； adduser --help 这个告诉你一些常用参数； info adduesr；\n\n### 问题四：\n\nLs 命令执行什么功能？ 可以带哪些参数，有什么区别？\n答案：\nls 执行的功能： 列出指定目录中的目录，以及文件\n哪些参数以及区别： a 所有文件l 详细信息，包括大小字节数，可读可写可执行的权限等\n\n### 问题五：\n\n建立软链接(快捷方式)，以及硬链接的命令。\n答案：\n软链接： ln -s slink source\n硬链接： ln link source\n\n### 问题六：\n\n目录创建用什么命令？创建文件用什么命令？复制文件用什么命令？\n答案：\n创建目录： mkdir\n创建文件：典型的如 touch，vi 也可以创建文件，其实只要向一个不存在的文件输出，都会创建文件\n复制文件： cp \n\n### 问题七：\n\n文件权限修改用什么命令？格式是怎么样的？\n文件权限修改： chmod\n格式如下：\n\n```\n$ chmod u+x file 给 file 的属主增加执行权限\n$ chmod 751 file 给 file 的属主分配读、写、执行(7)的权限，给 file 的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限\n$ chmod u=rwx,g=rx,o=x file 上例的另一种形式\n$ chmod =r file 为所有用户分配读权限\n$ chmod 444 file 同上例\n$ chmod a-wx,a+r file同上例\n$ chmod -R u+r directory 递归地给 directory 目录下所有文件和子目录的属主分配读的权限\n```\n\n###  问题八：\n\n查看文件内容有哪些命令可以使用？\n答案：\nvi 文件名 #编辑方式查看，可修改\ncat 文件名 #显示全部文件内容\nmore 文件名 #分页显示文件内容\nless 文件名 #与 more 相似，更好的是可以往前翻页\ntail 文件名 #仅查看尾部，还可以指定行数\nhead 文件名 #仅查看头部,还可以指定行数\n\n### 问题九：\n\n随意写文件命令？怎么向屏幕输出带空格的字符串，比如”hello world”? \n\n答案：\n\n写文件命令：vi\n\n向屏幕输出带空格的字符串:echo hello world\n\n### 问题十：\n\n终端是哪个文件夹下的哪个文件？黑洞文件是哪个文件夹下的哪个命令？\n答案：\n终端  /dev/tty\n\n黑洞文件  /dev/null\n\n### 问题十一：\n\n移动文件用哪个命令？改名用哪个命令？\n答案：\nmv mv\n\n### 问题十二：\n\n复制文件用哪个命令？如果需要连同文件夹一块复制呢？如果需要有提示功能呢？\n答案：\ncp cp -r  ？？？？\n\n### 问题十三：\n\n删除文件用哪个命令？如果需要连目录及目录下文件一块删除呢？删除空文件夹用什么命令？\n答案：\nrm rm -r rmdir\n\n### 问题十四： \n\nLinux 下命令有哪几种可使用的通配符？分别代表什么含义?\n答案：\n“？”可替代单个字符。\n\n“*”可替代任意多个字符。\n\n方括号“[charset]”可替代 charset 集中的任何单个字符，如[a-z]，[abABC]\n\n### 问题十五：\n\n用什么命令对一个文件的内容进行统计？(行号、单词数、字节数)\n答案：\n\nwc 命令 - c 统计字节数 - l 统计行数 - w 统计字数。\n\n### 问题十六：\n\nGrep 命令有什么用？ 如何忽略大小写？ 如何查找不含该串的行?\n答案：\n是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。\ngrep [stringSTRING] filename grep [^string] filename\n\n### 问题十七：\n\nLinux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？\n答案：\n（1）、不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号。\n（2）、暂停状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。\n“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。\n\n（3）、就绪状态：在 run_queue 队列里的状态\n\n（4）、运行状态：在 run_queue 队列里的状态\n（5）、可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起\n（6）、zombie 状态（僵尸）：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉\n（7）、退出状态\n\nD 不可中断 Uninterruptible（usually IO）\nR 正在运行，或在队列中的进程\nS 处于休眠状态\nT 停止或被追踪\nZ 僵尸进程\nW 进入内存交换（从内核 2.6 开始无效）\nX 死掉的进程\n\n### 问题十八：\n\n怎么使一个命令在后台运行?\n答案：\n一般都是使用 & 在命令结尾来让程序自动运行。(命令后可以不追加空格)\n\n### 问题十九：\n\n利用 ps 怎么显示所有的进程? 怎么利用 ps 查看指定进程的信息？\n答案：\nps -ef (system v 输出) \n\nps -aux bsd 格式输出\n\nps -ef | grep pid\n\n### 问题二十：\n\n哪个命令专门用来查看后台任务? \n\n答案：\n\njob -l\n\n### 问题二十一：\n\n把后台任务调到前台执行使用什么命令?把停下的后台任务在后台执行起来用什么命令?\n答案：\n把后台任务调到前台执行 fg\n\n把停下的后台任务在后台执行起来 bg\n\n### 问题二十二：\n\n终止进程用什么命令? 带什么参数? \n\n答案：\n\n```shell\nkill [-s <信息名称或编号>][程序] 或 kill [-l <信息编号>] \nkill-9 pid\n```\n\n### 问题二十三：\n\n怎么查看系统支持的所有信号？\n\n答案：\n\nkill -l\n\n### 问题二十四：\n\n搜索文件用什么命令? 格式是怎么样的? \n\n答案：\n\nfind <指定目录> <指定条件> <指定动作>\n\nwhereis 加参数与文件名\n\nlocate 只加文件名\n\nfind 直接搜索磁盘，较慢。\n\nfind / -name \"string*\"\n\n### 问题二十五：\n\n查看当前谁在使用该主机用什么命令? 查找自己所在的终端信息用什么命令?\n答案：\n查找自己所在的终端信息：who am i\n\n查看当前谁在使用该主机：who \n\n### 问题二十六：\n\n使用什么命令查看用过的命令列表?\n\n答案：\n\nhistory\n\n### 问题二十七：\n\n使用什么命令查看磁盘使用空间？ 空闲空间呢?\n\n答案：\n\ndf -hl\n文件系统 容量 已用 可用 已用% 挂载点\nFilesystem Size Used Avail Use% Mounted on /dev/hda2 45G 19G 24G 44% /\n/dev/hda1 494M 19M 450M 4% /boot\n\n### 问题二十八：\n\n使用什么命令查看网络是否连通?\n答案：\nnetstat\n\n### 问题二十九：\n\n使用什么命令查看 ip 地址及接口信息？\n\n答案：\n\nifconfig\n\n### 问题三十：\n\n查看各类环境变量用什么命令?\n\n答案：\n\n查看所有 env\n查看某个，如 home： env $HOME\n\n### 问题三十一：\n\n通过什么命令指定命令提示符?\n\n答案：\n\n\\u：显示当前用户账号\n\n\\h：显示当前主机名\n\n\\W：只显示当前路径最后一个目录\n\n\\w：显示当前绝对路径（当前用户目录会以~代替）\n\n$PWD：显示当前全路径\n\n\\$：显示命令行’$'或者’#'符号\n\n\\#：下达的第几个命令\n\n\\d：代表日期，格式为week day month date，例如：\"MonAug1\"\n\n\\t：显示时间为24小时格式，如：HH：MM：SS\n\n\\T：显示时间为12小时格式\n\n\\A：显示时间为24小时格式：HH：MM\n\n\\v：BASH的版本信息 如export PS1=’[\\u@\\h\\w\\#]\\$‘ \n\n### 问题三十二：\n\n查找命令的可执行文件是去哪查找的? 怎么对其进行设置及添加? \n\n答案：\n\n```shell\nwhereis [-bfmsu][-B <目录>...][-M <目录>...][-S <目录>...][文件...]\n```\n\n补充说明：whereis 指令会在特定目录中查找符合条件的文件。这些文件的烈性应属于原始代码，二进制文件，或是帮助文件。\n\n-b   只查找二进制文件。\n\n-B<目录> 只在设置的目录下查找二进制文件。 -f 不显示文件名前的路径名称。\n-m   只查找说明文件。\n-M<目录> 只在设置的目录下查找说明文件。 -s 只查找原始代码文件。\n-S<目录> 只在设置的目录下查找原始代码文件。 -u 查找不包含指定类型的文件。\nwhich 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。\n-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。\n-p 与-n 参数相同，但此处的包括了文件的路径。 -w 指定输出时栏位的宽度。\n-V   显示版本信息\n\n### 问题三十三：\n\n通过什么命令查找执行命令?\n答案：\nwhich 只能查可执行文件\n\nwhereis 只能查二进制文件、说明文档，源文件等\n\n### 问题三十四：\n\n怎么对命令进行取别名？\n答案：\nalias la='ls -a'\n\n### 问题三十五：\n\ndu 和 df 的定义，以及区别？\n答案：\n\ndu 显示目录或文件的大小\n\ndf 显示每个<文件>所在的文件系统的信息，默认是显示所有文件系统。\n（文件系统分配其中的一些磁盘块用来记录它自身的一些数据，如 i 节点，磁盘分布图，间接块，超级块等。这些数据对大多数用户级的程序来说是不可见的，通常称为 Meta Data。） du 命令是用户级的程序，它不考虑 Meta Data，而 df 命令则查看文件系统的磁盘分配图并考虑 Meta Data。\ndf 命令获得真正的文件系统数据，而 du 命令只查看文件系统的部分情况。\n\n### 问题三十六：\n\nawk 详解。\n答案：\n\n```shell\nawk '{pattern + action}' {filenames}\n#cat /etc/passwd |awk -F ':' '{print $1\"\\t\"$7}' //-F 的意思是以':'分隔 root /bin/bash\ndaemon /bin/sh 搜索/etc/passwd 有 root 关键字的所有行\n\n#awk -F: '/root/' /etc/passwd root:x:0:0:root:/root:/bin/bash\n```\n\n### 问题三十七：\n\n当你需要给命令绑定一个宏或者按键的时候，应该怎么做呢？\n\n答案：\n\n可以使用bind命令，bind可以很方便地在shell中实现宏或按键的绑定。\n\n在进行按键绑定的时候，我们需要先获取到绑定按键对应的字符序列。\n\n比如获取F12的字符序列获取方法如下：先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^[[24~。\n\n接着使用bind进行绑定。\n\n```shell\n[root@localhost ~]# bind ‘”\\e[24~\":\"date\"'\n```\n\n注意：相同的按键在不同的终端或终端模拟器下可能会产生不同的字符序列。\n\n【附】也可以使用showkey -a命令查看按键对应的字符序列。 \n\n### 问题三十八：\n\n如果一个linux新手想要知道当前系统支持的所有命令的列表，他需要怎么做？\n\n答案：\n\n使用命令compgen ­-c，可以打印出所有支持的命令列表。\n\n```shell\n[root@localhost ~]$ compgen -c\n\nl.\n\nll\n\nls\n\nwhich\n\nif\n\nthen\n\nelse\n\nelif\n\nfi\n\ncase\n\nesac\n\nfor\n\nselect\n\nwhile\n\nuntil\n\ndo\n\ndone\n\n… \n```\n\n### 问题三十九：\n\n如果你的助手想要打印出当前的目录栈，你会建议他怎么做？\n\n答案：\n\n使用Linux 命令dirs可以将当前的目录栈打印出来。\n\n```shell\n[root@localhost ~]# dirs\n\n/usr/share/X11\n```\n\n【附】：目录栈通过pushd popd 来操作。\n\n### 问题四十：\n\n你的系统目前有许多正在运行的任务，在不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？\n\n答案：\n\n使用linux命令 ’disown -r ’可以将所有正在运行的进程移除。\n\n### 问题四十一：\n\nbash shell 中的hash 命令有什么作用？\n\n答案：\n\nlinux命令’hash’管理着一个内置的哈希表，记录了已执行过的命令的完整路径, 用该命令可以打印出你所使用过的命令以及执行的次数。\n\n```shell\n[root@localhost ~]# hash\n\nhits command\n\n2 /bin/ls\n\n2 /bin/sua\n```\n\n### 问题四十二：\n\n哪一个bash内置命令能够进行数学运算。\n\n答案：\n\nbash shell 的内置命令let 可以进行整型数的数学运算。\n\n```shell\n#! /bin/bash\n…\n…\nlet c=a+b\n…\n…\n```\n\n### 问题四十三：\n\n怎样一页一页地查看一个大文件的内容呢？\n\n答案：\n\n通过管道将命令”cat file_name.txt” 和 ’more’ 连接在一起可以实现这个需要.\n\n```shell\n[root@localhost ~]# cat file_name.txt | more\n```\n\n### 问题四十四：\n\n数据字典属于哪一个用户的？\n\n答案：\n\n数据字典是属于’SYS’用户的，用户‘SYS’ 和 ’SYSEM’是由系统默认自动创建的\n\n### 问题四十五：\n\n怎样查看一个linux命令的概要与用法？假设你在/bin目录中偶然看到一个你从没见过的的命令，怎样才能知道它的作用和用法呢？\n\n答案：\n\n使用命令whatis 可以先出显示出这个命令的用法简要，比如，你可以使用whatis zcat 去查看‘zcat’的介绍以及使用简要。\n\n```shell\n[root@localhost ~]# whatis zcat\n\nzcat [gzip] (1) – compress or expand files\n```\n\n### 问题四十六：\n\n使用哪一个命令可以查看自己文件系统的磁盘空间配额呢？\n\n答案：\n\n使用命令repquota 能够显示出一个文件系统的配额信息\n\n【附】只有root用户才能够查看其它用户的配额。","tags":["linux"]},{"title":"【others】钢琴游戏-琴谱","url":"/2018/12/24/【others】钢琴游戏-琴谱/","content":"\n[游戏链接](http://img.meijiecao.net/ac/gangqin.swf)\n\n*玩法：先用鼠标点击键盘上的任意一个键，然后按照下面曲谱输入键盘上的字母就行了。*\n\n### **曲谱：**\n\n```\n《童话》 LONOL LONOL LONO OOMMLLONOL LQPPO LONOM MMOTS PPRRQQ QQNPOONO ONOR LSRQPPPRRQQ QQVUTUV VPOT TTSSSLSRQQRQ QRQ RQPOOQST TTSPPRQ OQST TTSPPRQRQPO PQMMOONO\n\n《星语心愿》 TVUTSTQ TSTVUVUTUV VWXXXXW VUTUS TVUTST QSTXWVUV VUTTTTSSTQ SSTXWVUVV VUTTSUT\n\n《会呼吸的痛》 STVTXXTW WWVUVWXWSV VUTUVRRRVVWVSSS SYXWXX STVTXXTW WWVUVWXWSVV VUTUVRRRVVWVSSS STUVVUVV\n\n《欢乐颂》 J J K L L K J I H H I J J I IJ J K L L K J I H H I J I H H I I J H I J K J H I J K J I H I E J J K L L K J I H H I J I H H\n\n《千千阙歌》 HHIJ LMONNNLJ IIIJK MOQPPNLHHIJ LMONNNLJ IIIJK MOQPPNLMLMLMNNMN PPPPNOPQQQPPPOQ NLMLMOPQQPQ QPOP OMM LMOP QQPQ QSTSQQQQPPOPOM QQRQPOP QQ Q PPOP OMOO\n\n《婚礼进行曲》 HKKK HLJK HKNNMLKJKL HKKK HLJK HKMOMKILMKNMLII JKLL NMLII JKLL HKKK HLJK HKMOMKILMKILMKK\n\n《青花瓷》 LLJ IJF IJLJ I LLJ IJE IJLI H HIJLMLJ LJJI I HIH IHI IJLJ J LLJ IJF IJLJI LLJ IJE IJLIH HIJ LMLJ LJJII EJIIH\n\n《夜曲》 MN OOOONQQ TTTSRSOO RRRSQNQP PONOON OOOONQQ TTTSRSOO RRR QPNOM\n\n《暗香》 JKJGHJM ONLJ JKJGHJM ONLQ MMMOQLKMP PQRPQRQ MPQRPQRM MQRSQRSM PQRMR SKPQPQRQ JKJGHJMONLJ JKJGHJMONLM\n\n《遇见》 LJ LI JIH HGFGHGHIJ LJ LP ONO HGFGHGHIH LMNONONMLML HIJKJKLHIJ LMNONONPOPOQL HIJKJKJIHGH LMNONOPONML HIJKJKLHHML LMNONOPOPQL, HIJKJKLHHML LMNONOPOPQL, HIJIJILHIJH LMNONOMNLKL JJJKLJEE IIIJKIEE HHHIJIGH GFGHG FEFML IKJIH HGFIIHFFGH\n\n《波斯猫》 OOOMLMLJJ MMMLJLJII OOOMOMOJJ IMJ JL M M M\n\n《菊花台》 JJIJ JLJIJ HHIJLJ IIHI J LJML MLLJL EJIILJIIIHI JJIJ JLJIJ HHIJLJ IIHI J LJML MLLJL JIJLJIIH HIJJLM MQQPOML MLJIH FHIIHI HIJJLM MQPOOPO LLJNOHIJIH\n\n《北京欢迎你》歌谱 QSQPQPQQPMO QP POMOPQSPQTSSPO POMOPQSPQTSSQ PQPOSTQMQPPO QSVSTTS QQ SS QS TV WV SQ P S Q Q QS VS TV WV SQ SVT QP QS XW VV\n\n《致爱丽斯》 QPQPQNPOMHJMNJLNOJQPQPQNPOMHJMNJONMNOPQLRQPKQPOJPONNJQQQQPQPQNPOMHJMNJLNOJQPQPQNPOMHJMNJONMORQQPPRTSRQPONMMLMNOPPQRMOPNOPQSPNOPQSPNQQQQQP\n\n《约定》 LOPQPOQPLL JMNONMONJL MLLKKOJJPO PQRQQPOMP LOPQPOQPNL QMNONMONJL MLLKKOPQO MNOMOTSS POSQ QPONOMJM OPOTR RQRMNOP QRSSSTO SNPO PQMORQRSP POSQ QPONOMJM OPOTR RQRMNOP QRSSSTO SNPO PQRMRQOPO\n\n《美丽的神话》 MQN MOPOQ MTSTSPRQ MTSPQRQ O MQPNM MQNMOPOQ MTSTSPRQ MTSPQRQPO MPONM MNOPQONL MOPQQ MNOPQONLMOPOO MPONM MNOPQONL MOPQQ MNOPQONLMOPOO OOPQONLONMNT\n\n《有没有人告诉你》 JMMMMMMMMJKLK JLLLLLLLMNNJ JMMMMMMMMQQP NNNNNJONON JMMMMMMMMJKLK ILLLLLLLMNNJ JMMMMMMMMQQP NNNNNNNMNM QTQQQQOMJJQP JSSSSSSSTUUQ QTQQQQOMJJQP PPPPPJNNM\n\n《卡农》　(括号是一起按) H-JLO E-ILN F-HJM C-GIL D-FHK A-EHJ D-FHK E-GIL (HQ)-JLO (EP)-GIL (OF)-HJM (NC)-GJL (MD)-FHK (LA)-CEH (MD)-FHK (NE)-GIL ONOH (G B )LIJ (CH)ONM (CN)QST (DR)QPR (QA)PON (DM)LKJ (EI)KJI (EH)IJK (EG)ILK (FJ)MLK (CL)KJI (DH)FMN (AO)NML (DK)JIM LML (SJ)QRS-QR(SE)LMNOPQR (FQ)OPQ-JK(GL)MLKLJKL (FK)MLK-JI(JE)IHIJKLM (FK)MLM-NO(GL)MNOPQRS (SI)QRS-QR(SE)LMNOPQR (FQ)OPQ-JK(GL)MLKLJKL (FK)MLK-JI(EJ)IHIJKLM (FK)MLM-NO(GL)MNOPQRS (HQ)-JLO (EP)-GIL (OF)-HJM (NC)-GJL (MD)-FHK (LA)-CEH (MD)-FHK (NE)-\n\n《月亮代表我的心》Flash键盘钢琴谱 LOQSONQS STUVTS QPOOO QPOOO PQPOMPQP LOQSONQS STUVTS POOO QPOOO PQPMNOPO QSQPOSN MNMNMLQ SQPOSN MNOOOPQP LOQSONQS STUVTS QPOOO QPOOO PQPMNOPO\n\n《安静》 Flash键盘钢琴谱 QQQQPONPPPO LQPOOOLQPOOP QQQQPONPPPO LQPOOOLQPOOPPQR RRRRQPOOOPP LSSSRQPPPQQ MRQRQPOONOL QRQRQPOPS LQRSRQSLQRSRQS LQRSRQOPPPQO SSOONOOSSOONOO RRQQPPORRQQPPO LQRSRQSLQRSRQS LQRSRQOPPPQO SSOONOOSSOONOO RRQQPPOORQPOMOO\n\n《好好恋爱》 Flash键盘钢琴谱 JKLLLLLKJIIL NNONOOOPQNNL HMMMJMOLLLLJH KKKJKLMMMOML JKJJKLLLLJIHHO NMLML JHHMMLLLKJ OOOONOPP LRQLLRPLRQRQRQPO ONMMQMQMLLQLQL RQRQOP LRQLLRSPLRQQQRQPQ ONMMQMQMLLQLQPOM OPNMNMNQPOO\n\n《痴心绝对》 Flash键盘钢琴谱 OPQQQRQPPOPPSP ONOOOQQOOMNNQN MLMMMRRQSO MLMMMRROOMP OOPQQQRQPPOPPSP ONOOOQQOOMNNQN MLMMRRQSO MLMMMRROOONO\n\n《想唱就唱》Flash键盘钢琴谱 onopol jkkklj onopol lmmmon onopqolj opolj onopqolo rqpoq qrst oopqp pqrs srqpq qrstss uuvuspq rqrs qrst oopqp pqs quuqv vuvtsoo tsrqrs ts qrst oopqp pqrs srqpq qrstss uuvuspq rqrs qrst oopqp pqs quuqv vuvtsoo tsrqrs\n\n《梦里》Flash键盘钢琴谱 qqqqqqpo lmoooomq qqqqstsqp lpppppsq qqrs oopq llmoqpsq qqrs oopq llmoqpoo opqrsssrqrss ssssvtsq qqpo opm moppppqp opqrsssrqrss ssssvtsq qqpo opm mopqqqqpom qqqqqqpo lmoooomq qqqqstsqp lpppppsq qqrs oopq llmoqpsq qqrs oopq llmoqpoo opqrsssrqrss ssssvtsq qqpo opm moppppqp opqrsssrqrss ssssvtsq qqpo opm mopqqqqmpqt\n\n《画心》Flash键盘钢琴谱 LJJ IHIILJ LJJIHILmJ LJJIHIHGHIGEF CEF FJIHGEF EEFFHGFEBC CCEFGHEHIJ LJJ IHIHGHIGEF CEFFJIHGEF CEFHGFEFC CEFFGHEHIJ LJJ IHIHGHIGEF CEFFJIHGEF LJJ IHIHGHIGEF CEFFJIHGEF LJJIHIILJ LJJIHILmJ LJJIHIHGHIGEF CEFFJIHGEF\n\n《雪绒花》Flash键盘钢琴谱 CEI HED CCCDEFE CEI HED CEEFGHH I EEGFECEH FHIHGE CEI HED CEEFGHH\n\n《隐形的翅膀》Flash键盘钢琴谱 JLOON MLMOJIH HHHOLMLJHI JLOON MLMOJIH HHHOLMLJIH\n\n《说好的幸福－周杰伦》Flash键盘钢琴谱 L LLLL LLLL LLORQ QPQP NO PLLMNI LLM NIJMN OKJ KNO PLK LLM NMJ IFG前奏 MNONMNL MLKLJ MNONMNLPP QQRQP LMNOO OONOPP PPPPOPLOO OOLOLOO OOOL OLOO OOOP QQQQ QQRQ 中间 OPQ QQQQ QQQQ QQQP PNOP PPPP PPP PQPO OOOO SRRQ QPPO PPOP POPO RQQP POOP RRRR SO QQQQ QQQQ QQQP PNOS SSSS SSSP PQPO OMMO SRRQ QPPO QPLL QPO 高潮\n\n《給我一首歌的时间》Flash键盘钢琴谱 LQQROPOOPQP LQQPOOMOMPO QQRQPOOMOMPL LLMPOOMOMOPP\n\n《最熟悉的陌生人》Flash键盘钢琴谱 PQPQ OPQRSRRQQPOP PQPQ OTSRRQRQPQPO OVUUTSQTSSRSRS PQRQRV TVWW VWXXXXYXXX WVVTX SSTVVVTS SXXXWV VVVTW VWXXXXYXXX WVVWWV SSTVVVTSSXXXWVTV\n\n《世上只有妈妈好》Flash键盘钢琴谱 M L J L O M L M J L M L J I H F L J I I J L L M J I H L J I H F H E\n\n《死了都要爱》Flash键盘钢琴谱 JOOOO PNMLKIJJ KKLM IIJK MNMN JOOOO PNMLKIJJ KKLM ONMM\n\n《虫儿飞》Flash键盘钢琴谱 jjjkljii hhhijjgg fji fji fjihh jjjkljii hhhijjgg fji fji fjihh jil kji lkjklji hfji hfih kjkjh hkjkjhih\n\n《大海》Flash键盘钢琴谱 FEHHHH EFHHIH FHIIII HFIIJI JLMMLM LJIJIHF EFHHHHIH JLMMMMOMLLML JIHHHHIJ JIHHHHOMLLML JLMOOML JLMMMMOMLLML JIHHHHLJ JIHHHHIJLLJL JLM FJIHH\n\n《天空之城》Flash键盘钢琴谱 MNONOQN LJMLMOLL KJKOJ JHOON OONNMN ONOQN JMLMHLJ JKONOPQOO ONMMNLM OPQPQSP LONOQQ MNOONOPO LLRQPOQ QTSQPO POPSQ QTSQPO POPNM MNONOQN JMLMHLJ\n\n《梁祝》Flash键盘钢琴谱 LJIH IGFE NMNLMKJL IJLIJKJIH LGIFHE FHE CEFHI FHE LOMLJLI IJGFEFHICHFEFHE JLGIFHE CECEFGIF EFHILJIJIHFECH FHFECEFHE JLIJIHGFE\n\n《我是真的受伤了》Flash键盘钢琴谱 momqp lnlpo mrqomopo momqp lnlpo momqppopsq momqp lnlpo lrqomop-po rrqqp psppo rrqqppopqrqq ttsspprqpo mqoo sqpp— momqp lnlpo momqppopsq ttttspsppo mrqomopo—- JKONOPQOO ONMMNLM\n\n《往事难忘》Flash键盘钢琴谱 H HIJ JKL MLJ LKJI KJIH H HIJ JKL MLJ LKJI JIH LKJI EEKJIH LKJI KJIH H HIJ JKL MLJ LKJI JIH\n\n《离家出走》Flash键盘钢琴谱 STSQP SQPPO OOPQO OPPOQP STSQS VUSQSTS PQRQORQPO SZRQRSTSRQP QRSTS VUTUVVVUTUS QRSSTTQPPQRRSSPO ORQRQRRSTS QRTSVV SZZX VQQQPQUUUVTOSTSQ RRRPTS VUSSVV SWWU VTVTV ZYX TVWXVW TVUUV TVWXYXYW VUVWVXX UVWUVQQQ QQUUVUV TOSTSV TVVUVW XWVSVV SWWU VTVTVZYX TVWXVW TVUTS\n\n《心乱如麻》 Flash键盘钢琴谱 TSRQRSRQ RRVUTSS QTS TSRQRSRQ RRTSVUV WVXWV VVUUVWS SQTS RRSQVUV WVXWV SXXXYXWV XXXYXWV SWWVWVXXW QSTTSS TVWWVV SZYXVVTTVXYXW SVWXYXVWX WVWVZZ XXTVX XTUVWV QRSTSVWUTS SYXSYXSXYZXVW QSTTSS TVWWVV SZYXVVTTVXYXW SVWXYXVWX WVWVZZ XXTVX XTUVWV\n\n《不能说的秘密》 Flash键盘钢琴谱 EHHH EGGG EHHH EIII EHHH EGGG EHHH EIII EKKKK KJJ KKKLJIHGGH ELLLL LKK LLLLLKKJJI EKKKK KJJ KKKLJIHGGIH FHLMH LLLLLKKJJI HONOOLLLLKKJ HONOOLLLLPPO HONONMHNMNML HMLMLKKJKLMML HONOOLLLLKKJ HONOOLLLLPPO HONONM HNMNML HMLMLKKJKLMML HLHKJ HHLHKJH\n\n《蜗牛》 Flash键盘钢琴谱 J JJKJIJIH HHK KIHHIJ HHL LMLKJK GH EEJ JKJIJH EEH HEHIJKL HONN NONMMNLHKLM MNOPQL EFLK KLKJIHI EEH HEHIJKL HONN NONMMNL HKLM MNOPQL EFLK KJIHHGH\n\n《123木头人》 Flash键盘钢琴谱 LKJJJ III JIHIJO NML MKJKJK IJKONL MLL LKJJJ ILN MNONM J LMK KPOL IJKKJKL J I H\n\n《神秘园》 Flash键盘钢琴谱 jmno no opnmn nomlm lj jmno no opnmn nomlm lm nost tusrs noqr rsqpq nost tusrs strqr rsqpq jmno no opnmn nomlm lj jmno no opnmn nomlm lm\n\n《轨迹》 Flash键盘钢琴谱 qeee reee weewqe qwee eweq hqewqw qeee reee weewqte qwee eweq hqewqw qjqjwq jwqjq q ttqqt qgqrewe ee rewqj wewq qtrewqwet g r eee ereww weqq ett qttrr ewreq qq wEwqw gr eee ereww weqq ett qttrr ewreq qerw jq\n\n《无赖》 Flash键盘钢琴谱 HIJJIJKJIGE FGHHIJJMLJL JLMMMLK JKLLKJ JKKLKHI HIJJIJKJIGE FGHHIJJMLJL JLMMMLK JKLLKJ JKJHIH HHEFGHHIJHE EDDFEDE EFFGJIIHGH HHFEFG EEEJIHHIJHL JJLMMNOLJ JJLMMMKMNMLKLJ JKJKLMLL EJIHHIJHL JJLMMNONJ JJLMMMKMNMLJIH JKJKLMLLJIHH\n\n《海阔天空》 Flash键盘钢琴谱 QPO PQSSSSTS TUVVVVVVUTST TSS SQPO QRQPPQPP QPPPOOOO POO TUVVVVVVUTSSSQPO VVVVWWWVWX XWV VVVVWW SSXWV VVVVWWWWVUV TTUTUV VVWVWX XWXV\n\n《下一站天后》 Flash键盘钢琴谱 QQQSP PSOOOQM RQRTQ RSPPMOP QPQSSPQVUSST RQRSMOQPO QSUVUTSS QRSTRRQP POPQSS QTQPOP MOQPPQS VUTUT SSOQSS TTTRQP PPUS QQSO QQPPP TQS VUTUTSS OQSS TTTTVUTUVSSQSTSSRMNO\n\n《红河谷》Flash键盘钢琴谱 ehjjjjijih ehjhjlkji lkjjihijlk ffeghijih lhjjjijih ehjjjlkji lkjjihijlkk ffegijih\n\n《生日快乐》 Flash键盘钢琴谱\n\nEEFEHG EEFEIH\n\nEELJHGF KKJHIH\n\n09年1月21日更新Flash键盘钢琴谱\n\n《亡灵序曲》变奏和弦版Flash键盘钢琴谱 TQTTUV TUV UTU QQVUT TTUTX WVW VUV\n\nWX WVZW WVW VUV QTUUVT MJMMNO MNO NMN\n\nJJON(MT)MMNMR QPQ POP (QW)R QPT QPQ POP JMNNOM TTUUV(TZ)(MT)(OU)(VP)(VP)(MT)\n\nTQTTUV TUV UTU QQVUT TTUTX WVW VUV\n\nWX WVZW WVW VUV QTUUVT\n\nMJMMNO MNO NMN\n\nJJON(MT)MMNMR QPQ POP\n\n(QW)R QPT QPQ POP JMNNOM\n\n(OU)(MT)(OU)(QW)(PV)(OU)(MT)\n\nMMOMR QPQ POPS S(TZ)\n\n《一千年以后》Flash键盘钢琴曲谱 OHIJML KJHJI OHIJMNL JM NNNOPON ONOQQ NMNL MMNOPOPRQPPQO ONOQ NMNLMO\n\nOOOPQRQOQP LOP QPOLP QPONMJN\n\nONMNOPLQQ QRQOPP LOP QPOLP PQPONMPN\n\nONMLMOLPO QQRQP OPQPOPOLPO\n\n《男儿当自强》Flash键盘钢琴谱 MOMOMLM MOMOLMP QOPS QPQO PQOPM OPMOL MOPOML MOL MOMLM OPOML MOLMP QSPQT QTSRQSQPQ QSTUTSQ QSTUSTU TUTSQSTUTSQSP QPOPSRQSP PQSTQSQPO MPO MOPQN NQPNM MOMLM MOMLM QSPQT\n\n《舞娘》Flash键盘钢琴曲谱\n\nKJK JKJK LKJ KJK JLK J- FKJK JKJK LKJ FFGHIHIH.IHIHFF MMLLKKJJMJ- FMMLLKKJ FMMLLKKJJMJ FFGHIHIH- .IHIHFF HH.JJ FFLJ FFGHJ FFGHL HH.JJFFLJ- FJIHI FJIHIJIHF IJIHIJIHF FJIHIJIHF\n\n(间奏略) MMLLKKJJMI FJKJKJKJ JKJI\n\n《借口》 Flash键盘钢琴曲谱\n\nLLJKJKL JLONML 翻着我们的照片，想念若隐若现 MONOO QOOOLP 去年的冬天，我们笑得很甜 LLJKJKL JLONML 看着你哭泣的脸，背着我说再见 MONOO QOOPQP 来不及听见，你已走的很远 N（NN）ML（MN）P 也许你已经放弃我 O（OO）NM（NO）Q 也许已经很难回头 QPPOOLPO 我知道是自己错过 MNOOONOP PQPQP请在给我一个理由，说你不爱我 LJLPRQ LJLPRQ 就算是我不懂，能不能原谅我 LJLPRQPOPQPO 请不要把分手当作你的请求 MMKQPQP LLJPOPO 我知道坚持要走，是你受伤的借口 OPQO OPPOPQQPQP 请你回头，我会陪你一直走到最后 LJLPRQ LJLPRQ 就算没有结果，我也能够承受 LJLPRQ POPQPO 我知道你的痛是我给的承诺 MMKQPQP LLJPONO 你说给过我纵容，沉默是因为包容 OPQO LQPOO 如果要走，请你记得我 OPQO LQPOO 如果难过，请你忘了我。\n\n《当你孤单想起谁 和弦版》Flash键盘钢琴谱 (EJ)K(AL)L(CL)L(EL) (CJ)K(EL)L(GL)L(IL) (HM)N(FO)J(NJ)J(GJ)J-I(EGJ) 你的心情总在飞 什么事都想去追 想抓住一点安慰 (GL)(DL)K(FK)J(DI)H Q (QL)R(OQ)P(JQO)–(SL)(DL)K(FK)J(HK)L–J(IE)–(X)(SW) 你总是喜欢在人群中徘徊 你最害怕孤单的滋味 (EJ)K(AL)L(CL)L(EL)-(CJ)K(EL)L(GL)M(IL) 你的心那么脆 一碰就会碎 U(HM)N(FO)J(NJ)J(GJ)J-I(EGJ) J(K) (L) (SL)(DL)K(FK)J(DI)H 经不起一点风吹 你的身边总是要 Q (QL)R(OQ)P(QO)–(SL)(DL)K(FK)J(HK)L 许多人陪 你最害怕每天的天黑 (RM)-N (FO)(JO)(WP)O–O(CN)O(SN)(QL) 但是天总会黑 人总要离别 L(DM)FH(FK)–K(JE)L-J(IE) 谁也不能永远陪谁 (TM)N (FO)(JO)(WP)O–O(CN)O(SN)(QL) 而孤单的滋味 谁都要面对 L(DM)O(FO)O(HO)O-O(QOL)P(PL)O-Q(PGL)- 不只是你我会感觉到疲惫 (OJ)P(QHO)-(QO)R(JO) (NP)O(LP)-(SP)P(NUP) (QFO)-(JO)P(MO) (NJ)M(NC)-(GQ)N(NSL) 当你孤单你会想起谁 你想不想找个人来陪 k(KM) PQ(LP)OM–(GL) PQ(EP)OM–(DTM) (WP)X(WEP)V(PT)U (VLA)- 你的快乐伤悲 只有我能体会 让我再陪你走一回\n\n周华健的《朋友》Flash键盘钢琴谱\n\nQ-(OHIJA)–(PHIJ)-(AHQ)-(OHIJA)–(PHIJ)-(CQ)-(SHIJG)–(SHIJ)-(TGN)-(OFHJA)–(MAC)-(OF)-(PHIJ)–(PHIJ)-(OIB)-(MFHJ)–(MFHJ)-(OIB)-(PHIJB)-Q-(PHIJ)-(OIB)-(PGIL)–(QGIL)-(PE)O(OHIJA)–(PHIJ)-(QHA)O(OHIJ)–(PHIJ)-(QHA)-(SGIJ)–(SGIJ)-(TNG)-(OFHJ)–(MFHJ)-(OF)-(PHIK)–(PHIK)-(OIB)-(MADF)–(LBEG)-M-(OHJLF)CG-H-E-H-(IQ)-(SJ)-(SA)-(SE)-(SHJL)-(TE)-(SG)-E-(TGJL)-(UE)-(VF)-(TJ)-(THJM)-(SF)-(QE)–(QGJL)-(PE)-(OD)-H-(OHJM)-(TF)-(SC)-G-(QFJL)-(PE)-(OBI)-F-(MIFB)-(PDB)-(PE)BEF(QG)I(SL)N(SL)J(SH)E(LS)J(TH)E(SL)JHE(TL)Q(UG)E(VM)J(TH)F(TM)J(SH)F(QL)JGE(QL)J(PG)(OE)(OK)HFD(OK)H(TF)(SD)(SJ)GEC(QJ)G(PE)(OC)(OK)HFD(FB)D(OE)I(OHA)EHIJLOP(DK)HMMOMORT(AHJLO)-\n\n《笑傲江湖》 Flash键盘钢琴谱\n\nJMJ LL-J IJLML J–\n\nJMJ LL-J IJLML J–\n\nJ JI HHIJ IIIIH MMHIJ\n\nLMLJI HIIJ IIIH MMHIJ LM-\n\nQPO P– OMSSQ P–\n\nMHII ILJ MIJ HIM\n\nHML MJIJL M– M–\n\nJMJ LL-J IJLML J–\n\nJMJ LL-J IJLML J–\n\n请不要爱我 键盘钢琴谱 (SH) L (QO) S (SI) M (SP) 9 (SJ) N Q 9 S – – (SH) L (QO) S (SI) M (SP) 9 (SJ) N Q ST(US) T S [9S9] (QH) L O Q (9I) M P 9 (SE) I L N (U9) – – – (SH) L (SO) S S S S – (9I) M (9P) 9 9 U 9 P (QH) L (QO) Q Q – Q – (PB) F (MI) N P – – [99] (SH) L (SO) S S U S – (9\\`) I (94) 9 9 U 9 P (QA) E (QH) (QE) (QJ) – Q – (9B) F I 4 (/M) (UE) I L (UN) (UP) (TN) (SL) (UI) (TI) M P (T9) (WT) (U9) (VP) (WM) (UC) G J (UL) (VN) U (TL) (SJ) (VA) E U E T E S E O C F H J – (PM) – 9 B (U\\`) G (9I) – (P4） (QA) E H J L S Q U B F (TI) 4 M P (94) (TI) (SW) B E G I G (NPE) B (SW) B E G (SVI) G (SUE) C (TB) (TWF) (TWH) (TWJ) (TWL) (TJ) (UH) (VF) (SUC) G J L (SN) L (9J) G (RB) (PSF) (PSI) (PS4) (SWZE) I (WYL) N (VXA) E H J (XL) (XZ) X – [ ` G . Z – – (V,) E G I 4 V X T C G J L (QSN) (QT) (QU) (QS) (QSVA) E H J L – Q – (9B) F (PI) 4 (9U) F I (T4) (TA) E (SH) J L – 9 – S B (PE) G (PS) B (PTE) G (9U) B (9WE) G (9X) B (9/E) G (SC) G J 4 L – – –\n\n回到过去 hjjiihgh hggffecf feehhjji ihhhgfe hjjiihgih hggffecg feee edced hjji iiihijji eghhghml hihjhhgee ehihjhkkji ehijj jijkkjji ihjjjiihgh hihjjjj hhlljjj hhiihhhfhfhi ehigh\n\n亲爱的那不是爱情 OOONMMLMLLKJL HMMMMLOJJIIHI JIHGHLL LHMLLL MNOOOLKJIHH OOONMMLMLLKJL HMMMMLOJJIIHI JIHGHLL LHMLLL MNOOOLKJIHH JJLPQLNNOM KKMSRMOOPN LLJPOPQPOJ ONLONNLQQRP JJLPQLNNOM KKMSRMOOPN LLJPOPQPOO MOSRQPOO\n\n哆啦A梦 ehhjmjl lmljkji fiiknnmlkkjfghi ehhjmjl lmljkji fiiknnmlkkjfgih mmlklml ijkil mlkinmlmlk lmjih\n\n同桌的你 lllljkln mmmmkml llllnmlk kkkkjih oooolmoq pppponm nnnnnopl nnopono oooolmoq pppponm nnnnnopl nnopono\n\n大海 FEHHHH EFHHIH FHIIII HFIIJI JLMMLM LJIJIHF EFHHHHIH JIMMMMOMLLML JIHHHHIJ JIHHHHOMLLML JLMOOML JIMMMMOMLLML JIHHHHLJ JIHHHHIJLLJL JLM FJIHH\n\n送别》 LJLO MOL LHIJ IHI LJLO NMOL LIJK GA\n\n天空之城 MNONOQN LJMLMOLL KJKOJ JHOON OONNMN ONOQN JMLMHLJ JKONOPQOO ONMMNLM OPQPQSP LONOQQ MNOONOPO LLRQPOQ QTSQPO POPSQ QTSQPO POPNM MNONOQN JMLMHLJ JKONOPQOO ONMMNLM\n\n梁祝 LJIH IGFE NMNLMKJL IJLIJKJIH LGIFHE FHE CEFHI FHE LOMLJLI IJGFEFHICHFEFHE JLGIFHE CECEFGIF EFHILJIJIHFECH FHFECEFHE JLIJIHGFE\n```\n\n","tags":["others"]},{"title":"【tools】vi/vim基本使用方法","url":"/2018/12/10/【tools】vivim 基本使用/","content":"\n### vi/vim 基本使用方法\n\n本文介绍了vi (vim)的基本使用方法，但对于普通用户来说基本上够了！i/vim的区别简单点来说，它们都是多模式编辑器，不同的是vim 是vi的升级版本，它不仅兼容vi的所有指令，而且还有一些新的特性在里面。例如语法加亮，可视化操作不仅可以在终端运行，也可以运行于x window、 mac os、 windows。\n\nvi编辑器是所有Unix及Linux系统下标准的编辑器，它的强大不逊色于任何最新的文本编辑器，这里只是简单地介绍一下它的用法和一小部分指令。由于对Unix及 Linux系统的任何版本，vi编辑器是完全相同的，因此您可以在其他任何介绍vi的地方进一步了解它。Vi也是Linux中最基本的文本编辑器，学会它后，您将在Linux的世界里畅行无阻。\n\n[简单地，可以使用上下左右方向箭头和delete，backspace键来进行位置移动和删除，不管是命令模式还是插入模式]\n\n### 1、vi的基本概念\n基本上vi可以分为三种状态，分别是命令模式（command mode）、插入模式（Insert mode）和底行模式（last line mode），各模式的功能区分如下：\n1) 命令行模式command mode）\n控制屏幕光标的移动，字符、字或行的删除，移动复制某区段及进入Insert mode下，或者到 last line mode。\n2) 插入模式（Insert mode）\n只有在Insert mode下，才可以做文字输入，按「ESC」键可回到命令行模式。\n3) 底行模式（last line mode）\n将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号……等。\n\n不过一般我们在使用时把vi简化成两个模式，就是将底行模式（last line mode）也算入命令行模式command mode）。\n\n### 2、vi的基本操作\na) 进入vi\n在系统提示符号输入vi及文件名称后，就进入vi全屏幕编辑画面：$ vi myfile。不过有一点要特别注意，就是您进入vi之后，是处于「命令行模式（command mode）」，您要切换到「插入模式（Insert mode）」才能够输入文字。初次使用vi的人都会想先用上下左右键移动光标，结果电脑一直哔哔叫，把自己气个半死，所以进入vi后，先不要乱动，转换到「插入模式（Insert mode）」再说吧！\n\nb) 切换至插入模式（Insert mode）编辑文件\n在「命令行模式（command mode）」下按一下字母「i」就可以进入「插入模式（Insert mode）」，这时候你就可以开始输入文字了。\n\nc) Insert 的切换\n您目前处于「插入模式（Insert mode）」，您就只能一直输入文字，如果您发现输错了字！想用光标键往回移动，将该字删除，就要先按一下「ESC」键转到「命令行模式（command mode）」再删除文字。\n\nd) 退出vi及保存文件\n在「命令行模式（command mode）」下，按一下「：」冒号键进入「Last line mode」，例如：\n: w filename （输入 「w filename」将文章以指定的文件名filename保存）\n: wq (输入「wq」，存盘并退出vi)\n: q! (输入q!， 不存盘强制退出vi)\n\n### 3、命令行模式（command mode）功能键\n1）. 插入模式\n按「i」切换进入插入模式「insert mode」，按“i”进入插入模式后是从光标当前位置开始输入文件；\n按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字；\n按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。\n\n2）. 从插入模式切换为命令行模式\n按「ESC」键。\n\n3）. 移动光标\nvi可以直接用键盘上的光标来上下左右移动，但正规的vi是用小写英文字母「h」、「j」、「k」、「l」，分别控制光标左、下、上、右移一格。\n按「ctrl」+「b」：屏幕往“后”移动一页。\n按「ctrl」+「f」：屏幕往“前”移动一页。\n按「ctrl」+「u」：屏幕往“后”移动半页。\n按「ctrl」+「d」：屏幕往“前”移动半页。\n按数字「0」：移到文章的开头。\n按「G」：移动到文章的最后。\n按「$」：移动到光标所在行的“行尾”。\n按「^」：移动到光标所在行的“行首”\n按「w」：光标跳到下个字的开头\n按「e」：光标跳到下个字的字尾\n按「b」：光标回到上个字的开头\n按「#l」：光标移到该行的第#个位置，如：5l,56l。\n\n4）. 删除文字\n「x」：每按一次，删除光标所在位置的“后面”一个字符。\n「#x」：例如，「6x」表示删除光标所在位置的“后面”6个字符。\n「X」：大写的X，每按一次，删除光标所在位置的“前面”一个字符。\n「#X」：例如，「20X」表示删除光标所在位置的“前面”20个字符。\n「dd」：删除光标所在行。\n「#dd」：从光标所在行开始删除#行\n\n5）. 复制\n「yw」：将光标所在之处到字尾的字符复制到缓冲区中。\n「#yw」：复制#个字到缓冲区\n「yy」：复制光标所在行到缓冲区。\n「#yy」：例如，「6yy」表示拷贝从光标所在的该行“往下数”6行文字。\n「p」：将缓冲区内的字符贴到光标所在位置。注意：所有与“y”有关的复制命令都必须与“p”配合才能完成复制与粘贴功能。\n\n6）. 替换\n「r」：替换光标所在处的字符。\n「R」：替换光标所到之处的字符，直到按下「ESC」键为止。\n\n7）. 回复上一次操作\n「u」：如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次“u”可以执行多次回复。\n\n8）. 更改\n「cw」：更改光标所在处的字到字尾处\n「c#w」：例如，「c3w」表示更改3个字\n\n9）. 跳至指定的行\n「ctrl」+「g」列出光标所在行的行号。\n「#G」：例如，「15G」，表示移动光标至文章的第15行行首。\n\n### 4、Last line mode下命令简介\n　　在使用「last line mode」之前，请记住先按「ESC」键确定您已经处于「command mode」下后，再按「：」冒号即可进入「last line mode」。\n\nA) 列出行号\n「set nu」：输入「set nu」后，会在文件中的每一行前面列出行号。\n\nB) 跳到文件中的某一行\n「#」：「#」号表示一个数字，在冒号后输入一个数字，再按回车键就会跳到该行了，如输入数字15，再回车，就会跳到文章的第15行。\n\nC) 查找字符\n「/关键字」：先按「/」键，再输入您想寻找的字符，如果第一次找的关键字不是您想要的，可以一直按「n」会往后寻找到您要的关键字为止。\n「?关键字」：先按「?」键，再输入您想寻找的字符，如果第一次找的关键字不是您想要的，可以一直按「n」会往前寻找到您要的关键字为止。\n\nD) 保存文件\n「w」：在冒号输入字母「w」就可以将文件保存起来。\n\nE) 离开vi\n「q」：按「q」就是退出，如果无法离开vi，可以在「q」后跟一个「!」强制离开vi。\n「qw」：一般建议离开时，搭配「w」一起使用，这样在退出的时候还可以保存文件。","tags":["tools","vi","vim"]},{"title":"【随笔】201811","url":"/2018/11/30/【随笔】201811/","content":"\n## 2018-11-12\n\n#普通流模型，都处于一维\n\n1. position(static,relative,fixed,absolute,sticky)\n    CSS position属性用于指定一个元素在文档中的定位方式。top，right，bottom 和 left 属性则决定了该元素的最终位置。\n    没有选取定位方式，设置top，right，bottom 和 left 属性无效\n    *relative*\n    被看作普通流定位模型的一部分，定位元素的位置相对于它在普通流中的位置进行移动。使用相对定位的元素不管它是否进行移动，元素仍要占据它原来的位置。移动元素会导致它覆盖其他的框。\n    *absolute*\n    相对于已定位的最近的祖先元素，如果没有已定位的最近的祖先元素，那么它的位置就相对于最初的包含块（如body）。绝对定位的框可以从它的包含块向上、右、下、左移动。\n    绝对定位的框脱离普通流，所以它可以覆盖页面上的其他元素，可以通过设置Ｚ-Iindex属性来控制这些框的堆放次序。\n    *fixed*\n    相对于浏览器窗口，其余的特点类似于绝对定位。\n\n\n2. display(none,block,inline-block)\n\n\n3. overflow(auto,visible,hidden,scroll)\n\n\n4. 百分比(100%) \n5. float\n\n\n\n## 2018-11-13\n\n1. 响应式工具\n\n为了加快对移动设备友好的页面开发工作，利用媒体查询功能并使用这些工具类可以方便的针对不同设备展示或隐藏页面内容。另外还包含了针对打印机显示或隐藏内容的工具类。\n\n| 类组                      | CSS `display`            |\n| ------------------------- | ------------------------ |\n| `.visible-*-block`        | `display: block;`        |\n| `.visible-*-inline`       | `display: inline;`       |\n| `.visible-*-inline-block` | `display: inline-block;` |\n\n因此，以超小屏幕（`xs`）为例，可用的 `.visible-*-*` 类是：`.visible-xs-block`、`.visible-xs-inline` 和 `.visible-xs-inline-block`。\n\n`.visible-xs`、`.visible-sm`、`.visible-md` 和 `.visible-lg` 类也同时存在。但是**从 v3.2.0 版本开始不再建议使用**。除了 `<table>` 相关的元素的特殊情况外，它们与 `.visible-*-block` 大体相同。\n\n和常规的响应式类一样，使用下面的类可以针对打印机隐藏或显示某些内容。\n\n| class                                                        | 浏览器 | 打印机 |\n| :----------------------------------------------------------- | ------ | ------ |\n| `.visible-print-block`              `.visible-print-inline`              `.visible-print-inline-block` | 隐藏   | 可见   |\n| `.hidden-print`                                              | 可见   | 隐藏   |\n\n`.visible-print` 类也是存在的，但是从 v3.2.0 版本开始**不建议使用**。它与 `.visible-print-block` 类大致相同，除了 `<table>` 相关元素的特殊情况外。\n\n2. 阻止默认事件，事件冒泡\n\n\n\n## 2018-11-14\n\n1. ui.bootstrap modal完全可控操作\n2. angular-touch 左右滑动最优使用","tags":["web","angularjs","随笔","201811","bootstrap"]},{"title":"【web】nodejs学习实践","url":"/2018/11/12/【web】nodejs学习实践/","content":"\n### NPM配置国内源\n\n```shell\n# 设置淘宝源\nnpm config set registry https://registry.npm.taobao.org \nnpm info underscore （如果上面配置正确这个命令会有字符串response）\n\n# 出现错误：\nnpm info retry will retry, error on last attempt: Error: CERT_UNTRUSTED\n\n# 这是因为ssl验证问题，我们取消ssl验证:\nnpm config set strict-ssl false\n```\n\n\n\n在我们创建 Node.js 第一个 \"Hello, World!\" 应用前，让我们先了解下 Node.js 应用是由哪几部分组成的：\n\n1. **引入 required 模块**：我们可以使用 **require** 指令来载入 Node.js 模块。\n2. **创建服务器**：服务器可以监听客户端的请求，类似于 Apache 、Nginx 等 HTTP 服务器。\n3. **接收请求与响应请求** 服务器很容易创建，客户端可以使用浏览器或终端发送 HTTP 请求，服务器接收请求后返回响应数据。\n\n#### Node.js 事件循环\n\nNode.js 是单进程单线程应用程序，但是因为 V8 引擎提供的异步执行回调接口，通过这些接口可以处理大量的并发，所以性能非常高。\n\nNode.js 几乎每一个 API 都是支持回调函数的。\n\nNode.js 基本上所有的事件机制都是用设计模式中观察者模式实现。\n\nNode.js 单线程类似进入一个while(true)的事件循环，直到没有事件观察者退出，每个异步事件都生成一个事件观察者，如果有事件发生就调用该回调函数.\n\n","tags":["web","nodejs"]},{"title":"【Linux】LVM使用及扩展","url":"/2018/11/10/【linux】LVM使用及扩展/","content":"\n## LVM介绍\n\nLVM是 Logical Volume Manager（逻辑卷管理）的简写，它是Linux环境下对磁盘分区进行管理的一种机制，它由Heinz Mauelshagen在Linux 2.4内核上实现，目前最新版本为：稳定版1.0.5，开发版 1.1.0-rc2，以及LVM2开发版。Linux用户安装Linux操作系统时遇到的一个常见的难以决定的问题就是如何正确地评估各分区大小，以分配合适的硬盘空间。普通的磁盘分区管理方式在逻辑分区划分好之后就无法改变其大小，当一个逻辑分区存放不下某个文件时，这个文件因为受上层文件系统的限制，也不能跨越多个分区来存放，所以也不能同时放到别的磁盘上。而遇到出现某个分区空间耗尽时，解决的方法通常是使用符号链接，或者使用调整分区大小的工具，但这只是暂时解决办法，没有从根本上解决问题。随着Linux的逻辑卷管理功能的出现，这些问题都迎刃而解，用户在无需停机的情况下可以方便地调整各个分区大小。\n\n\n\n## LVM使用\n\n### 1. 查看可用磁盘信息\n\n```shell\nfdisk -l\n```\n\n### 2. 创建PV\n\n```shell\npvcreate /dev/sdb\n\npvscan\npvs\npvdisplay\n```\n\n### 3. 创建VG，并将PV加入到VG\n\n```shell\nvgcreate vg_name /dev/sdb\n\nvgscan\nvgs\nvgdisplay\n```\n\n### 4. 创建LV\n\n```shell\nlvcreate -L 5G -n lv_name vg_name\n\nlvscan\nlvs\nlvdisplay\n```\n\n### 5. 给LV创建文件系统\n\n```shell\n# xfs文件系统\nmkfs.xfs -f /dev/vg_name/lv_name\n\n# ext4文件系统\nmkfs.ext4 /dev/vg_name/lv_name\n```\n\n### 6. 将LV挂载到相应的目录\n\n```shell\n# 挂载\nmount /dev/vg_name/lv_name /data\n\n# 开机自动挂载\n/dev/vg_name/lv_name /data xfs defaults 0 0\n/dev/vg_name/lv_name /data exts defaults 0 0\n# 使用UUID挂载，目录可能会发生变化\n# blkid命令查看UUID\nUUID=a613d4f4-2f10-4f74-aa23-1815faf8f2fa /data xfs defaults 0 0\n# iscsi存储挂载，网卡必须先启动\n/dev/vg_name/lv_name /data xfs defaults,_netdev 0 0\n\n```\n\n\n\n## LVM扩展\n\n### 1. 查看磁盘信息\n\n```shell\nfdisk -l\n```\n\n### 2. VG扩容\n\n```shell\n# 一块新盘加入到卷组\nvgextend vg_name /dev/sdc\n\n# 创建新分区\nfdisk /dev/sdc\n# partprobe 将磁盘分区表变化信息通知内核，请求操作系统重新加载分区表，不需要重启系统\npvcreate /dev/sdc3\n# 一个新分区加入到卷组\nvgextend vg_name /dev/sdc3\n\n```\n\n### 3. LV扩容\n\n```\nlvextend -L +5G /dev/vg_name/lv_name\n```\n\n### 4. 扩展文件系统\n\n```shell\n# xfs扩展\nxfs_growfs /dev/vg_name/lv_name\n\n# ext4扩展\nresize2fs -f /dev/vg_name/lv_name\n```\n\n","tags":["linux","lvm"]},{"title":"【tools】git部署使用教程","url":"/2018/10/29/【tools】git部署使用教程/","content":"\n### 配置Git\n\n1. 创建本地ssh key。\n\n```shell\nssh-keygen -t rsa -C \"your_email@youremail.com\"\n#后面的your_email@youremail.com改为你在github上注册的邮箱，之后会要求确认路径和输入密码，我们这使用默认的一路回车就行。\n```\n\n2. 复制`~/.ssh/id_rsa.pub`里面的`key`。\n3. 回到github上，进入 Account Settings（账户配置），左边选择SSH Keys，Add SSH Key,title随便填，粘贴在你电脑上生成的key。\n4. 验证是否成功，在git bash下输入：\n\n```shell\nssh -T git@github.com\n#如果是第一次的会提示是否continue，输入yes就会看到：You've successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github。 \n```\n\n5. 设置username和email，因为github每次commit都会记录他们。\n\n```shell\ngit config --global user.name \"your name\"\ngit config --global user.email \"your_email@youremail.com\"\n```\n\n6. 进入要上传的仓库，右键git bash，添加远程地址：\n\n```shell\ngit remote add origin git@github.com:yourName/yourRepo.git\n#后面的yourName和yourRepo表示你再github的用户名和刚才新建的仓库，加完之后进入.git，打开config，这里会多出一个remote \"origin\"内容，这就是刚才添加的远程地址，也可以直接修改config来配置远程地址。 \n```\n\n7. 创建新文件夹，打开，然后执行` git init`以创建新的 git 仓库。\n\n### 检出仓库\n\n执行如下命令以创建一个本地仓库的克隆版本：\n\n```shell\ngit clone /path/to/repository \n```\n\n 如果是远端服务器上的仓库，你的命令会是这个样子： \n\n```shell\ngit clone username@host:/path/to/repository\n```\n\n### 工作流\n\n你的本地仓库由 git 维护的三棵\"树\"组成。第一个是你的 `工作目录`，它持有实际文件；第二个是 `暂存区（Index）`，它像个缓存区域，临时保存你的改动；最后是 `HEAD`，它指向你最后一次提交的结果。         \n\n你可以提出更改（把它们添加到暂存区），使用如下命令：\n\n```shell\ngit add <filename>\ngit add *\n```\n\n这是 git 基本工作流程的第一步；使用如下命令以实际提交改动：\n\n```shell\ngit commit -m \"代码提交信息\"\n```\n\n现在，你的改动已经提交到了 **HEAD**，但是还没到你的远端仓库。         ​      \n\n### 推送改动\n\n你的改动现在已经在本地仓库的 **HEAD** 中了。执行如下命令以将这些改动提交到远端仓库：\n\n```shell\ngit push origin master\n```\n\n可以把 *master* 换成你想要推送的任何分支。\n\n可以把 *master* 换成你想要推送的任何分支。\n\n如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：\n\n```shell\ngit remote add origin <server>\n```\n\n 如此你就能够将你的改动推送到所添加的服务器上去了。 \n\n 如此你就能够将你的改动推送到所添加的服务器上去了。 \n\n### 分支\n\n分支是用来将特性开发绝缘开来的。在你创建仓库的时候，*master* 是\"默认的\"分支。在其他分支上进行开发，完成后再将它们合并到主分支上。 \t\t\n\n创建一个叫做\"feature_x\"的分支，并切换过去：\n\n```shell\ngit checkout -b feature_x\n```\n\n切换回主分支：\n\n```shell\ngit checkout master\n```\n\n再把新建的分支删掉：\n\n```shell\ngit branch -d feature_x\n```\n\n除非你将分支推送到远端仓库，不然该分支就是 *不为他人所见的*：\n\n```shell\ngit push origin <branch>\n```","tags":["git"]},{"title":"【web】angularjs项目学习笔记","url":"/2018/10/26/【web】angularjs项目学习笔记/","content":"\n正则表达式处理地址栏URL\n\n```javascript\nnew RegExp(\"login$\").test(location.href)\n```\n\nCSS布局策略（100%）\n\n```html\n<html style=\"height:100%;\">\n<body style=\"height:100%;\">\n\t<div class=\"container\" style=\"height:100%;\">\n\t\t<div class=\"row\" style=\"height:100%;\">\n\t\t\n\t\t</div>\n\t</div>\n</body>\n</html>\n```\n\n","tags":["web","angularjs"]},{"title":"【web】实现表格表头固定内容滚动效果","url":"/2018/10/25/【web】表格实现表头固定内容滚动/","content":"\n> ## CSS table-layout 属性\n\n## 浏览器支持\n\n所有浏览器都支持 table-layout 属性。\n\n注释：任何的版本的 Internet Explorer （包括 IE8）都不支持属性值 \"inherit\"。\n\n## 定义和用法\n\ntableLayout 属性用来显示表格单元格、行、列的算法规则。\n\n#### 固定表格布局：\n\n固定表格布局与自动表格布局相比，允许浏览器更快地对表格进行布局。\n\n在固定表格布局中，水平布局仅取决于表格宽度、列宽度、表格边框宽度、单元格间距，而与单元格的内容无关。\n\n通过使用固定表格布局，用户代理在接收到第一行后就可以显示表格。\n\n#### 自动表格布局：\n\n在自动表格布局中，列的宽度是由列单元格中没有折行的最宽的内容设定的。\n\n此算法有时会较慢，这是由于它需要在确定最终的布局之前访问表格中所有的内容。\n\n#### 说明\n\n该属性指定了完成表布局时所用的布局算法。固定布局算法比较快，但是不太灵活，而自动算法比较慢，不过更能反映传统的 HTML 表。\n\n| 默认值：          | auto                               |\n| ----------------- | ---------------------------------- |\n| 继承性：          | yes                                |\n| 版本：            | CSS2                               |\n| JavaScript 语法： | *object*.style.tableLayout=\"fixed\" |\n\n## 可能的值\n\n| 值        | 描述                                         |\n| --------- | -------------------------------------------- |\n| automatic | 默认。列宽度由单元格内容设定。               |\n| fixed     | 列宽由表格宽度和列宽度设定。                 |\n| inherit   | 规定应该从父元素继承 table-layout 属性的值。 |\n\n## 应用实例\n\n```html\n<!DOCTYPE HTML>\n<html>  \n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n<title>转载自·威易网CSS教程</title>\n<style>\ntable tbody {\n\tdisplay:block;\n\theight:195px;\n\toverflow-y:scroll;\n}\ntable thead,tbody tr {\n\tdisplay:table;\n\twidth:100%;\n\ttable-layout:fixed;\n}\ntable thead {\n\twidth:calc( 100% - 1em )\n}\ntable thead th {\n\tbackground:#ccc;\n}\t\t\n</style>\n</head>\n<body>\n\t<table width=\"80%\" border=\"1\">\n\t\t<thead>\n\t\t\t<tr>\n\t\t\t\t<th>姓名</th>\n\t\t\t\t<th>年龄</th>\n\t\t\t\t<th>出生年月</th>\n\t\t\t\t<th>手机号码</th>\n\t\t\t\t<th>单位</th></tr>\n\t\t</thead>\n\t\t<tbody>\n\t\t\t<tr>\n\t\t\t\t<td>张三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三封</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴与四十大盗</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张小三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>腾讯科技</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>浏阳河就业</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三疯子</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张大三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三五</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张刘三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t\t<tr>\n\t\t\t\t<td>张三</td>\n\t\t\t\t<td>18</td>\n\t\t\t\t<td>1990-9-9</td>\n\t\t\t\t<td>13682299090</td>\n\t\t\t\t<td>阿里巴巴</td></tr>\n\t\t</tbody>\n\t</table>\n</body>\n</html>\n\n```\n\n","tags":["web","html","css"]},{"title":"【tools】开发模块和便捷工具","url":"/2018/10/24/【tools】tips & modules/","content":"\n### Web相关\n\n```javascript\nangularjs/ng-table/ui-router/requirejs/oclazyload\nyarn/nodejs/sinopia\njstree\n#http://javascript.ruanyifeng.com/tool/phantomjs.html\nphantomjs 无界面浏览器\nlodash\npolyfill\nwebpack\nurl-extract\nclipboard.js现代化的“复制到剪切板”插件。不包含 Flash。gzip 压缩后仅 3kb。\nekko-lightbox.js是一款基于Bootstrap3的jQuery lightBox图片画廊插件。该lightBox插件基于Bootstrap的模态窗口插件来制作，可以显示图片，HTML内容，视频等，也可以远程加载内容\nanalytics.js JavaScript代码段是一种可用于衡量用户与您网站的互动情况的全新方式。它与之前的跟踪代码ga.js类似，但为开发者自定义实现方案提供了更大的灵活性。\npurl.js JS地址栏插件 \n```\n\n### blog 搭建\n\n```\nGitHub Pages\nOctopress\nJekyll/Hexo\nWordPress\n```\n\n### 编辑器\n\n```\nwecode\ntypora\n```\n\n### Others\n\n```\nckplayer-超酷网页视频播放器\n```\n\n### 工具网站\n\n```shell\n#Http User-Agent 用户代理检查 - 开放管理员工具\nhttps://useragent.openadmintools.com/\n#火狐开发者文档\nhttps://developer.mozilla.org/zh-CN/\n\n```\n\n### Python & Nodejs\n\n```shell\n#Node.js v10.13.0 文档\nhttp://nodejs.cn/api/\n#NodeJs 爬虫进阶：Puppeteer 谷歌开源的无头浏览器\ncherrypy 是一个极简主义风格的 Pythonic Web框架.\n```\n\n### Web桌面应用开发\n\n```shell\n#https://nwjs.io/\n#https://nwjs.org.cn/\nNW.js\n#https://electronjs.org/\nElectron 用HTML，CSS和JavaScript来构建跨平台桌面应用程序的一个开源库。、\n#https://weolar.github.io/miniblink/\nminiblink 精简版的electron，完全可以兼容原版electron，只有一个dll一个exe，打包完才6M\n#http://hex.youdao.com/zh-cn/index.html\nheX 一个允许你采用前端技术（HTML，CSS，JavaScript）开发桌面应用软件的跨平台解决方案。\n#\n他山框架\n豌豆荚开源的one-ring\nlibcef\nIE控件\n\n#https://www.helplib.com/GitHub/article_134091\nPyFladesk, 使用 Flask 和QtWebKit创建桌面应用程序\n```\n\n","tags":["tools","others"]},{"title":"【tools】使用Hexo和AirCloud主题在GitHub上构建Blog","url":"/2018/10/24/【tools】使用Hexo和AirCloud主题在GitHub上构建Blog/","content":"\n### Hexo常用命令\n\n```bash\n#新建一篇博客\nhexo new post \"blog title\"\n#删除生成的public文件夹\nhexo clean\n#生成public文件夹\nhexo g\n#启动本地访问服务，默认：http://localhost:4000\nhexo s\n#部署到GitHub项目中，需要预先配置\nhexo d\n```\n\n### Hexo配置文件（_config.yml）\n\n```yaml\n# Hexo Configuration\n## Docs: https://hexo.io/docs/configuration.html\n## Source: https://github.com/hexojs/hexo/\n\n# Site\ntitle: STRIVELIBOO Blog\nsubtitle: 既然选择了远方，便只顾风雨兼程！\nauthor: liboo\nlanguage: zh\ntimezone:\n\n# URL\n## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'\nurl: https://liboo0731.github.io\nroot: /\npermalink: :year/:month/:day/:title/\npermalink_defaults:\n\n#Custom Setting Start\n\n# Site settings\n# 网站综合内容设置：\nSEOTitle: STRIVELIBOO的博客 | STRIVELIBOO's Blog\nemail: striveliboo@163.com\ndescription: \"李博的博客\"\nkeyword: \"LIBOO\"\n\n# SNS settings\n# 一些社交平台地址，支持以下几种：\nzhihu_username:     li-bo-2-25\ngithub_username:    liboo0731\n\n# Build settings\nanchorjs: true                          # if you want to customize anchor. check out line:181 of `post.html`\n\nsidebar-avatar: img/avatar.jpg      # use absolute URL, seeing it's used in both `/` and `/about/`\n\n# Friends\n# 友情链接\nfriends: [\n    {\n        title: \"STRIVELIBOO_博客园\",\n        href: \"https://www.cnblogs.com/liboo/\"\n    },{\n        title: \"搞事情的LIBOO_CSDN\",\n        href: \"https://blog.csdn.net/weixin_40108079\"\n    }\n]\n\n#comment:\n#  type: gitment\n#  id: your-id-created-by-https://github.com/settings/applications/new\n#  secret: your-secret-created-by-https://github.com/settings/applications/new\n#  owner: aircloud\n#  repo: hexo-aircloud-blog\n\ncomment:\n   type: disqus\n   script: 'https://airclouds-blog.disqus.com/embed.js'\n\n\n# The following content is not recommended to modify\n# 搜索数据文件路径设置，不建议改动：\nsearch:\n  path: search.json\n  field: post\n\n# 文章样式(是否首行缩进)：\npost_style:\n  indent: default\n\n# Custom Setting End\n# Directory\nsource_dir: source\npublic_dir: public\ntag_dir: tags\narchive_dir: archive\ncategory_dir: categories\ncode_dir: downloads/code\ni18n_dir: :lang\nskip_render:\n\n# Writing\nnew_post_name: :title.md # File name of new posts\ndefault_layout: post\ntitlecase: false # Transform title into titlecase\nexternal_link: true # Open external links in new tab\nfilename_case: 0\nrender_drafts: false\npost_asset_folder: true\nrelative_link: false\nfuture: true\nhighlight:\n  enable: true\n  line_number: true\n  auto_detect: true\n  tab_replace:\n\n# Category & Tag\ndefault_category: uncategorized\ncategory_map:\ntag_map:\n\n# Date / Time format\n## Hexo uses Moment.js to parse and display date\n## You can customize the date format as defined in\n## http://momentjs.com/docs/#/displaying/format/\ndate_format: YYYY-MM-DD\ntime_format: HH:mm:ss\n\n# Pagination\n## Set per_page to 0 to disable pagination\nper_page: 8\npagination_dir: page\n\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: aircloud\n\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repo: git@github.com:liboo0731/liboo0731.github.io.git\n  branch: master\n\n```\n\n","tags":["tools","hexo","aircloud","github"]},{"title":"【pssh】PSSH批量远程管理主机","url":"/2018/10/21/【pssh】PSSH批量远程管理主机/","content":"\n### pssh介绍\n\npssh是python写的可以并发在多台机器上批量执行命令的工具，它的用法可以媲美ansible的一些简单用法，执行起来速度比ansible快它支持文件并行复制，远程命令执行，杀掉远程主机上的进程等等。杀手锏是文件并行复制，当需要在远程主机批量上传下载的时候，最好使用它。\n\n### pssh的使用\n\n在使用pssh之前，必须要保证管理主机和本地主机进行过密钥的认证，或者是在进行批量时，没有做过密钥认证，但是必须保证被管理的多台主机的密码相同。关于如何做密钥认证，这里就不多说了，可以自行百度。\n\n#### 安装\n\n官网下载地址：[PSSH Download](https://code.google.com/archive/p/parallel-ssh/downloads)\n\n```\nwget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/parallel-ssh/pssh-2.3.1.tar.gz\ntar -zxvf pssh-2.3.1.tar.gz\ncd pssh-2.3.1\npython setup.py install\n或者\nyum install -y pssh\n```\n\n使用yum安装后，只能使用pssh，但是编译安装后会包括其他命令也安装了（pscp  prsync  pnuke  pslurp）\n\n- pssh：在远程多台主机上并行运行命令\n- pscp :把文件并行复制到多台远程主机上\n- prsync:使用rsync协议本地文件同步到远程多台主机上。\n- pnuke:在远程多台主机上并行killall某一进程\n- pslurp:把文件从远程多台主机上复制到本地主机上\n\n#### pssh常用参数\n\n```\npssh  --help\n\nUsage: pssh [OPTIONS] command [...]\n\nOptions:\n  --version             show program's version number and exit\n  --help                show this help message and exit\n  -h HOST_FILE, --hosts=HOST_FILE\n                        hosts file (each line \"[user@]host[:port]\")\n  -H HOST_STRING, --host=HOST_STRING\n                        additional host entries (\"[user@]host[:port]\")\n  -l USER, --user=USER  username (OPTIONAL)\n  -p PAR, --par=PAR     max number of parallel threads (OPTIONAL)\n  -o OUTDIR, --outdir=OUTDIR\n                        output directory for stdout files (OPTIONAL)\n  -e ERRDIR, --errdir=ERRDIR\n                        output directory for stderr files (OPTIONAL)\n  -t TIMEOUT, --timeout=TIMEOUT\n                        timeout (secs) (0 = no timeout) per host (OPTIONAL)\n  -O OPTION, --option=OPTION\n                        SSH option (OPTIONAL)\n  -v, --verbose         turn on warning and diagnostic messages (OPTIONAL)\n  -A, --askpass         Ask for a password (OPTIONAL)\n  -x ARGS, --extra-args=ARGS\n                        Extra command-line arguments, with processing for\n                        spaces, quotes, and backslashes\n  -X ARG, --extra-arg=ARG\n                        Extra command-line argument\n  -i, --inline          inline aggregated output and error for each server\n  --inline-stdout       inline standard output for each server\n  -I, --send-input      read from standard input and send as input to ssh\n  -P, --print           print output as we get it\n\nExample: pssh -h hosts.txt -l irb2 -o /tmp/foo uptime\n```\n\n具体常用介绍：\n\n- -h   HOST_FILE   后边跟远程主机列表（ip）\n- -H   HOST_STRING   后边跟远程主机名或者ip地址\n- -l   USER  指定远程主机的用户名\n- -p  PAR   指定pssh最大的并行线程数。\n- -o  将输出的内容重定向到一个指定的文件中\n- -O 指定ssh参数的具体配置\n- -e  将执行错误重定向到一个指定的文件中\n- -t  设定命令执行超时时间\n- -x  传递ssh命令的一些参数\n- -i  在远程主机上执行命令完成后显示标准输出和标准错误\n- -P  在执行远程命令时，输出执行结果\n\n 用法实例：\n\n```\npssh -P  -i   -h  sz_vpc.txt  \"w\" \n```\n\n### pscp拷贝文件到远程主机\n\n```\npscp  -h  ip.txt /etc/wenjian.txt   /tmp/\n```\n\n### pnuke杀掉某一进程\n\n这个命令类似yu  killall命令\n\n```\npnuke  -h  iplist.txt   httpd\n```\n\n上边的意思是在远程主机上批量关闭httpd服务\n\n能通过killall关闭的服务，都可以通过pnuke来批量完成\n\n### pslurp 远程主机拷贝文件到本地主机\n\n```\npslurp -h iplist.txt -L /home/ /hose/wenjian/yuanc.conf open.conf\n```\n\n上边是，将所有远程主机/hose/wenjian/yuanc.conf复制到本地主机/home/目录下，并且重新命名为open.conf  -L 来指定本地文件路径\n\n下面这个是拷贝目录\n\n```\n pslurp -h iplist.txt -r -L /home/ /hose/wenjian/ open\n```\n\n\n\n***PS：建议分发文件，执行命令，批量杀死进程，使用pssh,pscp，pnuke,速度很快的***","tags":["pssh"]},{"title":"【web】ui-router学习笔记","url":"/2018/10/21/【web】ui-router/","content":"\n##### ui-sref\n\n```html\n<a ui-sref=\"home\">Home</a>\n<a ui-sref=\"about\">About</a>\n<!-- 在当前状态只是参数变更，可以简写 -->\n<a ui-sref=\"contacts\">About</a>\n<a ui-sref=\"{page: 2}\">Next page</a>\n<!-- 带参数写法 -->\n<a ui-sref=\"contacts.detail({ id: contact.id })\">{{ contact.name }}</a>\n```\n\n##### ui-sref-active\n\n```html\n<!-- 如果点击状态包含“home.users.list”，“用户列表”就会高亮 -->\n<li ui-sref-active=\"active\">\n    <a ui-sref=\"home.users.list\">用户列表</a>\n</li>\n\n<!-- 等同上面 -->\n<li ui-sref-active=\"{'active':'home.users.list'}\">\n    <a ui-sref=\"home.users.list\">用户列表</a>\n</li>\n\n<!-- 在同一模块下操作，保持导航栏该模块一直高亮，即该模块active值取公共状态 -->\n<!-- 点击“用户1”或“用户2”，“用户列表”仍保持高亮 -->\n<a ui-sref=\"home.users.list({'userId':1})\">用户1</a>\n<a ui-sref=\"home.users.list({'userId':2})\">用户2</a>\n\n```\n\n##### ui-sref-opts\n\n```html\n<!-- location,inherit,reload -->\n<a ui-sref=\"home\" ui-sref-opts=\"{ reload: true }\">Home</a>\n\n<!-- instead of `click` -->\n<input type=\"text\" ui-sref=\"contacts\" ui-sref-opts=\"{ events: ['change', 'blur'] }\">\n```\n\n","tags":["web","ui-router"]},{"title":"【windows】如何查看某个端口被谁占用","url":"/2018/10/19/【windows】如何查看某个端口被谁占用/","content":"\n我们在启动应用的时候经常发现我们需要使用的端口被别的程序占用，但是我们又不知道是被谁占用，这时候我们需要找出“真凶”，如何做到呢？\n\n1. 开始---->运行---->cmd，或者是window+R组合键，调出命令窗口\n\n2. 输入命令：netstat -ano，列出所有端口的情况。在列表中我们观察被占用的端口，比如是49157，首先找到它。\n\n3. 查看被占用端口对应的PID，输入命令：netstat -aon|findstr \"49157\"，回车，记下最后一位数字，即PID,这里是2720。\n\n4. 继续输入tasklist|findstr \"2720\"，回车，查看是哪个进程或者程序占用了2720端口，结果是：svchost.exe\n\n5. 或者是我们打开任务管理器，切换到进程选项卡，在PID一列查看2720对应的进程是谁，如果看不到PID这一列,如下图：\n\n6. 则我们点击查看--->选择列，将PID(进程标示符)前面的勾打上，点击确定。\n\n7. 这样我们就看到了PID这一列标识，看一下2720对应的进程是谁，如果没有，我们把下面的显示所有用户的进程前面的勾打上，就可以看到了，映像名称是svchost.exe，描述是，Windows的主进程,与上面命令查看的完全一致。\n\n8. 结束该进程：在任务管理器中选中该进程点击”结束进程“按钮，或者是在cmd的命令窗口中输入：taskkill /f /t /im Tencentdl.exe。\n\n","tags":["windows"]},{"title":"【shell】Shell常用脚本集合（1）","url":"/2018/10/16/【shell】Shell常用脚本集合（1）/","content":"\n#### 复制文件\n\n```shell\ncp create.sql.gz{,.bak}\n```\n\n#### 查看配置文件\n\n```shell\negrep -v \"^#|^$\" /usr/local/nagios/etc/nrpe.cfg\ncat /usr/local/nagios/etc/nrpe.cfg |grep -v ^# |grep -v ^$\ngrep -n '^'[a-z] /etc/zabbix/zabbix_server.conf\n```\n\n#### 删除文件/文件夹\n\n```shell\n#删除多个文件夹\nrm -rf {META-INF,org,resources,WEB-INF}\n#反向删除\nrm -rf `ls | grep -v comps.xml$`\n#查找删除\nfind iso/ -name boot.cat | xargs rm\nfind iso/ -name TRANS.TBL -exec rm {} \\;\n```\n\n#### 查看文件/文件夹个数\n\n```shell\n#当前目录文件个数\nls -l | grep \"^-\" | wc -l \nfind ./company -type f | wc -l \n#当前目录文件夹个数\nls -l | grep \"^d\" | wc -l \n#查看某文件夹下文件的个数，包括子文件夹里的。 \nls -lR | grep \"^-\" | wc -l \n#查看某文件夹下文件夹的个数，包括子文件夹里的。 \nls -lR | grep \"^d\" | wc -l \n```\n\n#### 解压/压缩\n\n```shell\n#软件数据包解压\ntar xzvf infoShare-web-3.0.4.tar.gz\n#软件数据包压缩\ntar zcvf infoShare-web-3.0.4.tar.gz infoShare-web-3.0.4/\n```\n\n#### 获取本地IP地址\n\n```shell\nipaddr='172.0.0.1'\nipaddr=$(ip addr | awk '/^[0-9]+: / {}; /inet.*global/ {print gensub(/(.*)\\/(.*)/, \"\\\\1\", \"g\", $2)}')\n```\n\n#### RPM定制打包\n\n```shell\n#RPM包生成\nrpmbuild -ba infoShare-web.spec\n```\n\n#### ISO定制打包\n\n```shell\n#ISO定制化文件解包\nunsquashfs -dest squashfs-root squashfs.img\n#ISO定制化文件打包\nmksquashfs squashfs-root squashfs.img -noappend -all-root\n\n#ISO本地源仓库信息\nmv ./*-comps.xml ./infoShare-x86_64-comps.xml && rm -rf `ls |grep -v comps.xml$`\n#创建ISO 本地源\ncreaterepo -g repodata/infoShare-x86_64-comps.xml ./\n\ncp /usr/share/comps/i386/.discinfo iso/\n\n#ISO镜像生成\nmkisofs -r -V \"CentOS 7 x86_64\" -b isolinux/isolinux.bin -c isolinux/boot.cat -cache-inodes -J -l -no-emul-boot -boot-load-size 4 -boot-info-table -o /InfoShare-3.0.0.iso ./iso/\n```\n\n#### Linux基本操作\n\n```shell\n#查看当前登录用户信息\nw 查看当前系统信息和用户登录信息\nwho 查看当前正在登录的用户\nusers 可用于打印输出登录服务器的用户名称。该命令除了有help和version选项外，再没有其他选项。如果某用户使用了多个终端，则相应的会显示多个重复的用户名。\nwhoami 查看你所使用的登录名称\nid 显示真实有效的用户 ID(UID) 和组 ID(GID)。UID 是对一个用户的单一身份标识。组 ID（GID）则对应多个UID。 \nlast 用于显示特定用户登录系统的历史记录。如果没有指定任何参数，则显示所有用户的历史信息。在默认情况下，这些信息（所显示的信息）将来源于/var/log/wtmp文件。\n\n#罗列所有用户\nawk -F: '{print $1}' /etc/passwd\nawk -F: '{print $1}' /etc/shadow\n\n#过滤长度为三位的用户\nawk -F: '{print $1}' /etc/passwd |grep ^...$\n\n#cut是一个选取命令，就是将一段数据经过分析，取出我们想要的。一般来说，选取信息通常是针对“行”来进行分析的，并不是整篇信息分析的\ncut -d: -f1 /etc/passwd\n\n#compgen 是 bash 的内置命令，它将显示所有可用的命令，别名和函数。\ncompgen -u\n\n#从系统数据库读数据。用于判定用户是否存在等，十分好用。支持的数据库：\nahosts ahostsv4 ahostsv6 aliases ethers group gshadow hosts netgroup\nnetworks passwd protocols rpc services shadow\n# 判定用户组test是否存在：如果存在就退出，不存在就创建\ngetent group test || groupadd test\n\nnetstat && ss\n\n```\n\n#### Linux用户、用户组\n\n```shell\nlinux的权限系统主要是由用户、用户组和权限组成。\n用户就是一个个的登录并使用linux的用户。linux内部用UID表示。\n用户组就是用户的分组。linux内部用GID表示。\n权限分为读、写、执行三种权限。\n\nlinux的用户信息保存在/etc/passwd文件中，另外，/etc/shadow文件存放的是用户密码相关信息。\n\n/etc/passwd文件格式：\n用户名:密码:UID:GID:用户信息:HOME目录路径:用户shell\n其中UID为0则是用户root，1～499为系统用户，500以上为普通用户\n\n/etc/shadow保存用户密码信息，包括加密后的密码，密码过期时间，密码过期提示天数等。\n\n用户组信息保存在/etc/group文件中.\n格式如下：\n用户组名:组密码:GID:组内帐号（多个帐号用逗号分隔）\n\n用户登录后，/etc/passwd文件里的GID为用户的初始用户组。\n用户的初始用户组这一事实不会再/etc/group中体现。\n\n-----------------------------------------------------------------\n\n查看当前用户的用户组命令：\n[root@local opt]#groups\nroot bin daemon sys adm disk wheel\n输出的信息中，第一个用户组为当前用户的有效用户组（当前用户组）\n\n切换有效用户组命令：\n[root@local opt]#newgrp 用户组名\n要离开新的有效用户组，则输入exit回车。\n\n新建用户命令：\n[root@local opt]#useradd 用户名 -g 初始用户组 -G 其他用户组（修改/etc/group） -c 用户说明 -u 指定UID\n\n建完用户需要为用户设置密码：\n[root@local opt]#passwd 用户名\n\n用户要修改自己密码命令：\n[root@local opt]#passwd\n\n修改用户信息命令：\n[root@local opt]#usermod 参数 用户名\n参数:\n -c 说明\n -g 组名 初始用户组\n -e 过期日期 格式：YYYY-MM-DD\n -G 组名 其他用户组\n -l 修改用户名\n -L 锁定账号（在/etc/shadow文件中用户对应密码密码串的前面加上两个叹号(!!)）\n -U 解锁\n\n删除用户命令：\n[root@local opt]#userdel [-r] 用户名\n其中，参数-r为删除用户的home目录。\n其实，可能在系统其他地方也有该用户文件，要完整删除一个用户和其文件要先找到属于他的文件：\n[root@local opt]#find / -user 用户名\n然后删除，再运行userdel删除用户。\n\n查看可用shell命令：\n[root@local opt]#chsh -l\n修改自己的shell命令：\n[root@local opt]#chsh -s\n\n查看自己或某人UID/GID信息：\n[root@local opt]#id [用户名]\n返回信息中groups为有效用户组\n\n新增用户组命令：\n[root@local opt]#groupadd 用户组名\n\n修改用户组名命令：\n[root@local opt]#groupmod -n 名称\n\n删除用户组命令：\n[root@local opt]#groupdel 用户组名\n\n设置用户组密码命令：\n[root@local opt]#gpasswd 用户组名\n\n如果gpasswd加上参数则有其他功能\n\n设置用户组管理员命令：\n[root@local opt]#gpasswd -A 用户名 用户组名\n\n添加某帐号到组命令：\n[root@local opt]#gpasswd -M 用户名 用户组名\n\n从组中删除某帐号命令：\n[root@local opt]#gpasswd -d 用户名 用户组名\n\npasswd相关参数操作：\n-l 锁用户\n-u 解锁用户\n-n 天数  密码不可改天数\n-x 天数  密码过期天数\n-w 天数  警告天数\n```\n\n#### Linux文件权限\n\n```shell\n先看个实例：\n[root@local opt]#ls -al\nls -al 命令是列出目录的所有文件，包括隐藏文件。隐藏文件的文件名第一个字符为'.'\n-rw-r--r--  1 root root    81 08-02 14:54 gtkrc-1.2-gnome2\n-rw-------  1 root root   189 08-02 14:54 ICEauthority\n-rw-------  1 root root    35 08-05 10:02 .lesshst\ndrwx------  3 root root  4096 08-02 14:54 .metacity\ndrwxr-xr-x  3 root root  4096 08-02 14:54 nautilus\n\n列表的列定义如下：\n[权限属性信息] [连接数] [拥有者] [拥有者所属用户组] [大小] [最后修改时间] [文件名]\n\n权限属性列表为10个字符：\n第一个字符表示文件类型，d为目录 -为普通文件 l为连接 b为可存储的接口设备 c为键盘鼠标等输入设备\n2、3、4个字符表示所有者权限，5、6、7个字符表示所有者同组用户权限，8、9、10为其他用户权限\n\n修改文件所属组命令：\n[root@local opt]#chgrp [-R] 组名 文件名\n其中-R为递归设置\n\n修改文件的所有者和组命令：\n[root@local opt]#chown [-R] 用户[:用户组] 文件名\n\n修改文件访问权限命令：\n[root@local opt]#chmod [-R] 0777 文件名\n```\n\n#### Shell变量定义及使用\n\n```shell\n#有效的 Shell 变量名示例如下：\nRUNOOB\nLD_LIBRARY_PATH\n_var\nvar2\n#用语句给变量赋值\nfor file in `ls /etc`\n或\nfor file in $(ls /etc)\n#使用变量\nyour_name=\"qinjx\"\necho $your_name\necho ${your_name}\n```\n\n#### 获取Linux所有磁盘\n\n```shell\n# 磁盘存在格式\n# /dev/vda\n# /dev/sda\nfdisk -l 2>/dev/null | grep -o \"Disk /dev/.d[a-z]\"\n\n#一般/dev/sda属于主分区，让用户选择此外的其他盘进行扩展\nfdisk -l 2>/dev/null | grep -o \"Disk /dev/.d[b-z]\"\n```\n\n#### 获取系统内存大小\n\n```shell\n#打印内存大小，以kb为单位\nawk '($1 == \"MemTotal:\"){print $2}' /proc/meminfo\n```\n\n#### 获取系统IP地址\n\n```shell\nip addr | awk '/^[0-9]+: / {}; /inet.*global/ {print gensub(/(.*)\\/(.*)/, \"\\\\1\", \"g\", $2)}'\n```\n\n#### 数据库权限修改\n\n```shell\nmysql -uroot -p'+w_:5sHO3r!S' -e \"grant all privileges on *.* to 'infoShare'@'%' identified by 'PASSWORD';\"\nflush privileges;\n```\n\n#### 数据库密码修改\n\n```shell\nmysql -uroot -p'+w_:5sHO3r!S' -e \"alter user 'infoShare'@'%' identified by 'PASSWORD';\"\n```\n\n#### 防火墙端口修改\n\n```shell\n#罗列端口\nfirewall-cmd --list-ports\n#添加端口\nfirewall-cmd --zone=public --permanent --add-port=80/tcp\n#移除端口\nfirewall-cmd --zone=public --permanent --remove-port=80/tcp\n#重启防火墙\nsystemctl restart firewalld\n```\n\n#### RPM包操作\n\n```shell\n#强制卸载rpm包\nrpm -e --nodeps `rpm -qa|grep mariadb-libs`\n#测试安装\nrpm -ivh --test *.rpm\n\n```\n\n#### sed命令集合\n\n```shell\n#去除前后空格\nsed -i s/[[:space:]]//g /etc/my.cnf\n#最后一行追加内容\nsed -i '$a\\innodb_buffer_pool_size=8G' /etc/my.cnf\n\n```\n\n#### CentOS6服务相关\n\n```shell\n# /etc/init.d/\nchkconfig --add fwdport\nchkconfig --del fwdport\nchkconfig fwdport on\nchkconfig --list\n```\n\n#### 计算文件夹中所有文件md5值\n\n```shell\nfind resources/ -type f -not \\( -name '.*' \\) -exec md5sum {} \\;>resources.txt\n```\n\n#### ISO镜像生成\n\n```shell\nmkisofs -r -V \"CentOS 7 x86_64\" -b isolinux/isolinux.bin -c isolinux/boot.cat -cache-inodes -J -l -no-emul-boot -boot-load-size 4 -boot-info-table -o /Info.iso ./iso7.4/\n```\n\n","tags":["shell"]},{"title":"【linux】Capabilities简介","url":"/2018/09/29/【linux】Capabilities简介/","content":"\nCapabilities的主要思想在于分割root用户的特权，即将root的特权分割成不同的能力，每种能力代表一定的特权操作。例如：能力CAP_SYS_MODULE表示用户能够加载(或卸载)内核模块的特权操作，而CAP_SETUID表示用户能够修改进程用户身份的特权操作。在Capbilities中系统将根据进程拥有的能力来进行特权操作的访问控制。\n\n在Capilities中，只有进程和可执行文件才具有能力，每个进程拥有三组能力集，分别称为cap_effective, cap_inheritable, cap_permitted(分别简记为:pE,pI,pP)，其中cap_permitted表示进程所拥有的最大能力集；cap_effective表示进程当前可用的能力集，可以看做是cap_permitted的一个子集；而cap_inheitable则表示进程可以传递给其子进程的能力集。系统根据进程的cap_effective能力集进行访问控制，cap_effective为cap_permitted的子集，进程可以通过取消cap_effective中的某些能力来放弃进程的一些特权。可执行文件也拥有三组能力集，对应于进程的三组能力集，分别称为cap_effective, cap_allowed 和 cap_forced（分别简记为fE,fI,fP），其中，cap_allowed表示程序运行时可从原进程的cap_inheritable中集成的能力集，cap_forced表示运行文件时必须拥有才能完成其服务的能力集；而cap_effective则表示文件开始运行时可以使用的能力。\n\n **Linux内核从2.2版本开始，就加进的Capabilities的概念与机制，并随着版本升高逐步得到改进。在linux中，root权限被分割成一下29中能力：**\n\n- CAP_CHOWN:修改文件属主的权限\n\n- CAP_DAC_OVERRIDE:忽略文件的DAC访问限制\n\n- CAP_DAC_READ_SEARCH:忽略文件读及目录搜索的DAC访问限制\n\n- CAP_FOWNER：忽略文件属主ID必须和进程用户ID相匹配的限制\n\n- CAP_FSETID:允许设置文件的setuid位\n\n- CAP_KILL:允许对不属于自己的进程发送信号\n\n- CAP_SETGID:允许改变进程的组ID\n\n- CAP_SETUID:允许改变进程的用户ID\n\n- CAP_SETPCAP:允许向其他进程转移能力以及删除其他进程的能力\n\n- CAP_LINUX_IMMUTABLE:允许修改文件的IMMUTABLE和APPEND属性标志\n\n- CAP_NET_BIND_SERVICE:允许绑定到小于1024的端口\n\n- CAP_NET_BROADCAST:允许网络广播和多播访问\n\n- CAP_NET_ADMIN:允许执行网络管理任务\n\n- CAP_NET_RAW:允许使用原始套接字\n\n- CAP_IPC_LOCK:允许锁定共享内存片段\n\n- CAP_IPC_OWNER:忽略IPC所有权检查\n\n- CAP_SYS_MODULE:允许插入和删除内核模块\n\n- CAP_SYS_RAWIO:允许直接访问/devport,/dev/mem,/dev/kmem及原始块设备\n\n- CAP_SYS_CHROOT:允许使用chroot()系统调用\n\n- CAP_SYS_PTRACE:允许跟踪任何进程\n\n- CAP_SYS_PACCT:允许执行进程的BSD式审计\n\n- CAP_SYS_ADMIN:允许执行系统管理任务，如加载或卸载文件系统、设置磁盘配额等\n\n- CAP_SYS_BOOT:允许重新启动系统\n\n- CAP_SYS_NICE:允许提升优先级及设置其他进程的优先级\n\n- CAP_SYS_RESOURCE:忽略资源限制\n\n- CAP_SYS_TIME:允许改变系统时钟\n\n- CAP_SYS_TTY_CONFIG:允许配置TTY设备\n\n- CAP_MKNOD:允许使用mknod()系统调用\n\n- CAP_LEASE:允许修改文件锁的FL_LEASE标志\n\n\n\n*参考链接：[Android的能力(capability)机制](https://blog.csdn.net/zhao_cancan/article/details/38366541)*\n\n","tags":["linux"]},{"title":"【web】AngularJs的UI组件ui-bootstrap —— Model","url":"/2018/09/28/【web】angularjs 弹窗（2）/","content":"\nModel是用来创建模态窗口的，但是实际上，并没有Model指令，而只有`$uibModal`服务，创建模态窗口是使用`$uibModal.open()`方法。\n\n全局的设置可以通过`$uibModalProvider.options`来配置。\n\n##### $uibModal.open()方法可以使用的参数：\n\n| 参数名            | 默认值                         | 备注                                                         |\n| ----------------- | ------------------------------ | ------------------------------------------------------------ |\n| animation         | true                           | 是否启用动画                                                 |\n| appendTo          | body                           | 把模态窗口放在指定的dom元素中。例如$document.find('aside').eq(0) |\n| backdrop          | true                           | 打开模态窗口时的背景设置。可设置的值有：true（显示灰色背景，在模态窗口之外单击会关闭模态窗口），false （不显示灰色背景），\"static\"（显示灰色背景，在模态窗口关闭之前背景元素不可用） |\n| backdropClass     |                                | 为背景添加的类名                                             |\n| bindToController  | false                          | 设置为true并且使用controllerAs参数时，$scope的属性会传递给模态窗口所使用的controller |\n| controller        |                                | 可以设置为一个表示controller的字符串，或者一个函数，或者一个数组（使用数组标记的方式为控制器注入依赖）。 控制器中可使用$uibModalInstance来表示模态窗口的实例。 |\n| controllerAs      |                                | controller-as语法的替代写法                                  |\n| keyboard          | true                           | 是否允许用ESC键关闭模态窗口                                  |\n| openedClass       | modal-open                     | 打开模态窗口时为body元素增加的类名                           |\n| resolve           |                                | 传递到模态窗口中的对象                                       |\n| scope             | $rootScope                     | 模态窗口的父作用域对象                                       |\n| size              |                                | 一个字符串，和前缀“model-”组合成类名添加到模态窗口上         |\n| template          |                                | 表示模态窗口内容的文本                                       |\n| templateUrl       |                                | 模态窗口内容的模板url                                        |\n| windowClass       |                                | 添加到模态窗口模板的类名（不是模态窗口内容模板）             |\n| windowTemplateUrl | uib/template/modal/window.html |                                                              |\n| windowTopClass    |                                | 添加到顶层模态窗口的类名                                     |\n\n##### $uibModal.open()方法返回模态窗实例的属性：\n\n| 属性名          | 类型     | 说明                                                         |\n| --------------- | -------- | ------------------------------------------------------------ |\n| close(result)   | function | 关闭模态窗口，传递一个结果                                   |\n| dismiss(reason) | function | 取消模态窗口，传递一个原因                                   |\n| result          | promise  | 一个promise，窗口关闭时为resolved，窗口取消时为rejected      |\n| opened          | promise  | 一个promise，窗口打开并下载完内容解析了所有变量后，promise为resolved |\n| closed          | promise  | 一个promise，窗口关闭并且动画结束后为resolved                |\n| rendered        | promise  | 一个promise，窗口呈现出来后为resolved                        |\n\n##### 静态资源引入：\n\n```html\n<link href=\"plugins/bootstrap/css/bootstrap.css\" rel=\"stylesheet\" />\n\n<script src=\"js/angular.js\"></script>\n<script src=\"js/ocLazyLoad.js\"></script>\n<script src=\"js/ui-bootstrap-tpls\"></script>\n```\n\n##### 定义模块：\n\n```javascript\nvar baseModule=angular.module('base-module',[\n\t'ui.bootstrap',\n\t'oc.lazyLoad'\n]);\n```\n\n##### 创建弹窗自定义指令：\n\n```javascript\nbaseModule.directive('uibModal',[\n\t'$uibModal',\n\t'$ocLazyLoad',\n\t'$rootScope',function(\n\t\t\t$uibModal,\n\t\t\t$ocLazyLoad,\n\t\t\t$rootScope){\n\treturn {\n\t\trestrict: 'A',\n\t\tscope: {\n\t\t\tuibModal: '='\n\t\t},\n\t\tlink:function(scope,element,attr){\n\t\t\telement.on('click', function() {\n\t\t\t\t//动态加载组件\n\t\t\t\t$ocLazyLoad.load(scope.uibModal.componentUrl).then(function(){\n\t\t\t\t\t//解绑事件，否则下次执行会累计增加一个弹窗\n\t\t\t\t\telement.blur();\n\t\t        \t//打开弹窗\n\t\t\t\t\tvar options=angular.extend({\n\t\t\t\t\t\tanimation:false,\n\t\t\t\t\t\tbackdrop:'static',\n\t\t\t\t\t\tauth:true,\n\t\t            },scope.uibModal);\n\t\t\t\t\tvar modalInstance=$uibModal.open(options);\n\t\t\t\t\t//下面的特性，要求静态资源也要检查登录,或者要求组件内有发起过数据获取\n\t\t\t\t\tif(options.auth){\n\t\t\t\t\t\tmodalInstance.rendered.then(function(){\n\t\t\t\t\t\t\tif(!$rootScope.currentUser){\n\t\t\t\t\t\t\t\tmodalInstance.close();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t    });\n\t\t}\n\t}\n}]);\n```\n\n##### 组件中绑定：\n\n```javascript\nangular.module('user-groups').component('userGroupsForm', {\n\tbindings:{\n\t\tresolve:'<',\n\t\tclose:'&',\n\t    dismiss:'&'\n\t}\n});\n```\n\n##### 页面调用：\n\n```html\n<button type=\"button\" uib-modal=\"{componentUrl:'user-groups/form/component',component:'userGroupsForm',size:'lg',resolve:{title:{title:'新建群组'}}}\">新建群组</button>\n```\n\n","tags":["web","angularjs","ui-bootstrap","ocLazyLoad"]},{"title":"【kickstart】Kickstart Option","url":"/2018/09/14/【kickstart】Kickstart-Option/","content":"\n### [Kickstart Options](https://www.cnblogs.com/liboo/p/9646091.html)\n\n- autopart  (optional)\n\n  Automatically create partitions — 1 GB or more root (/) partition, a swap partition, and an appropriate boot partition for the architecture. One or more of the default partition sizes can be redefined with the part  directive.--encrypted  — Should all devices with support be encrypted by default? This is equivalent to checking the Encrypt checkbox on the initial partitioning screen.--passphrase=  — Provide a default system-wide passphrase for all encrypted devices.\n\n- ignoredisk  (optional)\n\n  Causes the installer to ignore the specified disks. This is useful if you use autopartition and want to be sure that some disks are ignored. For example, without ignoredisk, attempting to deploy on a SAN-cluster the kickstart would fail, as the installer detects passive paths to the SAN that return no partition table. The --only-use  option specifies that only the disks listed will be used during installion.The ignoredisk  option is also useful if you have multiple paths to your disks.The syntax is:ignoredisk --drives=*drive1,drive2*,...where *driveN* is one of sda, sdb,..., hda,... etc.--only-use  — specifies a list of disks for the installer to use. All other disks are ignored. For example, to use disk sda  during installation and ignore all other disks:ignoredisk --only-use=sda\n\n- autostep  (optional)\n\n  Similar to interactive  except it goes to the next screen for you. It is used mostly for debugging.--autoscreenshot  — Take a screenshot at every step during installation and copy the images over to /root/anaconda-screenshots  after installation is complete. This is most useful for documentation.\n\n- auth  or authconfig  (required)\n\n  Sets up the authentication options for the system. It is similar to the authconfig  command, which can be run after the install. By default, passwords are normally encrypted and are not shadowed.--enablemd5  — Use md5 encryption for user passwords.--enablenis  — Turns on NIS support. By default, --enablenis  uses whatever domain it finds on the network. A domain should almost always be set by hand with the --nisdomain=  option.--nisdomain=  — NIS domain name to use for NIS services.--nisserver=  — Server to use for NIS services (broadcasts by default).--useshadow  or --enableshadow  — Use shadow passwords.--enableldap  — Turns on LDAP support in /etc/nsswitch.conf, allowing your system to retrieve information about users (UIDs, home directories, shells, etc.) from an LDAP directory. To use this option, you must install the nss_ldap  package. You must also specify a server and a base DN (distinguished name) with --ldapserver=  and --ldapbasedn=.--enableldapauth  — Use LDAP as an authentication method. This enables the pam_ldap  module for authentication and changing passwords, using an LDAP directory. To use this option, you must have the nss_ldap  package installed. You must also specify a server and a base DN with --ldapserver=  and --ldapbasedn=.--ldapserver=  — If you specified either --enableldap  or --enableldapauth, use this option to specify the name of the LDAP server to use. This option is set in the /etc/ldap.conf  file.--ldapbasedn=  — If you specified either --enableldap  or --enableldapauth, use this option to specify the DN in your LDAP directory tree under which user information is stored. This option is set in the /etc/ldap.conf  file.--enableldaptls  — Use TLS (Transport Layer Security) lookups. This option allows LDAP to send encrypted usernames and passwords to an LDAP server before authentication.--enablekrb5  — Use Kerberos 5 for authenticating users. Kerberos itself does not know about home directories, UIDs, or shells. If you enable Kerberos, you must make users' accounts known to this workstation by enabling LDAP, NIS, or Hesiod or by using the /usr/sbin/useradd  command. If you use this option, you must have the pam_krb5  package installed.--krb5realm=  — The Kerberos 5 realm to which your workstation belongs.--krb5kdc=  — The KDC (or KDCs) that serve requests for the realm. If you have multiple KDCs in your realm, separate their names with commas (,).--krb5adminserver=  — The KDC in your realm that is also running kadmind. This server handles password changing and other administrative requests. This server must be run on the master KDC if you have more than one KDC.--enablehesiod  — Enable Hesiod support for looking up user home directories, UIDs, and shells. More information on setting up and using Hesiod on your network is in /usr/share/doc/glibc-2.x.x/README.hesiod, which is included in the glibc  package. Hesiod is an extension of DNS that uses DNS records to store information about users, groups, and various other items.--hesiodlhs  — The Hesiod LHS (\"left-hand side\") option, set in /etc/hesiod.conf. This option is used by the Hesiod library to determine the name to search DNS for when looking up information, similar to LDAP's use of a base DN.--hesiodrhs  — The Hesiod RHS (\"right-hand side\") option, set in /etc/hesiod.conf. This option is used by the Hesiod library to determine the name to search DNS for when looking up information, similar to LDAP's use of a base DN.NoteTo look up user information for \"jim\", the Hesiod library looks up *jim.passwd<LHS><RHS>*, which should resolve to a TXT record that looks like what his passwd entry would look like (jim:*:501:501:Jungle Jim:/home/jim:/bin/bash). For groups, the situation is identical, except *jim.group<LHS><RHS>* would be used.Looking up users and groups by number is handled by making \"501.uid\" a CNAME for \"jim.passwd\", and \"501.gid\" a CNAME for \"jim.group\". Note that the library does not place a period . in front of the LHS and RHS values when performing a search. Therefore the LHS and RHS values need to have a period placed in front of them in order if they require this.--enablesmbauth  — Enables authentication of users against an SMB server (typically a Samba or Windows server). SMB authentication support does not know about home directories, UIDs, or shells. If you enable SMB, you must make users' accounts known to the workstation by enabling LDAP, NIS, or Hesiod or by using the /usr/sbin/useradd  command to make their accounts known to the workstation. To use this option, you must have the pam_smb  package installed.--smbservers=  — The name of the server(s) to use for SMB authentication. To specify more than one server, separate the names with commas (,).--smbworkgroup=  — The name of the workgroup for the SMB servers.--enablecache  — Enables the nscd  service. The nscd  service caches information about users, groups, and various other types of information. Caching is especially helpful if you choose to distribute information about users and groups over your network using NIS, LDAP, or hesiod.--passalgo  — Enables SHA256 or SHA512 hashing for passphrases. Use --passalgo=sha256  or --passalgo=sha215  and remove the --enablemd5  if present.\n\n- bootloader  (required)\n\n  Specifies how the boot loader should be installed. This option is required for both installations and upgrades.--append=  — Specifies kernel parameters. To specify multiple parameters, separate them with spaces. For example:bootloader --location=mbr --append=\"hdd=ide-scsi ide=nodma\"--driveorder  — Specify which drive is first in the BIOS boot order. For example:bootloader --driveorder=sda,hda--hvargs  — If using GRUB, specifies Xen hypervisor arguments. To specify multiple parameters, separate them with spaces. For example:bootloader --hvargs=\"dom0_mem=2G dom0_max_vcpus=4\"--location=  — Specifies where the boot record is written. Valid values are the following: mbr  (the default), partition  (installs the boot loader on the first sector of the partition containing the kernel), or none  (do not install the boot loader).--password=  — If using GRUB, sets the GRUB boot loader password to the one specified with this option. This should be used to restrict access to the GRUB shell, where arbitrary kernel options can be passed.--md5pass=  — If using GRUB, similar to --password=  except the password should already be encrypted.--upgrade  — Upgrade the existing boot loader configuration, preserving the old entries. This option is only available for upgrades.\n\n- clearpart  (optional)\n\n  Removes partitions from the system, prior to creation of new partitions. By default, no partitions are removed.NoteIf the clearpart  command is used, then the --onpart  command cannot be used on a logical partition.\n\n- cmdline  (optional)\n\n  Perform the installation in a completely non-interactive command line mode. Any prompts for interaction halts the install. This mode is useful on IBM System z systems with the x3270 console.\n\n- device  (optional)\n\n  On most PCI systems, the installation program autoprobes for Ethernet and SCSI cards properly. On older systems and some PCI systems, however, kickstart needs a hint to find the proper devices. The device  command, which tells the installation program to install extra modules, is in this format:device *<type>* *<moduleName>* --opts=*<options>**<type>* — Replace with either scsi  or eth.*<moduleName>* — Replace with the name of the kernel module which should be installed.--opts=  — Mount options to use for mounting the NFS export. Any options that can be specified in /etc/fstab  for an NFS mount are allowed. The options are listed in the nfs(5)  man page. Multiple options are separated with a comma.\n\n- driverdisk  (optional)\n\n  Driver diskettes can be used during kickstart installations. You must copy the driver diskettes's contents to the root directory of a partition on the system's hard drive. Then you must use the driverdisk  command to tell the installation program where to look for the driver disk.driverdisk *<partition>* [--type=*<fstype>*]Alternatively, a network location can be specified for the driver diskette:driverdisk --source=ftp://path/to/dd.imgdriverdisk --source=http://path/to/dd.imgdriverdisk --source=nfs:host:/path/to/img*<partition>* — Partition containing the driver disk.--type=  — File system type (for example, vfat or ext2).\n\n- firewall  (optional)\n\n  This option corresponds to the Firewall Configuration screen in the installation program:firewall --enabled|--disabled [--trust=] *<device>* [--port=]--enabled  or --enable  — Reject incoming connections that are not in response to outbound requests, such as DNS replies or DHCP requests. If access to services running on this machine is needed, you can choose to allow specific services through the firewall.--disabled  or --disable  — Do not configure any iptables rules.--trust=  — Listing a device here, such as eth0, allows all traffic coming from that device to go through the firewall. To list more than one device, use --trust eth0 --trust eth1. Do NOT use a comma-separated format such as --trust eth0, eth1.*<incoming>* — Replace with one or more of the following to allow the specified services through the firewall.--ssh--telnet--smtp--http--ftp--port=  — You can specify that ports be allowed through the firewall using the port:protocol format. For example, to allow IMAP access through your firewall, specify imap:tcp. Numeric ports can also be specified explicitly; for example, to allow UDP packets on port 1234 through, specify 1234:udp. To specify multiple ports, separate them by commas.\n\n- firstboot  (optional)\n\n  Determine whether the Setup Agent starts the first time the system is booted. If enabled, the firstboot  package must be installed. If not specified, this option is disabled by default.--enable  or --enabled  — The Setup Agent is started the first time the system boots.--disable  or --disabled  — The Setup Agent is not started the first time the system boots.--reconfig  — Enable the Setup Agent to start at boot time in reconfiguration mode. This mode enables the language, mouse, keyboard, root password, security level, time zone, and networking configuration options in addition to the default ones.\n\n- halt  (optional)\n\n  Halt the system after the installation has successfully completed. This is similar to a manual installation, where anaconda displays a message and waits for the user to press a key before rebooting. During a kickstart installation, if no completion method is specified, this option is used as the default.The halt  option is roughly equivalent to the shutdown -h  command.For other completion methods, refer to the poweroff, reboot, and shutdown  kickstart options.\n\n- graphical  (optional)\n\n  Perform the kickstart installation in graphical mode. This is the default.\n\n- install  (optional)\n\n  Tells the system to install a fresh system rather than upgrade an existing system. This is the default mode. For installation, you must specify the type of installation from cdrom, harddrive, nfs, or url  (for FTP or HTTP installations). The install  command and the installation method command must be on separate lines.cdrom  — Install from the first CD-ROM drive on the system.harddrive  — Install from a Red Hat installation tree on a local drive, which must be either vfat or ext2.--biospart=BIOS partition to install from (such as 82).--partition=Partition to install from (such as sdb2).--dir=Directory containing the `variant`  directory of the installation tree.For example:harddrive --partition=hdb2 --dir=/tmp/install-treenfs  — Install from the NFS server specified.--server=Server from which to install (hostname or IP).--dir=Directory containing the `variant`  directory of the installation tree.--opts=Mount options to use for mounting the NFS export. (optional)For example:nfs --server=nfsserver.example.com --dir=/tmp/install-treeurl  — Install from an installation tree on a remote server via FTP or HTTP.For example:url --url http://*<server>*/*<dir>*or:url --url ftp://*<username>*:*<password>@<server>*/*<dir>*\n\n- interactive  (optional)\n\n  Uses the information provided in the kickstart file during the installation, but allow for inspection and modification of the values given. You are presented with each screen of the installation program with the values from the kickstart file. Either accept the values by clicking Next or change the values and click Next to continue. Refer to the autostep  command.\n\n- iscsi  (optional)\n\n  iscsi --ipaddr= [options].Specifies additional iSCSI storage to be attached during installation. If you use the *iscsi* parameter, you must also assign a name to the iSCSI node, using the *iscsiname* parameter. The *iscsiname* parameter must appear before the *iscsi* parameter in the kickstart file.We recommend that wherever possible you configure iSCSI storage in the system BIOS or firmware (iBFT for Intel systems) rather than use the *iscsi* parameter. Anaconda automatically detects and uses disks configured in BIOS or firmware and no special configuration is necessary in the kickstart file.If you must use the *iscsi* parameter, ensure that networking is activated at the beginning of the installation, and that the *iscsi* parameter appears in the kickstart file before you refer to iSCSI disks with parameters such as *clearpart* or *ignoredisk*.--port=  (mandatory) — the port number (typically, --port=3260)--user=  — the username required to authenticate with the target--password=  — the password that corresponds with the username specified for the target--reverse-user=  — the username required to authenticate with the initiator from a target that uses reverse CHAP authentication--reverse-password=  — the password that corresponds with the username specified for the initiator\n\n- iscsiname  (optional)\n\n  Assigns a name to an iSCSI node specified by the iscsi parameter. If you use the *iscsi* parameter in your kickstart file, this parameter is mandatory, and you must specify *iscsiname* in the kickstart file before you specify *iscsi*.\n\n- key  (optional)\n\n  Specify an installation key, which is needed to aid in package selection and identify your system for support purposes.--skip  — Skip entering a key. Usually if the key command is not given, anaconda will pause at this step to prompt for a key. This option allows automated installation to continue if you do not have a key or do not want to provide one.\n\n- keyboard  (required)\n\n  Sets system keyboard type. Here is the list of available keyboards on i386, Itanium, and Alpha machines:be-latin1, bg, br-abnt2, cf, cz-lat2, cz-us-qwertz, de, de-latin1,de-latin1-nodeadkeys, dk, dk-latin1, dvorak, es, et, fi, fi-latin1,fr, fr-latin0, fr-latin1, fr-pc, fr_CH, fr_CH-latin1, gr, hu, hu101,is-latin1, it, it-ibm, it2, jp106, la-latin1, mk-utf, no, no-latin1,pl, pt-latin1, ro_win, ru, ru-cp1251, ru-ms, ru1, ru2, ru_win,se-latin1, sg, sg-latin1, sk-qwerty, slovene, speakup, speakup-lt,sv-latin1, sg, sg-latin1, sk-querty, slovene, trq, ua, uk, us, us-acentosThe file /usr/lib/python2.2/site-packages/rhpl/keyboard_models.py  also contains this list and is part of the rhpl  package.\n\n- lang  (required)\n\n  Sets the language to use during installation and the default language to use on the installed system. For example, to set the language to English, the kickstart file should contain the following line:lang en_USThe file /usr/share/system-config-language/locale-list  provides a list of the valid language codes in the first column of each line and is part of the system-config-language  package.Certain languages (mainly Chinese, Japanese, Korean, and Indic languages) are not supported during text mode installation. If one of these languages is specified using the lang command, installation will continue in English though the running system will have the specified language by default.\n\n- langsupport  (deprecated)\n\n  The langsupport keyword is deprecated and its use will cause an error message to be printed to the screen and installation to halt. Instead of using the langsupport keyword, you should now list the support package groups for all languages you want supported in the %packages  section of your kickstart file. For instance, adding support for French means you should add the following to %packages:@french-support\n\n- logvol  (optional)\n\n  Create a logical volume for Logical Volume Management (LVM) with the syntax:logvol *<mntpoint>* --vgname=*<name>* --size=*<size>* --name=*<name>* *<options>*The options are as follows:--noformat  — Use an existing logical volume and do not format it.--useexisting  — Use an existing logical volume and reformat it.--fstype=  — Sets the file system type for the logical volume. Valid values are xfs, ext2, ext3, ext4, swap, vfat, and hfs.--fsoptions=  — Specifies a free form string of options to be used when mounting the filesystem. This string will be copied into the /etc/fstab  file of the installed system and should be enclosed in quotes.--bytes-per-inode=  — Specifies the size of inodes on the filesystem to be made on the logical volume. Not all filesystems support this option, so it is silently ignored for those cases.--grow=  — Tells the logical volume to grow to fill available space (if any), or up to the maximum size setting.--maxsize=  — The maximum size in megabytes when the logical volume is set to grow. Specify an integer value here, and do not append the number with MB.--recommended=  — Determine the size of the logical volume automatically.--percent=  — Specify the size of the logical volume as a percentage of available space in the volume group.Create the partition first, create the logical volume group, and then create the logical volume. For example:part pv.01 --size 3000volgroup myvg pv.01logvol / --vgname=myvg --size=2000 --name=rootvol\n\n- logging  (optional)\n\n  This command controls the error logging of anaconda during installation. It has no effect on the installed system.--host=  — Send logging information to the given remote host, which must be running a syslogd process configured to accept remote logging.--port=  — If the remote syslogd process uses a port other than the default, it may be specified with this option.--level=  — One of debug, info, warning, error, or critical.Specify the minimum level of messages that appear on tty3. All messages will still be sent to the log file regardless of this level, however.\n\n- mediacheck  (optional)\n\n  If given, this will force anaconda to run mediacheck on the installation media. This command requires that installs be attended, so it is disabled by default.\n\n- monitor  (optional)\n\n  If the monitor command is not given, anaconda will use X to automatically detect your monitor settings. Please try this before manually configuring your monitor.--hsync=  — Specifies the horizontal sync frequency of the monitor.--monitor=  — Use specified monitor; monitor name should be from the list of monitors in /usr/share/hwdata/MonitorsDB from the hwdata package. The list of monitors can also be found on the X Configuration screen of the Kickstart Configurator. This is ignored if --hsync or --vsync is provided. If no monitor information is provided, the installation program tries to probe for it automatically.--noprobe=  — Do not try to probe the monitor.--vsync=  — Specifies the vertical sync frequency of the monitor.\n\n- mouse  (deprecated)\n\n  The mouse keyword is deprecated.\n\n- network  (optional)\n\n  Configures network information for the system. If the kickstart installation does not require networking (in other words, it is not installed over NFS, HTTP, or FTP), networking is not configured for the system. If the installation does require networking and network information is not provided in the kickstart file, the installation program assumes that the installation should be done over eth0 via a dynamic IP address (BOOTP/DHCP), and configures the final, installed system to determine its IP address dynamically. The network  option configures networking information for kickstart installations via a network as well as for the installed system.--bootproto=  — One of dhcp, bootp, or static.It defaults to dhcp. bootp  and dhcp  are treated the same.The DHCP method uses a DHCP server system to obtain its networking configuration. As you might guess, the BOOTP method is similar, requiring a BOOTP server to supply the networking configuration. To direct a system to use DHCP:network --bootproto=dhcpTo direct a machine to use BOOTP to obtain its networking configuration, use the following line in the kickstart file:network --bootproto=bootpThe static method requires that you enter all the required networking information in the kickstart file. As the name implies, this information is static and is used during and after the installation. The line for static networking is more complex, as you must include all network configuration information on one line. You must specify the IP address, netmask, gateway, and nameserver.Note that although the presentation of this example on this page has broken the line, in a real kickstart file, you must include all this information on a single line with no break.network --bootproto=static --ip=10.0.2.15 --netmask=255.255.255.0--gateway=10.0.2.254 --nameserver=10.0.2.1If you use the static method, be aware of the following two restrictions:All static networking configuration information must be specified on *one* line; you cannot wrap lines using a backslash, for example.You can also configure multiple nameservers here. To do so, specify them as a comma-delimited list in the command line.Note that although the presentation of this example on this page has broken the line, in a real kickstart file, you must include all this information on a single line with no break.network --bootproto=static --ip=10.0.2.15 --netmask=255.255.255.0--gateway=10.0.2.254 --nameserver 192.168.2.1,192.168.3.1--device=  — Used to select a specific Ethernet device for installation. Note that using --device=  is not effective unless the kickstart file is a local file (such as ks=floppy), since the installation program configures the network to find the kickstart file. For example:network --bootproto=dhcp --device=eth0--ip=  — IP address for the machine to be installed.--gateway=  — Default gateway as an IP address.--nameserver=  — Primary nameserver, as an IP address.--nodns  — Do not configure any DNS server.--netmask=  — Netmask for the installed system.--hostname=  — Hostname for the installed system.--ethtool=  — Specifies additional low-level settings for the network device which will be passed to the ethtool program.--essid=  — The network ID for wireless networks.--wepkey=  — The encryption key for wireless networks.--onboot=  — Whether or not to enable the device at boot time.--dhcpclass=  — The DHCP class.--mtu=  — The MTU of the device.--noipv4  — Disable IPv4 on this device.--noipv6  — Disable IPv6 on this device.\n\n- multipath  (optional)\n\n  Specifies a multipath device in the format:multipath --name=mpath*X* --device=*device_name* --rule=*policy*For example:multipath --name=mpath0 --device=/dev/sdc --rule=failoverThe available options are:--name=  — the name for the multipath device, in the format mpath*X*, where *X* is an integer.--device=  — the block device connected as a multipath device.--rule=  — a multipath *policy*: failover, multibus, group_by_serial, group_by_prio, or group_by_node_name. Refer to the multipath manpage for a description of these policies.\n\n- part  or partition  (required for installs, ignored for upgrades)\n\n  Creates a partition on the system.If more than one Red Hat Enterprise Linux installation exists on the system on different partitions, the installation program prompts the user and asks which installation to upgrade.WarningAll partitions created are formatted as part of the installation process unless --noformat  and --onpart  are used.For a detailed example of part  in action, refer to [Section 31.4.1, \"Advanced Partitioning Example\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-kickstart2-options.html#s2-kickstart2-options-part-examples).*<mntpoint>* — The *<mntpoint>* is where the partition is mounted and must be of one of the following forms:/*<path>*For example, /, /usr, /home swapThe partition is used as swap space.To determine the size of the swap partition automatically, use the --recommended  option:swap --recommendedThe recommended maximum swap size for machines with less than 2GB of RAM is twice the amount of RAM. For machines with 2GB or more, this recommendation changes to 2GB plus the amount of RAM.raid.*<id>*The partition is used for software RAID (refer to raid).pv.*<id>*The partition is used for LVM (refer to logvol).--size=  — The minimum partition size in megabytes. Specify an integer value here such as 500. Do not append the number with MB.--grow  — Tells the partition to grow to fill available space (if any), or up to the maximum size setting.NoteIf you use --grow=  without setting --maxsize=  on a swap partition, Anaconda will limit the maximum size of the swap partition. For systems that have less than 2GB of physical memory, the imposed limit is twice the amount of physical memory. For systems with more than 2GB, the imposed limit is the size of physical memory plus 2GB.--maxsize=  — The maximum partition size in megabytes when the partition is set to grow. Specify an integer value here, and do not append the number with MB.--noformat  — Tells the installation program not to format the partition, for use with the --onpart  command.--onpart=  or --usepart=  — Put the partition on the *already existing* device. For example:partition /home --onpart=hda1puts /home  on /dev/hda1, which must already exist.--ondisk=  or --ondrive=  — Forces the partition to be created on a particular disk. For example, --ondisk=sdb  puts the partition on the second SCSI disk on the system.--asprimary  — Forces automatic allocation of the partition as a primary partition, or the partitioning fails.--type=  (replaced by fstype) — This option is no longer available. Use fstype.--fstype=  — Sets the file system type for the partition. Valid values are xfs, ext2, ext3, ext4, swap, vfat, and hfs.--start=  — Specifies the starting cylinder for the partition. It requires that a drive be specified with --ondisk=  or ondrive=. It also requires that the ending cylinder be specified with --end=  or the partition size be specified with --size=.--end=  — Specifies the ending cylinder for the partition. It requires that the starting cylinder be specified with --start=.--bytes-per-inode=  — Specifies the size of inodes on the filesystem to be made on the partition. Not all filesystems support this option, so it is silently ignored for those cases.--recommended  — Determine the size of the partition automatically.--onbiosdisk  — Forces the partition to be created on a particular disk as discovered by the BIOS.--encrypted  — Specifies that this partition should be encrypted.--passphrase=  — Specifies the passphrase to use when encrypting this partition. Without the above --encrypted  option, this option does nothing. If no passphrase is specified, the default system-wide one is used, or the installer will stop and prompt if there is no default.--fsoptions=  — Specifies a free form string of options to be used when mounting the filesystem. This string will be copied into the /etc/fstab  file of the installed system and should be enclosed in quotes.NoteIf partitioning fails for any reason, diagnostic messages appear on virtual console 3.\n\n- poweroff  (optional)\n\n  Shut down and power off the system after the installation has successfully completed. Normally during a manual installation, anaconda displays a message and waits for the user to press a key before rebooting. During a kickstart installation, if no completion method is specified, the halt  option is used as default.The poweroff  option is roughly equivalent to the shutdown -p  command.NoteThe poweroff  option is highly dependent on the system hardware in use. Specifically, certain hardware components such as the BIOS, APM (advanced power management), and ACPI (advanced configuration and power interface) must be able to interact with the system kernel. Contact your manufacturer for more information on you system's APM/ACPI abilities.For other completion methods, refer to the halt, reboot, and shutdown  kickstart options.\n\n- raid  (optional)\n\n  Assembles a software RAID device. This command is of the form:raid *<mntpoint>* --level=*<level>* --device=*<mddevice>* *<partitions\\*>**<mntpoint>* — Location where the RAID file system is mounted. If it is /, the RAID level must be 1 unless a boot partition (/boot) is present. If a boot partition is present, the /boot  partition must be level 1 and the root (/) partition can be any of the available types. The *<partitions\\*>* (which denotes that multiple partitions can be listed) lists the RAID identifiers to add to the RAID array.--level=  — RAID level to use (0, 1, 4, 5, 6, or 10).--device=  — Name of the RAID device to use (such as md0 or md1). RAID devices range from md0 to md15, and each may only be used once.--bytes-per-inode=  — Specifies the size of inodes on the filesystem to be made on the RAID device. Not all filesystems support this option, so it is silently ignored for those cases.--spares=  — Specifies the number of spare drives allocated for the RAID array. Spare drives are used to rebuild the array in case of drive failure.--fstype=  — Sets the file system type for the RAID array. Valid values are xfs, ext2, ext3, ext4, swap, vfat, and hfs.--fsoptions=  — Specifies a free form string of options to be used when mounting the filesystem. This string will be copied into the /etc/fstab file of the installed system and should be enclosed in quotes.--noformat  — Use an existing RAID device and do not format the RAID array.--useexisting  — Use an existing RAID device and reformat it.--encrypted  — Specifies that this RAID device should be encrypted.--passphrase=  — Specifies the passphrase to use when encrypting this RAID device. Without the above --encrypted  option, this option does nothing. If no passphrase is specified, the default system-wide one is used, or the installer will stop and prompt if there is no default.The following example shows how to create a RAID level 1 partition for /, and a RAID level 5 for /usr, assuming there are three SCSI disks on the system. It also creates three swap partitions, one on each drive.part raid.01 --size=60 --ondisk=sdapart raid.02 --size=60 --ondisk=sdbpart raid.03 --size=60 --ondisk=sdcpart swap --size=128 --ondisk=sdapart swap --size=128 --ondisk=sdbpart swap --size=128 --ondisk=sdcpart raid.11 --size=1 --grow --ondisk=sdapart raid.12 --size=1 --grow --ondisk=sdbpart raid.13 --size=1 --grow --ondisk=sdcraid / --level=1 --device=md0 raid.01 raid.02 raid.03raid /usr --level=5 --device=md1 raid.11 raid.12 raid.13For a detailed example of raid  in action, refer to [Section 31.4.1, \"Advanced Partitioning Example\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-kickstart2-options.html#s2-kickstart2-options-part-examples).\n\n- reboot  (optional)\n\n  Reboot after the installation is successfully completed (no arguments). Normally, kickstart displays a message and waits for the user to press a key before rebooting.The reboot  option is roughly equivalent to the shutdown -r  command.Specify reboot  to automate installation fully when installing in cmdline mode on System z.For other completion methods, refer to the halt, poweroff, and shutdown  kickstart options.The halt  option is the default completion method if no other methods are explicitly specified in the kickstart file.NoteUse of the reboot  option *may* result in an endless installation loop, depending on the installation media and method.\n\n- repo  (optional)\n\n  Configures additional yum repositories that may be used as sources for package installation. Multiple repo lines may be specified.repo --name=*<repoid>* [--baseurl=*<url>*| --mirrorlist=*<url>*]--name=  — The repo id. This option is required.--baseurl=  — The URL for the repository. The variables that may be used in yum repo config files are not supported here. You may use one of either this option or --mirrorlist, not both.--mirrorlist=  — The URL pointing at a list of mirrors for the repository. The variables that may be used in yum repo config files are not supported here. You may use one of either this option or --baseurl, not both.\n\n- rootpw  (required)\n\n  Sets the system's root password to the *<password>* argument.rootpw [--iscrypted] *<password>*--iscrypted  — If this is present, the password argument is assumed to already be encrypted.\n\n- selinux  (optional)\n\n  Sets the state of SELinux on the installed system. SELinux defaults to enforcing in anaconda.selinux [--disabled|--enforcing|--permissive]--enforcing  — Enables SELinux with the default targeted policy being enforced.\n\n> #### Note\n>\n> > If the selinux  option is not present in the kickstart file, SELinux is enabled and set to --enforcing  by default.\n> >\n> > - --permissive  — Outputs warnings based on the SELinux policy, but does not actually enforce the policy.\n> > - --disabled  — Disables SELinux completely on the system.\n\n- services  (optional)\n\n  Modifies the default set of services that will run under the default runlevel. The services listed in the disabled list will be disabled before the services listed in the enabled list are enabled.--disabled  — Disable the services given in the comma separated list.--enabled  — Enable the services given in the comma separated list.***Do not include spaces in the list of services***If you include spaces in the comma-separated list, kickstart will enable or disable only the services up to the first space. For example:services --disabled auditd, cups,smartd,nfslock will disable only the auditd service. To disable all four services, this entry should include no spaces between services:services --disabled auditd,cups,smartd,nfslock \n\n- shutdown  (optional)\n\n  Shut down the system after the installation has successfully completed. During a kickstart installation, if no completion method is specified, the halt  option is used as default.The shutdown  option is roughly equivalent to the shutdown  command.For other completion methods, refer to the halt, poweroff, and reboot  kickstart options.\n\n- skipx  (optional)\n\n  If present, X is not configured on the installed system.\n\n- text  (optional)\n\n  Perform the kickstart installation in text mode. Kickstart installations are performed in graphical mode by default.\n\n- timezone  (required)\n\n  Sets the system time zone to *<timezone>* which may be any of the time zones listed by timeconfig.timezone [--utc] *<timezone>*--utc  — If present, the system assumes the hardware clock is set to UTC (Greenwich Mean) time.\n\n- upgrade  (optional)\n\n  Tells the system to upgrade an existing system rather than install a fresh system. You must specify one of cdrom, harddrive, nfs, or url  (for FTP and HTTP) as the location of the installation tree. Refer to install  for details.\n\n- user  (optional)\n\n  Creates a new user on the system.user --name=*<username>* [--groups=*<list>*] [--homedir=*<homedir>*] [--password=*<password>*] [--iscrypted] [--shell=*<shell>*] [--uid=*<uid>*]--name=  — Provides the name of the user. This option is required.--groups=  — In addition to the default group, a comma separated list of group names the user should belong to. The groups must exist before the user account is created.--homedir=  — The home directory for the user. If not provided, this defaults to /home/*<username>*.--password=  — The new user's password. If not provided, the account will be locked by default.--iscrypted=  — Is the password provided by --password already encrypted or not?--shell=  — The user's login shell. If not provided, this defaults to the system default.--uid=  — The user's UID. If not provided, this defaults to the next available non-system UID.\n\n- vnc  (optional)\n\n  Allows the graphical installation to be viewed remotely via VNC. This method is usually preferred over text mode, as there are some size and language limitations in text installs. With no options, this command will start a VNC server on the machine with no password and will print out the command that needs to be run to connect a remote machine.vnc [--host=*<hostname>*] [--port=*<port>*] [--password=*<password>*]--host=  — Instead of starting a VNC server on the install machine, connect to the VNC viewer process listening on the given hostname.--port=  — Provide a port that the remote VNC viewer process is listening on. If not provided, anaconda will use the VNC default.--password=  — Set a password which must be provided to connect to the VNC session. This is optional, but recommended.\n\n- volgroup  (optional)\n\n  Use to create a Logical Volume Management (LVM) group with the syntax:volgroup *<name>* *<partition>* *<options>*The options are as follows:--noformat  — Use an existing volume group and do not format it.--useexisting  — Use an existing volume group and reformat it.--pesize=  — Set the size of the physical extents.Create the partition first, create the logical volume group, and then create the logical volume. For example:part pv.01 --size 3000volgroup myvg pv.01logvol / --vgname=myvg --size=2000 --name=rootvolFor a detailed example of volgroup  in action, refer to [Section 31.4.1, \"Advanced Partitioning Example\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-kickstart2-options.html#s2-kickstart2-options-part-examples).\n\n- xconfig  (optional)\n\n  Configures the X Window System. If this option is not given, the user must configure X manually during the installation, if X was installed; this option should not be used if X is not installed on the final system.--driver  — Specify the X driver to use for the video hardware.--videoram=  — Specifies the amount of video RAM the video card has.--defaultdesktop=  — Specify either GNOME or KDE to set the default desktop (assumes that GNOME Desktop Environment and/or KDE Desktop Environment has been installed through %packages).--startxonboot  — Use a graphical login on the installed system.--resolution=  — Specify the default resolution for the X Window System on the installed system. Valid values are 640x480, 800x600, 1024x768, 1152x864, 1280x1024, 1400x1050, 1600x1200. Be sure to specify a resolution that is compatible with the video card and monitor.--depth=  — Specify the default color depth for the X Window System on the installed system. Valid values are 8, 16, 24, and 32. Be sure to specify a color depth that is compatible with the video card and monitor.\n\n- %include  (optional)\n\n  Use the %include */path/to/file*  command to include the contents of another file in the kickstart file as though the contents were at the location of the %include  command in the kickstart file.\n\n### Advanced Partitioning Example\n\nThe following is a single, integrated example showing the clearpart, raid, part, volgroup, and logvol  kickstart options in action:\n\nclearpart --drives=hda,hdc --initlabel\n\n\\# Raid 1 IDE config\n\npart raid.11 --size 1000 --asprimary --ondrive=hda\n\npart raid.12 --size 1000 --asprimary --ondrive=hda\n\npart raid.13 --size 2000 --asprimary --ondrive=hda\n\npart raid.14 --size 8000 --ondrive=hda\n\npart raid.15 --size 1 --grow --ondrive=hda\n\npart raid.21 --size 1000 --asprimary --ondrive=hdc\n\npart raid.22 --size 1000 --asprimary --ondrive=hdc\n\npart raid.23 --size 2000 --asprimary --ondrive=hdc\n\npart raid.24 --size 8000 --ondrive=hdc\n\npart raid.25 --size 1 --grow --ondrive=hdc\n\n\n\n\\# You can add --spares=x\n\nraid / --fstype ext3 --device md0 --level=RAID1 raid.11 raid.21\n\nraid /safe --fstype ext3 --device md1 --level=RAID1 raid.12 raid.22\n\nraid swap --fstype swap --device md2 --level=RAID1 raid.13 raid.23\n\nraid /usr --fstype ext3 --device md3 --level=RAID1 raid.14 raid.24\n\nraid pv.01 --fstype ext3 --device md4 --level=RAID1 raid.15 raid.25\n\n\n\n\\# LVM configuration so that we can resize /var and /usr/local later\n\nvolgroup sysvg pv.01\n\nlogvol /var --vgname=sysvg --size=8000 --name=var\n\nlogvol /var/freespace --vgname=sysvg --size=8000 --name=freespacetouse\n\nlogvol /usr/local --vgname=sysvg --size=1 --grow --name=usrlocal\n\nThis advanced example implements LVM over RAID, as well as the ability to resize various directories for future growth.\n\nYou can use a kickstart file to install every available package by specifying @Everything  or simply *  in the %packages  section. Red Hat does not support this type of installation.\n\nMoreover, using a kickstart file in this way will introduce package and file conflicts onto the installed system. Packages known to cause such problems are assigned to the @Conflicts  group. If you specify @Everything  in a kickstart file, be sure to exclude @Conflicts  or the installation will fail:\n\n@Everything\n\n-@Conflicts\n\nNote that Red Hat does not support the use of @Everything  in a kickstart file, even if you exclude @Conflicts.\n\nUse the %packages  command to begin a kickstart file section that lists the packages you would like to install (this is for installations only, as package selection during upgrades is not supported).\n\nPackages can be specified by group or by individual package name, including with globs using the asterisk. The installation program defines several groups that contain related packages. Refer to the *variant*/repodata/comps-*.xml  file on the first Red Hat Enterprise Linux CD-ROM for a list of groups. Each group has an id, user visibility value, name, description, and package list. In the package list, the packages marked as mandatory are always installed if the group is selected, the packages marked default are selected by default if the group is selected, and the packages marked optional must be specifically selected even if the group is selected to be installed.\n\nAvailable groups vary slightly between different variants of Red Hat Enterprise Linux 5, but include:\n\n- Administration Tools\n- Authoring and Publishing\n- Development Libraries\n- Development Tools\n- DNS Name Server\n- Eclipse\n- Editors\n- Engineering and Scientific\n- FTP Server\n- GNOME Desktop Environment\n- GNOME Software Development\n- Games and Entertainment\n- Graphical Internet\n- Graphics\n- Java Development\n- KDE (K Desktop Environment)\n- KDE Software Development\n- Legacy Network Server\n- Legacy Software Development\n- Legacy Software Support\n- Mail Server\n- Misc\n- Multimedia\n- MySQL Database\n- Network Servers\n- News Server\n- Office/Productivity\n- OpenFabrics Enterprise Distribution\n- PostgreSQL Database\n- Printing Support\n- Server Configuration Tools\n- Sound and Video\n- System Tools\n- Text-based Internet\n- Web Server\n- Windows File Server\n- Windows PV Drivers\n- X Software Development\n- X Window System\n\nIn most cases, it is only necessary to list the desired groups and not individual packages. Note that the Core  and Base  groups are always selected by default, so it is not necessary to specify them in the %packages  section.\n\nHere is an example %packages  selection:\n\n%packages\n\n@ X Window System\n\n@ GNOME Desktop Environment\n\n@ Graphical Internet\n\n@ Sound and Video dhcp\n\nAs you can see, groups are specified, one to a line, starting with an @  symbol, a space, and then the full group name as given in the comps.xml  file. Groups can also be specified using the id for the group, such as gnome-desktop. Specify individual packages with no additional characters (the dhcp  line in the example above is an individual package).\n\nYou can also specify which packages not to install from the default package list:\n\n-autofs\n\nThe following options are available for the %packages  option:\n\n- --nobase \n\n  Do not install the @Base group. Use this option if you are trying to create a very small system.\n\n- --resolvedeps \n\n  The --resolvedeps option has been deprecated. Dependencies are resolved automatically every time now.\n\n- --ignoredeps \n\n  The --ignoredeps option has been deprecated. Dependencies are resolved automatically every time now.\n\n- --ignoremissing \n\n  Ignore the missing packages and groups instead of halting the installation to ask if the installation should be aborted or continued. For example:%packages --ignoremissing\n\n- interpreter */usr/bin/python* \n\n  Allows you to specify a different scripting language, such as Python. Replace */usr/bin/python* with the scripting language of your choice.\n\n### Example\n\nHere is an example %pre  section:\n\n%pre\n\n\\#!/bin/sh\n\nhds=\"\"\n\nmymedia=\"\"\n\nfor file in /proc/ide/h* do\n\n​    mymedia=`cat $file/media`\n\n​    if [ $mymedia == \"disk\" ] ; then\n\n​        hds=\"$hds `basename $file`\"\n\n​    fi\n\ndone\n\nset $hds\n\nnumhd=`echo $#`\n\ndrive1=`echo $hds | cut -d' ' -f1`\n\ndrive2=`echo $hds | cut -d' ' -f2`\n\n\\#Write out partition scheme based on whether there are 1 or 2 hard drives\n\nif [ $numhd == \"2\" ] ; then\n\n​    \\#2 drives\n\n​    echo \"#partitioning scheme generated in %pre for 2 drives\" > /tmp/part-include\n\n​    echo \"clearpart --all\" >> /tmp/part-include\n\n​    echo \"part /boot --fstype ext3 --size 75 --ondisk hda\" >> /tmp/part-include\n\n​    echo \"part / --fstype ext3 --size 1 --grow --ondisk hda\" >> /tmp/part-include\n\n​    echo \"part swap --recommended --ondisk $drive1\" >> /tmp/part-include\n\n​    echo \"part /home --fstype ext3 --size 1 --grow --ondisk hdb\" >> /tmp/part-include\n\nelse\n\n​    \\#1 drive\n\n​    echo \"#partitioning scheme generated in %pre for 1 drive\" > /tmp/part-include\n\n​    echo \"clearpart --all\" >> /tmp/part-include\n\n​    echo \"part /boot --fstype ext3 --size 75\" >> /tmp/part-include\n\n​    echo \"part swap --recommended\" >> /tmp/part-include\n\n​    echo \"part / --fstype ext3 --size 2048\" >> /tmp/part-include\n\n​    echo \"part /home --fstype ext3 --size 2048 --grow\" >> /tmp/part-include\n\nfi\n\nThis script determines the number of hard drives in the system and writes a text file with a different partitioning scheme depending on whether it has one or two drives. Instead of having a set of partitioning commands in the kickstart file, include the line:\n\n%include /tmp/part-include\n\nThe partitioning commands selected in the script are used.\n\n#### Note\n\n- The pre-installation script section of kickstart *cannot* manage multiple install trees or source media. This information must be included for each created ks.cfg file, as the pre-installation script occurs during the second stage of the installation process.\n\n### Post-installation Script\n\nYou have the option of adding commands to run on the system once the installation is complete. This section must be at the end of the kickstart file and must start with the %post  command. This section is useful for functions such as installing additional software and configuring an additional nameserver.\n\n#### Notes\n\n- If you configured the network with static IP information, including a nameserver, you can access the network and resolve IP addresses in the %post  section. If you configured the network for DHCP, the /etc/resolv.conf  file has not been completed when the installation executes the %post  section. You can access the network, but you can not resolve IP addresses. Thus, if you are using DHCP, you must specify IP addresses in the %post  section.\n\n- The post-install script is run in a chroot environment; therefore, performing tasks such as copying scripts or RPMs from the installation media do not work.\n\n  - --nochroot \n\n    Allows you to specify commands that you would like to run outside of the chroot environment.The following example copies the file /etc/resolv.conf  to the file system that was just installed.%post --nochrootcp /etc/resolv.conf /mnt/sysimage/etc/resolv.conf\n\n  - --interpreter */usr/bin/python* \n\n    Allows you to specify a different scripting language, such as Python. Replace */usr/bin/python* with the scripting language of your choice.\n\n  - --log */path/to/logfile* \n\n    Logs the output of the post-install script. Note that the path of the log file must take into account whether or not you use the --nochroot  option. For example, without --nochroot:This command is available in Red Hat Enterprise Linux 5.5 and later.%post --log=/root/ks-post.logwith --nochroot:%post --nochroot --log=/mnt/sysimage/root/ks-post.log\n\n### Examples\n\nRegister the system to a Red Hat Network Satellite, using a subshell to log the result in Red Hat Enterprise Linux 5.4 and earlier:\n\n%post\n\n( # Note that in this example we run the entire %post section as a subshell for logging.\n\nwget -O- http://proxy-or-sat.example.com/pub/bootstrap_script | /bin/bash\n\n/usr/sbin/rhnreg_ks --activationkey=*<activationkey>*\n\n\\# End the subshell and capture any output to a post-install log file.\n\n) 1>/root/post_install.log 2>&1\n\nRegister the system to a Red Hat Network Satellite, using the --log  option to log the result in Red Hat Enterprise Linux 5.5 and later:\n\n%post --log=/root/ks-post.log\n\nwget -O- http://proxy-or-sat.example.com/pub/bootstrap_script | /bin/bash\n\n/usr/sbin/rhnreg_ks --activationkey=*<activationkey>*\n\nRun a script named runme  from an NFS share:\n\nmkdir /mnt/temp\n\nmount -o nolock 10.10.0.2:/usr/new-machines /mnt/temp open -s -w --\n\n/mnt/temp/runme\n\numount /mnt/temp\n\n### Note\n\nNFS file locking is *not* supported while in kickstart mode, therefore -o nolock  is required when mounting an NFS mount.\n\n### Making the Kickstart File Available\n\nA kickstart file must be placed in one of the following locations:\n\n- On a boot diskette\n- On a boot CD-ROM\n- On a network\n\nNormally a kickstart file is copied to the boot diskette, or made available on the network. ***The network-based approach is most commonly used, as most kickstart installations tend to be performed on networked computers.***\n\nLet us take a more in-depth look at where the kickstart file may be placed.\n\n### 31.8.1. Creating Kickstart Boot Media\n\nDiskette-based booting is no longer supported in Red Hat Enterprise Linux. Installations must use CD-ROM or flash memory products for booting. However, the kickstart file may still reside on a diskette's top-level directory, and must be named ks.cfg.\n\nTo perform a CD-ROM-based kickstart installation, the kickstart file must be named ks.cfg  and must be located in the boot CD-ROM's top-level directory. Since a CD-ROM is read-only, the file must be added to the directory used to create the image that is written to the CD-ROM. Refer to [Section 2.4.1, \"Alternative Boot Methods\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/ch02s04.html#sect-New_Users-Alternative_Boot_Methods) for instructions on creating boot media; however, before making the file.iso  image file, copy the ks.cfg  kickstart file to the isolinux/  directory.\n\nTo perform a pen-based flash memory kickstart installation, the kickstart file must be named ks.cfg  and must be located in the flash memory's top-level directory. Create the boot image first, and then copy the ks.cfg  file.\n\n### Note\n\nCreation of USB flash memory pen drives for booting is possible, but is heavily dependent on system hardware BIOS settings. Refer to your hardware manufacturer to see if your system supports booting to alternate devices.\n\n### Making the Kickstart File Available on the Network\n\nNetwork installations using kickstart are quite common, because system administrators can easily automate the installation on many networked computers quickly and painlessly. In general, the approach most commonly used is for the administrator to have both a BOOTP/DHCP server and an NFS server on the local network. The BOOTP/DHCP server is used to give the client system its networking information, while the actual files used during the installation are served by the NFS server. Often, these two servers run on the same physical machine, but they are not required to.\n\nTo perform a network-based kickstart installation, you must have a BOOTP/DHCP server on your network, and it must include configuration information for the machine on which you are attempting to install Red Hat Enterprise Linux. The BOOTP/DHCP server provides the client with its networking information as well as the location of the kickstart file.\n\nIf a kickstart file is specified by the BOOTP/DHCP server, the client system attempts an NFS mount of the file's path, and copies the specified file to the client, using it as the kickstart file. The exact settings required vary depending on the BOOTP/DHCP server you use.\n\nHere is an example of a line from the dhcpd.conf  file for the DHCP server:\n\nfilename *\"/usr/new-machine/kickstart/\"*; next-server *blarg.redhat.com;*\n\nNote that you should replace the value after filename  with the name of the kickstart file (or the directory in which the kickstart file resides) and the value after next-server  with the NFS server name.\n\nIf the file name returned by the BOOTP/DHCP server ends with a slash (\"/\"), then it is interpreted as a path only. In this case, the client system mounts that path using NFS, and searches for a particular file. The file name the client searches for is:\n\n*<ip-addr>*-kickstart\n\nThe `<ip-addr>`  section of the file name should be replaced with the client's IP address in dotted decimal notation. For example, the file name for a computer with an IP address of 10.10.0.1 would be 10.10.0.1-kickstart.\n\nNote that if you do not specify a server name, then the client system attempts to use the server that answered the BOOTP/DHCP request as its NFS server. If you do not specify a path or file name, the client system tries to mount /kickstart  from the BOOTP/DHCP server and tries to find the kickstart file using the same *<ip-addr>*-kickstart  file name as described above.\n\n### Making the Installation Tree Available\n\nThe kickstart installation must access an *installation tree*. An installation tree is a copy of the binary Red Hat Enterprise Linux CD-ROMs with the same directory structure.\n\nIf you are performing a CD-based installation, insert the Red Hat Enterprise Linux CD-ROM #1 into the computer before starting the kickstart installation.\n\nIf you are performing a hard drive installation, make sure the ISO images of the binary Red Hat Enterprise Linux CD-ROMs are on a hard drive in the computer.\n\nIf you are performing a network-based (NFS, FTP, or HTTP) installation, you must make the installation tree available over the network. Refer to [Section 2.5, \"Preparing for a Network Installation\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-steps-network-installs-x86.html) for details.\n\n### Starting a Kickstart Installation\n\nTo begin a kickstart installation, you must boot the system from boot media you have made or the Red Hat Enterprise Linux CD-ROM #1, and enter a special boot command at the boot prompt. The installation program looks for a kickstart file if the ks  command line argument is passed to the kernel.\n\n- CD-ROM #1 and Diskette\n\n  The linux ks=floppy command also works if the ks.cfg  file is located on a vfat or ext2 file system on a diskette and you boot from the Red Hat Enterprise Linux CD-ROM #1.An alternate boot command is to boot off the Red Hat Enterprise Linux CD-ROM #1 and have the kickstart file on a vfat or ext2 file system on a diskette. To do so, enter the following command at the boot:  prompt:linux ks=hd:fd0:/ks.cfg\n\n- With Driver Disk\n\n  If you need to use a driver disk with kickstart, specify the dd option as well. For example, to boot off a boot diskette and use a driver disk, enter the following command at the boot:  prompt:linux ks=floppy dd\n\n- Boot CD-ROM\n\n  If the kickstart file is on a boot CD-ROM as described in [Section 31.8.1, \"Creating Kickstart Boot Media\"](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/s1-kickstart2-putkickstarthere.html#s2-kickstart2-boot-media), insert the CD-ROM into the system, boot the system, and enter the following command at the boot:  prompt (where ks.cfg  is the name of the kickstart file):linux ks=cdrom:/ks.cfg\n\nOther options to start a kickstart installation are as follows:\n\n- askmethod \n\n  Do not automatically use the CD-ROM as the install source if we detect a Red Hat Enterprise Linux CD in your CD-ROM drive.\n\n- autostep \n\n  Make kickstart non-interactive.\n\n- debug \n\n  Start up pdb immediately.\n\n- dd \n\n  Use a driver disk.\n\n- dhcpclass=*<class>* \n\n  Sends a custom DHCP vendor class identifier. ISC's dhcpcd can inspect this value using \"option vendor-class-identifier\".\n\n- dns=*<dns>* \n\n  Comma separated list of nameservers to use for a network installation.\n\n- driverdisk \n\n  Same as 'dd'.\n\n- expert \n\n  Turns on special features:allows partitioning of removable mediaprompts for a driver disk\n\n- gateway=*<gw>* \n\n  Gateway to use for a network installation.\n\n- graphical \n\n  Force graphical install. Required to have ftp/http use GUI.\n\n- isa \n\n  Prompt user for ISA devices configuration.\n\n- ip=*<ip>* \n\n  IP to use for a network installation, use 'dhcp' for DHCP.\n\n- keymap=*<keymap>* \n\n  Keyboard layout to use. Valid values are those which can be used for the 'keyboard' kickstart command.\n\n- ks=nfs:*<server>*:/*<path>* \n\n  The installation program looks for the kickstart file on the NFS server *<server>*, as file *<path>*. The installation program uses DHCP to configure the Ethernet card. For example, if your NFS server is server.example.com and the kickstart file is in the NFS share /mydir/ks.cfg, the correct boot command would be ks=nfs:server.example.com:/mydir/ks.cfg.\n\n- ks=http://*<server>*/*<path>* \n\n  The installation program looks for the kickstart file on the HTTP server *<server>*, as file *<path>*. The installation program uses DHCP to configure the Ethernet card. For example, if your HTTP server is server.example.com and the kickstart file is in the HTTP directory /mydir/ks.cfg, the correct boot command would be ks=http://server.example.com/mydir/ks.cfg.\n\n- ks=floppy \n\n  The installation program looks for the file ks.cfg  on a vfat or ext2 file system on the diskette in /dev/fd0.\n\n- ks=floppy:/*<path>* \n\n  The installation program looks for the kickstart file on the diskette in /dev/fd0, as file *<path>*.\n\n- ks=hd:*<device>*:/*<file>* \n\n  The installation program mounts the file system on *<device>* (which must be vfat or ext2), and look for the kickstart configuration file as *<file>* in that file system (for example, ks=hd:sda3:/mydir/ks.cfg).\n\n- ks=file:/*<file>* \n\n  The installation program tries to read the file *<file>* from the file system; no mounts are done. This is normally used if the kickstart file is already on the initrd  image.\n\n- ks=cdrom:/*<path>* \n\n  The installation program looks for the kickstart file on CD-ROM, as file *<path>*.\n\n- ks \n\n  If ks  is used alone, the installation program configures the Ethernet card to use DHCP. The kickstart file is read from the \"bootServer\" from the DHCP response as if it is an NFS server sharing the kickstart file. By default, the bootServer is the same as the DHCP server. The name of the kickstart file is one of the following:If DHCP is specified and the boot file begins with a /, the boot file provided by DHCP is looked for on the NFS server.If DHCP is specified and the boot file begins with something other than a /, the boot file provided by DHCP is looked for in the /kickstart  directory on the NFS server.If DHCP did not specify a boot file, then the installation program tries to read the file /kickstart/1.2.3.4-kickstart, where *1.2.3.4* is the numeric IP address of the machine being installed.\n\n- ksdevice=*<device>* \n\n  The installation program uses this network device to connect to the network. For example, consider a system connected to an NFS server through the eth1 device. To perform a kickstart installation on this system using a kickstart file from the NFS server, you would use the command ks=nfs:*<server>*:/*<path>* ksdevice=eth1  at the boot:  prompt.\n\n- kssendmac \n\n  Adds HTTP headers to ks=http:// request that can be helpful for provisioning systems. Includes MAC address of all nics in CGI environment variables of the form: \"X-RHN-Provisioning-MAC-0: eth0 01:23:45:67:89:ab\".\n\n- lang=*<lang>* \n\n  Language to use for the installation. This should be a language which is valid to be used with the 'lang' kickstart command.\n\n- loglevel=*<level>* \n\n  Set the minimum level required for messages to be logged. Values for <level> are debug, info, warning, error, and critical. The default value is info.\n\n- lowres \n\n  Force GUI installer to run at 640x480.\n\n- mediacheck \n\n  Activates loader code to give user option of testing integrity of install source (if an ISO-based method).\n\n- method=cdrom \n\n  Do a CDROM based installation.\n\n- method=ftp://*<path>* \n\n  Use <path> for an FTP installation.\n\n- method=hd:*<dev>*:*<path>* \n\n  Use <path> on <dev> for a hard drive installation.\n\n- method=http://*<path>* \n\n  Use <path> for an HTTP installation.\n\n- method=nfs:*<path>* \n\n  Use <path> for an NFS installation.\n\n- netmask=*<nm>* \n\n  Netmask to use for a network installation.\n\n- nofallback \n\n  If GUI fails exit.\n\n- nofb \n\n  Do not load the VGA16 framebuffer required for doing text-mode installation in some languages.\n\n- nofirewire \n\n  Do not load support for firewire devices.\n\n- noipv6 \n\n  Disable IPv6 networking during installation.This option is not available during PXE installationsDuring installations from a PXE server, IPv6 networking might become active before anaconda processes the Kickstart file. If so, this option will have no effect during installation.\n\n- nomount \n\n  Don't automatically mount any installed Linux partitions in rescue mode.\n\n- nonet \n\n  Do not auto-probe network devices.\n\n- noparport \n\n  Do not attempt to load support for parallel ports.\n\n- nopass \n\n  Don't pass keyboard/mouse info to stage 2 installer, good for testing keyboard and mouse config screens in stage2 installer during network installs.\n\n- nopcmcia \n\n  Ignore PCMCIA controller in system.\n\n- noprobe \n\n  Do not attempt to detect hw, prompts user instead.\n\n- noshell \n\n  Do not put a shell on tty2 during install.\n\n- nostorage \n\n  Do not auto-probe storage devices (SCSI, IDE, RAID).\n\n- nousb \n\n  Do not load USB support (helps if install hangs early sometimes).\n\n- nousbstorage \n\n  Do not load usbstorage module in loader. May help with device ordering on SCSI systems.\n\n- rescue \n\n  Run rescue environment.\n\n- resolution=*<mode>* \n\n  Run installer in mode specified, '1024x768' for example.\n\n- serial \n\n  Turns on serial console support.\n\n- skipddc \n\n  Skips DDC probe of monitor, may help if it's hanging system.\n\n- syslog=*<host>*[:*<port>*] \n\n  Once installation is up and running, send log messages to the syslog process on *<host>*, and optionally, on port *<port>*. Requires the remote syslog process to accept connections (the -r option).\n\n- text \n\n  Force text mode install.\n\n- updates \n\n  Prompt for floppy containing updates (bug fixes).\n\n- updates=ftp://*<path>* \n\n  Image containing updates over FTP.\n\n- updates=http://*<path>* \n\n  Image containing updates over HTTP.\n\n- upgradeany \n\n  Don't require an /etc/redhat-release that matches the expected syntax to upgrade.\n\n- vnc \n\n  Enable vnc-based installation. You will need to connect to the machine using a vnc client application.\n\n- vncconnect=*<host>*[:*<port>*] \n\n  Once installation is up and running, connect to the vnc client named *<host>*, and optionally use port *<port>*.Requires 'vnc' option to be specified as well.\n\n- vncpassword=*<password>* \n\n  Enable a password for the vnc connection. This will prevent someone from inadvertently connecting to the vnc-based installation.Requires 'vnc' option to be specified as well.\n\n## \n\n##  \n\n","tags":["kickstart"]},{"title":"【web】NgTable params & settings","url":"/2018/09/06/【web】ng-table params & settings/","content":"\n### Default params：\n\n```javascript\nngTableDefaults.params.count = 5;    // 单页显示5 条数据，number\nngTableDefaults.params.filter = {name:'a'};    // [name: string]: any\nngTableDefaults.params.group = ;    //    string | Grouping\nngTableDefaults.params.page = 2;    // 从第2 页开始，number\nngTableDefaults.params.sorting = {name:'desc'};    // 使用表名为name的列降序排列\n```\n\n### Default settings：\n\n```javascript\nngTableDefaults.settings.$loading = true;    // 开启加载动画，boolean\nngTableDefaults.settings.counts = [5,10,20];    // 单页显示条目数组，number[]\nngTableDefaults.settings.dataOptions = {\n        applyFilter:true,    // 是否过滤，boolean\n        applyPaging:true,    // 是否分页，boolean\n        applySort:true    // 是否排序，boolean\n};\nngTableDefaults.settings.dataset = [];    // 数据源，T[]\nngTableDefaults.settings.debugMode = true;    // 开启调试，boolean\nngTableDefaults.settings.defaultSort = 'desc',    // 默认排序，asc 或desc，string\nngTableDefaults.settings.filterOptions = {\n        filterComparator:true,    // 如果为true，则精确查询（Exact）；如果为false，模糊查询（ Contains），boolean\n        filterDelay:0,    // 默认0，在应用过滤器之前等待用户停止键入的持续时间，number\n        filterDelayThreshold:10000,    // 托管内存数组被认为很小的元素数量。 默认为10000，number\n        filterFilterName:'filter',    // 实际执行过滤的名称，默认为filter，string\n        filterFn:function(data,fileter,filterComparator){    // 使用提供的此函数来执行过滤，而不是选择角度$filter\n            // data：数组 []\n            // fileter：[name: string]: any ，在数据行上声明的字段名称的映射以及相应的过滤器值\n            // filterComparator：true 或者false\n            retrun [''];    // 返回一个数组\n        },    \n        filterLayout:'stack'    // 在单个表标题列中呈现多个html模板时要使用的布局，\"stack\" | \"horizontal\"，string\n};\nngTableDefaults.settings.getData = function(params){\n    return;    // 返回promise\n};\nngTableDefaults.settings.getGroups = function(params){\n    return;    // 返回promise\n};\nngTableDefaults.settings.groupOptions = {\n        defaultSort:'asc',    // 默认排序，asc 或desc，string\n        isExpanded:true    // 是否展开,默认true，boolean\n};\nngTableDefaults.settings.interceptors = [{    // 在数据行显示在表中之前对getData函数的调用结果的拦截器集合，集合中后一个拦截器会去拦截前一个的返回值，最终返回最后一个拦截器的处理结果\n        response:function(data,params){\n            // data: TData\n            // params: NgTableParams<T>\n            return;    // 返回数组，TData    \n        },\n        responseError:function(reason,params){\n            // reason: any\n            // params: NgTableParams<T>\n            return;    // any    \n        }\n}];    \nngTableDefaults.settings.paginationMaxBlocks = 10;    // 分页显示的最多按钮块，number\nngTableDefaults.settings.paginationMinBlocks = 2;    // 分页显示的最少按钮块，number\nngTableDefaults.settings.sortingIndicator = 'string';    // html标记，用于在表头中显示排序指示符，string\nngTableDefaults.settings.total = 100;    // 数据总行数：100，number\n```\n\n### NgTableParams methods：\n\n```\nNgTableParams: \ncount : ƒ (count)\ndata:(10) [{…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, visibleColumnCount: 7]\nfilter : ƒ (filter)\ngeneratePagesArray : ƒ (currentPage, totalItems, pageSize, maxBlocks)\ngroup : ƒ (group, sortDirection)\nhasErrorState : ƒ ()\nhasFilter : ƒ ()\nhasFilterChanges : ƒ ()\nhasGroup : ƒ (group, sortDirection)\nisDataReloadRequired : ƒ ()\nisSortBy : ƒ (field, direction)\norderBy : ƒ ()\npage : ƒ (page)\nparameters : ƒ (newParameters, parseParamsFromUrl)\nreload : ƒ ()\nreloadPages : ƒ ()\nsettings : ƒ (newSettings)\nsorting : ƒ (sorting, direction)\ntotal : ƒ (total)\nurl : ƒ (asString)\n__proto__:Object\n```\n\n","tags":["web","ng-table"]},{"title":"【web】Array & Json 处理","url":"/2018/09/06/【web】Array & Json 处理/","content":"\n### JavaScript 数组操作\n\n##### 1. 创建\n\n```javascript\nvar arrayObj = new Array();　//创建一个数组\nvar arrayObj = new Array([size]);　//创建一个数组并指定长度，注意不是上限，是长度\nvar arrayObj = new Array([element0[, element1[, ...[, elementN]]]]);　//创建一个数组并赋值\n\n//要说明的是，虽然第二种方法创建数组指定了长度，但实际上所有情况下数组都是变长的，也就是说即使指定了长度为5，仍然可以将元素存储在规定长度以外的，注意：这时长度会随之改变\n```\n\n##### 2. 访问\n\n```javascript\nvar testGetArrValue=arrayObj[1]; //获取数组的元素值\narrayObj[1]= \"这是新值\"; //给数组元素赋予新的值\n```\n\n#####  3. 添加\n\n```javascript\narrayObj.push([item1 [item2 [. . . [itemN ]]]]);// 将一个或多个新元素添加到数组结尾，并返回数组新长度\narrayObj.unshift([item1 [item2 [. . . [itemN ]]]]);// 将一个或多个新元素添加到数组开始，数组中的元素自动后移，返回数组新长度\narrayObj.splice(insertPos,0,[item1[, item2[, . . . [,itemN]]]]);//将一个或多个新元素插入到数组的指定位置，插入位置的元素自动后移，返回\"\"\n```\n\n##### 4. 删除\n\n```javascript\narrayObj.pop(); //移除最后一个元素并返回该元素值\narrayObj.shift(); //移除最前一个元素并返回该元素值，数组中元素自动前移\narrayObj.splice(deletePos,deleteCount); //删除从指定位置deletePos开始的指定数量deleteCount的元素，数组形式返回所移除的元素\n```\n\n##### 5. 截取\n\n```javascript\narrayObj.slice(start, [end]); //以数组的形式返回数组的一部分，注意不包括 end 对应的元素，如果省略 end 将复制 start 之后的所有元素\n```\n\n##### 6. 合并\n\n```javascript\narrayObj.concat([item1[, item2[, . . . [,itemN]]]]); //将多个数组（也可以是字符串，或者是数组和字符串的混合）连接为一个数组，返回连接好的新的数组\n```\n\n##### 7. 拷贝\n\n```javascript\narrayObj.slice(0); //返回数组的拷贝数组，注意是一个新的数组，不是指向\narrayObj.concat(); //返回数组的拷贝数组，注意是一个新的数组，不是指向\n```\n\n##### 8. 排序\n\n```javascript\narrayObj.reverse(); //反转元素（最前的排到最后、最后的排到最前），返回数组地址\narrayObj.sort(); //对数组元素排序，返回数组地址\n```\n\n9. 字符串化\n\n```javascript\narrayObj.join(separator); //返回字符串，这个字符串将数组的每一个元素值连接在一起，中间用 separator 隔开\n```\n\n### jQuery 数组操作\n\n##### $.each()\n\n```javascript\n//$.each(array/object,function(index/key,value){})\n//退出 each 循环可使回调函数返回 false, 其它返回值将被忽略\n//The method returns its first argument, the object that was iterated.\n$.each([ 52, 97 ], function( index, value ) {\n  alert( index + \": \" + value );\n});\n//This produces two messages:\n// 0: 52 \n// 1: 97\n\n//If an object is used as the collection, the callback is passed a key-value pair each time:\nvar obj = {\n  \"flammable\": \"inflammable\",\n  \"duh\": \"no duh\"\n};\n$.each( obj, function( key, value ) {\n  alert( key + \": \" + value );\n});\n//Once again, this produces two messages:\n// flammable: inflammable \n// duh: no duh\n```\n\n##### $(selector).each() \n\n```html\n<!-- Suppose you have a simple unordered list on the page: -->\n<ul>\n  <li>foo</li>\n  <li>bar</li>\n</ul>\n```\n\n```javascript\n//$(selector).each(function(index,element){}) \n//You can select the list items and iterate across them:\n$( \"li\" ).each(function( index ) {\n  console.log( index + \": \" + $( this ).text() );\n});\n//A message is thus logged for each item in the list:\n// 0: foo \n// 1: bar\n\n//You can stop the loop from within the callback function by returning false.\n```\n\n##### $.map()\n\n```javascript\n//$.map(array/object,function(value,index/key){return;})\n//更新数组元素值,或根据原值扩展一个新的副本元素\n//Map the original array to a new one and add 4 to each value.\n$.map( [ 0, 1, 2 ], function( n ) {\n  return n + 4;\n});\n//Result: [4, 5, 6]\n```\n\n##### $(selector).map()\n\n```javascript\n//$(selector).map(function(index,domElement){return;})\n//The .map() method is particularly useful for getting or setting the value of a collection of elements. Consider a form with a set of checkboxes in it:\n<form method=\"post\" action=\"\">\n  <fieldset>\n    <div>\n      <label for=\"two\">2</label>\n      <input type=\"checkbox\" value=\"2\" id=\"two\" name=\"number[]\">\n    </div>\n    <div>\n      <label for=\"four\">4</label>\n      <input type=\"checkbox\" value=\"4\" id=\"four\" name=\"number[]\">\n    </div>\n    <div>\n      <label for=\"six\">6</label>\n      <input type=\"checkbox\" value=\"6\" id=\"six\" name=\"number[]\">\n    </div>\n    <div>\n      <label for=\"eight\">8</label>\n      <input type=\"checkbox\" value=\"8\" id=\"eight\" name=\"number[]\">\n    </div>\n  </fieldset>\n</form>\n\n//To get a comma-separated list of checkbox IDs:\n$( \":checkbox\" )\n  .map(function() {\n    return this.id;\n  })\n  .get()\n  .join();\n//The result of this call is the string, \"two,four,six,eight\".\n\n//Within the callback function, this refers to the current DOM element for each iteration. The function can return an individual data item or an array of data items to be inserted into the resulting set. If an array is returned, the elements inside the array are inserted into the set. If the function returns null or undefined, no element will be inserted.\n```\n\n##### $.inArray()\n\n```javascript\n//$.inArray(value,arrary)\n//确定第一个参数在数组中的位置, 从0开始计数，如果没有找到则返回 -1\n$.inArray( 5 + 5, [ \"8\", \"9\", \"10\", 10 + \"\" ] );\n//indexOf()返回字符串的首次出现位置\n```\n\n##### $.merge()\n\n```javascript\n//$.merge(firstArray,secondArray)\n//返回的结果会修改第一个数组的内容\n//Merges two arrays, altering the first argument.\n$.merge( [ 0, 1, 2 ], [ 2, 3, 4 ] )\n//Result: [ 0, 1, 2, 2, 3, 4 ]\n```\n\n##### $.grep()\n\n```javascript\n//$.grep(arrary,function(value,index){return boolean;},[invert])\n//$.grep() 函数使用指定的函数过滤数组中的元素，并返回过滤后的数组。\n//提示：源数组不会受到影响，过滤结果只反映在返回的结果数组中。\n//数组元素过滤，返回true 保留，返回false 删除；\n//第三个参数可选，默认为true，如果为false 表示结果取反\n//Filter an array of numbers to include only numbers bigger then zero.\n$.grep( [ 0, 1, 2 ], function( n, i ) {\n  return n > 0;\n});\n//Result: [ 1, 2 ]\n```\n\n##### $.unique()\n\n```javascript\n//$.unique(arrary)\n//过滤Jquery对象数组中重复的元素(内部实现为===)(不同版本不一样，不建议使用)\n//只处理删除DOM元素数组,而不能处理字符串或者数字数组.\n```\n\n#####  $.makeArray()\n\n```javascript\n//$.makeArray($(selector))\n//将类数组对象转换为数组对象, 类数组对象有 length 属性,其成员索引为0至 length-1\n//比如用getElementsByTagName获取的元素对象集合转换成数组对象\n```\n\n##### $(selector).toArray() \n\n```javascript\n//把jQuery集合中所有DOM元素恢复成一个数组\n//.toArray() returns all of the elements in the jQuery set:\nalert( $( \"li\" ).toArray() );\n//All of the matched DOM nodes are returned by this call, contained in a standard array:\n// [<li id=\"foo\">, <li id=\"bar\">]\n```\n\n \n\n### JSON 处理\n\n##### 1. 返回JSON数组 长度\n\n```javascript\nfunction getJsonLength(jsonData){\n    var jsonLength = 0;\n    for(var item in jsonData){\n        jsonLength++;\n    };\n    return jsonLength;\n};\n```\n\n##### 2. JSON 数组去重\n\n```javascript\nfunction uniqueArray(array, key){\n    var result = [array[0]];\n    for(var i = 1; i < array.length; i++){\n        var item = array[i];\n        var repeat = false;\n        for (var j = 0; j < result.length; j++) {\n            if (item[key] == result[j][key]) {\n                repeat = true;\n                break;\n            }\n        }\n        if (!repeat) {\n            result.push(item);\n        }\n    }\n    return result;\n}\n```\n\n\n\n ","tags":["web","javascript","jquery","json"]},{"title":"【nfs】NFS服务器搭建","url":"/2018/09/03/【nfs】nfs搭建流程/","content":"\n# NFS 服务器搭建\n\n## 1.下载\n```\nyum install nfs-utils nfs-utils-lib\nyum install portreserve            \n```\n\n## 2.开启服务\n```\n/etc/init.d/portreserve start\n```\n注意yum install portreserve实际下载的包名，这里要启动这个服务。\n\n```\n/etc/init.d/nfs start\nchkconfig --level 35 portreserve on\nchkconfig --level 35 nfs on\n```\n\n## 3.服务端设置\n```\nvi /etc/exports\n```\n文件中写入相应的信息如\n\n```\n/nfsshare 192.168.0.101(rw,sync,no_root_squash) 192.168.1.1(rw)\n```\n`/nfsshare` 是可以访问目录的绝对路径  \n`192.168.0.101`是访问者的ip  \n`rw`访问这可读可写 `ro` read only \n`sync` 同步模式    \n`async` 非同步  \n`no_root_squash` root 用户登录有最高权限  \n`root_squash`root用户没有权限，匿名登录  \n`all_squash`所有用户匿名登录\n\n同一目录对多个主机开放，可以连续写下去。可以用通配符，但是不能用在IP网段上。  \n修改文件后用`exportfs -ra`重新导出\n\n\n## 4.客户端设置\n显示服务端有哪些贡献目录\n```\nshowmount -e <服务端ip>\n```\n客户端挂载那个目录\n\n```\nmount -r nfs 192.168.11.124:/nfsshare /mnt/nfsshare\n```\n\n永久挂载\n```\nvi /etc/fstab\n\n192.168.11.124：/nfsshare /mnt nfs defaults 0 0\n```\n\n## 5.一些指令\n\nshowmount -e 显示本地可贡献目录  \nshowmount -e <server ip> 显示远程可共享目录  \nexportfs -v 显示本地共享目录和选项  \nexportfs -a 显示所有共享目录\n\n\n参考<https://www.tecmint.com/how-to-setup-nfs-server-in-linux/>  \n需要更多信息请阅读<http://cn.linux.vbird.org/linux_server/0330nfs.php#nfsserver_need>\n","tags":["nfs"]},{"title":"【web】AngularJs错误集锦","url":"/2018/08/29/【web】angularjs 错误集锦/","content":"\n错误信息：\n\n```javascript\n// IE10 及以上\nTypeError: 无法获取未定义或 null 引用的属性“pager”\n   at Anonymous function (http://localhost:9090/AngularProject/1/resources/files/list/component.js?bust=1535512101027:19:5)\n   at processQueue (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:17169:13)\n   at Anonymous function (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:17217:27)\n   at Scope.prototype.$digest (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:18352:15)\n   at Scope.prototype.$apply (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:18649:13)\n   at done (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12627:36)\n   at completeRequest (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12871:7)\n   at requestLoaded (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12788:9) Possibly unhandled rejection: {\"description\":\"无法获取未定义或 null 引用的属性“pager”\",\"number\":-2146823281,\"stack\":\"TypeError: 无法获取未定义或 null 引用的属性“pager”\\n   at Anonymous function (http://localhost:9090/AngularProject/1/resources/files/list/component.js?bust=1535512101027:19:5)\\n   at processQueue (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:17169:13)\\n   at Anonymous function (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:17217:27)\\n   at Scope.prototype.$digest (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:18352:15)\\n   at Scope.prototype.$apply (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:18649:13)\\n   at done (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12627:36)\\n   at completeRequest (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12871:7)\\n   at requestLoaded (http://localhost:9090/AngularProject/1/resources/js/angular.js?bust=1535512101027:12788:9)\"}\n\n// IE9\nError: 拒绝访问。\n Possibly unhandled rejection: {\"message\":\"拒绝访问。\\r\\n\",\"description\":\"拒绝访问。\\r\\n\",\"number\":-2147024891,\"resource\":{}}\n```\n\n解决方案：\n\n```javascript\napp.config(['$qProvider', function ($qProvider) {\n    $qProvider.errorOnUnhandledRejections(false);\n}]);\n```\n\n","tags":["web","angularjs"]},{"title":"【web】四种浏览器内核","url":"/2018/08/26/【web】四种浏览器内核/","content":"\n“浏览器内核”主要指渲染引擎(Rendering Engine)，负责解析网页语法(如HTML、JavaScript)并渲染、展示网页。\n\n因此，所谓的浏览器内核通常也就是指浏览器所采用的渲染引擎，渲染引擎决定了浏览器如何显示网页的内容以及页面的格式信息。\n\n不同的浏览器内核对网页编写语法的解析也有所不同，因此同一网页在不同的内核浏览器里的渲染、展示效果也可能不同。\n\n浏览器内核种类繁多，商用的加上非商业的免费内核，大约会超过10款，我们今天重点看一下目前主流的四大浏览器内核Trident、Gecko、WebKit以及Presto。\n\n了解网页浏览器四种主要内核：\n\n#### 一、Trident内核（代表：Internet Explorer）\n\n说起Trident，很多人都会感到陌生，但提起IE(Internet Explorer)则无人不知无人不晓，由于其被包含在全世界使用率最高的操作系统Windows中，得到了极高的市场占有率，所以我们又经常称其为IE内核。\n\nTrident(又称为MSHTML)，是微软开发的一种排版引擎。它在1997年10月与IE4一起诞生，一直在被不断地更新和完善。\n\n而且除IE外，许多产品都在使用Trident核心，比如Windows的Help程序、RealPlayer、Windows Media Player、Windows Live Messenger、Outlook Express等等都使用了Trident技术。\n\nTrident实际上是一款开放的内核，Trident引擎被设计成一个软件模块，使得其他软件开发人员很容易将网页浏览功能加到他们自行开发的应用程序里，\n\n其接口内核设计相当成熟，因此涌现出许多采用IE内核而非IE的浏览器，但是Trident只能用于Windows平台。\n\n使用Trient渲染引擎的浏览器包括：IE、傲游、世界之窗浏览器、Avant、腾讯TT、Sleipnir、GOSURF、GreenBrowser和KKman等。\n\n#### 二、Gecko内核（代表：Mozilla Firefox）\n\nGecko是开放源代码、以C++编写的网页排版引擎，目前被Mozilla家族网页浏览器以及Netscape 6以后版本浏览器所使用。\n\n这款软件原本是由网景通讯公司开发的，现在则由Mozilla基金会维护。由于Gecko的特点是代码完全公开，因此，其可开发程度很高，全世界的程序员都可以为其编写代码，增加功能。\n\n因为这是个开源内核，因此受到许多人的青睐，采用Gecko内核的浏览器也很多，这也是Gecko内核虽然年轻但市场占有率能够迅速提高的重要原因。\n\nGecko排版引擎提供了一个丰富的程序界面以供与互联网相关的应用程序使用，例如网页浏览器、HTML编辑器、客户端/服务器等。\n\n虽然最初的主要对象是Mozilla的衍生产品，如Netscape和Mozilla Firefox，但是现在已有很多其他软件利用这个排版引擎。此外Gecko也是一个跨平台内核，可以在Windows、BSD、Linux和Mac OS X中使用。\n\n正在和曾经使用Gecko引擎的浏览器有Firefox、网景6～9、SeaMonkey、Camino、Mozilla、Flock、Galeon、K-Meleon、Minimo、Sleipni、Songbird、XeroBank。Google Gadget引擎采用的就是Gecko浏览器引擎。\n\n#### 三、WebKit内核（代表：Safari、Chrome）\n\nWebKit 是一个开放源代码的浏览器引擎(Web Browser Engine)，WebKit最初的代码来自KDE的KHTML和KJS(它们均为开放源代码，都是自由软件，在GPL协议下授权)。\n\n所以WebKit也是自由软件，同时开放源代码。它的特点在于源码结构清晰、渲染速度极快。主要代表产品有Safari和Google的浏览器Chrome。\n\nWebKit内核在手机上的应用也十分广泛，例如Google的Android平台浏览器、Apple的iPhone浏览器、Nokia S60浏览器等所使用的浏览器内核引擎，都是基于WebKit引擎的。\n\nWebKit内核也广泛应用于Widget引擎产品，包括中国移动的BAE、Apple的Dashboard以及Nokia WRT在内采用的均为WebKit引擎。\n\n#### 四、Presto内核（代表：Opera）\n\nPresto是由Opera Software开发的浏览器排版引擎，供Opera 7.0及以上使用。\n\n它取代了旧版Opera 4至6版本使用的Elektra排版引擎，包括加入动态功能，例如网页或其部分可随着DOM及Script语法的事件而重新排版。\n\nPresto的特点就是渲染速度的优化达到了极致，它是目前公认的网页浏览速度最快的浏览器内核，然而代价是牺牲了网页的兼容性。\n\nPresto实际上是一个动态内核，与Trident、Gecko等内核的最大区别就在于脚本处理上，Presto有着天生的优势，页面的全部或者部分都能够在回应脚本事件时等情况下被重新解析。\n\n此外该内核在执行JavaScript时有着最快的速度，根据同等条件下的测试，Presto内核执行同等JavaScript所需的时间仅有Trident和Gecko内核的约1/3。\n\nPresto是商业引擎，了Opera以外较少浏览器使用Presto内核，这在一定程度上限制了Presto的发展。\n\n","tags":["web"]},{"title":"【web】angularjs弹窗（ui-bootstrap+directive+ocLazyLoad）","url":"/2018/08/16/【web】angularjs 弹窗（1）/","content":"\n由于angularjs 项目中频繁使用弹窗，完全自行编写耗时耗力，所以结合ui-boostrap 中的modal 模块来实现功能\n\n1. 创建一个公共弹窗服务，在使用的组件中依赖注入后调用弹窗方法\n2. 在最外层组件（其余组件的父组件）注入弹窗服务，并定义调用弹窗的方法；其余组件require 此父组件，调用父组件中的方法\n3. 自定义一个弹窗指令，设置仅属性调用（restrict: 'A'），在主模块注入后，即可全局调用\n\n经过一步步实践和优化后，尽量减少中间环节，最终确认使用自定义指令来实现弹窗功能。\n\n##### 静态资源引入：\n\n```html\n<link href=\"css/main.css\" rel=\"stylesheet\" />\n<link href=\"plugins/bootstrap/css/bootstrap.css\" rel=\"stylesheet\" />\n\n<script src=\"js/ocLazyLoad.js\"></script>\n<script src=\"js/drag.js\"></script>\n<script src=\"js/angular.js\"></script>\n<script src=\"js/ui-bootstrap-tpls\"></script>\n```\n\n##### 自定义弹窗指令：\n\n```javascript\nangular.module('common', [\n    'ui.bootstrap',\n    'oc.lazyLoad'\n])\n.directive('uibModal',['$uibModal','$ocLazyLoad',function($uibModal,$ocLazyLoad){\n    return {\n        restrict: 'A',\n        scope: {\n            uibModal: '='\n        },\n        link: function(scope,element,attr){\n            element.on('click', function() {\n                //动态加载组件,在组件加载完成后打开弹窗\n                $ocLazyLoad\n                    .load(scope.uibModal.path)\n                    .then(function(){\n                        //弹窗打开方法\n                        $uibModal.open({\n                            animation:false,\n                            size:scope.uibModal.size?scope.uibModal.size:'',\n                            backdrop:'static',\n                            component: scope.uibModal.component,\n                            resolve:{\n                                //获取所点击元素内容作为标题\n                                title:function(){\n                                    return element.context.innerHTML;\n                                },\n                                //传入组件的数据\n                                data:function(){\n                                    return scope.uibModal.data;\n                                }\n                            }\n                            }).rendered.then(function(){\n                                //弹窗显示出来后，绑定拖拽功能\n                                $('.modal-content').drag(function(ev,dd){\n                                    $(this).css({\n                                        top: dd.offsetY,\n                                        left: dd.offsetX\n                                    });\n                                },{\n                                    handle:'.modal-header',\n                                    relative:true\n                                });\n                            });\n                });\n            });\n        }\n    }\n}]);\n```\n\n##### 参数解释：\n\n- path：组件存放路径，按需加载\n- component：组件名\n- size：弹窗尺寸，默认，sm，lg\n- data：传入组件的数据，Object\n\n##### 组件传值及事件绑定：\n\n```javascript\nangular.module('users').component('usersForm',{\n    templateUrl:'users/form/template.html',\n    controller:[function(){\n        var $ctrl = this;\n        $ctrl.$onInit = function(){\n            console.log(this.resolve);\n        };\n\n        $ctrl.ok = function () {\n          $ctrl.close({$value: $ctrl.resolve.title});\n        };\n\n        $ctrl.cancel = function () {\n          $ctrl.dismiss({$value: 'cancel'});\n        };\n    }],\n    //close 和dismiss 被绑定自$uibModalInstance\n    bindings:{\n        resolve:'<',\n        close: '&',\n        dismiss: '&'\n    }\n})\n```\n\n##### 页面调用：\n\n```html\n<a uib-modal=\"{path:'users/detail/component',component:'usersDetail',data:user}\">查看详情</a>\n\n<button type=\"button\" uib-modal=\"{path:'users/form/component',component:'usersForm'}\">新建群组</button>\n```\n\n\n\n","tags":["web","angularjs","ui-bootstrap","ocLazyLoad"]},{"title":"【shell】Shell基础巩固（1）","url":"/2018/08/01/【shell】Shell基础巩固（1）/","content":"\n### 算术运算符\n\n下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20：\n\n| 运算符 | 说明                                          | 举例                          |\n| ------ | --------------------------------------------- | ----------------------------- |\n| +      | 加法                                          | `expr $a + $b` 结果为 30。    |\n| -      | 减法                                          | `expr $a - $b` 结果为 -10。   |\n| *      | 乘法                                          | `expr $a \\* $b` 结果为  200。 |\n| /      | 除法                                          | `expr $b / $a` 结果为 2。     |\n| %      | 取余                                          | `expr $b % $a` 结果为 0。     |\n| =      | 赋值                                          | a=$b 将把变量 b 的值赋给 a。  |\n| ==     | 相等。用于比较两个数字，相同则返回 true。     | [ $a == $b ] 返回 false。     |\n| !=     | 不相等。用于比较两个数字，不相同则返回 true。 | [ $a != $b ] 返回 true。      |\n\n**注意：**条件表达式要放在方括号之间，并且要有空格，例如: **[$a==$b]** 是错误的，必须写成 **[ $a == $b ]**。\n\n### 关系运算符\n\n关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n\n下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20：\n\n| 运算符 | 说明                                                  | 举例                       |\n| ------ | ----------------------------------------------------- | -------------------------- |\n| -eq    | 检测两个数是否相等，相等返回 true。                   | [ $a -eq $b ] 返回 false。 |\n| -ne    | 检测两个数是否不相等，不相等返回 true。               | [ $a -ne $b ] 返回 true。  |\n| -gt    | 检测左边的数是否大于右边的，如果是，则返回 true。     | [ $a -gt $b ] 返回 false。 |\n| -lt    | 检测左边的数是否小于右边的，如果是，则返回 true。     | [ $a -lt $b ] 返回 true。  |\n| -ge    | 检测左边的数是否大于等于右边的，如果是，则返回 true。 | [ $a -ge $b ] 返回 false。 |\n| -le    | 检测左边的数是否小于等于右边的，如果是，则返回 true。 | [ $a -le $b ] 返回 true。  |\n\n### 布尔运算符\n\n下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20：\n\n| 运算符 | 说明                                                | 举例                                     |\n| ------ | --------------------------------------------------- | ---------------------------------------- |\n| !      | 非运算，表达式为 true 则返回 false，否则返回 true。 | [ ! false ] 返回 true。                  |\n| -o     | 或运算，有一个表达式为 true 则返回 true。           | [ $a -lt 20 -o $b -gt 100 ] 返回 true。  |\n| -a     | 与运算，两个表达式都为 true 才返回 true。           | [ $a -lt 20 -a $b -gt 100 ] 返回 false。 |\n\n### 逻辑运算符\n\n以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20:\n\n```shell\n运算符\t\t说明\t\t举例\n&&\t\t逻辑的\tAND\t\t[[ $a -lt 100 && $b -gt 100 ]] 返回 false\n||\t\t逻辑的\tOR\t\t[[ $a -lt 100 || $b -gt 100 ]] 返回 true\n```\n\n### 字符串运算符\n\n下表列出了常用的字符串运算符，假定变量 a 为 \"abc\"，变量 b 为 \"efg\"：\n\n| 运算符 | 说明                                      | 举例                     |\n| ------ | ----------------------------------------- | ------------------------ |\n| =      | 检测两个字符串是否相等，相等返回 true。   | [ $a = $b ] 返回 false。 |\n| !=     | 检测两个字符串是否相等，不相等返回 true。 | [ $a != $b ] 返回 true。 |\n| -z     | 检测字符串长度是否为0，为0返回 true。     | [ -z $a ] 返回 false。   |\n| -n     | 检测字符串长度是否为0，不为0返回 true。   | [ -n \"$a\" ] 返回 true。  |\n| $      | 检测字符串是否为空，不为空返回 true。     | [ $a ] 返回 true。       |\n\n## 文件测试运算符\n\n文件测试运算符用于检测 Unix 文件的各种属性。\n\n属性检测描述如下：\n\n| 操作符  | 说明                                                         | 举例                      |\n| ------- | ------------------------------------------------------------ | ------------------------- |\n| -b file | 检测文件是否是块设备文件，如果是，则返回 true。              | [ -b $file ] 返回 false。 |\n| -c file | 检测文件是否是字符设备文件，如果是，则返回 true。            | [ -c $file ] 返回 false。 |\n| -d file | 检测文件是否是目录，如果是，则返回 true。                    | [ -d $file ] 返回 false。 |\n| -f file | 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 | [ -f $file ] 返回 true。  |\n| -g file | 检测文件是否设置了 SGID 位，如果是，则返回 true。            | [ -g $file ] 返回 false。 |\n| -k file | 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。  | [ -k $file ] 返回 false。 |\n| -p file | 检测文件是否是有名管道，如果是，则返回 true。                | [ -p $file ] 返回 false。 |\n| -u file | 检测文件是否设置了 SUID 位，如果是，则返回 true。            | [ -u $file ] 返回 false。 |\n| -r file | 检测文件是否可读，如果是，则返回 true。                      | [ -r $file ] 返回 true。  |\n| -w file | 检测文件是否可写，如果是，则返回 true。                      | [ -w $file ] 返回 true。  |\n| -x file | 检测文件是否可执行，如果是，则返回 true。                    | [ -x $file ] 返回 true。  |\n| -s file | 检测文件是否为空（文件大小是否大于0），不为空返回 true。     | [ -s $file ] 返回 true。  |\n| -e file | 检测文件（包括目录）是否存在，如果是，则返回 true。          | [ -e $file ] 返回 true。  |\n\n","tags":["shell"]},{"title":"【python】Python简单web服务器","url":"/2018/07/08/【python】Python简单web服务器/","content":"\n### Python 简易WEB服务：\n\n利用Python自带的包可以建立简单的web服务器。在DOS里cd到准备做服务器根目录的路径下，输入命令：\n\n```shell\npython -m Web服务器模块 [端口号，默认8000]\n```\n\n例如：\n\n```\npython -m SimpleHTTPServer 8080\n```\n\n然后就可以在浏览器中输入 \"[http://localhost](http://localhost/):端口号/路径\" 来访问服务器资源。\n\n例如：\n\n<http://localhost:8080/index.htm>（当然index.htm文件得自己创建）\n\n其他机器也可以通过服务器的IP地址来访问。\n\n\n\n**这里的“Web服务器模块”有如下三种：**\n\n- BaseHTTPServer: 提供基本的Web服务和处理器类，分别是HTTPServer和BaseHTTPRequestHandler。\n- SimpleHTTPServer: 包含执行GET和HEAD请求的SimpleHTTPRequestHandler类。\n- CGIHTTPServer: 包含处理POST请求和执行CGIHTTPRequestHandler类。","tags":["python"]},{"title":"【centos】CentOS免密登录","url":"/2018/06/12/【centos】CentOS免密登录/","content":"\n### CentOS免密登录\n\n```shell\n#!/bin/bash\n\nhost=$1\n\nssh-keygen -t rsa -P ''\nssh-copy-id -i ~/.ssh/id_rsa.pub ${host}\n#scp /root/.ssh/id_rsa.pub root@${host}:/root/.ssh/authorized_keys\nchmod 600 /root/.ssh/authorized_keys\n```\n\n","tags":["centos"]},{"title":"【centos】CentOS7-mkisofs命令","url":"/2018/06/09/【centos】CentOS7-mkisofs命令/","content":"\n**mkisofs命令**用来将指定的目录与文件做成ISO 9660格式的映像文件，以供刻录光盘。\n\n### 语法\n\nmkisofs(选项)(参数)\n\n### 选项\n\n- -a或--all：mkisofs通常不处理备份文件。使用此参数可以把备份文件加到映像文件中；\n- -A<应用程序[id](http://man.linuxde.net/id)>或-appid<应用程序ID>：指定光盘的应用程序ID；\n- -abstract<摘要文件>：指定摘要文件的文件名；\n- -b<开机映像文件>或-eltorito-boot<开机映像文件>：指定在制作可开机光盘时所需的开机映像文件；\n- -biblio<ISBN文件>：指定ISBN文件的文件名，ISBN文件位于光盘根目录下，记录光盘的ISBN；\n- -c<开机文件名称>：制作可开机光盘时，mkisofs会将开机映像文件中的全-eltorito-catalog<开机文件名称>全部内容作成一个文件；\n- -C<盘区编号，盘区编号>：将许多节区合成一个映像文件时，必须使用此参数；\n- -copyright<版权信息文件>：指定版权信息文件的文件名；\n- -d或-omit-period：省略文件后的句号；\n- -D或-disable-deep-relocation：ISO 9660最多只能处理8层的目录，超过8层的部分，RRIP会自动将它们设置成ISO 9660兼容的格式。使用-D参数可关闭此功能；\n- -f或-follow-links：忽略符号连接；\n- -h：显示帮助；\n- -hide<目录或文件名>：使指定的目录或文件在ISO 9660或Rock RidgeExtensions的系统中隐藏；\n- -hide-joliet<目录或文件名>：使指定的目录或文件在Joliet系统中隐藏；\n- -J或-joliet：使用Joliet格式的目录与文件名称；\n- -l或-full-iso9660-filenames：使用ISO 9660 32字符长度的文件名；\n- -L或-allow-leading-dots：允许文件名的第一个字符为句号；\n- -log-[file](http://man.linuxde.net/file)<记录文件>：在执行过程中若有错误信息，预设会显示在屏幕上；\n- -m<目录或文件名>或-exclude<目录或文件名>：指定的目录或文件名将不会房入映像文件中；\n- -M<映像文件>或-prev-session<映像文件>：与指定的映像文件合并；\n- -N或-omit-version-number：省略ISO 9660文件中的版本信息；\n- -o<映像文件>或-output<映像文件>：指定映像文件的名称；\n- -p<数据处理人>或-preparer<数据处理人>：记录光盘的数据处理人；\n- -print-size：显示预估的文件系统大小；\n- -quiet：执行时不显示任何信息；\n- -r或-rational-rock：使用Rock Ridge Extensions，并开放全部文件的读取权限；\n- -R或-rock：使用Rock Ridge Extensions；\n- -sysid<系统ID>：指定光盘的系统ID；\n- -T或-translation-table：建立文件名的转换表，适用于不支持Rock Ridge Extensions的系统上；\n- -v或-verbose：执行时显示详细的信息；\n- -V<光盘ID>或-volid<光盘ID>：指定光盘的卷册集ID；\n- -volset-size<光盘总数>：指定卷册集所包含的光盘张数；\n- -volset-seqno<卷册序号>：指定光盘片在卷册集中的编号；\n- -x<目录>：指定的目录将不会放入映像文件中；\n- -z：建立通透性压缩文件的SUSP记录，此记录目前只在Alpha机器上的Linux有效。\n\n### 参数\n\n路径：需要添加到映像文件中的路径。\n\n### 实例\n\nlinux中用mkisofs命令把文件制作成ISO步骤：\n\n#### 把NFS服务器上的目录挂载到本地/mnt/nfs/的目录：\n\nmount -t nfs 10.0.2.2:/linuxos/rhel4.0_update3/ /mnt/nfs/\n\n#### 把已挂载的文件复制到本地：\n\ncp -a /mnt/NFS/* /root/De cp -a /mnt/nfs/* /root/Desktop/rhel4.0/&sktop/rhel4.0/&\n\n#### 查找boot.cat文件并删除掉：\n\nfind iso/ -name boot.cat | xargs rm\n\n#### 查找TRANS.TBL文件并删除掉：\n\nfind iso/ -name TRANS.TBL -exec rm {} \\;\n\n#### 复制本地的所需文件到指定目录：\n\ncp /usr/share/comps/i386/.discinfo iso/\n\n#### 把指定目录下的所有文件制作成ISO文件：\n\nmkisofs -r -V \"CentOS 7 x86_64\" -b isolinux/isolinux.bin -c isolinux/boot.cat -cache-inodes -J -l -no-emul-boot -boot-load-size 4 -boot-info-table -o /InfoShare-3.0.0.iso ./iso/\n\n","tags":["centos","centos7","mkisofs"]},{"title":"【python】SQLAlchemy-入门模板","url":"/2018/05/04/【python】SQLAlchemy-基础操作/","content":"\n### SQLAlchemy-入门模板\n\n```python\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\n# DB_CONNECT_STRING 就是连接数据库的路径。“mysql+mysqldb”指定了使用 MySQL-Python 来连接\nDB_CONNECT_STRING = 'mysql+mysqldb://root:mysql@localhost/test?charset=utf8'\n# echo 参数为 True 时，会显示每条执行的 SQL 语句，生产环境下可关闭\nengine = create_engine(DB_CONNECT_STRING, echo=True)\nDB_Session = sessionmaker(bind=engine)\nsession = DB_Session()\n\n\nfrom sqlalchemy import Column\nfrom sqlalchemy.types import CHAR, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBaseModel = declarative_base()\ndef init_db():\n    BaseModel.metadata.create_all(engine)\ndef drop_db():\n    BaseModel.metadata.drop_all(engine)\n\nclass User(BaseModel):\n    __tablename__ = 'user'\n    id = Column(Integer, primary_key=True)\n    name = Column(CHAR(30)) # or Column(String(30))\n\ninit_db()\n\n```\n\n\n\n### SQLAlchemy-CRUD基础\n\n```python\n\n\nfrom sqlalchemy import func, or_, not_\n\nuser = User(name='a')\nsession.add(user)\nuser = User(name='b')\nsession.add(user)\nuser = User(name='a')\nsession.add(user)\nuser = User()\nsession.add(user)\nsession.commit()\nquery = session.query(User)\nprint query # 显示SQL 语句\nprint query.statement # 同上\nfor user in query: # 遍历时查询\n    print user.name\nprint query.all() # 返回的是一个类似列表的对象\nprint query.first().name # 记录不存在时，first() 会返回 None\n# print query.one().name # 不存在，或有多行记录时会抛出异常\nprint query.filter(User.id == 2).first().name\nprint query.get(2).name # 以主键获取，等效于上句\nprint query.filter('id = 2').first().name # 支持字符串\nquery2 = session.query(User.name)\nprint query2.all() # 每行是个元组\nprint query2.limit(1).all() # 最多返回 1 条记录\nprint query2.offset(1).all() # 从第 2 条记录开始返回\nprint query2.order_by(User.name).all()\nprint query2.order_by('name').all()\nprint query2.order_by(User.name.desc()).all()\nprint query2.order_by('name desc').all()\nprint session.query(User.id).order_by(User.name.desc(), User.id).all()\nprint query2.filter(User.id == 1).scalar() # 如果有记录，返回第一条记录的第一个元素\nprint session.query('id').select_from(User).filter('id = 1').scalar()\nprint query2.filter(User.id > 1, User.name != 'a').scalar() # and\nquery3 = query2.filter(User.id > 1) # 多次拼接的 filter 也是 and\nquery3 = query3.filter(User.name != 'a')\nprint query3.scalar()\nprint query2.filter(or_(User.id == 1, User.id == 2)).all() # or\nprint query2.filter(User.id.in_((1, 2))).all() # in\nquery4 = session.query(User.id)\nprint query4.filter(User.name == None).scalar()\nprint query4.filter('name is null').scalar()\nprint query4.filter(not_(User.name == None)).all() # not\nprint query4.filter(User.name != None).all()\nprint query4.count()\nprint session.query(func.count('*')).select_from(User).scalar()\nprint session.query(func.count('1')).select_from(User).scalar()\nprint session.query(func.count(User.id)).scalar()\nprint session.query(func.count('*')).filter(User.id > 0).scalar() # filter() 中包含 User，因此不需要指定表\nprint session.query(func.count('*')).filter(User.name == 'a').limit(1).scalar() == 1 # 可以用 limit() 限制 count() 的返回数\nprint session.query(func.sum(User.id)).scalar()\nprint session.query(func.now()).scalar() # func 后可以跟任意函数名，只要该数据库支持\nprint session.query(func.current_timestamp()).scalar()\nprint session.query(func.md5(User.name)).filter(User.id == 1).scalar()\nquery.filter(User.id == 1).update({User.name: 'c'})\nuser = query.get(1)\nprint user.name\nuser.name = 'd'\nsession.flush() # 写数据库，但并不提交\nprint query.get(1).name\nsession.delete(user)\nsession.flush()\nprint query.get(1)\nsession.rollback()\nprint query.get(1).name\nquery.filter(User.id == 1).delete()\nsession.commit()\nprint query.get(1)\n\n```\n\n\n\n### SQLAlchemy-非ORM操作\n\n#### 创建表格，初始化数据库\n\n```\n>>> users_table = Table('users', metadata,\n...     Column('id', Integer, primary_key=True),\n...     Column('name', String(40)),\n...     Column('email', String(120)))\n>>>\n>>> users_table.create()\n2014-01-09 10:03:32,436 INFO sqlalchemy.engine.base.Engine\nCREATE TABLE users (\n    id INTEGER NOT NULL,\n    name VARCHAR(40),\n    email VARCHAR(120),\n    PRIMARY KEY (id)\n)       \n2014-01-09 10:03:32,436 INFO sqlalchemy.engine.base.Engine ()\n2014-01-09 10:03:32,575 INFO sqlalchemy.engine.base.Engine COMMIT\n```\n\n##### 基本操作，插入\n\n如果已经table表已经存在， 第二次运行就不许要 create了， 使用 autoload 设置\n\n```\n>>> from sqlalchemy import *\n>>> from sqlalchemy.orm import *\n>>> engine = create_engine('sqlite:///./sqlalchemy.db', echo=True)\n>>> metadata = MetaData(engine)\n>>> users_table = Table('users', metadata, autoload=True)\n2014-01-09 10:20:01,580 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"users\")\n2014-01-09 10:20:01,581 INFO sqlalchemy.engine.base.Engine ()\n2014-01-09 10:20:01,582 INFO sqlalchemy.engine.base.Engine PRAGMA foreign_key_list(\"users\")\n2014-01-09 10:20:01,583 INFO sqlalchemy.engine.base.Engine ()\n2014-01-09 10:20:01,583 INFO sqlalchemy.engine.base.Engine PRAGMA index_list(\"users\")\n2014-01-09 10:20:01,583 INFO sqlalchemy.engine.base.Engine ()\n>>> users_table\nTable('users', MetaData(bind=Engine(sqlite:///./sqlalchemy.db)), Column('id', INTEGER(), table=<users>, primary_key=True, nullable=False), Column('name', VARCHAR(length=40), table=<users>), Column('email', VARCHAR(length=120), table=<users>), schema=None)\n>>>\n```\n\n","tags":["python","sqlalchemy"]},{"title":"【python】Selenium框架简单实践","url":"/2018/04/02/【python】Selenium框架简单实践/","content":"\n### selenium+Python（一）基本操作\n\n```python\n#!/usr/bin/python\n# -*- coding: utf8-*-\n\n\n# （一）首先是文件开头上要写\nfrom selenium import webdriver      #引入selenium模块。\nfrom [selenium.webdriver.common.keys](http://selenium.webdriver.common.keys/) import Keys  #模拟键盘输入。\nimport random,time  #经常要用到，一个是产生随机数，一个是时间操作的功能\n\n\n#（二）最简单的一段功能：\nbrowser = webdriver.Firefox()   #启动chrome浏览器\ntime.sleep(3)  #停顿3秒\nbrowser.maximize_window() #浏览器窗口最大化\n#OutputLogin = Login(browser,username, password) #登录网页的函数，后续讲解\ntime.sleep(int(random.uniform(1, 10)))#随机产生一个1到9秒的随机整数，然后等待这个时间\nbrowser.quit() #退出浏览器\n\n\n#（三）定义一个登录系统的函数\ndef Login(browser,username, password): #要有冒号\n    browser.get('网页的URL')  #浏览器登录网页的URL\n    time.sleep(3)\n    try:\n        # find user login input box\n        elem_user=browser.find_element_by_id(\"username\")\n        #这个是通过find_element_by_id函数来寻找定位网页上的id为username的控件\n        elem_user.clear()\n        elem_user.send_keys(username)\n        #然后向这个控件发送username的值\n        time.sleep(1)\n        # find pwd input box\n        elem_pwd=browser.find_element_by_id(\"password\")\n        elem_pwd.clear()\n        elem_pwd.send_keys(password)\n        time.sleep(1)\n        # enter RETURN in pwd box to activate\n        elem_pwd.send_keys(Keys.RETURN)\n        #然后向这个控件发送回车键，注意，如果是键盘上的回车，SHIFT，CONTROL键之类的，要用Keys.控制键的名称作为输入。\n        return username + \"  login successfully \\n\"\n    except:\n        return username + \"  login failed \\n\"\n        pass\n```\n\n### selenium+Python（二）定位元素\n\n自动化测试中常用的功能是通过各种元素，例如id，class，xpath，css等内容来寻找定位元素，而且不光可以定位一个元素，还可以定位一队元素，然后逐个操作。\n\n```python\n#定义一个定位操作单个元素的函数\ndef Signup_Click(browser):\n    input3 = browser.find_element_by_class_name(\"checkbtn\")\n    try:\n        input3.click()\n        return \"Signup successfully \\n\"\n    except:\n        return \"Signup failed \\n\"\n        pass\n\n#定义一个定位操作多个元素的函数\ndef Love_Clicks(browser,k):\n    inputs2 = browser.find_elements_by_class_name(\"love\")\n    #注意，是elements，不是element，复数形式\n    for input2 in inputs2:\n        try:\n            input2.click()\n        except:\n            pass\n    return str(i)+\" Love successfully \\n\"\n```\n\n### selenium+Python（三）键盘和鼠标操作\n\nPython也可以模拟鼠标和键盘的操作，不过要注意的是键盘带来的屏幕游标位置的挪动和鼠标在屏幕上的挪动位置，两个是不同的。\n\n```python\n#首先要在文件头引入\nfrom [selenium.webdriver.common.action_chains](http://selenium.webdriver.common.action_chains/) import ActionChains\n\n#定义一个函数\ndef Transfer_Clicks(browser):\n    browser.execute_script(\"window.scrollBy(0,-document.body.scrollHeight)\",\"\")\n    #这个是执行一段Javascript函数，将网页滚到到网页顶部。\n        try:\n            inputs1 = browser.find_elements_by_class_name(\"feedAttr_transfer\")\n            for input1 in inputs1:\n                try:\n                    ActionChains(browser).click(input1).perform()\n                    #模拟鼠标点击控件input1，此时的鼠标位置在input1处\n                    browser.execute_script(\"window.scrollBy(0,200)\",\"\")\n                    #向下滚动200个像素，鼠标位置也跟着变了\n                    ActionChains(browser).move_by_offset(0,-80).perform()\n                    #向上移动鼠标80个像素，水平方向不同\n                    ActionChains(browser).click().perform()\n                    #鼠标左键点击\n                    ActionChains(browser).key_down(Keys.TAB).perform()\n                    #模拟tab键的输入\n                    ActionChains(browser).send_keys(Keys.ENTER).perform()\n                    #模拟输入ENTER键\n                except:\n                    pass\n        except:\n            pass\n        return \"Transfer successfully \\n\"\n```\n\n### 杰云测试快捷登陆\n\n```python\n#coding=utf8\nfrom selenium import webdriver\nimport time\ndef Login(browser,url,username, password):\n    browser.get(url)\n    time.sleep(1)\n    try:\n        # find user login input box\n        elem_user=browser.find_element_by_id(\"j_username\")\n        elem_user.clear()\n        elem_user.send_keys(username)\n        time.sleep(1)\n        # find pwd input box\n        elem_pwd=browser.find_element_by_id(\"j_password\")\n        elem_pwd.clear()\n        elem_pwd.send_keys(password)\n        time.sleep(1)\n        # submit\n        elem_sub = browser.find_element_by_id(\"logoutBtn\")\n        elem_sub.click()\n        # action\n        # print browser.current_url\n        time.sleep(3)\n        # get rdp file (current session)\n        # print browser.find_element_by_xpath('/html/body/iframe').get_attribute('src')\n        return username + \"login successfully \\n\"\n    except:\n        return username + \"login failed \\n\"\nif __name__ == '__main__':\n    browser = webdriver.Chrome()\n    browser.maximize_window()\n    url = 'https://yangtzi.vicp.net:843'\n    usrname = 'user3'\n    password = '123456'\n    Login(browser,url,usrname,password)\n    browser.close()\n```\n\n","tags":["python","selenium"]},{"title":"【centos】CentOS7-安装MySQL5.7","url":"/2018/03/21/【centos】CentOS7-安装MySQL57/","content":"\n### 配置 yum 源\n\n在 <https://dev.mysql.com/downloads/repo/yum/> 找到 yum 源 rpm 安装包\n\n### 安装 mysql 源\n\n#### 下载\n\nshell> wget <https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm>\n\n#### 安装 mysql 源\n\nshell> yum localinstall mysql57-community-release-el7-11.noarch.rpm\n\n#### 用下面的命令检查 mysql 源是否安装成功\n\nshell> yum repolist enabled | grep \"mysql.*-community.*\"\n\n\n\n### 安装 MySQL\n\n#### 使用 yum install 命令安装\n\nshell> yum install mysql-community-server\n\n#### 启动 MySQL 服务，在 CentOS 7 下，新的启动/关闭服务的命令是 systemctl start|stop\n\nshell> systemctl start mysqld\n\n#### 用 systemctl status 查看 MySQL 状态\n\nshell> systemctl status mysqld\n\n#### MySQL 启动状态，设置开机启动\n\nshell> systemctl enable mysqld\n\nshell> systemctl daemon-reload\n\n#### 修改 root 本地账户密码，mysql 安装完成之后，生成的默认密码在 /var/log/mysqld.log 文件中。使用 grep 命令找到日志中的密码。\n\nshell> grep 'temporary password' /var/log/mysqld.log\n\n#### 查看临时密码，首次通过初始密码登录后，使用以下命令修改密码\n\nshell> mysql -uroot -p mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';\n\n或者\n\nmysql> set password for 'root'@'localhost'=password('MyNewPass4!');\n\n#### 以后通过 update set 语句修改密码\n\nmysql> use mysql; mysql> update user set password=PASSWORD('MyNewPass5!') where user='root';\n\n注意：mysql 5.7 默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。否则会提示 ERROR 1819 (HY000): Your password does not satisfy the current policy requirements 错误。查看 MySQL官网密码详细策略。\n\n\n\n### 添加远程登录用户\n\n默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须添加一个允许远程连接的帐户。或者修改 root 为允许远程连接（不推荐）\n\n### 添加一个允许远程连接的帐户\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO 'zhangsan'@'%' IDENTIFIED BY 'Zhangsan2018!' WITH GRANT OPTION;\n\n### 修改 root 为允许远程连接（不推荐）\n\nmysql> use mysql; mysql> UPDATE user SET Host='%' WHERE User='root'; mysql> flush privileges;\n\n### 设置默认编码为 utf8\n\nmysql 安装后默认不支持中文，需要修改编码。\n\n修改 /etc/my.cnf 配置文件，在相关节点（没有则自行添加）下添加编码配置，如下：\n\n```shell\n[mysqld]\ncharacter-set-server=utf8\n\n[client]\ndefault-character-set=utf8\n\n[mysql]\ndefault-character-set=utf8\n```\n\n重启mysql服务，查询编码。可以看到已经改过来了\n\nshell> systemctl restart mysqld \n\nshell> mysql -uroot -p \n\nmysql> show variables like 'character%';\n\n### 默认配置文件路径：\n\n配置文件：/etc/my.cnf\n\n日志文件：/var/log/var/log/mysqld.log\n\n服务启动脚本：/usr/lib/systemd/system/mysqld.service\n\nsocket文件：/var/run/mysqld/mysqld.pid","tags":["centos","centos7","mysql"]},{"title":"【clamav】ClamAV开源杀毒软件配置","url":"/2018/03/17/【clamav】ClamAV开源杀毒软件配置/","content":"\nClam AntiVirus（ClamAV）是免费而且开放源代码的防毒软件，软件与病毒码的更新皆由社群免费发布。\n\n目前ClamAV主要是使用在由Linux、FreeBSD等Unix-like系统架设的邮件服务器上，提供电子邮件的病毒扫描服务。\n\nClamAV 杀毒是Linux平台最受欢迎的杀毒软件，ClamAV属于免费开源产品，支持多种平台，如：Linux/Unix、MAC OS X、Windows、OpenVMS。\n\nClamAV是基于病毒扫描的命令行工具，但同时也有支持图形界面的ClamTK工具。\n\nClamAV主要用于邮件服务器扫描邮件。\n\n它有多种接口从邮件服务器扫描邮件，支持文件格式有如：ZIP、RAR、TAR、GZIP、BZIP2、HTML、DOC、PDF,、SIS CHM、RTF等等。\n\nClamAV有自动的数据库更新器，还可以从共享库中运行。\n\n命令行的界面让ClamAV运行流畅，你不必以后台进程的方式运行，当你想扫描时只需输入扫描命令指定文件或目录就行。\n\n### Centos7安装杀毒软件ClamAV\n\n#### 安装EPEL源\n\n（<http://www.cyberciti.biz/faq/installing-rhel-epel-repo-on-centos-redhat-7-x/>）\n\nClamav可以通过EPEL源来安装，所以要首先安装EPEL，可以采用两种方法来安装：\n\n**第一种，通过命令行安装**\n\n[root@server_for_product ~]# yum install epel-release\n\n**第二种，使用下载好的安装包进行安装**\n\n[root@server_for_product ~]# cd /tmp\n\n[root@server_for_product tmp]# wget <https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm>\n\n[root@server_for_product tmp]# yum install epel-release-7.noarch.rpm\n\n#### 安装ClamAV\n\n在安装了EPEL源后，运行下面的命令安装ClamAV\n\n[root@server_for_product ~]# yum install clamav-server clamav-data clamav-update clamav-filesystem clamav clamav-scanner-systemd clamav-devel clamav-lib clamav-server-systemd -y\n\n#### ClamAV 配置使用\n\n在两个配置文件/etc/freshclam.conf和/etc/clamd.d/scan.conf中移除“Example”字符\n\n[root@server_for_product ~]#sed -i -e \"s/^Example/#Example/\" /etc/freshclam.conf\n\n[root@server_for_product ~]#sed -i -e \"s/^Example/#Example/\" /etc/clamd.d/scan.conf\n\n**手动更新病毒库**\n\n[root@server_for_product ~]# freshclam\n\nfreshclam命令通过文件/etc/cron.d/clamav-update来自动运行\n\n默认情况下是禁止了自动更新功能，需要移除文件/etc/sysconfig/freshclam最后一行的配置才能启用\n\n移除后自动更新： // FRESHCLAM_DELAY=disabled-warn # REMOVE ME\n\n定义服务器类型（本地或者TCP），在这里定义为使用本地socket，将文件/etc/clamd.d/scan.conf中的这一行前面的注释符号去掉：\n\n\\#LocalSocket /var/run/clamd.scan/clamd.sock\n\n**配置开机启动**\n\n[root@server_for_product ~]# systemctl enable [clamd@scan.serv](mailto:clamd@scan.serv)ice\n\n[root@server_for_product ~]# ln -s '/usr/lib/systemd/system/clamd\\@scan.service' '/etc/systemd/system/multi-user.target.wants/clamd\\@scan.service'\n\n**启动并检查服务状态**\n\n[root@server_for_product ~]# systemctl start clamd@scan\n\n[root@server_for_product ~]# systemctl status clamd@scan\n\n#### 备注\n\n如果在手动更新病毒库的时候遇到错误：Update failed. Your network may be down or none of the mirrors listed in freshclam.conf is working.\n\n此时就要删除掉旧的镜像地址文件\n\n[root@server_for_product ~]# rm -f /var/lib/clamav/mirrors.dat\n\n再手动更新一次病毒库\n\n[root@server_for_product ~]# freshclam","tags":["clamav"]},{"title":"【python】SSH远程操作","url":"/2018/03/02/【python】SSH远程操作/","content":"\nparamiko模块提供了ssh及sft进行远程登录服务器执行命令和上传下载文件的功能。这是一个第三方的软件包，使用之前需要安装。\n\n### 1. 基于用户名和密码的 sshclient 方式登录\n\n```python\n# 建立一个sshclient对象\nssh = paramiko.SSHClient()\n# 允许将信任的主机自动加入到host_allow 列表，此方法必须放在connect方法的前面\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n# 调用connect方法连接服务器\nssh.connect(hostname='192.168.2.129', port=22, username='super', password='super')\n# 执行命令\nstdin, stdout, stderr = ssh.exec_command('df -hl')\n# 结果放到stdout中，如果有错误将放到stderr中\nprint(stdout.read().decode())\n# 关闭连接\nssh.close()\n```\n\n### 2. 基于用户名和密码的 transport 方式登录\n\n方法1是传统的连接服务器、执行命令、关闭的一个操作，有时候需要登录上服务器执行多个操作，比如执行命令、上传/下载文件，方法1则无法实现，可以通过如下方式来操作\n\n```python\n# 实例化一个transport对象\ntrans = paramiko.Transport(('192.168.2.129', 22))\n# 建立连接\ntrans.connect(username='super', password='super')\n# 将sshclient的对象的transport指定为以上的trans\nssh = paramiko.SSHClient()\nssh._transport = trans\n# 执行命令，和传统方法一样\nstdin, stdout, stderr = ssh.exec_command('df -hl')\nprint(stdout.read().decode())\n# 关闭连接\ntrans.close()\n```\n\n### 3 基于公钥密钥的 SSHClient 方式登录\n\n```python\n# 指定本地的RSA私钥文件,如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数\npkey = paramiko.RSAKey.from_private_key_file('/home/super/.ssh/id_rsa', password='12345')\n# 建立连接\nssh = paramiko.SSHClient()\nssh.connect(hostname='192.168.2.129',\n            port=22,\n            username='super',\n            pkey=pkey)\n\n# 执行命令\nstdin, stdout, stderr = ssh.exec_command('df -hl')\n# 结果放到stdout中，如果有错误将放到stderr中\nprint(stdout.read().decode())\n# 关闭连接\nssh.close()\n```\n\n以上需要确保被访问的服务器对应用户.ssh目录下有authorized_keys文件，也就是将服务器上生成的公钥文件保存为authorized_keys。并将私钥文件作为paramiko的登陆密钥\n\n### 4. 基于密钥的 Transport 方式登录\n\n指定本地的RSA私钥文件,如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数\n\n```python\npkey = paramiko.RSAKey.from_private_key_file('/home/super/.ssh/id_rsa', password='12345')\n# 建立连接\ntrans = paramiko.Transport(('192.168.2.129', 22))\ntrans.connect(username='super', pkey=pkey)\n# 将sshclient的对象的transport指定为以上的trans\nssh = paramiko.SSHClient()\nssh._transport = trans\n# 执行命令，和传统方法一样\nstdin, stdout, stderr = ssh.exec_command('df -hl')\nprint(stdout.read().decode())\n# 关闭连接\ntrans.close()\n##### 传文件 SFTP ###########\n# 实例化一个trans对象# 实例化一个transport对象\ntrans = paramiko.Transport(('192.168.2.129', 22))\n# 建立连接\ntrans.connect(username='super', password='super')\n# 实例化一个 sftp对象,指定连接的通道\nsftp = paramiko.SFTPClient.from_transport(trans)\n# 发送文件\nsftp.put(localpath='/tmp/11.txt', remotepath='/tmp/22.txt')\n# 下载文件\n# sftp.get(remotepath, localpath)\ntrans.close()\n```\n\n### 5. 实现输入命令立马返回结果的功能\n\n以上操作都是基本的连接，如果我们想实现一个类似xshell工具的功能，登录以后可以输入命令回车后就返回结果：\n\n```python\nimport paramiko\nimport os\nimport select\nimport sys\n\n# 建立一个socket\ntrans = paramiko.Transport(('192.168.2.129', 22))\n# 启动一个客户端\ntrans.start_client()\n\n# 如果使用rsa密钥登录的话\n\n'''\ndefault_key_file = os.path.join(os.environ['HOME'], '.ssh', 'id_rsa')\nprikey = paramiko.RSAKey.from_private_key_file(default_key_file)\ntrans.auth_publickey(username='super', key=prikey)\n'''\n\n# 如果使用用户名和密码登录\ntrans.auth_password(username='super', password='super')\n# 打开一个通道\nchannel = trans.open_session()\n# 获取终端\nchannel.get_pty()\n# 激活终端，这样就可以登录到终端了，就和我们用类似于xshell登录系统一样\nchannel.invoke_shell()\n# 下面就可以执行你所有的操作，用select实现\n# 对输入终端sys.stdin和 通道进行监控,\n# 当用户在终端输入命令后，将命令交给channel通道，这个时候sys.stdin就发生变化，select就可以感知\n# channel的发送命令、获取结果过程其实就是一个socket的发送和接受信息的过程\n\nwhile True:\n    readlist, writelist, errlist = select.select([channel, sys.stdin,], [], [])\n    # 如果是用户输入命令了,sys.stdin发生变化\n    if sys.stdin in readlist:\n        # 获取输入的内容\n        input_cmd = sys.stdin.read(1)\n        # 将命令发送给服务器\n        channel.sendall(input_cmd)\n\n    # 服务器返回了结果,channel通道接受到结果,发生变化 select感知到\n    if channel in readlist:\n        # 获取结果\n        result = channel.recv(1024)\n        # 断开连接后退出\n        if len(result) == 0:\n            print(\"\\r\\n**** EOF **** \\r\\n\")\n            break\n        # 输出到屏幕\n        sys.stdout.write(result.decode())\n        sys.stdout.flush()\n\n# 关闭通道\nchannel.close()\n# 关闭链接\ntrans.close()\n```\n\n### 6. 支持tab自动补全\n\n```python\nimport paramiko\nimport os\nimport select\nimport sys\nimport tty\nimport termios\n\n'''\n实现一个xshell登录系统的效果，登录到系统就不断输入命令同时返回结果\n支持自动补全，直接调用服务器终端\n'''\n\n# 建立一个socket\ntrans = paramiko.Transport(('192.168.2.129', 22))\n# 启动一个客户端\ntrans.start_client()\n\n# 如果使用rsa密钥登录的话\n'''\ndefault_key_file = os.path.join(os.environ['HOME'], '.ssh', 'id_rsa')\nprikey = paramiko.RSAKey.from_private_key_file(default_key_file)\ntrans.auth_publickey(username='super', key=prikey)\n'''\n\n# 如果使用用户名和密码登录\ntrans.auth_password(username='super', password='super')\n# 打开一个通道\nchannel = trans.open_session()\n# 获取终端\nchannel.get_pty()\n# 激活终端，这样就可以登录到终端了，就和我们用类似于xshell登录系统一样\nchannel.invoke_shell()\n\n# 获取原操作终端属性\noldtty = termios.tcgetattr(sys.stdin)\ntry:\n    # 将现在的操作终端属性设置为服务器上的原生终端属性,可以支持tab了\n    tty.setraw(sys.stdin)\n    channel.settimeout(0)\n    while True:\n        readlist, writelist, errlist = select.select([channel, sys.stdin,], [], [])\n        # 如果是用户输入命令了,sys.stdin发生变化\n        if sys.stdin in readlist:\n            # 获取输入的内容，输入一个字符发送1个字符\n            input_cmd = sys.stdin.read(1)\n            # 将命令发送给服务器\n            channel.sendall(input_cmd)\n        # 服务器返回了结果,channel通道接受到结果,发生变化 select感知到\n        if channel in readlist:\n            # 获取结果\n            result = channel.recv(1024)\n            # 断开连接后退出\n            if len(result) == 0:\n                print(\"\\r\\n**** EOF **** \\r\\n\")\n                break\n            # 输出到屏幕\n            sys.stdout.write(result.decode())\n            sys.stdout.flush()\nfinally:\n    # 执行完后将现在的终端属性恢复为原操作终端属性\n    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, oldtty)\n\n# 关闭通道\nchannel.close()\n# 关闭链接\ntrans.close()\n```\n\n### 7. SSH批量登陆执行命令（1）\n\n```python\n#-*- coding: utf-8 -*-\n#!/usr/bin/python\nimport paramiko\nimport threading\n\ndef ssh2(ip,username,passwd,cmd):\n    try:\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        ssh.connect(ip,22,username,passwd,timeout=5)\n        for m in cmd:\n            stdin, stdout, stderr = ssh.exec_command(m)\n#           stdin.write(\"Y\")   #简单交互，输入 ‘Y’\n            out = stdout.readlines()\n            #屏幕输出\n            for o in out:\n                print o,\n        print '%s\\tOK\\n'%(ip)\n        ssh.close()\n    except :\n        print '%s\\tError\\n'%(ip)\n\nif __name__=='__main__':\n    cmd = ['cal','echo hello!']#你要执行的命令列表\n    username = \"\"  #用户名\n    passwd = \"\"    #密码\n    threads = []   #多线程\n    print \"Begin......\"\n    for i in range(1,254):\n        ip = '192.168.1.'+str(i)\n        a=threading.Thread(target=ssh2,args=(ip,username,passwd,cmd))\n        a.start()\n```\n\n### 8. SSH批量登陆执行命令（2）\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport pexpect\n\ndef ssh_cmd(ip, passwd, cmd):\n    ret = -1\n    ssh = pexpect.spawn('ssh root@%s \"%s\"' % (ip, cmd))\n    try:\n        i = ssh.expect(['password:', 'continue connecting (yes/no)?'], timeout=5)\n        if i == 0 :\n            ssh.sendline(passwd)\n        elif i == 1:\n            ssh.sendline('yes\\n')\n            ssh.expect('password: ')\n            ssh.sendline(passwd)\n        ssh.sendline(cmd)\n        r = ssh.read()\n        print r\n        ret = 0\n    except pexpect.EOF:\n        print \"EOF\"\n        ssh.close()\n        ret = -1\n    except pexpect.TIMEOUT:\n        print \"TIMEOUT\"\n        ssh.close()\n        ret = -2\n    return ret\n```\n\n","tags":["python","ssh"]},{"title":"【centos】CentOS7-U盘安装","url":"/2018/01/19/【centos】CentOS7-U盘安装/","content":"\n### U盘安装CentOS7 系统尝试（1）：\n\n1. 正常U盘启动，等待超时后在命令行查找并确定U盘设备是那一块盘\n\n```shell\n[root@packages x86_64]# blkid\n/dev/sr0: UUID=\"2016-12-05-23-44-06-00\" LABEL=\"CentOS 7 x86_64\" TYPE=\"iso9660\" PTTYPE=\"dos\"\n/dev/sda1: UUID=\"4b2c4a17-1150-494c-8201-904b5a252212\" TYPE=\"xfs\"\n/dev/sda2: UUID=\"Z8Ty3N-kuAS-f9Sm-os3x-OtJq-xVzy-EKXgxm\" TYPE=\"LVM2_member\"\n/dev/mapper/cl-root: UUID=\"ae156d1c-ad75-4ddf-9338-41d2b57f8048\" TYPE=\"xfs\"\n/dev/mapper/cl-swap: UUID=\"104af556-91e3-45d1-8d0c-6dbc7ebeef03\" TYPE=\"swap\"\n```\n\n2. 重启服务器，从U盘启动\n\n3. 在CentOS7 安装界面按“Tab”键修改为如下，其中“sdc4”为U盘设备\n\nvmlinuz initrd=initrd.img inst.stage2=hd:/dev/sdc4 quiet\n\n4. 按“Enter”键开始安装\n\n\n\n### U盘安装CentOS7 系统尝试（2）：\n\n1. 正常U盘启动到CentOS7 安装界面，选择第一项“Install CentOS 7”并按“Tab”键\n\n2. 修改内容如下\n\nvmlinuz initrd=initrd.img linux dd quiet\n\n3. 按“Enter”键会列出你的设备列表，找到你的U盘设备\n\n4. 重启服务器，从U盘启动\n\n5. 在CentOS7 安装界面按“Tab”键修改为如下，其中“sdc4”为U盘设备\n\nvmlinz initrd=initrd.img inst.stage2=hd:/dev/sdc4 quiet\n\n6. 按“Enter”键开始安装","tags":["centos","centos7"]},{"title":"【python】htmlpy框架使用","url":"/2017/11/25/【python】htmlpy框架使用/","content":"\n### htmlPy Project\n\n```\nback_end_codes/\nstatic/\n    css/\n        style.css\n        .\n        .\n        .\n    js/\n        script.js\n        .\n        .\n        .\n    img/\n        logo.img\n        .\n        .\n        .\ntemplates/\n    first_template_directory/\n        template1.html\n        template2.html\n        .\n        .\n    another_template_directory/\n        another_template.html\n    base_layout.html\nmain.py\n```\n\n### Standalone application\n\n```python\nimport htmlPy\nimport os\n\napp = htmlPy.AppGUI(title=u\"htmlPy Quickstart\", maximized=True)\napp.template_path = os.path.abspath(\".\")\napp.static_path = os.path.abspath(\".\")\napp.template = (\"index.html\", {\"username\": \"htmlPy_user\"})\n\napp.start()\n```\n\n### Web based application\n\n```python\nimport htmlPy\n\n\nweb_app = htmlPy.WebAppGUI(title=u\"Python Website\", maximized=True)\nweb_app.url = u\"<http://python.org/>\"\n\nweb_app.start()\n```\n\n### Here’s a sample driver file\n\n```python\nimport os\nimport htmlPy\nfrom PyQt4 import QtGui\n\n# Initial confiurations\nBASE_DIR = os.path.abspath(os.path.dirname(__file__))\n# GUI initializations\napp = htmlPy.AppGUI(title=u\"Application\", maximized=True, plugins=True)\n\n# GUI configurations\napp.static_path = os.path.join(BASE_DIR, \"static/\")\napp.template_path = os.path.join(BASE_DIR, \"templates/\")\n\napp.web_app.setMinimumWidth(1024)\napp.web_app.setMinimumHeight(768)\napp.window.setWindowIcon(QtGui.QIcon(BASE_DIR + \"/static/img/icon.png\"))\n\n# Binding of back-end functionalities with GUI\n\n# Import back-end functionalities\nfrom html_to_python import ClassName\n\n# Register back-end functionalities\napp.bind(ClassName())\n\n# Instructions for running application\n\nif __name__ == \"__main__\":\n    # The driver file will have to be imported everywhere in back-end.\n    # So, always keep app.start() in if __name__ == \"__main__\" conditional\n\n    app.start()\n```\n\n### Set static_path and template_path\n\n```html\n<script src=\"{{ 'js/jquery.min.js'|staticfile }}\"></script>\n<link rel=\"stylesheet\" href=\"{{ 'css/bootstrap.min.css'|staticfile }}\">\n```\n\n### GUI to Python calls\n\n```python\nimport htmlPy\nimport json\nfrom sample_app import app as htmlPy_app\n\n\nclass ClassName(htmlPy.Object):\n    # GUI callable functions have to be inside a class.\n    # The class should be inherited from htmlPy.Object.\n\n    def __init__(self):\n        super(ClassName. self).__init__()\n        # Initialize the class here, if required.\n        return\n\n    @htmlPy.Slot()\n    def function_name(self):\n        # This is the function exposed to GUI events.\n        # You can change app HTML from here.\n        # Or, you can do pretty much any python from here.\n        #\n        # NOTE: @htmlPy.Slot decorater needs argument and return data-types.\n        # Refer to API documentation.\n        return\n\n    @htmlPy.Slot(str, result=str)\n    def form_function_name(self, json_data):\n        # @htmlPy.Slot(arg1_type, arg2_type, ..., result=return_type)\n        # This function can be used for GUI forms.\n        #\n        form_data = json.loads(json_data)\n        return json.dumps(form_data)\n\n    @htmlPy.Slot()\n    def javascript_function(self):\n        # Any function decorated with @htmlPy.Slot decorater can be called\n        # using javascript in GUI\n        return\n```\n\n\n\n```html\n<a href=\"ClassName.function_name\" id=\"link\" data-bind=\"true\">GUI clickable link</a>\n<!-- The \"a\" tag needs to have unique ID and data-bind attribute set to \"true\"\nThe ClassName and function_name have to be set in href attribute as displayed above.\nThe \"a\" tag can be styled using CSS with other HTML elements inside it -->\n\n<form action=\"ClassName.form_function_name\" id=\"form\" data-bind=\"true\">\n    <input type=\"text\" id=\"form_input\" name=\"name\">\n    <input type=\"submit\" value=\"Submit\" id=\"form_submit\">\n</form>\n<!-- The \"form\" tag needs to have unique ID and data-bind attribute set to \"true\".\nThe ClassName and form_function_name have to be set in action attribute as\ndisplayed above. The argument given to ClassName.form_function_name on form submit\nwill be a json string of the form data. -->\n\n<script>\nClassName.javascript_function();\n// You can treat the class inherited from htmlPy.Object (in this case, ClassName)\n// as a javascript object.\n</script>\n```\n\n#### Python to GUI calls\n\n```python\nfrom sample_app import app\n\n# app imported from sample_app file is an instance of htmlPy.AppGUI class.\n# Change HTML of the app\napp.html = u\"<html></html>\"\n\n# Change HTML of the app using Jinja2 templates\napp.template = (\"./index.html\", {\"template_variable_name\": \"value\"})\n\n# Execute javascript on currently displayed HTML in the app\napp.evaluate_javascript(\"alert('Hello from back-end')\")\n```\n\n### Using file input\n\n```html\n<input type=\"file\" name=\"file\" id=\"file\" data-filter=\"[{'title': 'Images', 'extensions': '*.png *.xpm *.jpg'}, {'title': 'Documents', 'extensions': '*.pdf *.doc *.docx'}]\">\n```\n\n### Integration with django\n\n```python\nimport os\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"<project_name>.settings\")\n```\n\n","tags":["python","htmlpy"]},{"title":"【client】基于H5的桌面应用开发","url":"/2017/11/09/【client】基于H5的桌面应用开发/","content":"\n### 1. Tide SDK\n\nTide SDK 是一个让你使用你的 Web 开发技能来创建漂亮而且独特桌面应用的开发工具包。支持跨平台开发。\n\nTideSDK 当前支持的编程语言包括：\n\nC/C++\n\nPython\n\nRuby\n\nPHP\n\nJavaScript\n\n接下来将支持：\n\nLua\n\nFalcon\n\nC# (maybe through Mono)\n\nJava\n\n<http://tidesdk.multipart.net/>\n\n### 2. htmlPy\n\nhtmlPy 是对 PySide 的 QtWebKit 库的 Python 封装。\n\n可以用 HTML5 和 CSS3 来开发漂亮的图形界面应用程序。\n\n基于 Qt 构建，具备高度可定制以及跨平台支持。\n\n兼容 Python2 和 Python3.可用于任何 Python 库和环境，如 django, flask, scipy, virtualenv 等。\n\n也可以使用前端框架，如 bootstrap, jQuery, jQuery UI 等。\n\n<http://amol-mandhane.github.io/htmlPy/>\n\n### 3. AlloyDesktop\n\nAlloyDesktop？这是一个什么东西呢？这是一个能将网页像软件一样运行在桌面上的app开发引擎。\n\n该引擎实现了对网页的透明渲染，使网页不再局限于浏览器的框框。\n\n<http://tencentopen.github.io/proj/AlloyDesktop/index.html>\n\n### 4. Pydown\n\npydown is another \"Presentation System in a single HTML page\" written by python inspired by keydown.\n\nLike keydown it uses the deck.js and its extentions for the presentation.\n\n<https://github.com/isnowfy/pydown>\n\n### 5. XUL\n\nXUL 是一个Mozilla使用XML来描述用户界面的一种技术，使用XUL你可以快速的创建出跨平台，基于因特网的应用程序。\n\n<https://developer.mozilla.org/zh-CN/docs/Mozilla/Tech/XUL>\n\nXUL + XPCOM + PyXPCOM + Gecko + XULRunner\n\n### 6. OneRing\n\nOneRing 是一个跨平台的桌面应用框架。和Adobe AIR类似，它支持用html/js/css制作用户界面，与之不同的是，它的应用为本地程序，可以直接访问操作系统的数据。\n\n授权协议： LGPL\n\n开发语言： Python\n\n操作系统： 跨平台\n\n### 7.Twisted + Nevow\n\nTwisted + Nevow  在python web开发上具有一定的优势，Nevow是一种比较新的CGI框架，而最近又有nufox(nevow+xul=nufox)出现，它是基于Nevow的技术\n\n### 8. 他山界面开发\n\n### 9. cefpython\n\n### 10. electron\n\n\n\n","tags":["client"]},{"title":"【python】爬虫简单实践","url":"/2017/10/24/【python】爬虫简单实践/","content":"\n### 豆瓣\n\n```python\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf8')\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib2\nimport xlwt\n\n#得到页面全部内容\ndef askURL(url):\n    request = urllib2.Request(url)#发送请求\n    try:\n        response = urllib2.urlopen(request)#取得响应\n        html= response.read()#获取网页内容\n        #print html\n    except urllib2.URLError, e:\n        if hasattr(e,\"code\"):\n            print e.code\n        if hasattr(e,\"reason\"):\n            print e.reason\n    return html\n\n#获取相关内容\ndef getData(baseurl):\n    #找到评论标题\n    pattern_title = re.compile(r'<a class=\"\".+title=\"(.+)\"')\n    #找到评论全文链接\n    pattern_link = re.compile(r'<a class=\"\".+href=\"(.+review.*?)\"')\n    #找到作者\n    pattern_author = re.compile(r'<a.+people.+\">(.+)</a>')\n    #找到评论的影片和影评详情链接\n    pattern_subject_link = re.compile(r'<a href=\"(.+subject.+)\" title=\"(.+)\">')\n    #找到推荐等级\n    pattern_star=re.compile(r'<span class=\"allstar\\d+\" title=\"(.+)\"></span>')\n    #找到回应数\n    pattern_response=re.compile(r'<span class=\"\">\\((\\d+)回应\\)</span>')\n    #找到有用数\n    pattern_use=re.compile(r'<em id=\"ucount\\d+u\">(\\d+)</em>')\n    remove=re.compile(r'<.+?>')#去除标签\n    datalist=[]\n    for i in range(0,5):#总共5页\n        url=baseurl+str(i*10)#更新url\n        html=askURL(url)\n        soup = BeautifulSoup(html)\n        #找到每一个影评项\n        for item in soup.find_all('ul',class_='tlst clearfix'):\n            data=[]\n            item=str(item)#转换成字符串\n            #print item\n            title = re.findall(pattern_title,item)[0]\n            #print title\n            reviewlink=re.findall(pattern_link,item)[0]\n            data.append(title)#添加标题\n            author=re.findall(pattern_author, item)[0]\n            data.append(author)#添加作者\n            list_subject_link = re.findall(pattern_subject_link, item)[0]\n            moviename=list_subject_link[1]\n            movielink=list_subject_link[0]\n            data.append(moviename)#添加片名\n            data.append(movielink)#添加影片链接\n            star=re.findall(pattern_star,item)[0]\n            data.append(star)#添加推荐等级\n            response=re.findall(pattern_response,item)\n            #回应数可能为0，就找不到\n            if(len(response)!=0):\n                response=response[0]\n            else:\n                response=0\n            data.append(response)#添加回应数\n            data.append(reviewlink)#添加评论正文链接\n            content=askURL(reviewlink)\n            use=re.findall(pattern_use,content)\n            #有用数可能为0，就找不到\n            if len(use)!=0:\n                use=use[0]\n            else:\n                use=0\n            content=BeautifulSoup(content)\n            desc=content.find_all('div',id='link-report')[0]\n            desc=re.sub(remove,'',str(desc))#去掉标签\n            data.append(desc)#添加评论正文\n            data.append(use)#添加有用数\n            datalist.append(data)\n    return datalist\n\n#将相关数据写入excel中\ndef saveData(datalist,savepath):\n    book=xlwt.Workbook(encoding='utf-8',style_compression=0)\n    sheet=book.add_sheet('豆瓣最受欢迎影评',cell_overwrite_ok=True)\n    col=('标题','作者','影片名','影片详情链接','推荐级','回应数','影评链接','影评','有用数')\n    for i in range(0,9):\n        sheet.write(0,i,col[i])#列名\n    for i in range(0,50):#总共50条影评\n        data=datalist[i]\n        for j in range(0,9):\n            sheet.write(i+1,j,data[j])#数据\n    book.save(savepath)#保存\n\ndef main():\n    baseurl='http://movie.douban.com/review/best/?start='\n    datalist=getData(baseurl)\n    savapath=u'豆瓣最受欢迎影评.xlsx'\n    saveData(datalist,savapath)\n\nmain()\n\n```\n\n### 新闻\n\n```python\n#!/usr/bin/python\n#-*- coding: utf-8 -*-\nimport os\nimport re\nimport urllib2\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf8')\n\n#得到页面全部内容\ndef askURL(url):\n    request = urllib2.Request(url)#发送请求\n    try:\n        response = urllib2.urlopen(request)#取得响应\n        html= response.read()#获取网页内容\n        #print html\n        html=html.decode('gbk','ignore')#将gbk编码转为unicode编码\n        html=html.encode('utf-8','ignore')#将unicode编码转为utf-8编码\n    except urllib2.URLError, e:\n        if hasattr(e,\"code\"):\n            print e.code\n        if hasattr(e,\"reason\"):\n            print e.reason\n    return html\n\n#得到正文\ndef getContent(url):\n    html=askURL(url)\n    text=''\n    #找到新闻主体所在的标签\n    findDiv=re.compile(r'<div class=\"left_zw\" style=\"position:relative\">'\n                       r'(.*)<div id=\"function_code_page\">',re.S)\n    div=re.findall(findDiv,html)\n    if len(div)!=0:\n        content=div[0]\n        labels=re.compile(r'[/]*<.*?>',re.S)\n        text=re.sub(labels,'',content)#去掉各种标签\n        text=re.sub(r'\\s|中新社.*?电|\\(完\\)|\\(记者.*?\\)','',text)#去掉空行和换行符,无关内容\n        text=re.sub(r'　　','\\n',text)#将缩进符替换成换行符\n        #print text\n    return text\n\n#根据类别按顺序命名文件\ndef saveFile(labelName,date,fileNum):\n    dirname=\"news\"\n    #若目录不存在，就新建\n    if(not os.path.exists(dirname)):\n        os.mkdir(dirname)\n    labelName=labelName.encode('gbk','ignore')\n    labelpath=dirname+'\\\\'+labelName\n    if(not os.path.exists(labelpath)):\n        os.mkdir(labelpath)\n    path=labelpath+\"\\\\\"+date+\"-0\"+str(fileNum)+\".txt\"#w文本保存路径\n    print \"正在下载\"+path\n    #path=path.encode('gbk','utf-8')#转换编码\n    f=open(path,'w+')\n    return f\n\n#得到正文的URL，读取正文，并保存\ndef getURL(nurl,labelName):\n    html=askURL(nurl)\n    findDiv=re.compile(r'<div class=\"dd_lm\">.*</div>')\n    findTime=re.compile(r'<div class=\"dd_time\">(.*)</div>')\n    findTitle=re.compile(r'<div class=\"dd_bt\"><a href=\"http://www.chinanews.com/.*\\.shtml\">(.*)</a></div>')\n    findURL=re.compile(r'<div class=\"dd_bt\"><a href=\"(http://www.chinanews.com/.*\\.shtml)\">.*</a></div>')\n    findLabel=re.compile(r'<div class=\"dd_lm\">\\[<a href=http://www.chinanews.com/.*\\.shtml>(.*)</a>\\]</div>')\n    fileNum=0\n    for info in re.findall(findDiv,html):\n        #print info\n        time=re.findall(findTime,info)[0]\n        date=re.findall(r'\\d?-\\d*',time)[0]#获取新闻发布日期\n        title=re.findall(findTitle,info)[0]\n        url=re.findall(findURL,info)[0]#获取新闻正文的链接\n        label=re.findall(findLabel,info)[0]#获取新闻所属类别\n        if(label==\"I&nbsp;&nbsp;T\"):#网页为I&nbsp;&nbsp;T\n            label=\"IT\"\n        if(labelName==label):\n            text=getContent(url)\n            #如果新闻内容长度大于1000，保存新闻标题和正文\n            if(len(text)>1000):\n                fileNum=fileNum+1\n                f=saveFile(labelName,date,fileNum)\n                f.write(title)\n                f.write(text)\n                f.close()\n\n#抓取新闻标题、类别、发布时间、url，并建立相应的文件，存到相应的类别文件夹中\ndef getNews(url,begin_page,end_page,labelName):\n    for i in range(begin_page, end_page+1):\n        nurl=url+str(i)+\".html\"\n        #print nurl\n        #获取网页内容\n        getURL(nurl,labelName)\n\n#接收输入类别、起始页数、终止页数\ndef main():\n    url='http://www.chinanews.com/scroll-news/news'\n    ch=int(raw_input(u'请输入类别的对应的数字（IT=1、财经=2、地方=3、国际=4、国内=5、健康=6、军事=7、'\n                 u'社会=8、体育=9、文化=10），输入-1退出，输入0表示全选：\\n'))\n    labels=('IT','财经','地方',\"国际\",\"国内\",\"健康\",\"军事\",\"社会\",\"体育\",\"文化\")\n    while(ch!=-1):\n        begin_page = int(raw_input(u'请输入开始的页数(1,)：\\n'))\n        end_page = int(raw_input(u'请输入终点的页数(1,)：\\n'))\n        if(ch>=1 and ch<=10):\n            getNews(url,begin_page,end_page,labels[ch-1])\n        elif(ch==0):\n            for label in labels:\n                getNews(url,begin_page,end_page,label)\n        else:\n            print \"输入错误，请重新输入！\"\n        ch=int(raw_input(u'请输入类别的对应的数字（IT=1、财经=2、地方=3、国际=4、国内=5、健康=6、军事=7、'\n                         u'社会=8、体育=9、文化=10），输入-1退出，输入0表示全选：\\n'))\n\n#调用主函数\n#一页有125条新闻\nmain()\n\n```\n\n### RPM源下载\n\n```python\n#!/usr/bin/python\n#coding:utf-8\n\nimport re\nimport urllib\n\nprint \"The Most Basic Download\\n\"\n\ndef getHtml(url):\n    page = urllib.urlopen(url)\n    html = page.read()\n    print html\n    return html\n\ndef getImg(html):\n    reg = r'href=\"(.*?\\.rpm)\"' #匹配的正则表达式\n    imgre = re.compile(reg)\n    imglist = re.findall(imgre,html)\n\n    for imgurl in imglist:\n        name = imgurl[:-4]\n        print name\n        httpurl = 'http://mirrors.163.com/centos/7/os/x86_64/Packages/' + imgurl\n        print  httpurl\n        urllib.urlretrieve(httpurl,'%s.jpg' % name) #下载的内容，并顺序命名\n\n\nurl =\"http://mirrors.163.com/centos/7/os/x86_64/Packages/\"\nhtml = getHtml(url)\ngetImg(html)\n\n#http://www.nvsheng.com/mm/\n\n\n\n\n#!/usr/bin/python\n#coding:utf-8\n'''\n多网址下载改进\n'''\nimport re\nimport urllib\n\ndef getHtml(url):\n    page = urllib.urlopen(url)\n    html = page.read()\n    getImg(html)\n\ndef getImg(html):\n    reg = r'href=\"(.*?\\.rpm)\"' #匹配的正则表达式\n    imgre = re.compile(reg)\n    imglist = re.findall(imgre,html)\n    file1 = open(\"rpm.txt\", \"w\")\n    x = 0\n    for imgurl in imglist:\n        print imgurl\n        x=x+1\n        file1.write('http://mirrors.163.com/centos/7/os/x86_64/Packages/' + imgurl + '\\n')\n    print x\n    file1.close()\n\nurl =\"http://mirrors.163.com/centos/7/os/x86_64/Packages/\"\nhtml = getHtml(url)\ngetImg(html)\n\n```\n\n### 静态网页\n\n```python\n#!/usr/bin/python\n#coding:utf-8\n\nimport re\nimport urllib\n\n\ndef getHtml(url):\n    page = urllib.urlopen(url)\n    html = page.read()\n    return html\n\ndef getImg(html):\n    reg = r'src=\"(.*?\\.jpg)\"'\n    imgre = re.compile(reg)\n    imglist = re.findall(imgre,html)\n    x = 0\n    for imgurl in imglist:\n        print imgurl\n        urllib.urlretrieve(imgurl,'%s.jpg' % x)\n        x += 1\n\n\nurl=\"\"\nhtml = getHtml(url)\ngetImg(html)\n\n--------------------------------------------------------\n\ndef getImg(html):\n    reg = r'src=\"(.*?\\.jpg)\"' #匹配的正则表达式\n    imgre = re.compile(reg)\n    imglist = re.findall(imgre,html)\n\n    for imgurl in imglist:\n        name1 = imgurl[:-4]\n        print name1\n        name2 = name1.split('/')[-1]\n        print name2\n        urllib.urlretrieve(imgurl,'%s.jpg' % name2)\n\n--------------------------------------------------------\n\nimport urllib2\n\ndef getHtml(url):\n    try:\n        respHtml = urllib2.urlopen(url).read();\n    except urllib2.URLError, e:\n        if hasattr(e, \"reason\"):\n            print \"Failed to reach the server\"\n            print \"The reason:\", e.reason\n        elif hasattr(e, \"code\"):\n            print \"The server couldn't fulfill the request\"\n            print \"Error code:\", e.code\n            print \"Return content:\", e.read()\n        else:\n            pass\n    return respHtml\n\n```\n\n### 图片获取\n\n```python\n#!/usr/bin/python\n#coding:gbk\n\nimport re\nimport urllib\nimport ctypes\n\nSTD_INPUT_HANDLE = -10\nSTD_OUTPUT_HANDLE = -11\nSTD_ERROR_HANDLE = -12\n\nFOREGROUND_BLACK = 0x0\nFOREGROUND_BLUE = 0x01  # text color contains blue.\nFOREGROUND_GREEN = 0x02  # text color contains green.\nFOREGROUND_RED = 0x04  # text color contains red.\nFOREGROUND_INTENSITY = 0x08  # text color is intensified.\n\nBACKGROUND_BLUE = 0x10  # background color contains blue.\nBACKGROUND_GREEN = 0x20  # background color contains green.\nBACKGROUND_RED = 0x40  # background color contains red.\nBACKGROUND_INTENSITY = 0x80  # background color is intensified.\n\n\n# 上面这一大段都是在设置前景色和背景色，其实可以用数字直接设置，我的代码直接用数字设置颜色\n\n\nclass Color:\n    std_out_handle = ctypes.windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE)\n\n    def set_cmd_color(self, color, handle=std_out_handle):\n        bool = ctypes.windll.kernel32.SetConsoleTextAttribute(handle, color)\n        return bool\n\n    def reset_color(self):\n        self.set_cmd_color(FOREGROUND_RED | FOREGROUND_GREEN | FOREGROUND_BLUE | FOREGROUND_INTENSITY)\n        # 初始化颜色为黑色背景，纯白色字，CMD默认是灰色字体的\n\n    def print_red_text(self, print_text):\n        self.set_cmd_color(4 | 8)\n        print print_text\n        self.reset_color()\n        # 红色字体\n\n    def print_green_text(self, print_text):\n        self.set_cmd_color(FOREGROUND_GREEN | FOREGROUND_INTENSITY)\n        c = raw_input(print_text)\n        self.reset_color()\n        return c\n        # 绿色字体。实现的是，让用户输入的字体是绿色的，记得返回函数值。\n\n    def print_yellow_text(self, print_text):\n        self.set_cmd_color(6 | 8)\n        print print_text\n        self.reset_color()\n        # 黄色字体\n\n    def print_blue_text(self, print_text):\n        self.set_cmd_color(1 | 10)\n        print print_text\n        self.reset_color()\n        # 蓝色字体\n\n\nclr = Color()\nclr.set_cmd_color(FOREGROUND_RED | FOREGROUND_GREEN | FOREGROUND_BLUE | FOREGROUND_INTENSITY)\nclr.print_yellow_text('*'*66)\nclr.print_yellow_text(\"*m.mm131.com\")\nclr.print_yellow_text(\"*Site examples:\\thttp://img1.mm131.com/pic/2721/1.jpg\")\nclr.print_yellow_text(\"*You can enter multiple IDs and Pages,Separated by ' '.\")\nclr.print_yellow_text(\"If you enter nothing, the program will end.\")\nclr.print_yellow_text('*'*66+'\\n')\n\nmodeUrl = \"http://img1.mm131.com/pic/\"\n\ndef getUrl(modeUrl,id,end):\n    file1 = open(\"resUrl.txt\",\"a\")\n    for i in range(1,int(end)+1):\n        url = modeUrl + id + '/' + str(i) +\".jpg\\n\"\n        print url\n        file1.write(url)\n    file1.write('\\n')\n    file1.close()\n    clr.print_yellow_text(\"Successful!\\n\")\n\ndef main():\n    ids = clr.print_green_text(\"Please enter the ID of the page you want to download:\\n\")\n    ends = clr.print_green_text(\"Please enter the total number of pages:\\n\")\n    while(ids!=''):\n        idlist = ids.split(' ')\n        endlist = ends.split(' ')\n        for (id,end) in zip(idlist,endlist):\n            if(int(id)>0):\n                getUrl(modeUrl,id,end)\n            else:\n                clr.print_red_text(\"\\nInput error,please enter again!\\n\")\n        ids = clr.print_green_text(\"Please enter the ID of the page you want to download:\\n\")\n        ends = clr.print_green_text(\"Please enter the total number of pages:\\n\")\n\nmain()\n\n#最新地址到：http://img1.mm131.com/pic/2721/0.jpg  2016-10-29\n\n```\n\n\n\n```python\n#!/bin/python\n#coding=utf-8\n\nfrom selenium import webdriver\nimport time\nimport json\nimport sys\nreload(sys)\nsys.setdefaultencoding( \"utf-8\" )\n\n\n# 获取导航栏\ndef getNavUrls(url):\n    browser.get(url)\n    nav_xpath = browser.find_element_by_xpath(\"/html/body/div[4]\")\n    nav_atags = nav_xpath.find_elements_by_tag_name(\"a\")\n    navs = []\n    for nav_atag in nav_atags:\n        nav = nav_atag.get_attribute(\"href\")\n        navs.append(nav)\n    return navs\n\n\n# 获取总页数\ndef getAllPages(navurl):\n    browser.get(navurl)\n    endPageUrl = browser.find_element_by_link_text(\"末页\").get_attribute(\"href\")\n    browser.get(endPageUrl)\n    page =  browser.find_element_by_class_name(\"page_now\").text\n    return int(page)\n\n\n# 获取模块具体内容\ndef getModeUrls(navs):\n    modeUrls = {}\n    for nav in navs:\n        print nav\n        nums = range(getAllPages(nav))\n        firstPage = nav\n        pics = {}\n        pages = {}\n        for nextPage in nums:\n            print nextPage\n            browser.get(firstPage)\n            mode_xpath = browser.find_element_by_xpath(\"/html/body/div[5]/dl\")\n            mode_imgs = mode_xpath.find_elements_by_tag_name(\"img\")\n            for mode_img in mode_imgs:\n                pics[mode_img.get_attribute(\"alt\")] = mode_img.get_attribute(\"src\")\n            pages[nextPage + 1] = pics\n            if nextPage < len(nums)-1:\n                firstPage = browser.find_element_by_link_text(\"下一页\").get_attribute(\"href\")\n        modeUrls[nav] = pages\n    with open('mm.json', 'w') as fp:\n        fp.write(json.dumps(modeUrls, encoding='UTF-8', ensure_ascii=False))\n    return json.dumps(modeUrls, encoding='UTF-8', ensure_ascii=False)\n\n\nprint time.ctime()\nbrowser = webdriver.PhantomJS()\nurl = \"http://www.mm131.com/\"\nnavs = getNavUrls(url)[1:]\nprint navs\nprint getModeUrls(navs)\nbrowser.close()\nprint time.ctime()\n\n```\n\n\n\n```python\n#!/bin/python\n#coding=utf-8\n\nfrom selenium import webdriver\nimport time\nimport json\nimport re\nimport sys\nreload(sys)\nsys.setdefaultencoding( \"utf-8\" )\n\n\n# 获取导航栏\ndef getNavUrls(url):\n    browser.get(url)\n    nav_xpath = browser.find_element_by_xpath(\"/html/body/div[4]\")\n    nav_atags = nav_xpath.find_elements_by_tag_name(\"a\")\n    navs = []\n    for nav_atag in nav_atags:\n        nav = nav_atag.get_attribute(\"href\")\n        navs.append(nav)\n    return navs\n\n\n# 获取概览的总页数\ndef getAllPages(navurl):\n    browser = webdriver.PhantomJS()\n    browser.get(navurl)\n    endPageUrl = browser.find_element_by_link_text(\"末页\").get_attribute(\"href\")\n    browser.get(endPageUrl)\n    page =  browser.find_element_by_class_name(\"page_now\").text\n    return int(page)\n\n\n# 获取所有概念图到json文件\ndef getModeUrls(navs):\n    modeUrls = {}\n    for nav in navs:\n        print nav\n        nums = range(getAllPages(nav))\n        firstPage = nav\n        pics = {}\n        pages = {}\n        for nextPage in nums:\n            print nextPage\n            browser.get(firstPage)\n            mode_xpath = browser.find_element_by_xpath(\"/html/body/div[5]/dl\")\n            mode_imgs = mode_xpath.find_elements_by_tag_name(\"img\")\n            for mode_img in mode_imgs:\n                pics[mode_img.get_attribute(\"alt\")] = mode_img.get_attribute(\"src\")\n            pages[nextPage + 1] = pics\n            if nextPage < len(nums)-1:\n                firstPage = browser.find_element_by_link_text(\"下一页\").get_attribute(\"href\")\n        modeUrls[nav] = pages\n    with open('mm.json', 'w') as fp:\n        fp.write(json.dumps(modeUrls, encoding='UTF-8', ensure_ascii=False))\n    return json.dumps(modeUrls, encoding='UTF-8', ensure_ascii=False)\n\n\n# 查看所有概览内容\ndef viewAllModel(navs):\n    for nav in  navs:\n        nums = getAllPages(nav)\n        browser.get(nav)\n        time.sleep(3)\n        num = 1\n        while num < nums:\n            browser.find_element_by_link_text(\"下一页\").click()\n            time.sleep(3)\n            num += 1\n\n\n# 顺序查看所有图片具体内容\ndef viewAllDetailPics(navs):\n    for nav in navs:\n        browser.get(nav)\n        durl = browser.find_element_by_xpath(\"/html/body/div[5]/dl/dd[1]/a\").get_attribute(\"href\")\n        browser.get(durl)\n        time.sleep(3)\n        while True:\n            # 获取总页数\n            allPages = browser.find_element_by_xpath(\"/html/body/div[6]/div[3]/span[1]\").text\n            pages = int(re.findall(r\"[0-9]{1,9}\", allPages)[0])\n            page = 1\n            while page < pages:\n                if browser.find_element_by_link_text(\"下一页\"):\n                    browser.find_element_by_link_text(\"下一页\").click()\n                    time.sleep(3)\n                page += 1\n            if browser.find_element_by_xpath(\"/html/body/div[6]/div[4]/a[1]\").text != \"没有了\":\n                browser.find_element_by_xpath(\"/html/body/div[6]/div[4]/a[1]\").click()\n            else:\n                break\n\n\n# 查看某个图片的具体信息\ndef viewSingleDetailPic(url):\n    browser.get(url)\n    # 获取总页数\n    allPages = browser.find_element_by_xpath(\"/html/body/div[6]/div[3]/span[1]\").text\n    pages = int(re.findall(r\"[0-9]{1,9}\", allPages)[0])\n    page = 1\n    while page < pages:\n        if browser.find_element_by_link_text(\"下一页\"):\n            browser.find_element_by_link_text(\"下一页\").click()\n        page += 1\n\n\n# 网页截图\ndef webScreenShotPics(url):\n    browser.get(url)\n    # 获取总页数\n    allPages = browser.find_element_by_xpath(\"/html/body/div[6]/div[3]/span[1]\").text\n    pages = int(re.findall(r\"[0-9]{1,9}\", allPages)[0])\n    page = 1\n    while page < pages:\n        if browser.find_element_by_link_text(\"下一页\"):\n            browser.save_screenshot(str(page) + \".png\")\n            browser.find_element_by_link_text(\"下一页\").click()\n        page += 1\n\n\n# 运行程序\nif __name__ == '__main__':\n    browser = webdriver.PhantomJS()\n    browser.maximize_window()\n\n    # url = \"http://www.mm131.com/\"\n    # navs = getNavUrls(url)[1:]\n    # print getModeUrls(navs)\n    # viewAllModel(navs)\n    # viewAllDetailPics(navs)\n\n    durl = \"http://www.mm131.com/xinggan/3455.html\"\n    # viewSingleDetailPic(durl)\n    # webScreenShotPics(durl)\n\n    browser.close()\n    \n```\n\n","tags":["python"]},{"title":"【windows】电脑关机、重启、注销等","url":"/2017/10/17/【windows】电脑关机、重启、注销等/","content":"\n如何在win cmd中进行电脑重启\n\n- shutdown.exe -a　 取消关机\n\n- shutdown.exe -s   关机\n\n- shutdown.exe -f　 强行关闭应用程序\n\n- shutdown.exe -m  \\\\计算机名　控制远程计算机\n\n- shutdown.exe -i　 显示“远程关机”图形用户界面，但必须是Shutdown的第一个参数\n\n- shutdown.exe -l　 注销当前用户\n\n- shutdown.exe -r　 关机并重启\n\n- shutdown.exe -s -t 时间　设置关机倒计时（shutdown -r -t 5   5秒后重启计算机）\n\n- shutdown.exe -h   休眠","tags":["windows","cmd"]},{"title":"【vmware】VMWare网络模式简介","url":"/2017/10/10/【vmware】vmware网络模式简介/","content":"\n### vmnet0(桥接模式)\n\n```\nvmnet0(桥接模式),无实体虚拟网卡,其实就是一个协议而已，会在对应网卡上加入 VMware bridge protocol桥接协议，其作用相对于使用一个虚拟交换机连接虚拟机和物理机网卡。\n```\n\n### vmnet1(仅主机模式, hostory)\n\n```\nvmnet1(仅主机模式, hostory)，生成vmnet1虚拟网卡，并定义一个ip地址，虚拟机设置为仅主机模式，需要手动设置和vmnet1相同的子网网段，作用相同与vmnet0但由于vmnet1不接入其他网络，所以数据只在虚拟机和物理机间交换。\n```\n\n### vmnet8(NAT模式,网络地址转换)\n\n```\nvmnet8(NAT模式，网络地址转换)，生成vmnet8虚拟机网卡，并通过VMware Net service提供网关和地址转换服务，VMware DHCP service提供虚拟机ip地址自动分配服务，通过vmnet8与虚拟机通讯。\n```\n\n","tags":["vmware","网络"]},{"title":"【openstack】OpenStack修改节点IP地址","url":"/2017/09/11/【openstack】OpenStack修改节点IP地址/","content":"\n### 1. 配置文件修改：\n\n```bash\n#!/bin/bash\n#OpenStack node ip change \necho '' \necho '***********************************************' \necho 'sed -i \"s/oldIP/newIP/g\" `grep -rl oldIP /etc/`' \necho '***********************************************' \necho '' \necho 'eg: ./change_ip.sh 192.168.10.2 192.168.10.3' \necho '' \nif [ -z \"$1\" ] \nthen \n\techo \"1st argument is empty!\" \n\techo '' \nelif [ -z \"$2\" ]\nthen \n\tgrep -rl $1 /etc/ \n\tgrep -l $1 /root/keystonerc_admin \n\techo '' \n\techo \"2nd argument is empty!\" \n\techo '' \nelse \n\tsed -i \"s/$1/$2/g\" `grep -rl $1 /etc/` \n\tsed -i \"s/$1/$2/g\" /root/keystonerc_admin \n\techo 'Successful' \n\techo '' \nfi\n\n```\n\n### 2. 数据库修改:\n\n```mysql\nmysql \nshow databases; \nuse keystone; \nshow tables; \nselect * from endpoint; \nupadte endpoint set url=replace(url,'$1','$2'); \nselect * from endpoint; \n\\q \n\nopenstack-service restart \nopenstack-status \n\n#echo \"192.168.10.2 controller\" >> /etc/hosts\n\n```\n\n","tags":["openstack"]},{"title":"【openstack】OpenStack命令整理","url":"/2017/09/11/【openstack】OpenStack命令整理/","content":"\n### 文件批量复制\n\n```bash\ncat allrpm.txt |while read name ;do cp -a /mnt/Packages/$name.rpm /root/orgin/ ;done\n```\n\n### 批量删除云主机\n\n```bash\nsource ~/keystonerc_admin\na=`nova list |grep '[a-zA-Z0-9]\\{8\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{12\\}' -o`\nfor b in $a\ndo\n    echo $b\n    nova force-delete $b\n    #nova delete $b\ndone\n```\n\n### 设置安全组规则（Nova-network）\n\n```bash\nsource ~/keystonerc_admin\nnova secgroup-add-rule default tcp 1 65535 0.0.0.0/0\nnova secgroup-add-rule default udp 1 65535 0.0.0.0/0\nnova secgroup-add-rule default icmp -1 -1 0.0.0.0/0\n```\n\n###  设置安全组规则（Neutron）\n\n```bash\nsource ~/keystonerc_admin\na=`neutron security-group-rule-list |grep '[a-zA-Z0-9]\\{8\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{12\\}' -o`\nfor b in $a\ndo\n\tneutron security-group-rule-delete $b\ndone\na1=`neutron security-group-list |grep '[a-zA-Z0-9]\\{8\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{4\\}-[a-zA-Z0-9]\\{12\\}' -o`\nfor b1 in $a1\ndo\n\tneutron security-group-rule-create --protocol tcp --port-range-min 1 --port-range-max 65535 --direction ingress $b1\n\tneutron security-group-rule-create --protocol udp --port-range-min 1 --port-range-max 65535 --direction ingress $b1\n\tneutron security-group-rule-create --protocol icmp --direction ingress $b1\n\tneutron security-group-rule-create --protocol icmp --direction egress $b1\ndone\n```\n\n### 上传镜像（Icehouse）\n\n```bash\nsource /root/keystonerc_admin\nglance image-create --name cirros --file cirros-0.3.1-x86_64-disk.img --disk-format qcow2 --container-format bare --is-public True --progress\n```\n\n### 上传镜像（Mitaka）\n\n```bash\nsource /root/keystonerc_admin\nglance image-create --name cirros --file cirros-0.3.1-x86_64-disk.img --disk-format qcow2 --container-format bare --progress\n```\n\n### 创建网络（Neutron）\n\n```bash\nsource ~/keystonerc_admin\nneutron net-create private\nneutron subnet-create private 172.16.1.0/24 --name private_subnet --dns-nameserver 223.5.5.5\nneutron router-create router1\nneutron router-interface-add router1 private_subnet\nneutron net-create public --router:external\nneutron subnet-create public 10.0.0.0/24 --name public_subnet --enable_dhcp=False --allocation_pool start=10.0.0.100,end=10.0.0.200 --gateway 10.0.0.1\nneutron router-gateway-set router1 public\nneutron floatingip-create public\n```\n\n","tags":["openstack"]},{"title":"【openstack】OpenStack平台qcow2镜像制作","url":"/2017/09/08/【openstack】QCOW2镜像制作/","content":"\n## 一、qcow2镜像制作流程：\n\n### 1. 预先准备：\n\n- 虚拟机物理机均可，虚拟机需要开启硬件虚拟化 \n- 操作系统： centos6/centos7 桌面版 \n- 待制作镜像系统（iso）： win7/8/10 \n- virtio驱动： win默认iso镜像不包含virtio驱动，而通过openstack管理虚拟机需要两个virtio驱动，一个是硬盘的，一个是网卡的。\n\n```bash\n#下载地址：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.140-1/virtio-win-0.1.140.iso \n#64位：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.140-1/virtio-win-0.1.140_amd64.vfd  \n#32位：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.140-1/virtio-win-0.1.140_x86.vfd \n```\n\n> *以下操作均在root权限下执行，将下载的win7iso镜像和virtio驱动均放在 /root 目录下*\n\n\n\n### 2. 安装相关RPM软件包：\n\n```\nyum install tigervnc  vnc*   -y\nyum install qemu-kvm qemu-img –y\n```\n\n### 3. 创建连接：\n\n```bash\nln -s /usr/libexec/qemu-kvm /usr/bin/kvm\nln -s /usr/bin/qemu-img /usr/bin/kvm-img\n```\n\n### 4. 正式安装：\n\n#### 4.1 创建：\n\n```bash\nqemu-img create -f qcow2 win7.qcow2 10G\n```\n\n#### 4.2 vnc启动安装，关机：\n\n```bash\nkvm -m 1024 -cdrom win7.iso -drive file=win7.qcow2,if=virtio,boot=on -fda virtio-win-0.1.102_amd64.vfd -boot d -nographic -vnc :3\n```\n\n#### 4.3 vnc启动，更改网卡驱动为Redhat：\n\n```bash\nkvm -m 1024 -drive file=win7.qcow2,if=virtio,boot=on -cdrom virtio-win-0.1.102.iso -net nic,model=virtio -net user -boot c -nographic -vnc :3\n```\n\n#### 4.4 关机拷贝：\n\n```bash\nvncviewer\n```\n\n\n\n## 二、基于OpenStack平台的qcow2镜像直接获取\n\n> 待制作操作系统：Windows/linux\n>\n> 处理：使用刻录工具将硬盘及网卡驱动放进iso包中，并另存为新的iso镜像文件（只针对Windows镜像，linux本身就有相关驱动文件）\n>\n\n### OpenStack-icehouse平台\n\n- 新建一个“云主机类型”（flavor），启用第二块存储盘（Ephemeral disk）设置其大小足够安装iso镜像，将默认的第一块存储盘（root disk）大小设置为0。\n\n- 选择此“云主机类型”启动一个云主机实例，此时第一块存储盘就被当成cdrom，数据将被安装到第二块盘中，利用VNC窗口安装操作系统，手动选择硬盘驱动。\n\n- 系统安装完成后使用命令弹出此“光驱设备”（root disk），执行云主机快照（create snapshot）功能，获取你所需要的qcow2镜像\n\n```bash\n#其中 “1” 为云主机的ID，可通过virsh list命令查询\nvirsh attach-disk --type cdrom --mode readonly 1 \"\" hda --live\n```\n\n> *注意：*\n>\n> *在OpenStack-icehouse版本代码里默认只有一块Ephemeral disk，数据会被默认存储到一个名为 disk.local 文件中，在把root disk作为cdrom弹出以后，创建快照时会直接对Ephemeral disk进行快照。在高版本的OpenStack中，这部分代码进行了优化，Ephemeral disk可能不只一个，所以返回值不能确定，进行上述操作时会报错，或者你可能对root disk的iso镜像创建了一个快照。*\n>\n> *既然我们已经知道创建的云主机会存储到什么地方，那就可以直接对存储的数据进行操作。使用高版本的OpenStack按照上述方式安装iso镜像，直接对数据盘（qcow2格式）进行镜像上传，至此你就获得了一台初始的qcow2模板虚拟机。*","tags":["openstack","qcow2"]},{"title":"【centos】YUM源创建及使用","url":"/2017/08/08/【centos】YUM源创建及使用/","content":"\n### YUM源创建前目录结构：\n\n```shell\n[root@packages ~]# tree tmp-packages/\n\ntmp-packages/\n├── Packages\n│   └── xxx.rpm\n└── repodata\n    └── comps.xml\n\n2 directories, 2 files\n```\n\n### YUM源创建后目录结构：\n\n```shell\n[root@packages ~]# tree tmp-packages/\n\ntmp-packages/\n├── Packages\n│   └── xxx.rpm\n└── repodata\n    ├── comps.xml\n    ├── comps.xml.gz\n    ├── filelists.sqlite.bz2\n    ├── filelists.xml.gz\n    ├── other.sqlite.bz2\n    ├── other.xml.gz\n    ├── primary.sqlite.bz2\n    └── primary.xml.gz\n\n2 directories, 9 files\n```\n\n### YUM源创建及使用流程如下：\n\n1. 将所有RPM安装包拷贝到“Packages”目录下\n2. 编辑“comps.xml”文件，并移至“repodata”目录下\n3. 执行“creatrtepo -g ./repodata/comps.xml ./”命令\n4. 编辑“xxx.repo”软件仓库文件，移至“/etc/yum.repo.d/”目录下\n5. 使用yum 命令安装RPM 包\n\n### “xxx.repo”文件内容参考如下：\n\n- [....]     代表这个库的名字，必须是唯一的，不可以重复。\n- name＝     是这个库的说明，没有太大的实际意义，只是一个字段说明。\n- baseurl＝  说明采取什么方式传输，具体路径在哪里，可以使用的方式有,file://，ftp://，http://等。\n- enabled=1  说明启用这个更新库，0表示不启用。\n- gpgcheck=1 表示使用gpg文件来检查软件包的签名。\n- gpgkey=    表示gpg文件所存放的位置，此处也可以有http方式的位置。\n\n\n\n","tags":["centos","yum"]},{"title":"【centos】CentOS6-定制化ISO","url":"/2017/05/22/【centos】CentOS6-定制化ISO/","content":"\n### CentOS-6.5.iso定制化\n\n#### 1、安装制作系统镜像所需要的工具\n\n```shell\nyum -y install anaconda repodata createrepo mkisofs rsync\n```\n\n#### 2、拷贝iso解压后的文件到/os目录下\n\n#### 3、修改启动安装导向文件/os/isolinux/isolinux.cfg,下面为修改后内容\n\n```shell\ndefault vesamenu.c32\n\n#prompt 1\n\ntimeout 200\n\ndisplay boot.msg\n\nmenu background splash.jpg\nmenu title Welcome to GCloud 4.1!\nmenu color border 0 #ffffffff #00000000\nmenu color sel 7 #ffffffff #ff000000\nmenu color title 0 #ffffffff #00000000\nmenu color tabmsg 0 #ffffffff #00000000\nmenu color unsel 0 #ffffffff #00000000\nmenu color hotsel 0 #ff000000 #ffffffff\nmenu color hotkey 7 #ffffffff #ff000000\nmenu color scrollbar 0 #ffffffff #00000000\n\nlabel linux\n  menu label ^Install gcloud 4.1!\n  menu default\n  kernel vmlinuz\n  append ks=cdrom:/isolinux/ks.cfg initrd=initrd.img\n```\n\n#### 4、创建自响应文件 ks.cfg ，把此文件放在/os/isolinux/ks.cfg\n\n```shell\n# Kickstart file automatically generated by anaconda.\n\n#version=DEVEL\n\ninstall\n\ncdrom\n\nlang en_US.UTF-8\n\nkeyboard us\n\nnetwork --onboot no --device eth0 --bootproto dhcp --noipv6\n\nrootpw --plaintext infocore\n\nfirewall --disabled\n\nauthconfig --enableshadow --passalgo=sha512\n\nselinux --disabled\n\ntimezone Asia/Shanghai\n\nbootloader --location=mbr\n\nzerombr\n\nclearpart --all --initlabel\n\n%pre\n\nmkdir /os\nmount /dev/sr0 /os\nrepo --name=\"CentOS\"  --baseurl=file:///os --cost=100\n\n%packages --nobase\n\n@core\n\n%end\n\nreboot\n\n%post\n\necho -ne '\nmkdir /os/\nmount -o loop /dev/sr0/ /os/\nmkdir -p /root/gcloud/\ncp -R /os/gcloud/* /root/gcloud/\nchmod +x /root/gcloud/*.sh\n/root/gcloud/compute.sh\n' >>/root/install.sh\n\nchmod +x /root/install.sh\n/root/install.sh\nrm -f /root/install.sh\ncp /root/gcloud/onekeyInstall.sh /root/\n\n%end\n```\n\n#### 5、创建软件仓库\n\n```shell\ncd /os\n\ndeclare -x discinfo=$(head -1 .discinfo)\n\ncp repodata/*-c6-x86_64-comps.xml ./c6-x86_64-comps.xml\n\nrm -f /repodata/*\n\nmv ./c6-x86_64-comps.xml repodata\n\ncreaterepo -g repodata/c6-x86_64-comps.xml ./\n```\n\n#### 6.修改光盘背景，文字等信息\n\n##### 6.1修改系统自动安装过程中显示的背景图片.修改光盘背景，文字等信息\n\n```shell\n#进入光盘images目录\ncd /os/images/\n\n#install.img镜像中包含了光盘安装过程中使用到的背景图片，挂载此img文件\nmount -o loop -t squashfs install.img /mnt/install\n\nmkdir tmp\n\n#挂载的install.img不能编辑，需要拷贝一份，修改后替换原install.img文件\nrsync -av /mnt/install/ tmp/\n\n#进入背景图片所在目录,选择需要修改的图片，并替换（主机图片尺寸，格式需要与原来的相同）,图片位置为：tmp/install/usr/share/anaconda/pixmaps\n\n#重新创建新的install.img\nmksquashfs tmp/ install_v1.img -all-root\n\n#替换install.img\ncp tmp/install_v1.img install.img\n```\n\n##### 6.2 修改安装过程中的欢迎语\n\n```shell\nmkdir /os/isolinux/tmp\n\n#解压initrd.img镜像\nxz -dc ../initrd.img | cpio -id\n\n#修改欢迎语.buildstamp文件，把其中的CentOS替换为PowerSoft\nvim .buildstamp\n\n#创建新的initrd.img并替换\nfind . | cpio -c -o | xz -9 --format=lzma > ../initrd.img\n```\n\n#### 7、启动界面及登录界面CentOS字样修改：\n\n```shell\nyum install -y rpm-build\n\nrmp -ivh *.src.rpm\n\nrpmbuild -ba *.spec\n\ntar -xzvf *.tar.gz\n\ntar -zcvf *.tar.gz *\n\ninfonix-release-6-5.3.infonix.11.src.rpm\n\ncentos-release-6-5.el6.centos.11.1.x86_64.rpm\n```\n\n#### 8、重构系统，生成ISO镜像\n\n```shell\nmkisofs -o /tmp/GCloud-4.1_64.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T .\n\nls .|grep -v \"comps.xml\"|xargs -i rm -f {} cd ../ createrepo -g repodata/comps.xml ./ declare -x discinfo=`head -1 .discinfo` mkisofs -R -J -T -r -l -d -joliet-long -allow-multidot -allow-leading-dots -no-bak -o/opt/Mycentos7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-\n```\n\n\n\n\n\n\n\n","tags":["centos","centos6"]}]